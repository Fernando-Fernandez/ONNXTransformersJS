var transformers = (() => {
  var __defProp = Object.defineProperty;
  var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
  var __getOwnPropNames = Object.getOwnPropertyNames;
  var __hasOwnProp = Object.prototype.hasOwnProperty;
  var __require = /* @__PURE__ */ ((x2) => typeof require !== "undefined" ? require : typeof Proxy !== "undefined" ? new Proxy(x2, {
    get: (a2, b2) => (typeof require !== "undefined" ? require : a2)[b2]
  }) : x2)(function(x2) {
    if (typeof require !== "undefined") return require.apply(this, arguments);
    throw Error('Dynamic require of "' + x2 + '" is not supported');
  });
  var __export = (target, all) => {
    for (var name in all)
      __defProp(target, name, { get: all[name], enumerable: true });
  };
  var __copyProps = (to2, from, except, desc) => {
    if (from && typeof from === "object" || typeof from === "function") {
      for (let key of __getOwnPropNames(from))
        if (!__hasOwnProp.call(to2, key) && key !== except)
          __defProp(to2, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
    }
    return to2;
  };
  var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

  // public/transformers.min.js
  var transformers_min_exports = {};
  __export(transformers_min_exports, {
    ASTFeatureExtractor: () => o,
    ASTForAudioClassification: () => i,
    ASTModel: () => l,
    ASTPreTrainedModel: () => d,
    AlbertForMaskedLM: () => u,
    AlbertForQuestionAnswering: () => c,
    AlbertForSequenceClassification: () => p,
    AlbertModel: () => m,
    AlbertPreTrainedModel: () => h,
    AlbertTokenizer: () => f,
    ArceeForCausalLM: () => _,
    ArceeModel: () => g,
    ArceePreTrainedModel: () => w,
    AudioClassificationPipeline: () => b,
    AutoConfig: () => y,
    AutoFeatureExtractor: () => M,
    AutoImageProcessor: () => x,
    AutoModel: () => v,
    AutoModelForAudioClassification: () => T,
    AutoModelForAudioFrameClassification: () => k,
    AutoModelForAudioTextToText: () => P,
    AutoModelForCTC: () => $,
    AutoModelForCausalLM: () => C,
    AutoModelForDepthEstimation: () => S,
    AutoModelForDocumentQuestionAnswering: () => F,
    AutoModelForImageClassification: () => E,
    AutoModelForImageFeatureExtraction: () => I,
    AutoModelForImageMatting: () => A,
    AutoModelForImageSegmentation: () => z,
    AutoModelForImageTextToText: () => L,
    AutoModelForImageToImage: () => O,
    AutoModelForMaskGeneration: () => D,
    AutoModelForMaskedLM: () => B,
    AutoModelForNormalEstimation: () => N,
    AutoModelForObjectDetection: () => j,
    AutoModelForPoseEstimation: () => R,
    AutoModelForQuestionAnswering: () => V,
    AutoModelForSemanticSegmentation: () => G,
    AutoModelForSeq2SeqLM: () => q,
    AutoModelForSequenceClassification: () => U,
    AutoModelForSpeechSeq2Seq: () => W,
    AutoModelForTextToSpectrogram: () => H,
    AutoModelForTextToWaveform: () => Q,
    AutoModelForTokenClassification: () => K,
    AutoModelForUniversalSegmentation: () => X,
    AutoModelForVision2Seq: () => J,
    AutoModelForXVector: () => Y,
    AutoModelForZeroShotObjectDetection: () => Z,
    AutoProcessor: () => ee,
    AutoTokenizer: () => te,
    AutomaticSpeechRecognitionPipeline: () => ne,
    BackgroundRemovalPipeline: () => re,
    BartForConditionalGeneration: () => se,
    BartForSequenceClassification: () => ae,
    BartModel: () => oe,
    BartPretrainedModel: () => ie,
    BartTokenizer: () => le,
    BaseModelOutput: () => de,
    BaseStreamer: () => ue,
    BeitFeatureExtractor: () => ce,
    BeitForImageClassification: () => pe,
    BeitModel: () => me,
    BeitPreTrainedModel: () => he,
    BertForMaskedLM: () => fe,
    BertForQuestionAnswering: () => _e,
    BertForSequenceClassification: () => ge,
    BertForTokenClassification: () => we,
    BertModel: () => be,
    BertPreTrainedModel: () => ye,
    BertTokenizer: () => Me,
    BitImageProcessor: () => xe,
    BlenderbotForConditionalGeneration: () => ve,
    BlenderbotModel: () => Te,
    BlenderbotPreTrainedModel: () => ke,
    BlenderbotSmallForConditionalGeneration: () => Pe,
    BlenderbotSmallModel: () => $e,
    BlenderbotSmallPreTrainedModel: () => Ce,
    BlenderbotSmallTokenizer: () => Se,
    BlenderbotTokenizer: () => Fe,
    BloomForCausalLM: () => Ee,
    BloomModel: () => Ie,
    BloomPreTrainedModel: () => Ae,
    BloomTokenizer: () => ze,
    CLIPFeatureExtractor: () => Le,
    CLIPImageProcessor: () => Oe,
    CLIPModel: () => De,
    CLIPPreTrainedModel: () => Be,
    CLIPSegForImageSegmentation: () => Ne,
    CLIPSegModel: () => je,
    CLIPSegPreTrainedModel: () => Re,
    CLIPTextModel: () => Ve,
    CLIPTextModelWithProjection: () => Ge,
    CLIPTokenizer: () => qe,
    CLIPVisionModel: () => Ue,
    CLIPVisionModelWithProjection: () => We,
    CamembertForMaskedLM: () => He,
    CamembertForQuestionAnswering: () => Qe,
    CamembertForSequenceClassification: () => Ke,
    CamembertForTokenClassification: () => Xe,
    CamembertModel: () => Je,
    CamembertPreTrainedModel: () => Ye,
    CamembertTokenizer: () => Ze,
    CausalLMOutput: () => et,
    CausalLMOutputWithPast: () => tt,
    ChineseCLIPFeatureExtractor: () => nt,
    ChineseCLIPModel: () => rt,
    ChineseCLIPPreTrainedModel: () => st,
    ClapAudioModelWithProjection: () => at,
    ClapFeatureExtractor: () => ot,
    ClapModel: () => it,
    ClapPreTrainedModel: () => lt,
    ClapTextModelWithProjection: () => dt,
    ClassifierFreeGuidanceLogitsProcessor: () => ut,
    CodeGenForCausalLM: () => ct,
    CodeGenModel: () => pt,
    CodeGenPreTrainedModel: () => mt,
    CodeGenTokenizer: () => ht,
    CodeLlamaTokenizer: () => ft,
    CohereForCausalLM: () => _t,
    CohereModel: () => gt,
    CoherePreTrainedModel: () => wt,
    CohereTokenizer: () => bt,
    ConvBertForMaskedLM: () => yt,
    ConvBertForQuestionAnswering: () => Mt,
    ConvBertForSequenceClassification: () => xt,
    ConvBertForTokenClassification: () => vt,
    ConvBertModel: () => Tt,
    ConvBertPreTrainedModel: () => kt,
    ConvBertTokenizer: () => Pt,
    ConvNextFeatureExtractor: () => $t,
    ConvNextForImageClassification: () => Ct,
    ConvNextImageProcessor: () => St,
    ConvNextModel: () => Ft,
    ConvNextPreTrainedModel: () => Et,
    ConvNextV2ForImageClassification: () => It,
    ConvNextV2Model: () => At,
    ConvNextV2PreTrainedModel: () => zt,
    DFineForObjectDetection: () => Lt,
    DFineModel: () => Ot,
    DFinePreTrainedModel: () => Dt,
    DINOv3ConvNextModel: () => Bt,
    DINOv3ConvNextPreTrainedModel: () => Nt,
    DINOv3ViTImageProcessor: () => jt,
    DINOv3ViTModel: () => Rt,
    DINOv3ViTPreTrainedModel: () => Vt,
    DPTFeatureExtractor: () => Gt,
    DPTForDepthEstimation: () => qt,
    DPTImageProcessor: () => Ut,
    DPTModel: () => Wt,
    DPTPreTrainedModel: () => Ht,
    DacDecoderModel: () => Qt,
    DacDecoderOutput: () => Kt,
    DacEncoderModel: () => Xt,
    DacEncoderOutput: () => Jt,
    DacFeatureExtractor: () => Yt,
    DacModel: () => Zt,
    DacPreTrainedModel: () => en,
    DataTypeMap: () => tn,
    DebertaForMaskedLM: () => nn,
    DebertaForQuestionAnswering: () => rn,
    DebertaForSequenceClassification: () => sn,
    DebertaForTokenClassification: () => an,
    DebertaModel: () => on,
    DebertaPreTrainedModel: () => ln,
    DebertaTokenizer: () => dn,
    DebertaV2ForMaskedLM: () => un,
    DebertaV2ForQuestionAnswering: () => cn,
    DebertaV2ForSequenceClassification: () => pn,
    DebertaV2ForTokenClassification: () => mn,
    DebertaV2Model: () => hn,
    DebertaV2PreTrainedModel: () => fn,
    DebertaV2Tokenizer: () => _n,
    DecisionTransformerModel: () => gn,
    DecisionTransformerPreTrainedModel: () => wn,
    DeiTFeatureExtractor: () => bn,
    DeiTForImageClassification: () => yn,
    DeiTImageProcessor: () => Mn,
    DeiTModel: () => xn,
    DeiTPreTrainedModel: () => vn,
    DepthAnythingForDepthEstimation: () => Tn,
    DepthAnythingPreTrainedModel: () => kn,
    DepthEstimationPipeline: () => Pn,
    DepthProForDepthEstimation: () => $n,
    DepthProPreTrainedModel: () => Cn,
    DetrFeatureExtractor: () => Sn,
    DetrForObjectDetection: () => Fn,
    DetrForSegmentation: () => En,
    DetrImageProcessor: () => In,
    DetrModel: () => An,
    DetrObjectDetectionOutput: () => zn,
    DetrPreTrainedModel: () => Ln,
    DetrSegmentationOutput: () => On,
    Dinov2ForImageClassification: () => Dn,
    Dinov2Model: () => Bn,
    Dinov2PreTrainedModel: () => Nn,
    Dinov2WithRegistersForImageClassification: () => jn,
    Dinov2WithRegistersModel: () => Rn,
    Dinov2WithRegistersPreTrainedModel: () => Vn,
    DistilBertForMaskedLM: () => Gn,
    DistilBertForQuestionAnswering: () => qn,
    DistilBertForSequenceClassification: () => Un,
    DistilBertForTokenClassification: () => Wn,
    DistilBertModel: () => Hn,
    DistilBertPreTrainedModel: () => Qn,
    DistilBertTokenizer: () => Kn,
    DocumentQuestionAnsweringPipeline: () => Xn,
    DonutFeatureExtractor: () => Jn,
    DonutImageProcessor: () => Yn,
    DonutSwinModel: () => Zn,
    DonutSwinPreTrainedModel: () => er,
    EdgeTamModel: () => tr,
    EfficientNetForImageClassification: () => nr,
    EfficientNetImageProcessor: () => rr,
    EfficientNetModel: () => sr,
    EfficientNetPreTrainedModel: () => ar,
    ElectraForMaskedLM: () => or,
    ElectraForQuestionAnswering: () => ir,
    ElectraForSequenceClassification: () => lr,
    ElectraForTokenClassification: () => dr,
    ElectraModel: () => ur,
    ElectraPreTrainedModel: () => cr,
    ElectraTokenizer: () => pr,
    EncodecFeatureExtractor: () => mr,
    EosTokenCriteria: () => hr,
    Ernie4_5_ForCausalLM: () => fr,
    Ernie4_5_Model: () => _r,
    Ernie4_5_PretrainedModel: () => gr,
    Ernie4_5_Tokenizer: () => wr,
    EsmForMaskedLM: () => br,
    EsmForSequenceClassification: () => yr,
    EsmForTokenClassification: () => Mr,
    EsmModel: () => xr,
    EsmPreTrainedModel: () => vr,
    EsmTokenizer: () => Tr,
    ExaoneForCausalLM: () => kr,
    ExaoneModel: () => Pr,
    ExaonePreTrainedModel: () => $r,
    FFT: () => Cr,
    FalconForCausalLM: () => Sr,
    FalconModel: () => Fr,
    FalconPreTrainedModel: () => Er,
    FalconTokenizer: () => Ir,
    FastViTForImageClassification: () => Ar,
    FastViTModel: () => zr,
    FastViTPreTrainedModel: () => Lr,
    FeatureExtractionPipeline: () => Or,
    FeatureExtractor: () => Dr,
    FillMaskPipeline: () => Br,
    Florence2ForConditionalGeneration: () => Nr,
    Florence2PreTrainedModel: () => jr,
    Florence2Processor: () => Rr,
    ForcedBOSTokenLogitsProcessor: () => Vr,
    ForcedEOSTokenLogitsProcessor: () => Gr,
    GLPNFeatureExtractor: () => qr,
    GLPNForDepthEstimation: () => Ur,
    GLPNModel: () => Wr,
    GLPNPreTrainedModel: () => Hr,
    GPT2LMHeadModel: () => Qr,
    GPT2Model: () => Kr,
    GPT2PreTrainedModel: () => Xr,
    GPT2Tokenizer: () => Jr,
    GPTBigCodeForCausalLM: () => Yr,
    GPTBigCodeModel: () => Zr,
    GPTBigCodePreTrainedModel: () => es,
    GPTJForCausalLM: () => ts,
    GPTJModel: () => ns,
    GPTJPreTrainedModel: () => rs,
    GPTNeoForCausalLM: () => ss,
    GPTNeoModel: () => as,
    GPTNeoPreTrainedModel: () => os,
    GPTNeoXForCausalLM: () => is,
    GPTNeoXModel: () => ls,
    GPTNeoXPreTrainedModel: () => ds,
    GPTNeoXTokenizer: () => us,
    Gemma2ForCausalLM: () => cs,
    Gemma2Model: () => ps,
    Gemma2PreTrainedModel: () => ms,
    Gemma3ForCausalLM: () => hs,
    Gemma3Model: () => fs,
    Gemma3PreTrainedModel: () => _s,
    Gemma3nAudioFeatureExtractor: () => gs,
    Gemma3nForConditionalGeneration: () => ws,
    Gemma3nPreTrainedModel: () => bs,
    Gemma3nProcessor: () => ys,
    GemmaForCausalLM: () => Ms,
    GemmaModel: () => xs,
    GemmaPreTrainedModel: () => vs,
    GemmaTokenizer: () => Ts,
    GlmForCausalLM: () => ks,
    GlmModel: () => Ps,
    GlmPreTrainedModel: () => $s,
    GraniteForCausalLM: () => Cs,
    GraniteModel: () => Ss,
    GraniteMoeHybridForCausalLM: () => Fs,
    GraniteMoeHybridModel: () => Es,
    GraniteMoeHybridPreTrainedModel: () => Is,
    GranitePreTrainedModel: () => As,
    Grok1Tokenizer: () => zs,
    GroundingDinoForObjectDetection: () => Ls,
    GroundingDinoImageProcessor: () => Os,
    GroundingDinoPreTrainedModel: () => Ds,
    GroundingDinoProcessor: () => Bs,
    GroupViTModel: () => Ns,
    GroupViTPreTrainedModel: () => js,
    HeliumForCausalLM: () => Rs,
    HeliumModel: () => Vs,
    HeliumPreTrainedModel: () => Gs,
    HerbertTokenizer: () => qs,
    HieraForImageClassification: () => Us,
    HieraModel: () => Ws,
    HieraPreTrainedModel: () => Hs,
    HubertForCTC: () => Qs,
    HubertForSequenceClassification: () => Ks,
    HubertModel: () => Xs,
    HubertPreTrainedModel: () => Js,
    IJepaForImageClassification: () => Ys,
    IJepaModel: () => Zs,
    IJepaPreTrainedModel: () => ea,
    Idefics3ForConditionalGeneration: () => ta,
    Idefics3ImageProcessor: () => na,
    Idefics3PreTrainedModel: () => ra,
    Idefics3Processor: () => sa,
    ImageClassificationPipeline: () => aa,
    ImageFeatureExtractionPipeline: () => oa,
    ImageFeatureExtractor: () => ia,
    ImageMattingOutput: () => la,
    ImageProcessor: () => da,
    ImageSegmentationPipeline: () => ua,
    ImageToImagePipeline: () => ca,
    ImageToTextPipeline: () => pa,
    InterruptableStoppingCriteria: () => ma,
    JAISLMHeadModel: () => ha,
    JAISModel: () => fa,
    JAISPreTrainedModel: () => _a,
    JinaCLIPImageProcessor: () => ga,
    JinaCLIPModel: () => wa,
    JinaCLIPPreTrainedModel: () => ba,
    JinaCLIPProcessor: () => ya,
    JinaCLIPTextModel: () => Ma,
    JinaCLIPVisionModel: () => xa,
    Lfm2ForCausalLM: () => va,
    Lfm2Model: () => Ta,
    Lfm2PreTrainedModel: () => ka,
    LiteWhisperForConditionalGeneration: () => Pa,
    Llama4ForCausalLM: () => $a,
    Llama4PreTrainedModel: () => Ca,
    LlamaForCausalLM: () => Sa,
    LlamaModel: () => Fa,
    LlamaPreTrainedModel: () => Ea,
    LlamaTokenizer: () => Ia,
    LlavaForConditionalGeneration: () => Aa,
    LlavaOnevisionForConditionalGeneration: () => za,
    LlavaOnevisionImageProcessor: () => La,
    LlavaPreTrainedModel: () => Oa,
    LlavaProcessor: () => Da,
    LlavaQwen2ForCausalLM: () => Ba,
    LogitsProcessor: () => Na,
    LogitsProcessorList: () => ja,
    LogitsWarper: () => Ra,
    LongT5ForConditionalGeneration: () => Va,
    LongT5Model: () => Ga,
    LongT5PreTrainedModel: () => qa,
    M2M100ForConditionalGeneration: () => Ua,
    M2M100Model: () => Wa,
    M2M100PreTrainedModel: () => Ha,
    M2M100Tokenizer: () => Qa,
    MBart50Tokenizer: () => Ka,
    MBartForCausalLM: () => Xa,
    MBartForConditionalGeneration: () => Ja,
    MBartForSequenceClassification: () => Ya,
    MBartModel: () => Za,
    MBartPreTrainedModel: () => eo,
    MBartTokenizer: () => to,
    MPNetForMaskedLM: () => no,
    MPNetForQuestionAnswering: () => ro,
    MPNetForSequenceClassification: () => so,
    MPNetForTokenClassification: () => ao,
    MPNetModel: () => oo,
    MPNetPreTrainedModel: () => io,
    MPNetTokenizer: () => lo,
    MT5ForConditionalGeneration: () => uo,
    MT5Model: () => co,
    MT5PreTrainedModel: () => po,
    MarianMTModel: () => mo,
    MarianModel: () => ho,
    MarianPreTrainedModel: () => fo,
    MarianTokenizer: () => _o,
    Mask2FormerImageProcessor: () => go,
    MaskFormerFeatureExtractor: () => wo,
    MaskFormerForInstanceSegmentation: () => bo,
    MaskFormerImageProcessor: () => yo,
    MaskFormerModel: () => Mo,
    MaskFormerPreTrainedModel: () => xo,
    MaskedLMOutput: () => vo,
    MaxLengthCriteria: () => To,
    Metric3DForDepthEstimation: () => ko,
    Metric3DPreTrainedModel: () => Po,
    Metric3Dv2ForDepthEstimation: () => $o,
    Metric3Dv2PreTrainedModel: () => Co,
    MgpstrForSceneTextRecognition: () => So,
    MgpstrModelOutput: () => Fo,
    MgpstrPreTrainedModel: () => Eo,
    MgpstrProcessor: () => Io,
    MgpstrTokenizer: () => Ao,
    MimiDecoderModel: () => zo,
    MimiDecoderOutput: () => Lo,
    MimiEncoderModel: () => Oo,
    MimiEncoderOutput: () => Do,
    MimiModel: () => Bo,
    MimiPreTrainedModel: () => No,
    MinLengthLogitsProcessor: () => jo,
    MinNewTokensLengthLogitsProcessor: () => Ro,
    MistralForCausalLM: () => Vo,
    MistralModel: () => Go,
    MistralPreTrainedModel: () => qo,
    MobileBertForMaskedLM: () => Uo,
    MobileBertForQuestionAnswering: () => Wo,
    MobileBertForSequenceClassification: () => Ho,
    MobileBertModel: () => Qo,
    MobileBertPreTrainedModel: () => Ko,
    MobileBertTokenizer: () => Xo,
    MobileLLMForCausalLM: () => Jo,
    MobileLLMModel: () => Yo,
    MobileLLMPreTrainedModel: () => Zo,
    MobileNetV1FeatureExtractor: () => ei,
    MobileNetV1ForImageClassification: () => ti,
    MobileNetV1ForSemanticSegmentation: () => ni,
    MobileNetV1ImageProcessor: () => ri,
    MobileNetV1Model: () => si,
    MobileNetV1PreTrainedModel: () => ai,
    MobileNetV2FeatureExtractor: () => oi,
    MobileNetV2ForImageClassification: () => ii,
    MobileNetV2ForSemanticSegmentation: () => li,
    MobileNetV2ImageProcessor: () => di,
    MobileNetV2Model: () => ui,
    MobileNetV2PreTrainedModel: () => ci,
    MobileNetV3FeatureExtractor: () => pi,
    MobileNetV3ForImageClassification: () => mi,
    MobileNetV3ForSemanticSegmentation: () => hi,
    MobileNetV3ImageProcessor: () => fi,
    MobileNetV3Model: () => _i,
    MobileNetV3PreTrainedModel: () => gi,
    MobileNetV4FeatureExtractor: () => wi,
    MobileNetV4ForImageClassification: () => bi,
    MobileNetV4ForSemanticSegmentation: () => yi,
    MobileNetV4ImageProcessor: () => Mi,
    MobileNetV4Model: () => xi,
    MobileNetV4PreTrainedModel: () => vi,
    MobileViTFeatureExtractor: () => Ti,
    MobileViTForImageClassification: () => ki,
    MobileViTImageProcessor: () => Pi,
    MobileViTModel: () => $i,
    MobileViTPreTrainedModel: () => Ci,
    MobileViTV2ForImageClassification: () => Si,
    MobileViTV2Model: () => Fi,
    MobileViTV2PreTrainedModel: () => Ei,
    ModelOutput: () => Ii,
    ModernBertDecoderForCausalLM: () => Ai,
    ModernBertDecoderModel: () => zi,
    ModernBertDecoderPreTrainedModel: () => Li,
    ModernBertForMaskedLM: () => Oi,
    ModernBertForSequenceClassification: () => Di,
    ModernBertForTokenClassification: () => Bi,
    ModernBertModel: () => Ni,
    ModernBertPreTrainedModel: () => ji,
    Moondream1ForConditionalGeneration: () => Ri,
    MoonshineFeatureExtractor: () => Vi,
    MoonshineForConditionalGeneration: () => Gi,
    MoonshineModel: () => qi,
    MoonshinePreTrainedModel: () => Ui,
    MoonshineProcessor: () => Wi,
    MptForCausalLM: () => Hi,
    MptModel: () => Qi,
    MptPreTrainedModel: () => Ki,
    MultiModalityCausalLM: () => Xi,
    MultiModalityPreTrainedModel: () => Ji,
    MusicgenForCausalLM: () => Yi,
    MusicgenForConditionalGeneration: () => Zi,
    MusicgenModel: () => el,
    MusicgenPreTrainedModel: () => tl,
    NanoChatForCausalLM: () => nl,
    NanoChatModel: () => rl,
    NanoChatPreTrainedModel: () => sl,
    NeoBertForMaskedLM: () => al,
    NeoBertForQuestionAnswering: () => ol,
    NeoBertForSequenceClassification: () => il,
    NeoBertForTokenClassification: () => ll,
    NeoBertModel: () => dl,
    NeoBertPreTrainedModel: () => ul,
    NllbTokenizer: () => cl,
    NoBadWordsLogitsProcessor: () => pl,
    NoRepeatNGramLogitsProcessor: () => ml,
    NomicBertModel: () => hl,
    NomicBertPreTrainedModel: () => fl,
    NougatImageProcessor: () => _l,
    NougatTokenizer: () => gl,
    OPTForCausalLM: () => wl,
    OPTModel: () => bl,
    OPTPreTrainedModel: () => yl,
    ObjectDetectionPipeline: () => Ml,
    Olmo2ForCausalLM: () => xl,
    Olmo2Model: () => vl,
    Olmo2PreTrainedModel: () => Tl,
    OlmoForCausalLM: () => kl,
    OlmoModel: () => Pl,
    OlmoPreTrainedModel: () => $l,
    OpenELMForCausalLM: () => Cl,
    OpenELMModel: () => Sl,
    OpenELMPreTrainedModel: () => Fl,
    OwlViTFeatureExtractor: () => El,
    OwlViTForObjectDetection: () => Il,
    OwlViTImageProcessor: () => Al,
    OwlViTModel: () => zl,
    OwlViTPreTrainedModel: () => Ll,
    OwlViTProcessor: () => Ol,
    Owlv2ForObjectDetection: () => Dl,
    Owlv2ImageProcessor: () => Bl,
    Owlv2Model: () => Nl,
    Owlv2PreTrainedModel: () => jl,
    PaliGemmaForConditionalGeneration: () => Rl,
    PaliGemmaPreTrainedModel: () => Vl,
    PaliGemmaProcessor: () => Gl,
    ParakeetFeatureExtractor: () => ql,
    ParakeetForCTC: () => Ul,
    ParakeetPreTrainedModel: () => Wl,
    PatchTSMixerForPrediction: () => Hl,
    PatchTSMixerModel: () => Ql,
    PatchTSMixerPreTrainedModel: () => Kl,
    PatchTSTForPrediction: () => Xl,
    PatchTSTModel: () => Jl,
    PatchTSTPreTrainedModel: () => Yl,
    Phi3ForCausalLM: () => Zl,
    Phi3Model: () => ed,
    Phi3PreTrainedModel: () => td,
    Phi3VForCausalLM: () => nd,
    Phi3VImageProcessor: () => rd,
    Phi3VPreTrainedModel: () => sd,
    Phi3VProcessor: () => ad,
    PhiForCausalLM: () => od,
    PhiModel: () => id,
    PhiPreTrainedModel: () => ld,
    Pipeline: () => dd,
    PreTrainedModel: () => ud,
    PreTrainedTokenizer: () => cd,
    PretrainedConfig: () => pd,
    PretrainedMixin: () => md,
    Processor: () => hd,
    PvtForImageClassification: () => fd,
    PvtImageProcessor: () => _d,
    PvtModel: () => gd,
    PvtPreTrainedModel: () => wd,
    PyAnnoteFeatureExtractor: () => bd,
    PyAnnoteForAudioFrameClassification: () => yd,
    PyAnnoteModel: () => Md,
    PyAnnotePreTrainedModel: () => xd,
    PyAnnoteProcessor: () => vd,
    QuestionAnsweringModelOutput: () => Td,
    QuestionAnsweringPipeline: () => kd,
    Qwen2ForCausalLM: () => Pd,
    Qwen2Model: () => $d,
    Qwen2PreTrainedModel: () => Cd,
    Qwen2Tokenizer: () => Sd,
    Qwen2VLForConditionalGeneration: () => Fd,
    Qwen2VLImageProcessor: () => Ed,
    Qwen2VLPreTrainedModel: () => Id,
    Qwen2VLProcessor: () => Ad,
    Qwen3ForCausalLM: () => zd,
    Qwen3Model: () => Ld,
    Qwen3PreTrainedModel: () => Od,
    RFDetrForObjectDetection: () => Dd,
    RFDetrModel: () => Bd,
    RFDetrObjectDetectionOutput: () => Nd,
    RFDetrPreTrainedModel: () => jd,
    RTDetrForObjectDetection: () => Rd,
    RTDetrImageProcessor: () => Vd,
    RTDetrModel: () => Gd,
    RTDetrObjectDetectionOutput: () => qd,
    RTDetrPreTrainedModel: () => Ud,
    RTDetrV2ForObjectDetection: () => Wd,
    RTDetrV2Model: () => Hd,
    RTDetrV2ObjectDetectionOutput: () => Qd,
    RTDetrV2PreTrainedModel: () => Kd,
    RawAudio: () => Xd,
    RawImage: () => Jd,
    RawVideo: () => Yd,
    RawVideoFrame: () => Zd,
    RepetitionPenaltyLogitsProcessor: () => eu,
    ResNetForImageClassification: () => tu,
    ResNetModel: () => nu,
    ResNetPreTrainedModel: () => ru,
    RoFormerForMaskedLM: () => su,
    RoFormerForQuestionAnswering: () => au,
    RoFormerForSequenceClassification: () => ou,
    RoFormerForTokenClassification: () => iu,
    RoFormerModel: () => lu,
    RoFormerPreTrainedModel: () => du,
    RoFormerTokenizer: () => uu,
    RobertaForMaskedLM: () => cu,
    RobertaForQuestionAnswering: () => pu,
    RobertaForSequenceClassification: () => mu,
    RobertaForTokenClassification: () => hu,
    RobertaModel: () => fu,
    RobertaPreTrainedModel: () => _u,
    RobertaTokenizer: () => gu,
    Sam2ImageProcessor: () => wu,
    Sam2ImageSegmentationOutput: () => bu,
    Sam2Model: () => yu,
    Sam2PreTrainedModel: () => Mu,
    Sam2Processor: () => xu,
    Sam2VideoProcessor: () => vu,
    Sam3ImageProcessor: () => Tu,
    Sam3TrackerModel: () => ku,
    SamImageProcessor: () => Pu,
    SamImageSegmentationOutput: () => $u,
    SamModel: () => Cu,
    SamPreTrainedModel: () => Su,
    SamProcessor: () => Fu,
    SapiensForDepthEstimation: () => Eu,
    SapiensForNormalEstimation: () => Iu,
    SapiensForSemanticSegmentation: () => Au,
    SapiensPreTrainedModel: () => zu,
    SeamlessM4TFeatureExtractor: () => Lu,
    SegformerFeatureExtractor: () => Ou,
    SegformerForImageClassification: () => Du,
    SegformerForSemanticSegmentation: () => Bu,
    SegformerImageProcessor: () => Nu,
    SegformerModel: () => ju,
    SegformerPreTrainedModel: () => Ru,
    Seq2SeqLMOutput: () => Vu,
    SequenceClassifierOutput: () => Gu,
    SiglipImageProcessor: () => qu,
    SiglipModel: () => Uu,
    SiglipPreTrainedModel: () => Wu,
    SiglipTextModel: () => Hu,
    SiglipTokenizer: () => Qu,
    SiglipVisionModel: () => Ku,
    SmolLM3ForCausalLM: () => Xu,
    SmolLM3Model: () => Ju,
    SmolLM3PreTrainedModel: () => Yu,
    SmolVLMForConditionalGeneration: () => Zu,
    SmolVLMImageProcessor: () => ec,
    SmolVLMProcessor: () => tc,
    SnacDecoderModel: () => nc,
    SnacEncoderModel: () => rc,
    SnacFeatureExtractor: () => sc,
    SnacModel: () => ac,
    SnacPreTrainedModel: () => oc,
    SpeechT5FeatureExtractor: () => ic,
    SpeechT5ForSpeechToText: () => lc,
    SpeechT5ForTextToSpeech: () => dc,
    SpeechT5HifiGan: () => uc,
    SpeechT5Model: () => cc,
    SpeechT5PreTrainedModel: () => pc,
    SpeechT5Processor: () => mc,
    SpeechT5Tokenizer: () => hc,
    SqueezeBertForMaskedLM: () => fc,
    SqueezeBertForQuestionAnswering: () => _c,
    SqueezeBertForSequenceClassification: () => gc,
    SqueezeBertModel: () => wc,
    SqueezeBertPreTrainedModel: () => bc,
    SqueezeBertTokenizer: () => yc,
    StableLmForCausalLM: () => Mc,
    StableLmModel: () => xc,
    StableLmPreTrainedModel: () => vc,
    Starcoder2ForCausalLM: () => Tc,
    Starcoder2Model: () => kc,
    Starcoder2PreTrainedModel: () => Pc,
    StoppingCriteria: () => $c,
    StoppingCriteriaList: () => Cc,
    StyleTextToSpeech2Model: () => Sc,
    StyleTextToSpeech2PreTrainedModel: () => Fc,
    SummarizationPipeline: () => Ec,
    SupertonicForConditionalGeneration: () => Ic,
    SupertonicPreTrainedModel: () => Ac,
    SuppressTokensAtBeginLogitsProcessor: () => zc,
    Swin2SRForImageSuperResolution: () => Lc,
    Swin2SRImageProcessor: () => Oc,
    Swin2SRModel: () => Dc,
    Swin2SRPreTrainedModel: () => Bc,
    SwinForImageClassification: () => Nc,
    SwinForSemanticSegmentation: () => jc,
    SwinModel: () => Rc,
    SwinPreTrainedModel: () => Vc,
    T5ForConditionalGeneration: () => Gc,
    T5Model: () => qc,
    T5PreTrainedModel: () => Uc,
    T5Tokenizer: () => Wc,
    TableTransformerForObjectDetection: () => Hc,
    TableTransformerModel: () => Qc,
    TableTransformerObjectDetectionOutput: () => Kc,
    TableTransformerPreTrainedModel: () => Xc,
    TemperatureLogitsWarper: () => Jc,
    Tensor: () => Yc,
    Text2TextGenerationPipeline: () => Zc,
    TextClassificationPipeline: () => ep,
    TextGenerationPipeline: () => tp,
    TextStreamer: () => np,
    TextToAudioPipeline: () => rp,
    TokenClassificationPipeline: () => sp,
    TokenClassifierOutput: () => ap,
    TokenizerModel: () => op,
    TopKLogitsWarper: () => ip,
    TopPLogitsWarper: () => lp,
    TrOCRForCausalLM: () => dp,
    TrOCRPreTrainedModel: () => up,
    TranslationPipeline: () => cp,
    UltravoxModel: () => pp,
    UltravoxPreTrainedModel: () => mp,
    UltravoxProcessor: () => hp,
    UniSpeechForCTC: () => fp,
    UniSpeechForSequenceClassification: () => _p,
    UniSpeechModel: () => gp,
    UniSpeechPreTrainedModel: () => wp,
    UniSpeechSatForAudioFrameClassification: () => bp,
    UniSpeechSatForCTC: () => yp,
    UniSpeechSatForSequenceClassification: () => Mp,
    UniSpeechSatModel: () => xp,
    UniSpeechSatPreTrainedModel: () => vp,
    VLChatProcessor: () => Tp,
    VLMImageProcessor: () => kp,
    VaultGemmaForCausalLM: () => Pp,
    VaultGemmaModel: () => $p,
    VaultGemmaPreTrainedModel: () => Cp,
    ViTFeatureExtractor: () => Sp,
    ViTForImageClassification: () => Fp,
    ViTImageProcessor: () => Ep,
    ViTMAEModel: () => Ip,
    ViTMAEPreTrainedModel: () => Ap,
    ViTMSNForImageClassification: () => zp,
    ViTMSNModel: () => Lp,
    ViTMSNPreTrainedModel: () => Op,
    ViTModel: () => Dp,
    ViTPreTrainedModel: () => Bp,
    VisionEncoderDecoderModel: () => Np,
    VitMatteForImageMatting: () => jp,
    VitMatteImageProcessor: () => Rp,
    VitMattePreTrainedModel: () => Vp,
    VitPoseForPoseEstimation: () => Gp,
    VitPoseImageProcessor: () => qp,
    VitPosePreTrainedModel: () => Up,
    VitsModel: () => Wp,
    VitsModelOutput: () => Hp,
    VitsPreTrainedModel: () => Qp,
    VitsTokenizer: () => Kp,
    VoxtralForConditionalGeneration: () => Xp,
    VoxtralProcessor: () => Jp,
    Wav2Vec2BertForCTC: () => Yp,
    Wav2Vec2BertForSequenceClassification: () => Zp,
    Wav2Vec2BertModel: () => em,
    Wav2Vec2BertPreTrainedModel: () => tm,
    Wav2Vec2CTCTokenizer: () => nm,
    Wav2Vec2FeatureExtractor: () => rm,
    Wav2Vec2ForAudioFrameClassification: () => sm,
    Wav2Vec2ForCTC: () => am,
    Wav2Vec2ForSequenceClassification: () => om,
    Wav2Vec2Model: () => im,
    Wav2Vec2PreTrainedModel: () => lm,
    Wav2Vec2Processor: () => dm,
    Wav2Vec2ProcessorWithLM: () => um,
    WavLMForAudioFrameClassification: () => cm,
    WavLMForCTC: () => pm,
    WavLMForSequenceClassification: () => mm,
    WavLMForXVector: () => hm,
    WavLMModel: () => fm,
    WavLMPreTrainedModel: () => _m,
    WeSpeakerFeatureExtractor: () => gm,
    WeSpeakerResNetModel: () => wm,
    WeSpeakerResNetPreTrainedModel: () => bm,
    WhisperFeatureExtractor: () => ym,
    WhisperForConditionalGeneration: () => Mm,
    WhisperModel: () => xm,
    WhisperPreTrainedModel: () => vm,
    WhisperProcessor: () => Tm,
    WhisperTextStreamer: () => km,
    WhisperTimeStampLogitsProcessor: () => Pm,
    WhisperTokenizer: () => $m,
    XLMForQuestionAnswering: () => Cm,
    XLMForSequenceClassification: () => Sm,
    XLMForTokenClassification: () => Fm,
    XLMModel: () => Em,
    XLMPreTrainedModel: () => Im,
    XLMRobertaForMaskedLM: () => Am,
    XLMRobertaForQuestionAnswering: () => zm,
    XLMRobertaForSequenceClassification: () => Lm,
    XLMRobertaForTokenClassification: () => Om,
    XLMRobertaModel: () => Dm,
    XLMRobertaPreTrainedModel: () => Bm,
    XLMRobertaTokenizer: () => Nm,
    XLMTokenizer: () => jm,
    XLMWithLMHeadModel: () => Rm,
    XVectorOutput: () => Vm,
    YolosFeatureExtractor: () => Gm,
    YolosForObjectDetection: () => qm,
    YolosImageProcessor: () => Um,
    YolosModel: () => Wm,
    YolosObjectDetectionOutput: () => Hm,
    YolosPreTrainedModel: () => Qm,
    ZeroShotAudioClassificationPipeline: () => Km,
    ZeroShotClassificationPipeline: () => Xm,
    ZeroShotImageClassificationPipeline: () => Jm,
    ZeroShotObjectDetectionPipeline: () => Ym,
    bankers_round: () => Zm,
    cat: () => eh,
    cos_sim: () => th,
    dot: () => nh,
    dynamic_time_warping: () => rh,
    env: () => sh,
    full: () => ah,
    full_like: () => oh,
    getCacheShapes: () => ih,
    hamming: () => lh,
    hanning: () => dh,
    interpolate: () => uh,
    interpolate_4d: () => ch,
    interpolate_data: () => ph,
    is_chinese_char: () => mh,
    layer_norm: () => hh,
    load_image: () => fh,
    load_video: () => _h,
    log_softmax: () => gh,
    magnitude: () => wh,
    matmul: () => bh,
    max: () => yh,
    mean: () => Mh,
    mean_pooling: () => xh,
    medianFilter: () => vh,
    mel_filter_bank: () => Th,
    min: () => kh,
    ones: () => Ph,
    ones_like: () => $h,
    permute: () => Ch,
    permute_data: () => Sh,
    pipeline: () => Fh,
    quantize_embeddings: () => Eh,
    rand: () => Ih,
    randn: () => Ah,
    read_audio: () => zh,
    rfft: () => Lh,
    round: () => Oh,
    slice: () => Dh,
    softmax: () => Bh,
    spectrogram: () => Nh,
    stack: () => jh,
    std_mean: () => Rh,
    topk: () => Vh,
    window_function: () => Gh,
    zeros: () => qh,
    zeros_like: () => Uh
  });
  var import_meta = {};
  var e;
  var t;
  var n = { "./node_modules/onnxruntime-web/dist/ort-wasm-simd-threaded.jsep.wasm": (e2, t2, n2) => {
    e2.exports = n2.p + "ort-wasm-simd-threaded.jsep.wasm";
  }, "./node_modules/onnxruntime-web/dist/ort.bundle.min.mjs?46eb": (e2, t2, n2) => {
    e2.exports = n2.p + "ort.bundle.min.mjs";
  }, "?2ce3": () => {
  }, "?7992": () => {
  }, "?5af5": () => {
  }, "?2b25": () => {
  }, "?db59": () => {
  }, "?383f": () => {
  }, "?fa4b": () => {
  }, "./node_modules/@huggingface/jinja/dist/index.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Environment: () => ae2, Interpreter: () => oe2, Template: () => fe2, parse: () => R2, tokenize: () => d2 });
    var r2 = Object.freeze({ Text: "Text", NumericLiteral: "NumericLiteral", StringLiteral: "StringLiteral", Identifier: "Identifier", Equals: "Equals", OpenParen: "OpenParen", CloseParen: "CloseParen", OpenStatement: "OpenStatement", CloseStatement: "CloseStatement", OpenExpression: "OpenExpression", CloseExpression: "CloseExpression", OpenSquareBracket: "OpenSquareBracket", CloseSquareBracket: "CloseSquareBracket", OpenCurlyBracket: "OpenCurlyBracket", CloseCurlyBracket: "CloseCurlyBracket", Comma: "Comma", Dot: "Dot", Colon: "Colon", Pipe: "Pipe", CallOperator: "CallOperator", AdditiveBinaryOperator: "AdditiveBinaryOperator", MultiplicativeBinaryOperator: "MultiplicativeBinaryOperator", ComparisonBinaryOperator: "ComparisonBinaryOperator", UnaryOperator: "UnaryOperator", Comment: "Comment" }), s2 = class {
      constructor(e3, t3) {
        this.value = e3, this.type = t3;
      }
    };
    function a2(e3) {
      return /\w/.test(e3);
    }
    function o2(e3) {
      return /[0-9]/.test(e3);
    }
    var i2 = [["{%", r2.OpenStatement], ["%}", r2.CloseStatement], ["{{", r2.OpenExpression], ["}}", r2.CloseExpression], ["(", r2.OpenParen], [")", r2.CloseParen], ["{", r2.OpenCurlyBracket], ["}", r2.CloseCurlyBracket], ["[", r2.OpenSquareBracket], ["]", r2.CloseSquareBracket], [",", r2.Comma], [".", r2.Dot], [":", r2.Colon], ["|", r2.Pipe], ["<=", r2.ComparisonBinaryOperator], [">=", r2.ComparisonBinaryOperator], ["==", r2.ComparisonBinaryOperator], ["!=", r2.ComparisonBinaryOperator], ["<", r2.ComparisonBinaryOperator], [">", r2.ComparisonBinaryOperator], ["+", r2.AdditiveBinaryOperator], ["-", r2.AdditiveBinaryOperator], ["~", r2.AdditiveBinaryOperator], ["*", r2.MultiplicativeBinaryOperator], ["/", r2.MultiplicativeBinaryOperator], ["%", r2.MultiplicativeBinaryOperator], ["=", r2.Equals]], l2 = /* @__PURE__ */ new Map([["n", "\n"], ["t", "	"], ["r", "\r"], ["b", "\b"], ["f", "\f"], ["v", "\v"], ["'", "'"], ['"', '"'], ["\\", "\\"]]);
    function d2(e3, t3 = {}) {
      const n3 = [], d3 = (function(e4, t4 = {}) {
        return e4.endsWith("\n") && (e4 = e4.slice(0, -1)), t4.lstrip_blocks && (e4 = e4.replace(/^[ \t]*({[#%-])/gm, "$1")), t4.trim_blocks && (e4 = e4.replace(/([#%-]})\n/g, "$1")), e4.replace(/-%}\s*/g, "%}").replace(/\s*{%-/g, "{%").replace(/-}}\s*/g, "}}").replace(/\s*{{-/g, "{{").replace(/-#}\s*/g, "#}").replace(/\s*{#-/g, "{#").replace(/{%\s*(end)?generation\s*%}/gs, "");
      })(e3, t3);
      let u3 = 0, c3 = 0;
      const p3 = (e4) => {
        let t4 = "";
        for (; e4(d3[u3]); ) if ("\\" !== d3[u3]) {
          if (t4 += d3[u3++], u3 >= d3.length) throw new SyntaxError("Unexpected end of input");
        } else {
          if (++u3, u3 >= d3.length) throw new SyntaxError("Unexpected end of input");
          const e5 = d3[u3++], n4 = l2.get(e5);
          if (void 0 === n4) throw new SyntaxError(`Unexpected escaped character: ${e5}`);
          t4 += n4;
        }
        return t4;
      };
      e: for (; u3 < d3.length; ) {
        const e4 = n3.at(-1)?.type;
        if (void 0 === e4 || e4 === r2.CloseStatement || e4 === r2.CloseExpression || e4 === r2.Comment) {
          let e5 = "";
          for (; u3 < d3.length && ("{" !== d3[u3] || "%" !== d3[u3 + 1] && "{" !== d3[u3 + 1] && "#" !== d3[u3 + 1]); ) e5 += d3[u3++];
          if (e5.length > 0) {
            n3.push(new s2(e5, r2.Text));
            continue;
          }
        }
        if ("{" === d3[u3] && "#" === d3[u3 + 1]) {
          u3 += 2;
          let e5 = "";
          for (; "#" !== d3[u3] || "}" !== d3[u3 + 1]; ) {
            if (u3 + 2 >= d3.length) throw new SyntaxError("Missing end of comment tag");
            e5 += d3[u3++];
          }
          n3.push(new s2(e5, r2.Comment)), u3 += 2;
          continue;
        }
        p3(((e5) => /\s/.test(e5)));
        const t4 = d3[u3];
        if ("-" === t4 || "+" === t4) {
          const e5 = n3.at(-1)?.type;
          if (e5 === r2.Text || void 0 === e5) throw new SyntaxError(`Unexpected character: ${t4}`);
          switch (e5) {
            case r2.Identifier:
            case r2.NumericLiteral:
            case r2.StringLiteral:
            case r2.CloseParen:
            case r2.CloseSquareBracket:
              break;
            default: {
              ++u3;
              const e6 = p3(o2);
              n3.push(new s2(`${t4}${e6}`, e6.length > 0 ? r2.NumericLiteral : r2.UnaryOperator));
              continue;
            }
          }
        }
        for (const [e5, t5] of i2) {
          if ("}}" === e5 && c3 > 0) continue;
          if (d3.slice(u3, u3 + e5.length) === e5) {
            n3.push(new s2(e5, t5)), t5 === r2.OpenExpression ? c3 = 0 : t5 === r2.OpenCurlyBracket ? ++c3 : t5 === r2.CloseCurlyBracket && --c3, u3 += e5.length;
            continue e;
          }
        }
        if ("'" !== t4 && '"' !== t4) if (o2(t4)) {
          let e5 = p3(o2);
          if ("." === d3[u3] && o2(d3[u3 + 1])) {
            ++u3;
            e5 = `${e5}.${p3(o2)}`;
          }
          n3.push(new s2(e5, r2.NumericLiteral));
        } else {
          if (!a2(t4)) throw new SyntaxError(`Unexpected character: ${t4}`);
          {
            const e5 = p3(a2);
            n3.push(new s2(e5, r2.Identifier));
          }
        }
        else {
          ++u3;
          const e5 = p3(((e6) => e6 !== t4));
          n3.push(new s2(e5, r2.StringLiteral)), ++u3;
        }
      }
      return n3;
    }
    var u2 = class {
      type = "Statement";
    }, c2 = class extends u2 {
      constructor(e3) {
        super(), this.body = e3;
      }
      type = "Program";
    }, p2 = class extends u2 {
      constructor(e3, t3, n3) {
        super(), this.test = e3, this.body = t3, this.alternate = n3;
      }
      type = "If";
    }, m2 = class extends u2 {
      constructor(e3, t3, n3, r3) {
        super(), this.loopvar = e3, this.iterable = t3, this.body = n3, this.defaultBlock = r3;
      }
      type = "For";
    }, h2 = class extends u2 {
      type = "Break";
    }, f2 = class extends u2 {
      type = "Continue";
    }, _2 = class extends u2 {
      constructor(e3, t3, n3) {
        super(), this.assignee = e3, this.value = t3, this.body = n3;
      }
      type = "Set";
    }, g2 = class extends u2 {
      constructor(e3, t3, n3) {
        super(), this.name = e3, this.args = t3, this.body = n3;
      }
      type = "Macro";
    }, w2 = class extends u2 {
      constructor(e3) {
        super(), this.value = e3;
      }
      type = "Comment";
    }, b2 = class extends u2 {
      type = "Expression";
    }, y2 = class extends b2 {
      constructor(e3, t3, n3) {
        super(), this.object = e3, this.property = t3, this.computed = n3;
      }
      type = "MemberExpression";
    }, M2 = class extends b2 {
      constructor(e3, t3) {
        super(), this.callee = e3, this.args = t3;
      }
      type = "CallExpression";
    }, x2 = class extends b2 {
      constructor(e3) {
        super(), this.value = e3;
      }
      type = "Identifier";
    }, v2 = class extends b2 {
      constructor(e3) {
        super(), this.value = e3;
      }
      type = "Literal";
    }, T2 = class extends v2 {
      type = "IntegerLiteral";
    }, k2 = class extends v2 {
      type = "FloatLiteral";
    }, P2 = class extends v2 {
      type = "StringLiteral";
    }, $2 = class extends v2 {
      type = "ArrayLiteral";
    }, C2 = class extends v2 {
      type = "TupleLiteral";
    }, S2 = class extends v2 {
      type = "ObjectLiteral";
    }, F2 = class extends b2 {
      constructor(e3, t3, n3) {
        super(), this.operator = e3, this.left = t3, this.right = n3;
      }
      type = "BinaryExpression";
    }, E2 = class extends b2 {
      constructor(e3, t3) {
        super(), this.operand = e3, this.filter = t3;
      }
      type = "FilterExpression";
    }, I2 = class extends u2 {
      constructor(e3, t3) {
        super(), this.filter = e3, this.body = t3;
      }
      type = "FilterStatement";
    }, A2 = class extends b2 {
      constructor(e3, t3) {
        super(), this.lhs = e3, this.test = t3;
      }
      type = "SelectExpression";
    }, z2 = class extends b2 {
      constructor(e3, t3, n3) {
        super(), this.operand = e3, this.negate = t3, this.test = n3;
      }
      type = "TestExpression";
    }, L2 = class extends b2 {
      constructor(e3, t3) {
        super(), this.operator = e3, this.argument = t3;
      }
      type = "UnaryExpression";
    }, O2 = class extends b2 {
      constructor(e3 = void 0, t3 = void 0, n3 = void 0) {
        super(), this.start = e3, this.stop = t3, this.step = n3;
      }
      type = "SliceExpression";
    }, D2 = class extends b2 {
      constructor(e3, t3) {
        super(), this.key = e3, this.value = t3;
      }
      type = "KeywordArgumentExpression";
    }, B2 = class extends b2 {
      constructor(e3) {
        super(), this.argument = e3;
      }
      type = "SpreadExpression";
    }, N2 = class extends u2 {
      constructor(e3, t3, n3) {
        super(), this.call = e3, this.callerArgs = t3, this.body = n3;
      }
      type = "CallStatement";
    }, j2 = class extends b2 {
      constructor(e3, t3, n3) {
        super(), this.condition = e3, this.trueExpr = t3, this.falseExpr = n3;
      }
      type = "Ternary";
    };
    function R2(e3) {
      const t3 = new c2([]);
      let n3 = 0;
      function a3(t4, r3) {
        const s3 = e3[n3++];
        if (!s3 || s3.type !== t4) throw new Error(`Parser Error: ${r3}. ${s3.type} !== ${t4}.`);
        return s3;
      }
      function o3(e4) {
        if (!u3(e4)) throw new SyntaxError(`Expected ${e4}`);
        ++n3;
      }
      function i3() {
        switch (e3[n3].type) {
          case r2.Comment:
            return new w2(e3[n3++].value);
          case r2.Text:
            return new P2(a3(r2.Text, "Expected text token").value);
          case r2.OpenStatement:
            return (function() {
              if (a3(r2.OpenStatement, "Expected opening statement token"), e3[n3].type !== r2.Identifier) throw new SyntaxError(`Unknown statement, got ${e3[n3].type}`);
              const t4 = e3[n3].value;
              let s3;
              switch (t4) {
                case "set":
                  ++n3, s3 = (function() {
                    const e4 = v3();
                    let t5 = null;
                    const s4 = [];
                    if (l3(r2.Equals)) ++n3, t5 = v3();
                    else {
                      for (a3(r2.CloseStatement, "Expected %} token"); !d3("endset"); ) s4.push(i3());
                      a3(r2.OpenStatement, "Expected {% token"), o3("endset");
                    }
                    return a3(r2.CloseStatement, "Expected closing statement token"), new _2(e4, t5, s4);
                  })();
                  break;
                case "if":
                  ++n3, s3 = b3(), a3(r2.OpenStatement, "Expected {% token"), o3("endif"), a3(r2.CloseStatement, "Expected %} token");
                  break;
                case "macro":
                  ++n3, s3 = (function() {
                    const e4 = Z3();
                    if ("Identifier" !== e4.type) throw new SyntaxError("Expected identifier following macro statement");
                    const t5 = Q3();
                    a3(r2.CloseStatement, "Expected closing statement token");
                    const n4 = [];
                    for (; !d3("endmacro"); ) n4.push(i3());
                    return new g2(e4, t5, n4);
                  })(), a3(r2.OpenStatement, "Expected {% token"), o3("endmacro"), a3(r2.CloseStatement, "Expected %} token");
                  break;
                case "for":
                  ++n3, s3 = (function() {
                    const e4 = v3(true);
                    if (!(e4 instanceof x2 || e4 instanceof C2)) throw new SyntaxError(`Expected identifier/tuple for the loop variable, got ${e4.type} instead`);
                    if (!u3("in")) throw new SyntaxError("Expected `in` keyword following loop variable");
                    ++n3;
                    const t5 = R3();
                    a3(r2.CloseStatement, "Expected closing statement token");
                    const s4 = [];
                    for (; !d3("endfor", "else"); ) s4.push(i3());
                    const o4 = [];
                    if (d3("else")) for (++n3, ++n3, a3(r2.CloseStatement, "Expected closing statement token"); !d3("endfor"); ) o4.push(i3());
                    return new m2(e4, t5, s4, o4);
                  })(), a3(r2.OpenStatement, "Expected {% token"), o3("endfor"), a3(r2.CloseStatement, "Expected %} token");
                  break;
                case "call": {
                  ++n3;
                  let e4 = null;
                  l3(r2.OpenParen) && (e4 = Q3());
                  const t5 = Z3();
                  if ("Identifier" !== t5.type) throw new SyntaxError("Expected identifier following call statement");
                  const u4 = Q3();
                  a3(r2.CloseStatement, "Expected closing statement token");
                  const c3 = [];
                  for (; !d3("endcall"); ) c3.push(i3());
                  a3(r2.OpenStatement, "Expected '{%'"), o3("endcall"), a3(r2.CloseStatement, "Expected closing statement token");
                  const p3 = new M2(t5, u4);
                  s3 = new N2(p3, e4, c3);
                  break;
                }
                case "break":
                  ++n3, a3(r2.CloseStatement, "Expected closing statement token"), s3 = new h2();
                  break;
                case "continue":
                  ++n3, a3(r2.CloseStatement, "Expected closing statement token"), s3 = new f2();
                  break;
                case "filter": {
                  ++n3;
                  let e4 = Z3();
                  e4 instanceof x2 && l3(r2.OpenParen) && (e4 = H3(e4)), a3(r2.CloseStatement, "Expected closing statement token");
                  const t5 = [];
                  for (; !d3("endfilter"); ) t5.push(i3());
                  a3(r2.OpenStatement, "Expected '{%'"), o3("endfilter"), a3(r2.CloseStatement, "Expected '%}'"), s3 = new I2(e4, t5);
                  break;
                }
                default:
                  throw new SyntaxError(`Unknown statement type: ${t4}`);
              }
              return s3;
            })();
          case r2.OpenExpression:
            return (function() {
              a3(r2.OpenExpression, "Expected opening expression token");
              const e4 = R3();
              return a3(r2.CloseExpression, "Expected closing expression token"), e4;
            })();
          default:
            throw new SyntaxError(`Unexpected token type: ${e3[n3].type}`);
        }
      }
      function l3(...t4) {
        return n3 + t4.length <= e3.length && t4.every(((t5, r3) => t5 === e3[n3 + r3].type));
      }
      function d3(...t4) {
        return e3[n3]?.type === r2.OpenStatement && e3[n3 + 1]?.type === r2.Identifier && t4.includes(e3[n3 + 1]?.value);
      }
      function u3(...t4) {
        return n3 + t4.length <= e3.length && t4.every(((t5, r3) => "Identifier" === e3[n3 + r3].type && t5 === e3[n3 + r3].value));
      }
      function b3() {
        const e4 = R3();
        a3(r2.CloseStatement, "Expected closing statement token");
        const t4 = [], s3 = [];
        for (; !d3("elif", "else", "endif"); ) t4.push(i3());
        if (d3("elif")) {
          ++n3, ++n3;
          const e5 = b3();
          s3.push(e5);
        } else if (d3("else")) for (++n3, ++n3, a3(r2.CloseStatement, "Expected closing statement token"); !d3("endif"); ) s3.push(i3());
        return new p2(e4, t4, s3);
      }
      function v3(e4 = false) {
        const t4 = e4 ? Z3 : R3, s3 = [t4()], a4 = l3(r2.Comma);
        for (; a4 && (++n3, s3.push(t4()), l3(r2.Comma)); ) ;
        return a4 ? new C2(s3) : s3[0];
      }
      function R3() {
        return V3();
      }
      function V3() {
        const e4 = G3();
        if (u3("if")) {
          ++n3;
          const t4 = G3();
          if (u3("else")) {
            ++n3;
            const r3 = V3();
            return new j2(t4, e4, r3);
          }
          return new A2(e4, t4);
        }
        return e4;
      }
      function G3() {
        let t4 = q3();
        for (; u3("or"); ) {
          const r3 = e3[n3];
          ++n3;
          const s3 = q3();
          t4 = new F2(r3, t4, s3);
        }
        return t4;
      }
      function q3() {
        let t4 = U3();
        for (; u3("and"); ) {
          const r3 = e3[n3];
          ++n3;
          const s3 = U3();
          t4 = new F2(r3, t4, s3);
        }
        return t4;
      }
      function U3() {
        let t4;
        for (; u3("not"); ) {
          const r3 = e3[n3];
          ++n3;
          const s3 = U3();
          t4 = new L2(r3, s3);
        }
        return t4 ?? (function() {
          let t5 = W3();
          for (; ; ) {
            let a4;
            if (u3("not", "in")) a4 = new s2("not in", r2.Identifier), n3 += 2;
            else if (u3("in")) a4 = e3[n3++];
            else {
              if (!l3(r2.ComparisonBinaryOperator)) break;
              a4 = e3[n3++];
            }
            const o4 = W3();
            t5 = new F2(a4, t5, o4);
          }
          return t5;
        })();
      }
      function W3() {
        let t4 = J3();
        for (; l3(r2.AdditiveBinaryOperator); ) {
          const r3 = e3[n3];
          ++n3;
          const s3 = J3();
          t4 = new F2(r3, t4, s3);
        }
        return t4;
      }
      function H3(e4) {
        let t4 = new M2(e4, Q3());
        return t4 = X3(t4), l3(r2.OpenParen) && (t4 = H3(t4)), t4;
      }
      function Q3() {
        a3(r2.OpenParen, "Expected opening parenthesis for arguments list");
        const t4 = (function() {
          const t5 = [];
          for (; !l3(r2.CloseParen); ) {
            let s3;
            if (e3[n3].type === r2.MultiplicativeBinaryOperator && "*" === e3[n3].value) {
              ++n3;
              const e4 = R3();
              s3 = new B2(e4);
            } else if (s3 = R3(), l3(r2.Equals)) {
              if (++n3, !(s3 instanceof x2)) throw new SyntaxError("Expected identifier for keyword argument");
              const e4 = R3();
              s3 = new D2(s3, e4);
            }
            t5.push(s3), l3(r2.Comma) && ++n3;
          }
          return t5;
        })();
        return a3(r2.CloseParen, "Expected closing parenthesis for arguments list"), t4;
      }
      function K3() {
        const e4 = [];
        let t4 = false;
        for (; !l3(r2.CloseSquareBracket); ) l3(r2.Colon) ? (e4.push(void 0), ++n3, t4 = true) : (e4.push(R3()), l3(r2.Colon) && (++n3, t4 = true));
        if (0 === e4.length) throw new SyntaxError("Expected at least one argument for member/slice expression");
        if (t4) {
          if (e4.length > 3) throw new SyntaxError("Expected 0-3 arguments for slice expression");
          return new O2(...e4);
        }
        return e4[0];
      }
      function X3(t4) {
        for (; l3(r2.Dot) || l3(r2.OpenSquareBracket); ) {
          const s3 = e3[n3];
          let o4;
          ++n3;
          const i4 = s3.type === r2.OpenSquareBracket;
          if (i4) o4 = K3(), a3(r2.CloseSquareBracket, "Expected closing square bracket");
          else if (o4 = Z3(), "Identifier" !== o4.type) throw new SyntaxError("Expected identifier following dot operator");
          t4 = new y2(t4, o4, i4);
        }
        return t4;
      }
      function J3() {
        let t4 = Y3();
        for (; l3(r2.MultiplicativeBinaryOperator); ) {
          const r3 = e3[n3++], s3 = Y3();
          t4 = new F2(r3, t4, s3);
        }
        return t4;
      }
      function Y3() {
        let e4 = (function() {
          let e5 = (function() {
            const e6 = X3(Z3());
            return l3(r2.OpenParen) ? H3(e6) : e6;
          })();
          for (; l3(r2.Pipe); ) {
            ++n3;
            let t4 = Z3();
            if (!(t4 instanceof x2)) throw new SyntaxError("Expected identifier for the filter");
            l3(r2.OpenParen) && (t4 = H3(t4)), e5 = new E2(e5, t4);
          }
          return e5;
        })();
        for (; u3("is"); ) {
          ++n3;
          const t4 = u3("not");
          t4 && ++n3;
          const r3 = Z3();
          if (!(r3 instanceof x2)) throw new SyntaxError("Expected identifier for the test");
          e4 = new z2(e4, t4, r3);
        }
        return e4;
      }
      function Z3() {
        const t4 = e3[n3++];
        switch (t4.type) {
          case r2.NumericLiteral: {
            const e4 = t4.value;
            return e4.includes(".") ? new k2(Number(e4)) : new T2(Number(e4));
          }
          case r2.StringLiteral: {
            let s3 = t4.value;
            for (; l3(r2.StringLiteral); ) s3 += e3[n3++].value;
            return new P2(s3);
          }
          case r2.Identifier:
            return new x2(t4.value);
          case r2.OpenParen: {
            const e4 = v3();
            return a3(r2.CloseParen, "Expected closing parenthesis, got ${tokens[current].type} instead."), e4;
          }
          case r2.OpenSquareBracket: {
            const e4 = [];
            for (; !l3(r2.CloseSquareBracket); ) e4.push(R3()), l3(r2.Comma) && ++n3;
            return ++n3, new $2(e4);
          }
          case r2.OpenCurlyBracket: {
            const e4 = /* @__PURE__ */ new Map();
            for (; !l3(r2.CloseCurlyBracket); ) {
              const t5 = R3();
              a3(r2.Colon, "Expected colon between key and value in object literal");
              const s3 = R3();
              e4.set(t5, s3), l3(r2.Comma) && ++n3;
            }
            return ++n3, new S2(e4);
          }
          default:
            throw new SyntaxError(`Unexpected token: ${t4.type}`);
        }
      }
      for (; n3 < e3.length; ) t3.body.push(i3());
      return t3;
    }
    function V2(e3, t3, n3 = 1) {
      void 0 === t3 && (t3 = e3, e3 = 0);
      const r3 = [];
      for (let s3 = e3; s3 < t3; s3 += n3) r3.push(s3);
      return r3;
    }
    function G2(e3, t3, n3, r3 = 1) {
      const s3 = Math.sign(r3);
      s3 >= 0 ? (t3 = (t3 ??= 0) < 0 ? Math.max(e3.length + t3, 0) : Math.min(t3, e3.length), n3 = (n3 ??= e3.length) < 0 ? Math.max(e3.length + n3, 0) : Math.min(n3, e3.length)) : (t3 = (t3 ??= e3.length - 1) < 0 ? Math.max(e3.length + t3, -1) : Math.min(t3, e3.length - 1), n3 = (n3 ??= -1) < -1 ? Math.max(e3.length + n3, -1) : Math.min(n3, e3.length - 1));
      const a3 = [];
      for (let o3 = t3; s3 * o3 < s3 * n3; o3 += r3) a3.push(e3[o3]);
      return a3;
    }
    function q2(e3) {
      return (function(e4, t3) {
        const n3 = new Intl.DateTimeFormat(void 0, { month: "long" }), r3 = new Intl.DateTimeFormat(void 0, { month: "short" }), s3 = (e5) => e5 < 10 ? "0" + e5 : e5.toString();
        return t3.replace(/%[YmdbBHM%]/g, ((t4) => {
          switch (t4) {
            case "%Y":
              return e4.getFullYear().toString();
            case "%m":
              return s3(e4.getMonth() + 1);
            case "%d":
              return s3(e4.getDate());
            case "%b":
              return r3.format(e4);
            case "%B":
              return n3.format(e4);
            case "%H":
              return s3(e4.getHours());
            case "%M":
              return s3(e4.getMinutes());
            case "%%":
              return "%";
            default:
              return t4;
          }
        }));
      })(/* @__PURE__ */ new Date(), e3);
    }
    var U2 = class extends Error {
    }, W2 = class extends Error {
    }, H2 = class {
      type = "RuntimeValue";
      value;
      builtins = /* @__PURE__ */ new Map();
      constructor(e3 = void 0) {
        this.value = e3;
      }
      __bool__() {
        return new J2(!!this.value);
      }
      toString() {
        return String(this.value);
      }
    }, Q2 = class extends H2 {
      type = "IntegerValue";
    }, K2 = class extends H2 {
      type = "FloatValue";
      toString() {
        return this.value % 1 == 0 ? this.value.toFixed(1) : this.value.toString();
      }
    }, X2 = class extends H2 {
      type = "StringValue";
      builtins = /* @__PURE__ */ new Map([["upper", new ne2((() => new X2(this.value.toUpperCase())))], ["lower", new ne2((() => new X2(this.value.toLowerCase())))], ["strip", new ne2((() => new X2(this.value.trim())))], ["title", new ne2((() => new X2(this.value.replace(/\b\w/g, ((e3) => e3.toUpperCase())))))], ["capitalize", new ne2((() => new X2(this.value.charAt(0).toUpperCase() + this.value.slice(1))))], ["length", new Q2(this.value.length)], ["rstrip", new ne2((() => new X2(this.value.trimEnd())))], ["lstrip", new ne2((() => new X2(this.value.trimStart())))], ["startswith", new ne2(((e3) => {
        if (0 === e3.length) throw new Error("startswith() requires at least one argument");
        const t3 = e3[0];
        if (t3 instanceof X2) return new J2(this.value.startsWith(t3.value));
        if (t3 instanceof ee2) {
          for (const e4 of t3.value) {
            if (!(e4 instanceof X2)) throw new Error("startswith() tuple elements must be strings");
            if (this.value.startsWith(e4.value)) return new J2(true);
          }
          return new J2(false);
        }
        throw new Error("startswith() argument must be a string or tuple of strings");
      }))], ["endswith", new ne2(((e3) => {
        if (0 === e3.length) throw new Error("endswith() requires at least one argument");
        const t3 = e3[0];
        if (t3 instanceof X2) return new J2(this.value.endsWith(t3.value));
        if (t3 instanceof ee2) {
          for (const e4 of t3.value) {
            if (!(e4 instanceof X2)) throw new Error("endswith() tuple elements must be strings");
            if (this.value.endsWith(e4.value)) return new J2(true);
          }
          return new J2(false);
        }
        throw new Error("endswith() argument must be a string or tuple of strings");
      }))], ["split", new ne2(((e3) => {
        const t3 = e3[0] ?? new re2();
        if (!(t3 instanceof X2 || t3 instanceof re2)) throw new Error("sep argument must be a string or null");
        const n3 = e3[1] ?? new Q2(-1);
        if (!(n3 instanceof Q2)) throw new Error("maxsplit argument must be a number");
        let r3 = [];
        if (t3 instanceof re2) {
          const e4 = this.value.trimStart();
          for (const { 0: t4, index: s3 } of e4.matchAll(/\S+/g)) {
            if (-1 !== n3.value && r3.length >= n3.value && void 0 !== s3) {
              r3.push(t4 + e4.slice(s3 + t4.length));
              break;
            }
            r3.push(t4);
          }
        } else {
          if ("" === t3.value) throw new Error("empty separator");
          r3 = this.value.split(t3.value), -1 !== n3.value && r3.length > n3.value && r3.push(r3.splice(n3.value).join(t3.value));
        }
        return new ee2(r3.map(((e4) => new X2(e4))));
      }))], ["replace", new ne2(((e3) => {
        if (e3.length < 2) throw new Error("replace() requires at least two arguments");
        const t3 = e3[0], n3 = e3[1];
        if (!(t3 instanceof X2 && n3 instanceof X2)) throw new Error("replace() arguments must be strings");
        let r3;
        if (r3 = e3.length > 2 ? "KeywordArgumentsValue" === e3[2].type ? e3[2].value.get("count") ?? new re2() : e3[2] : new re2(), !(r3 instanceof Q2 || r3 instanceof re2)) throw new Error("replace() count argument must be a number or null");
        return new X2((function(e4, t4, n4, r4) {
          if (0 === r4) return e4;
          let s3 = null == r4 || r4 < 0 ? 1 / 0 : r4;
          const a3 = 0 === t4.length ? new RegExp("(?=)", "gu") : new RegExp(t4.replace(/[.*+?^${}()|[\]\\]/g, "\\$&"), "gu");
          return e4.replaceAll(a3, ((e5) => s3 > 0 ? (--s3, n4) : e5));
        })(this.value, t3.value, n3.value, r3.value));
      }))]]);
    }, J2 = class extends H2 {
      type = "BooleanValue";
    }, Y2 = class extends H2 {
      type = "ObjectValue";
      __bool__() {
        return new J2(this.value.size > 0);
      }
      builtins = /* @__PURE__ */ new Map([["get", new ne2((([e3, t3]) => {
        if (!(e3 instanceof X2)) throw new Error(`Object key must be a string: got ${e3.type}`);
        return this.value.get(e3.value) ?? t3 ?? new re2();
      }))], ["items", new ne2((() => this.items()))], ["keys", new ne2((() => this.keys()))], ["values", new ne2((() => this.values()))]]);
      items() {
        return new ee2(Array.from(this.value.entries()).map((([e3, t3]) => new ee2([new X2(e3), t3]))));
      }
      keys() {
        return new ee2(Array.from(this.value.keys()).map(((e3) => new X2(e3))));
      }
      values() {
        return new ee2(Array.from(this.value.values()));
      }
    }, Z2 = class extends Y2 {
      type = "KeywordArgumentsValue";
    }, ee2 = class extends H2 {
      type = "ArrayValue";
      builtins = /* @__PURE__ */ new Map([["length", new Q2(this.value.length)]]);
      __bool__() {
        return new J2(this.value.length > 0);
      }
    }, te2 = class extends ee2 {
      type = "TupleValue";
    }, ne2 = class extends H2 {
      type = "FunctionValue";
    }, re2 = class extends H2 {
      type = "NullValue";
    }, se2 = class extends H2 {
      type = "UndefinedValue";
    }, ae2 = class {
      constructor(e3) {
        this.parent = e3;
      }
      variables = /* @__PURE__ */ new Map([["namespace", new ne2(((e3) => {
        if (0 === e3.length) return new Y2(/* @__PURE__ */ new Map());
        if (1 !== e3.length || !(e3[0] instanceof Y2)) throw new Error("`namespace` expects either zero arguments or a single object argument");
        return e3[0];
      }))]]);
      tests = /* @__PURE__ */ new Map([["boolean", (e3) => "BooleanValue" === e3.type], ["callable", (e3) => e3 instanceof ne2], ["odd", (e3) => {
        if (!(e3 instanceof Q2)) throw new Error(`cannot odd on ${e3.type}`);
        return e3.value % 2 != 0;
      }], ["even", (e3) => {
        if (!(e3 instanceof Q2)) throw new Error(`cannot even on ${e3.type}`);
        return e3.value % 2 == 0;
      }], ["false", (e3) => "BooleanValue" === e3.type && !e3.value], ["true", (e3) => "BooleanValue" === e3.type && e3.value], ["none", (e3) => "NullValue" === e3.type], ["string", (e3) => "StringValue" === e3.type], ["number", (e3) => e3 instanceof Q2 || e3 instanceof K2], ["integer", (e3) => e3 instanceof Q2], ["iterable", (e3) => "ArrayValue" === e3.type || "StringValue" === e3.type], ["mapping", (e3) => "ObjectValue" === e3.type], ["lower", (e3) => {
        const t3 = e3.value;
        return "StringValue" === e3.type && t3 === t3.toLowerCase();
      }], ["upper", (e3) => {
        const t3 = e3.value;
        return "StringValue" === e3.type && t3 === t3.toUpperCase();
      }], ["none", (e3) => "NullValue" === e3.type], ["defined", (e3) => "UndefinedValue" !== e3.type], ["undefined", (e3) => "UndefinedValue" === e3.type], ["equalto", (e3, t3) => e3.value === t3.value], ["eq", (e3, t3) => e3.value === t3.value]]);
      set(e3, t3) {
        return this.declareVariable(e3, ie2(t3));
      }
      declareVariable(e3, t3) {
        if (this.variables.has(e3)) throw new SyntaxError(`Variable already declared: ${e3}`);
        return this.variables.set(e3, t3), t3;
      }
      setVariable(e3, t3) {
        return this.variables.set(e3, t3), t3;
      }
      resolve(e3) {
        if (this.variables.has(e3)) return this;
        if (this.parent) return this.parent.resolve(e3);
        throw new Error(`Unknown variable: ${e3}`);
      }
      lookupVariable(e3) {
        try {
          return this.resolve(e3).variables.get(e3) ?? new se2();
        } catch {
          return new se2();
        }
      }
    };
    var oe2 = class {
      global;
      constructor(e3) {
        this.global = e3 ?? new ae2();
      }
      run(e3) {
        return this.evaluate(e3, this.global);
      }
      evaluateBinaryExpression(e3, t3) {
        const n3 = this.evaluate(e3.left, t3);
        switch (e3.operator.value) {
          case "and":
            return n3.__bool__().value ? this.evaluate(e3.right, t3) : n3;
          case "or":
            return n3.__bool__().value ? n3 : this.evaluate(e3.right, t3);
        }
        const r3 = this.evaluate(e3.right, t3);
        switch (e3.operator.value) {
          case "==":
            return new J2(n3.value == r3.value);
          case "!=":
            return new J2(n3.value != r3.value);
        }
        if (n3 instanceof se2 || r3 instanceof se2) {
          if (r3 instanceof se2 && ["in", "not in"].includes(e3.operator.value)) return new J2("not in" === e3.operator.value);
          throw new Error(`Cannot perform operation ${e3.operator.value} on undefined values`);
        }
        if (n3 instanceof re2 || r3 instanceof re2) throw new Error("Cannot perform operation on null values");
        if ("~" === e3.operator.value) return new X2(n3.value.toString() + r3.value.toString());
        if ((n3 instanceof Q2 || n3 instanceof K2) && (r3 instanceof Q2 || r3 instanceof K2)) {
          const t4 = n3.value, s3 = r3.value;
          switch (e3.operator.value) {
            case "+":
            case "-":
            case "*": {
              const a3 = "+" === e3.operator.value ? t4 + s3 : "-" === e3.operator.value ? t4 - s3 : t4 * s3;
              return n3 instanceof K2 || r3 instanceof K2 ? new K2(a3) : new Q2(a3);
            }
            case "/":
              return new K2(t4 / s3);
            case "%": {
              const e4 = t4 % s3;
              return n3 instanceof K2 || r3 instanceof K2 ? new K2(e4) : new Q2(e4);
            }
            case "<":
              return new J2(t4 < s3);
            case ">":
              return new J2(t4 > s3);
            case ">=":
              return new J2(t4 >= s3);
            case "<=":
              return new J2(t4 <= s3);
          }
        } else if (n3 instanceof ee2 && r3 instanceof ee2) {
          if ("+" === e3.operator.value) return new ee2(n3.value.concat(r3.value));
        } else if (r3 instanceof ee2) {
          const t4 = void 0 !== r3.value.find(((e4) => e4.value === n3.value));
          switch (e3.operator.value) {
            case "in":
              return new J2(t4);
            case "not in":
              return new J2(!t4);
          }
        }
        if ((n3 instanceof X2 || r3 instanceof X2) && "+" === e3.operator.value) return new X2(n3.value.toString() + r3.value.toString());
        if (n3 instanceof X2 && r3 instanceof X2) switch (e3.operator.value) {
          case "in":
            return new J2(r3.value.includes(n3.value));
          case "not in":
            return new J2(!r3.value.includes(n3.value));
        }
        if (n3 instanceof X2 && r3 instanceof Y2) switch (e3.operator.value) {
          case "in":
            return new J2(r3.value.has(n3.value));
          case "not in":
            return new J2(!r3.value.has(n3.value));
        }
        throw new SyntaxError(`Unknown operator "${e3.operator.value}" between ${n3.type} and ${r3.type}`);
      }
      evaluateArguments(e3, t3) {
        const n3 = [], r3 = /* @__PURE__ */ new Map();
        for (const s3 of e3) if ("SpreadExpression" === s3.type) {
          const e4 = s3, r4 = this.evaluate(e4.argument, t3);
          if (!(r4 instanceof ee2)) throw new Error(`Cannot unpack non-iterable type: ${r4.type}`);
          for (const e5 of r4.value) n3.push(e5);
        } else if ("KeywordArgumentExpression" === s3.type) {
          const e4 = s3;
          r3.set(e4.key.value, this.evaluate(e4.value, t3));
        } else {
          if (r3.size > 0) throw new Error("Positional arguments must come before keyword arguments");
          n3.push(this.evaluate(s3, t3));
        }
        return [n3, r3];
      }
      applyFilter(e3, t3, n3) {
        if ("Identifier" === t3.type) {
          const r3 = t3;
          if ("tojson" === r3.value) return new X2(le2(e3));
          if (e3 instanceof ee2) switch (r3.value) {
            case "list":
              return e3;
            case "first":
              return e3.value[0];
            case "last":
              return e3.value[e3.value.length - 1];
            case "length":
              return new Q2(e3.value.length);
            case "reverse":
              return new ee2(e3.value.reverse());
            case "sort":
              return new ee2(e3.value.sort(((e4, t4) => {
                if (e4.type !== t4.type) throw new Error(`Cannot compare different types: ${e4.type} and ${t4.type}`);
                switch (e4.type) {
                  case "IntegerValue":
                  case "FloatValue":
                    return e4.value - t4.value;
                  case "StringValue":
                    return e4.value.localeCompare(t4.value);
                  default:
                    throw new Error(`Cannot compare type: ${e4.type}`);
                }
              })));
            case "join":
              return new X2(e3.value.map(((e4) => e4.value)).join(""));
            case "string":
              return new X2(le2(e3));
            case "unique": {
              const t4 = /* @__PURE__ */ new Set(), n4 = [];
              for (const r4 of e3.value) t4.has(r4.value) || (t4.add(r4.value), n4.push(r4));
              return new ee2(n4);
            }
            default:
              throw new Error(`Unknown ArrayValue filter: ${r3.value}`);
          }
          else if (e3 instanceof X2) switch (r3.value) {
            case "length":
            case "upper":
            case "lower":
            case "title":
            case "capitalize": {
              const t4 = e3.builtins.get(r3.value);
              if (t4 instanceof ne2) return t4.value([], n3);
              if (t4 instanceof Q2) return t4;
              throw new Error(`Unknown StringValue filter: ${r3.value}`);
            }
            case "trim":
              return new X2(e3.value.trim());
            case "indent":
              return new X2(e3.value.split("\n").map(((e4, t4) => 0 === t4 || 0 === e4.length ? e4 : "    " + e4)).join("\n"));
            case "join":
            case "string":
              return e3;
            case "int": {
              const t4 = parseInt(e3.value, 10);
              return new Q2(isNaN(t4) ? 0 : t4);
            }
            case "float": {
              const t4 = parseFloat(e3.value);
              return new K2(isNaN(t4) ? 0 : t4);
            }
            default:
              throw new Error(`Unknown StringValue filter: ${r3.value}`);
          }
          else if (e3 instanceof Q2 || e3 instanceof K2) switch (r3.value) {
            case "abs":
              return e3 instanceof Q2 ? new Q2(Math.abs(e3.value)) : new K2(Math.abs(e3.value));
            case "int":
              return new Q2(Math.floor(e3.value));
            case "float":
              return new K2(e3.value);
            default:
              throw new Error(`Unknown NumericValue filter: ${r3.value}`);
          }
          else if (e3 instanceof Y2) switch (r3.value) {
            case "items":
              return new ee2(Array.from(e3.value.entries()).map((([e4, t4]) => new ee2([new X2(e4), t4]))));
            case "length":
              return new Q2(e3.value.size);
            default:
              throw new Error(`Unknown ObjectValue filter: ${r3.value}`);
          }
          else if (e3 instanceof J2) switch (r3.value) {
            case "bool":
              return new J2(e3.value);
            case "int":
              return new Q2(e3.value ? 1 : 0);
            case "float":
              return new K2(e3.value ? 1 : 0);
            case "string":
              return new X2(e3.value ? "true" : "false");
            default:
              throw new Error(`Unknown BooleanValue filter: ${r3.value}`);
          }
          throw new Error(`Cannot apply filter "${r3.value}" to type: ${e3.type}`);
        }
        if ("CallExpression" === t3.type) {
          const r3 = t3;
          if ("Identifier" !== r3.callee.type) throw new Error(`Unknown filter: ${r3.callee.type}`);
          const s3 = r3.callee.value;
          if ("tojson" === s3) {
            const [, t4] = this.evaluateArguments(r3.args, n3), s4 = t4.get("indent") ?? new re2();
            if (!(s4 instanceof Q2 || s4 instanceof re2)) throw new Error("If set, indent must be a number");
            return new X2(le2(e3, s4.value));
          }
          if ("join" === s3) {
            let t4;
            if (e3 instanceof X2) t4 = Array.from(e3.value);
            else {
              if (!(e3 instanceof ee2)) throw new Error(`Cannot apply filter "${s3}" to type: ${e3.type}`);
              t4 = e3.value.map(((e4) => e4.value));
            }
            const [a3, o3] = this.evaluateArguments(r3.args, n3), i3 = a3.at(0) ?? o3.get("separator") ?? new X2("");
            if (!(i3 instanceof X2)) throw new Error("separator must be a string");
            return new X2(t4.join(i3.value));
          }
          if ("int" === s3 || "float" === s3) {
            const [t4, a3] = this.evaluateArguments(r3.args, n3), o3 = t4.at(0) ?? a3.get("default") ?? ("int" === s3 ? new Q2(0) : new K2(0));
            if (e3 instanceof X2) {
              const t5 = "int" === s3 ? parseInt(e3.value, 10) : parseFloat(e3.value);
              return isNaN(t5) ? o3 : "int" === s3 ? new Q2(t5) : new K2(t5);
            }
            if (e3 instanceof Q2 || e3 instanceof K2) return e3;
            if (e3 instanceof J2) return "int" === s3 ? new Q2(e3.value ? 1 : 0) : new K2(e3.value ? 1 : 0);
            throw new Error(`Cannot apply filter "${s3}" to type: ${e3.type}`);
          }
          if ("default" === s3) {
            const [t4, s4] = this.evaluateArguments(r3.args, n3), a3 = t4[0] ?? new X2(""), o3 = t4[1] ?? s4.get("boolean") ?? new J2(false);
            if (!(o3 instanceof J2)) throw new Error("`default` filter flag must be a boolean");
            return e3 instanceof se2 || o3.value && !e3.__bool__().value ? a3 : e3;
          }
          if (e3 instanceof ee2) {
            switch (s3) {
              case "selectattr":
              case "rejectattr": {
                const t4 = "selectattr" === s3;
                if (e3.value.some(((e4) => !(e4 instanceof Y2)))) throw new Error(`\`${s3}\` can only be applied to array of objects`);
                if (r3.args.some(((e4) => "StringLiteral" !== e4.type))) throw new Error(`arguments of \`${s3}\` must be strings`);
                const [a3, o3, i3] = r3.args.map(((e4) => this.evaluate(e4, n3)));
                let l3;
                if (o3) {
                  const e4 = n3.tests.get(o3.value);
                  if (!e4) throw new Error(`Unknown test: ${o3.value}`);
                  l3 = e4;
                } else l3 = (...e4) => e4[0].__bool__().value;
                const d3 = e3.value.filter(((e4) => {
                  const n4 = e4.value.get(a3.value), r4 = !!n4 && l3(n4, i3);
                  return t4 ? r4 : !r4;
                }));
                return new ee2(d3);
              }
              case "map": {
                const [, t4] = this.evaluateArguments(r3.args, n3);
                if (t4.has("attribute")) {
                  const n4 = t4.get("attribute");
                  if (!(n4 instanceof X2)) throw new Error("attribute must be a string");
                  const r4 = t4.get("default"), s4 = e3.value.map(((e4) => {
                    if (!(e4 instanceof Y2)) throw new Error("items in map must be an object");
                    return e4.value.get(n4.value) ?? r4 ?? new se2();
                  }));
                  return new ee2(s4);
                }
                throw new Error("`map` expressions without `attribute` set are not currently supported.");
              }
            }
            throw new Error(`Unknown ArrayValue filter: ${s3}`);
          }
          if (e3 instanceof X2) {
            switch (s3) {
              case "indent": {
                const [t4, s4] = this.evaluateArguments(r3.args, n3), a3 = t4.at(0) ?? s4.get("width") ?? new Q2(4);
                if (!(a3 instanceof Q2)) throw new Error("width must be a number");
                const o3 = t4.at(1) ?? s4.get("first") ?? new J2(false), i3 = t4.at(2) ?? s4.get("blank") ?? new J2(false), l3 = e3.value.split("\n"), d3 = " ".repeat(a3.value), u3 = l3.map(((e4, t5) => !o3.value && 0 === t5 || !i3.value && 0 === e4.length ? e4 : d3 + e4));
                return new X2(u3.join("\n"));
              }
              case "replace": {
                const t4 = e3.builtins.get("replace");
                if (!(t4 instanceof ne2)) throw new Error("replace filter not available");
                const [s4, a3] = this.evaluateArguments(r3.args, n3);
                return t4.value([...s4, new Z2(a3)], n3);
              }
            }
            throw new Error(`Unknown StringValue filter: ${s3}`);
          }
          throw new Error(`Cannot apply filter "${s3}" to type: ${e3.type}`);
        }
        throw new Error(`Unknown filter: ${t3.type}`);
      }
      evaluateFilterExpression(e3, t3) {
        const n3 = this.evaluate(e3.operand, t3);
        return this.applyFilter(n3, e3.filter, t3);
      }
      evaluateTestExpression(e3, t3) {
        const n3 = this.evaluate(e3.operand, t3), r3 = t3.tests.get(e3.test.value);
        if (!r3) throw new Error(`Unknown test: ${e3.test.value}`);
        const s3 = r3(n3);
        return new J2(e3.negate ? !s3 : s3);
      }
      evaluateSelectExpression(e3, t3) {
        return this.evaluate(e3.test, t3).__bool__().value ? this.evaluate(e3.lhs, t3) : new se2();
      }
      evaluateUnaryExpression(e3, t3) {
        const n3 = this.evaluate(e3.argument, t3);
        if ("not" === e3.operator.value) return new J2(!n3.value);
        throw new SyntaxError(`Unknown operator: ${e3.operator.value}`);
      }
      evaluateTernaryExpression(e3, t3) {
        return this.evaluate(e3.condition, t3).__bool__().value ? this.evaluate(e3.trueExpr, t3) : this.evaluate(e3.falseExpr, t3);
      }
      evalProgram(e3, t3) {
        return this.evaluateBlock(e3.body, t3);
      }
      evaluateBlock(e3, t3) {
        let n3 = "";
        for (const r3 of e3) {
          const e4 = this.evaluate(r3, t3);
          "NullValue" !== e4.type && "UndefinedValue" !== e4.type && (n3 += e4.toString());
        }
        return new X2(n3);
      }
      evaluateIdentifier(e3, t3) {
        return t3.lookupVariable(e3.value);
      }
      evaluateCallExpression(e3, t3) {
        const [n3, r3] = this.evaluateArguments(e3.args, t3);
        r3.size > 0 && n3.push(new Z2(r3));
        const s3 = this.evaluate(e3.callee, t3);
        if ("FunctionValue" !== s3.type) throw new Error(`Cannot call something that is not a function: got ${s3.type}`);
        return s3.value(n3, t3);
      }
      evaluateSliceExpression(e3, t3, n3) {
        if (!(e3 instanceof ee2 || e3 instanceof X2)) throw new Error("Slice object must be an array or string");
        const r3 = this.evaluate(t3.start, n3), s3 = this.evaluate(t3.stop, n3), a3 = this.evaluate(t3.step, n3);
        if (!(r3 instanceof Q2 || r3 instanceof se2)) throw new Error("Slice start must be numeric or undefined");
        if (!(s3 instanceof Q2 || s3 instanceof se2)) throw new Error("Slice stop must be numeric or undefined");
        if (!(a3 instanceof Q2 || a3 instanceof se2)) throw new Error("Slice step must be numeric or undefined");
        return e3 instanceof ee2 ? new ee2(G2(e3.value, r3.value, s3.value, a3.value)) : new X2(G2(Array.from(e3.value), r3.value, s3.value, a3.value).join(""));
      }
      evaluateMemberExpression(e3, t3) {
        const n3 = this.evaluate(e3.object, t3);
        let r3, s3;
        if (e3.computed) {
          if ("SliceExpression" === e3.property.type) return this.evaluateSliceExpression(n3, e3.property, t3);
          r3 = this.evaluate(e3.property, t3);
        } else r3 = new X2(e3.property.value);
        if (n3 instanceof Y2) {
          if (!(r3 instanceof X2)) throw new Error(`Cannot access property with non-string: got ${r3.type}`);
          s3 = n3.value.get(r3.value) ?? n3.builtins.get(r3.value);
        } else if (n3 instanceof ee2 || n3 instanceof X2) if (r3 instanceof Q2) s3 = n3.value.at(r3.value), n3 instanceof X2 && (s3 = new X2(n3.value.at(r3.value)));
        else {
          if (!(r3 instanceof X2)) throw new Error(`Cannot access property with non-string/non-number: got ${r3.type}`);
          s3 = n3.builtins.get(r3.value);
        }
        else {
          if (!(r3 instanceof X2)) throw new Error(`Cannot access property with non-string: got ${r3.type}`);
          s3 = n3.builtins.get(r3.value);
        }
        return s3 instanceof H2 ? s3 : new se2();
      }
      evaluateSet(e3, t3) {
        const n3 = e3.value ? this.evaluate(e3.value, t3) : this.evaluateBlock(e3.body, t3);
        if ("Identifier" === e3.assignee.type) {
          const r3 = e3.assignee.value;
          t3.setVariable(r3, n3);
        } else if ("TupleLiteral" === e3.assignee.type) {
          const r3 = e3.assignee;
          if (!(n3 instanceof ee2)) throw new Error(`Cannot unpack non-iterable type in set: ${n3.type}`);
          const s3 = n3.value;
          if (s3.length !== r3.value.length) throw new Error(`Too ${r3.value.length > s3.length ? "few" : "many"} items to unpack in set`);
          for (let e4 = 0; e4 < r3.value.length; ++e4) {
            const n4 = r3.value[e4];
            if ("Identifier" !== n4.type) throw new Error(`Cannot unpack to non-identifier in set: ${n4.type}`);
            t3.setVariable(n4.value, s3[e4]);
          }
        } else {
          if ("MemberExpression" !== e3.assignee.type) throw new Error(`Invalid LHS inside assignment expression: ${JSON.stringify(e3.assignee)}`);
          {
            const r3 = e3.assignee, s3 = this.evaluate(r3.object, t3);
            if (!(s3 instanceof Y2)) throw new Error("Cannot assign to member of non-object");
            if ("Identifier" !== r3.property.type) throw new Error("Cannot assign to member with non-identifier property");
            s3.value.set(r3.property.value, n3);
          }
        }
        return new re2();
      }
      evaluateIf(e3, t3) {
        const n3 = this.evaluate(e3.test, t3);
        return this.evaluateBlock(n3.__bool__().value ? e3.body : e3.alternate, t3);
      }
      evaluateFor(e3, t3) {
        const n3 = new ae2(t3);
        let r3, s3;
        if ("SelectExpression" === e3.iterable.type) {
          const t4 = e3.iterable;
          s3 = this.evaluate(t4.lhs, n3), r3 = t4.test;
        } else s3 = this.evaluate(e3.iterable, n3);
        if (!(s3 instanceof ee2 || s3 instanceof Y2)) throw new Error(`Expected iterable or object type in for loop: got ${s3.type}`);
        s3 instanceof Y2 && (s3 = s3.keys());
        const a3 = [], o3 = [];
        for (let t4 = 0; t4 < s3.value.length; ++t4) {
          const i4 = new ae2(n3), l4 = s3.value[t4];
          let d3;
          if ("Identifier" === e3.loopvar.type) d3 = (t5) => t5.setVariable(e3.loopvar.value, l4);
          else {
            if ("TupleLiteral" !== e3.loopvar.type) throw new Error(`Invalid loop variable(s): ${e3.loopvar.type}`);
            {
              const t5 = e3.loopvar;
              if ("ArrayValue" !== l4.type) throw new Error(`Cannot unpack non-iterable type: ${l4.type}`);
              const n4 = l4;
              if (t5.value.length !== n4.value.length) throw new Error(`Too ${t5.value.length > n4.value.length ? "few" : "many"} items to unpack`);
              d3 = (e4) => {
                for (let r4 = 0; r4 < t5.value.length; ++r4) {
                  if ("Identifier" !== t5.value[r4].type) throw new Error(`Cannot unpack non-identifier type: ${t5.value[r4].type}`);
                  e4.setVariable(t5.value[r4].value, n4.value[r4]);
                }
              };
            }
          }
          if (r3) {
            d3(i4);
            if (!this.evaluate(r3, i4).__bool__().value) continue;
          }
          a3.push(l4), o3.push(d3);
        }
        let i3 = "", l3 = true;
        for (let t4 = 0; t4 < a3.length; ++t4) {
          const r4 = /* @__PURE__ */ new Map([["index", new Q2(t4 + 1)], ["index0", new Q2(t4)], ["revindex", new Q2(a3.length - t4)], ["revindex0", new Q2(a3.length - t4 - 1)], ["first", new J2(0 === t4)], ["last", new J2(t4 === a3.length - 1)], ["length", new Q2(a3.length)], ["previtem", t4 > 0 ? a3[t4 - 1] : new se2()], ["nextitem", t4 < a3.length - 1 ? a3[t4 + 1] : new se2()]]);
          n3.setVariable("loop", new Y2(r4)), o3[t4](n3);
          try {
            i3 += this.evaluateBlock(e3.body, n3).value;
          } catch (e4) {
            if (e4 instanceof W2) continue;
            if (e4 instanceof U2) break;
            throw e4;
          }
          l3 = false;
        }
        if (l3) {
          i3 += this.evaluateBlock(e3.defaultBlock, n3).value;
        }
        return new X2(i3);
      }
      evaluateMacro(e3, t3) {
        return t3.setVariable(e3.name.value, new ne2(((t4, n3) => {
          const r3 = new ae2(n3);
          let s3;
          t4 = t4.slice(), "KeywordArgumentsValue" === t4.at(-1)?.type && (s3 = t4.pop());
          for (let n4 = 0; n4 < e3.args.length; ++n4) {
            const a3 = e3.args[n4], o3 = t4[n4];
            if ("Identifier" === a3.type) {
              const e4 = a3;
              if (!o3) throw new Error(`Missing positional argument: ${e4.value}`);
              r3.setVariable(e4.value, o3);
            } else {
              if ("KeywordArgumentExpression" !== a3.type) throw new Error(`Unknown argument type: ${a3.type}`);
              {
                const e4 = a3, t5 = o3 ?? s3?.value.get(e4.key.value) ?? this.evaluate(e4.value, r3);
                r3.setVariable(e4.key.value, t5);
              }
            }
          }
          return this.evaluateBlock(e3.body, r3);
        }))), new re2();
      }
      evaluateCallStatement(e3, t3) {
        const n3 = new ne2(((t4, n4) => {
          const r4 = new ae2(n4);
          if (e3.callerArgs) for (let n5 = 0; n5 < e3.callerArgs.length; ++n5) {
            const s4 = e3.callerArgs[n5];
            if ("Identifier" !== s4.type) throw new Error(`Caller parameter must be an identifier, got ${s4.type}`);
            r4.setVariable(s4.value, t4[n5] ?? new se2());
          }
          return this.evaluateBlock(e3.body, r4);
        })), [r3, s3] = this.evaluateArguments(e3.call.args, t3);
        r3.push(new Z2(s3));
        const a3 = this.evaluate(e3.call.callee, t3);
        if ("FunctionValue" !== a3.type) throw new Error(`Cannot call something that is not a function: got ${a3.type}`);
        const o3 = new ae2(t3);
        return o3.setVariable("caller", n3), a3.value(r3, o3);
      }
      evaluateFilterStatement(e3, t3) {
        const n3 = this.evaluateBlock(e3.body, t3);
        return this.applyFilter(n3, e3.filter, t3);
      }
      evaluate(e3, t3) {
        if (!e3) return new se2();
        switch (e3.type) {
          case "Program":
            return this.evalProgram(e3, t3);
          case "Set":
            return this.evaluateSet(e3, t3);
          case "If":
            return this.evaluateIf(e3, t3);
          case "For":
            return this.evaluateFor(e3, t3);
          case "Macro":
            return this.evaluateMacro(e3, t3);
          case "CallStatement":
            return this.evaluateCallStatement(e3, t3);
          case "Break":
            throw new U2();
          case "Continue":
            throw new W2();
          case "IntegerLiteral":
            return new Q2(e3.value);
          case "FloatLiteral":
            return new K2(e3.value);
          case "StringLiteral":
            return new X2(e3.value);
          case "ArrayLiteral":
            return new ee2(e3.value.map(((e4) => this.evaluate(e4, t3))));
          case "TupleLiteral":
            return new te2(e3.value.map(((e4) => this.evaluate(e4, t3))));
          case "ObjectLiteral": {
            const n3 = /* @__PURE__ */ new Map();
            for (const [r3, s3] of e3.value) {
              const e4 = this.evaluate(r3, t3);
              if (!(e4 instanceof X2)) throw new Error(`Object keys must be strings: got ${e4.type}`);
              n3.set(e4.value, this.evaluate(s3, t3));
            }
            return new Y2(n3);
          }
          case "Identifier":
            return this.evaluateIdentifier(e3, t3);
          case "CallExpression":
            return this.evaluateCallExpression(e3, t3);
          case "MemberExpression":
            return this.evaluateMemberExpression(e3, t3);
          case "UnaryExpression":
            return this.evaluateUnaryExpression(e3, t3);
          case "BinaryExpression":
            return this.evaluateBinaryExpression(e3, t3);
          case "FilterExpression":
            return this.evaluateFilterExpression(e3, t3);
          case "FilterStatement":
            return this.evaluateFilterStatement(e3, t3);
          case "TestExpression":
            return this.evaluateTestExpression(e3, t3);
          case "SelectExpression":
            return this.evaluateSelectExpression(e3, t3);
          case "Ternary":
            return this.evaluateTernaryExpression(e3, t3);
          case "Comment":
            return new re2();
          default:
            throw new SyntaxError(`Unknown node type: ${e3.type}`);
        }
      }
    };
    function ie2(e3) {
      switch (typeof e3) {
        case "number":
          return Number.isInteger(e3) ? new Q2(e3) : new K2(e3);
        case "string":
          return new X2(e3);
        case "boolean":
          return new J2(e3);
        case "undefined":
          return new se2();
        case "object":
          return null === e3 ? new re2() : Array.isArray(e3) ? new ee2(e3.map(ie2)) : new Y2(new Map(Object.entries(e3).map((([e4, t3]) => [e4, ie2(t3)]))));
        case "function":
          return new ne2(((t3, n3) => ie2(e3(...t3.map(((e4) => e4.value))) ?? null)));
        default:
          throw new Error(`Cannot convert to runtime value: ${e3}`);
      }
    }
    function le2(e3, t3, n3) {
      const r3 = n3 ?? 0;
      switch (e3.type) {
        case "NullValue":
        case "UndefinedValue":
          return "null";
        case "IntegerValue":
        case "FloatValue":
        case "StringValue":
        case "BooleanValue":
          return JSON.stringify(e3.value);
        case "ArrayValue":
        case "ObjectValue": {
          const n4 = t3 ? " ".repeat(t3) : "", s3 = "\n" + n4.repeat(r3), a3 = s3 + n4;
          if ("ArrayValue" === e3.type) {
            const n5 = e3.value.map(((e4) => le2(e4, t3, r3 + 1)));
            return t3 ? `[${a3}${n5.join(`,${a3}`)}${s3}]` : `[${n5.join(", ")}]`;
          }
          {
            const n5 = Array.from(e3.value.entries()).map((([e4, n6]) => {
              const s4 = `"${e4}": ${le2(n6, t3, r3 + 1)}`;
              return t3 ? `${a3}${s4}` : s4;
            }));
            return t3 ? `{${n5.join(",")}${s3}}` : `{${n5.join(", ")}}`;
          }
        }
        default:
          throw new Error(`Cannot convert to JSON: ${e3.type}`);
      }
    }
    var de2 = "\n", ue2 = "{%- ", ce2 = " -%}";
    function pe2(...e3) {
      return ue2 + e3.join(" ") + ce2;
    }
    function me2(e3, t3, n3) {
      return e3.map(((e4) => (function(e5, t4, n4) {
        const r3 = n4.repeat(t4);
        switch (e5.type) {
          case "Program":
            return me2(e5.body, t4, n4);
          case "If":
            return (function(e6, t5, n5) {
              const r4 = n5.repeat(t5), s3 = [];
              let a3 = e6;
              for (; a3 && (s3.push({ test: a3.test, body: a3.body }), 1 === a3.alternate.length && "If" === a3.alternate[0].type); ) a3 = a3.alternate[0];
              let o3 = r4 + pe2("if", he2(s3[0].test)) + de2 + me2(s3[0].body, t5 + 1, n5);
              for (let e7 = 1; e7 < s3.length; ++e7) o3 += de2 + r4 + pe2("elif", he2(s3[e7].test)) + de2 + me2(s3[e7].body, t5 + 1, n5);
              a3 && a3.alternate.length > 0 && (o3 += de2 + r4 + pe2("else") + de2 + me2(a3.alternate, t5 + 1, n5));
              return o3 += de2 + r4 + pe2("endif"), o3;
            })(e5, t4, n4);
          case "For":
            return (function(e6, t5, n5) {
              const r4 = n5.repeat(t5);
              let s3 = "";
              if ("SelectExpression" === e6.iterable.type) {
                const t6 = e6.iterable;
                s3 = `${he2(t6.lhs)} if ${he2(t6.test)}`;
              } else s3 = he2(e6.iterable);
              let a3 = r4 + pe2("for", he2(e6.loopvar), "in", s3) + de2 + me2(e6.body, t5 + 1, n5);
              e6.defaultBlock.length > 0 && (a3 += de2 + r4 + pe2("else") + de2 + me2(e6.defaultBlock, t5 + 1, n5));
              return a3 += de2 + r4 + pe2("endfor"), a3;
            })(e5, t4, n4);
          case "Set":
            return (function(e6, t5, n5) {
              const r4 = n5.repeat(t5), s3 = he2(e6.assignee), a3 = e6.value ? he2(e6.value) : "", o3 = r4 + pe2("set", `${s3}${e6.value ? " = " + a3 : ""}`);
              if (0 === e6.body.length) return o3;
              return o3 + de2 + me2(e6.body, t5 + 1, n5) + de2 + r4 + pe2("endset");
            })(e5, t4, n4);
          case "Macro":
            return (function(e6, t5, n5) {
              const r4 = n5.repeat(t5), s3 = e6.args.map(he2).join(", ");
              return r4 + pe2("macro", `${e6.name.value}(${s3})`) + de2 + me2(e6.body, t5 + 1, n5) + de2 + r4 + pe2("endmacro");
            })(e5, t4, n4);
          case "Break":
            return r3 + pe2("break");
          case "Continue":
            return r3 + pe2("continue");
          case "CallStatement":
            return (function(e6, t5, n5) {
              const r4 = n5.repeat(t5), s3 = e6.callerArgs && e6.callerArgs.length > 0 ? `(${e6.callerArgs.map(he2).join(", ")})` : "", a3 = he2(e6.call);
              let o3 = r4 + pe2(`call${s3}`, a3) + de2;
              return o3 += me2(e6.body, t5 + 1, n5) + de2, o3 += r4 + pe2("endcall"), o3;
            })(e5, t4, n4);
          case "FilterStatement":
            return (function(e6, t5, n5) {
              const r4 = n5.repeat(t5), s3 = "Identifier" === e6.filter.type ? e6.filter.value : he2(e6.filter);
              let a3 = r4 + pe2("filter", s3) + de2;
              return a3 += me2(e6.body, t5 + 1, n5) + de2, a3 += r4 + pe2("endfilter"), a3;
            })(e5, t4, n4);
          case "Comment":
            return r3 + "{# " + e5.value + " #}";
          default:
            return r3 + "{{- " + he2(e5) + " -}}";
        }
      })(e4, t3, n3))).join(de2);
    }
    function he2(e3, t3 = -1) {
      switch (e3.type) {
        case "SpreadExpression":
          return `*${he2(e3.argument)}`;
        case "Identifier":
          return e3.value;
        case "IntegerLiteral":
        case "FloatLiteral":
          return `${e3.value}`;
        case "StringLiteral":
          return JSON.stringify(e3.value);
        case "BinaryExpression": {
          const n3 = e3, r3 = (function(e4) {
            switch (e4.operator.type) {
              case "MultiplicativeBinaryOperator":
                return 4;
              case "AdditiveBinaryOperator":
                return 3;
              case "ComparisonBinaryOperator":
                return 2;
              case "Identifier":
                return "and" === e4.operator.value ? 1 : "in" === e4.operator.value || "not in" === e4.operator.value ? 2 : 0;
            }
            return 0;
          })(n3), s3 = he2(n3.left, r3), a3 = he2(n3.right, r3 + 1), o3 = `${s3} ${n3.operator.value} ${a3}`;
          return r3 < t3 ? `(${o3})` : o3;
        }
        case "UnaryExpression": {
          const t4 = e3;
          return t4.operator.value + ("not" === t4.operator.value ? " " : "") + he2(t4.argument, 1 / 0);
        }
        case "CallExpression": {
          const t4 = e3, n3 = t4.args.map(he2).join(", ");
          return `${he2(t4.callee)}(${n3})`;
        }
        case "MemberExpression": {
          const t4 = e3;
          let n3 = he2(t4.object);
          ["Identifier", "MemberExpression", "CallExpression", "StringLiteral", "IntegerLiteral", "FloatLiteral", "ArrayLiteral", "TupleLiteral", "ObjectLiteral"].includes(t4.object.type) || (n3 = `(${n3})`);
          let r3 = he2(t4.property);
          return t4.computed || "Identifier" === t4.property.type || (r3 = `(${r3})`), t4.computed ? `${n3}[${r3}]` : `${n3}.${r3}`;
        }
        case "FilterExpression": {
          const t4 = e3, n3 = he2(t4.operand, 1 / 0);
          return "CallExpression" === t4.filter.type ? `${n3} | ${he2(t4.filter)}` : `${n3} | ${t4.filter.value}`;
        }
        case "SelectExpression": {
          const t4 = e3;
          return `${he2(t4.lhs)} if ${he2(t4.test)}`;
        }
        case "TestExpression": {
          const t4 = e3;
          return `${he2(t4.operand)} is${t4.negate ? " not" : ""} ${t4.test.value}`;
        }
        case "ArrayLiteral":
        case "TupleLiteral": {
          const t4 = e3.value.map(he2), n3 = "ArrayLiteral" === e3.type ? "[]" : "()";
          return `${n3[0]}${t4.join(", ")}${n3[1]}`;
        }
        case "ObjectLiteral":
          return `{${Array.from(e3.value.entries()).map((([e4, t4]) => `${he2(e4)}: ${he2(t4)}`)).join(", ")}}`;
        case "SliceExpression": {
          const t4 = e3;
          return `${t4.start ? he2(t4.start) : ""}:${t4.stop ? he2(t4.stop) : ""}${t4.step ? `:${he2(t4.step)}` : ""}`;
        }
        case "KeywordArgumentExpression": {
          const t4 = e3;
          return `${t4.key.value}=${he2(t4.value)}`;
        }
        case "Ternary": {
          const n3 = e3, r3 = `${he2(n3.trueExpr)} if ${he2(n3.condition, 0)} else ${he2(n3.falseExpr)}`;
          return t3 > -1 ? `(${r3})` : r3;
        }
        default:
          throw new Error(`Unknown expression type: ${e3.type}`);
      }
    }
    var fe2 = class {
      parsed;
      constructor(e3) {
        const t3 = d2(e3, { lstrip_blocks: true, trim_blocks: true });
        this.parsed = R2(t3);
      }
      render(e3) {
        const t3 = new ae2();
        if ((function(e4) {
          e4.set("false", false), e4.set("true", true), e4.set("none", null), e4.set("raise_exception", ((e5) => {
            throw new Error(e5);
          })), e4.set("range", V2), e4.set("strftime_now", q2), e4.set("True", true), e4.set("False", false), e4.set("None", null);
        })(t3), e3) for (const [n3, r3] of Object.entries(e3)) t3.set(n3, r3);
        return new oe2(t3).run(this.parsed).value;
      }
      format(e3) {
        return (function(e4, t3 = "	") {
          const n3 = "number" == typeof t3 ? " ".repeat(t3) : t3;
          return me2(e4.body, 0, n3).replace(/\n$/, "");
        })(this.parsed, e3?.indent || "	");
      }
    };
  }, "./node_modules/onnxruntime-common/dist/esm/backend-impl.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { registerBackend: () => a2, resolveBackendAndExecutionProviders: () => i2 });
    const r2 = /* @__PURE__ */ new Map(), s2 = [], a2 = (e3, t3, n3) => {
      if (!t3 || "function" != typeof t3.init || "function" != typeof t3.createInferenceSessionHandler) throw new TypeError("not a valid backend");
      {
        const a3 = r2.get(e3);
        if (void 0 === a3) r2.set(e3, { backend: t3, priority: n3 });
        else {
          if (a3.priority > n3) return;
          if (a3.priority === n3 && a3.backend !== t3) throw new Error(`cannot register backend "${e3}" using priority ${n3}`);
        }
        if (n3 >= 0) {
          const t4 = s2.indexOf(e3);
          -1 !== t4 && s2.splice(t4, 1);
          for (let t5 = 0; t5 < s2.length; t5++) if (r2.get(s2[t5]).priority <= n3) return void s2.splice(t5, 0, e3);
          s2.push(e3);
        }
      }
    }, o2 = async (e3) => {
      const t3 = r2.get(e3);
      if (!t3) return "backend not found.";
      if (t3.initialized) return t3.backend;
      if (t3.aborted) return t3.error;
      {
        const n3 = !!t3.initPromise;
        try {
          return n3 || (t3.initPromise = t3.backend.init(e3)), await t3.initPromise, t3.initialized = true, t3.backend;
        } catch (e4) {
          return n3 || (t3.error = `${e4}`, t3.aborted = true), t3.error;
        } finally {
          delete t3.initPromise;
        }
      }
    }, i2 = async (e3) => {
      const t3 = e3.executionProviders || [], n3 = t3.map(((e4) => "string" == typeof e4 ? e4 : e4.name)), r3 = 0 === n3.length ? s2 : n3;
      let a3;
      const i3 = [], l2 = /* @__PURE__ */ new Set();
      for (const e4 of r3) {
        const t4 = await o2(e4);
        "string" == typeof t4 ? i3.push({ name: e4, err: t4 }) : (a3 || (a3 = t4), a3 === t4 && l2.add(e4));
      }
      if (!a3) throw new Error(`no available backend found. ERR: ${i3.map(((e4) => `[${e4.name}] ${e4.err}`)).join(", ")}`);
      for (const { name: e4, err: t4 } of i3) n3.includes(e4) && console.warn(`removing requested execution provider "${e4}" from session options because it is not available: ${t4}`);
      const d2 = t3.filter(((e4) => l2.has("string" == typeof e4 ? e4 : e4.name)));
      return [a3, new Proxy(e3, { get: (e4, t4) => "executionProviders" === t4 ? d2 : Reflect.get(e4, t4) })];
    };
  }, "./node_modules/onnxruntime-common/dist/esm/backend.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { registerBackend: () => r2.registerBackend });
    var r2 = n2("./node_modules/onnxruntime-common/dist/esm/backend-impl.js");
  }, "./node_modules/onnxruntime-common/dist/esm/env-impl.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { env: () => a2 });
    var r2 = n2("./node_modules/onnxruntime-common/dist/esm/version.js");
    let s2 = "warning";
    const a2 = { wasm: {}, webgl: {}, webgpu: {}, versions: { common: r2.version }, set logLevel(e3) {
      if (void 0 !== e3) {
        if ("string" != typeof e3 || -1 === ["verbose", "info", "warning", "error", "fatal"].indexOf(e3)) throw new Error(`Unsupported logging level: ${e3}`);
        s2 = e3;
      }
    }, get logLevel() {
      return s2;
    } };
    Object.defineProperty(a2, "logLevel", { enumerable: true });
  }, "./node_modules/onnxruntime-common/dist/esm/env.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { env: () => r2 });
    const r2 = n2("./node_modules/onnxruntime-common/dist/esm/env-impl.js").env;
  }, "./node_modules/onnxruntime-common/dist/esm/index.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { InferenceSession: () => a2.InferenceSession, TRACE: () => i2.TRACE, TRACE_FUNC_BEGIN: () => i2.TRACE_FUNC_BEGIN, TRACE_FUNC_END: () => i2.TRACE_FUNC_END, Tensor: () => o2.Tensor, env: () => s2.env, registerBackend: () => r2.registerBackend });
    var r2 = n2("./node_modules/onnxruntime-common/dist/esm/backend.js"), s2 = n2("./node_modules/onnxruntime-common/dist/esm/env.js"), a2 = n2("./node_modules/onnxruntime-common/dist/esm/inference-session.js"), o2 = n2("./node_modules/onnxruntime-common/dist/esm/tensor.js"), i2 = (n2("./node_modules/onnxruntime-common/dist/esm/tensor-conversion.js"), n2("./node_modules/onnxruntime-common/dist/esm/tensor-factory.js"), n2("./node_modules/onnxruntime-common/dist/esm/trace.js"));
    n2("./node_modules/onnxruntime-common/dist/esm/onnx-model.js"), n2("./node_modules/onnxruntime-common/dist/esm/onnx-value.js");
  }, "./node_modules/onnxruntime-common/dist/esm/inference-session-impl.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { InferenceSession: () => o2 });
    var r2 = n2("./node_modules/onnxruntime-common/dist/esm/backend-impl.js"), s2 = n2("./node_modules/onnxruntime-common/dist/esm/tensor.js"), a2 = n2("./node_modules/onnxruntime-common/dist/esm/trace.js");
    class o2 {
      constructor(e3) {
        this.handler = e3;
      }
      async run(e3, t3, n3) {
        (0, a2.TRACE_FUNC_BEGIN)();
        const r3 = {};
        let o3 = {};
        if ("object" != typeof e3 || null === e3 || e3 instanceof s2.Tensor || Array.isArray(e3)) throw new TypeError("'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.");
        let i2 = true;
        if ("object" == typeof t3) {
          if (null === t3) throw new TypeError("Unexpected argument[1]: cannot be null.");
          if (t3 instanceof s2.Tensor) throw new TypeError("'fetches' cannot be a Tensor");
          if (Array.isArray(t3)) {
            if (0 === t3.length) throw new TypeError("'fetches' cannot be an empty array.");
            i2 = false;
            for (const e4 of t3) {
              if ("string" != typeof e4) throw new TypeError("'fetches' must be a string array or an object.");
              if (-1 === this.outputNames.indexOf(e4)) throw new RangeError(`'fetches' contains invalid output name: ${e4}.`);
              r3[e4] = null;
            }
            if ("object" == typeof n3 && null !== n3) o3 = n3;
            else if (void 0 !== n3) throw new TypeError("'options' must be an object.");
          } else {
            let e4 = false;
            const a3 = Object.getOwnPropertyNames(t3);
            for (const n4 of this.outputNames) if (-1 !== a3.indexOf(n4)) {
              const a4 = t3[n4];
              (null === a4 || a4 instanceof s2.Tensor) && (e4 = true, i2 = false, r3[n4] = a4);
            }
            if (e4) {
              if ("object" == typeof n3 && null !== n3) o3 = n3;
              else if (void 0 !== n3) throw new TypeError("'options' must be an object.");
            } else o3 = t3;
          }
        } else if (void 0 !== t3) throw new TypeError("Unexpected argument[1]: must be 'fetches' or 'options'.");
        for (const t4 of this.inputNames) if (void 0 === e3[t4]) throw new Error(`input '${t4}' is missing in 'feeds'.`);
        if (i2) for (const e4 of this.outputNames) r3[e4] = null;
        const l2 = await this.handler.run(e3, r3, o3), d2 = {};
        for (const e4 in l2) if (Object.hasOwnProperty.call(l2, e4)) {
          const t4 = l2[e4];
          t4 instanceof s2.Tensor ? d2[e4] = t4 : d2[e4] = new s2.Tensor(t4.type, t4.data, t4.dims);
        }
        return (0, a2.TRACE_FUNC_END)(), d2;
      }
      async release() {
        return this.handler.dispose();
      }
      static async create(e3, t3, n3, s3) {
        let i2;
        (0, a2.TRACE_FUNC_BEGIN)();
        let l2 = {};
        if ("string" == typeof e3) {
          if (i2 = e3, "object" == typeof t3 && null !== t3) l2 = t3;
          else if (void 0 !== t3) throw new TypeError("'options' must be an object.");
        } else if (e3 instanceof Uint8Array) {
          if (i2 = e3, "object" == typeof t3 && null !== t3) l2 = t3;
          else if (void 0 !== t3) throw new TypeError("'options' must be an object.");
        } else {
          if (!(e3 instanceof ArrayBuffer || "undefined" != typeof SharedArrayBuffer && e3 instanceof SharedArrayBuffer)) throw new TypeError("Unexpected argument[0]: must be 'path' or 'buffer'.");
          {
            const r3 = e3;
            let a3 = 0, o3 = e3.byteLength;
            if ("object" == typeof t3 && null !== t3) l2 = t3;
            else if ("number" == typeof t3) {
              if (a3 = t3, !Number.isSafeInteger(a3)) throw new RangeError("'byteOffset' must be an integer.");
              if (a3 < 0 || a3 >= r3.byteLength) throw new RangeError(`'byteOffset' is out of range [0, ${r3.byteLength}).`);
              if (o3 = e3.byteLength - a3, "number" == typeof n3) {
                if (o3 = n3, !Number.isSafeInteger(o3)) throw new RangeError("'byteLength' must be an integer.");
                if (o3 <= 0 || a3 + o3 > r3.byteLength) throw new RangeError(`'byteLength' is out of range (0, ${r3.byteLength - a3}].`);
                if ("object" == typeof s3 && null !== s3) l2 = s3;
                else if (void 0 !== s3) throw new TypeError("'options' must be an object.");
              } else if (void 0 !== n3) throw new TypeError("'byteLength' must be a number.");
            } else if (void 0 !== t3) throw new TypeError("'options' must be an object.");
            i2 = new Uint8Array(r3, a3, o3);
          }
        }
        const [d2, u2] = await (0, r2.resolveBackendAndExecutionProviders)(l2), c2 = await d2.createInferenceSessionHandler(i2, u2);
        return (0, a2.TRACE_FUNC_END)(), new o2(c2);
      }
      startProfiling() {
        this.handler.startProfiling();
      }
      endProfiling() {
        this.handler.endProfiling();
      }
      get inputNames() {
        return this.handler.inputNames;
      }
      get outputNames() {
        return this.handler.outputNames;
      }
    }
  }, "./node_modules/onnxruntime-common/dist/esm/inference-session.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { InferenceSession: () => r2 });
    const r2 = n2("./node_modules/onnxruntime-common/dist/esm/inference-session-impl.js").InferenceSession;
  }, "./node_modules/onnxruntime-common/dist/esm/onnx-model.js": (e2, t2, n2) => {
    n2.r(t2);
  }, "./node_modules/onnxruntime-common/dist/esm/onnx-value.js": (e2, t2, n2) => {
    n2.r(t2);
  }, "./node_modules/onnxruntime-common/dist/esm/tensor-conversion-impl.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { tensorToDataURL: () => r2, tensorToImageData: () => s2 });
    const r2 = (e3, t3) => {
      const n3 = "undefined" != typeof document ? document.createElement("canvas") : new OffscreenCanvas(1, 1);
      n3.width = e3.dims[3], n3.height = e3.dims[2];
      const r3 = n3.getContext("2d");
      if (null != r3) {
        let s3, a2;
        void 0 !== t3?.tensorLayout && "NHWC" === t3.tensorLayout ? (s3 = e3.dims[2], a2 = e3.dims[3]) : (s3 = e3.dims[3], a2 = e3.dims[2]);
        const o2 = void 0 !== t3?.format ? t3.format : "RGB", i2 = t3?.norm;
        let l2, d2;
        void 0 === i2 || void 0 === i2.mean ? l2 = [255, 255, 255, 255] : "number" == typeof i2.mean ? l2 = [i2.mean, i2.mean, i2.mean, i2.mean] : (l2 = [i2.mean[0], i2.mean[1], i2.mean[2], 0], void 0 !== i2.mean[3] && (l2[3] = i2.mean[3])), void 0 === i2 || void 0 === i2.bias ? d2 = [0, 0, 0, 0] : "number" == typeof i2.bias ? d2 = [i2.bias, i2.bias, i2.bias, i2.bias] : (d2 = [i2.bias[0], i2.bias[1], i2.bias[2], 0], void 0 !== i2.bias[3] && (d2[3] = i2.bias[3]));
        const u2 = a2 * s3;
        let c2 = 0, p2 = u2, m2 = 2 * u2, h2 = -1;
        "RGBA" === o2 ? (c2 = 0, p2 = u2, m2 = 2 * u2, h2 = 3 * u2) : "RGB" === o2 ? (c2 = 0, p2 = u2, m2 = 2 * u2) : "RBG" === o2 && (c2 = 0, m2 = u2, p2 = 2 * u2);
        for (let t4 = 0; t4 < a2; t4++) for (let n4 = 0; n4 < s3; n4++) {
          const s4 = (e3.data[c2++] - d2[0]) * l2[0], a3 = (e3.data[p2++] - d2[1]) * l2[1], o3 = (e3.data[m2++] - d2[2]) * l2[2], i3 = -1 === h2 ? 255 : (e3.data[h2++] - d2[3]) * l2[3];
          r3.fillStyle = "rgba(" + s4 + "," + a3 + "," + o3 + "," + i3 + ")", r3.fillRect(n4, t4, 1, 1);
        }
        if ("toDataURL" in n3) return n3.toDataURL();
        throw new Error("toDataURL is not supported");
      }
      throw new Error("Can not access image data");
    }, s2 = (e3, t3) => {
      const n3 = "undefined" != typeof document ? document.createElement("canvas").getContext("2d") : new OffscreenCanvas(1, 1).getContext("2d");
      let r3;
      if (null == n3) throw new Error("Can not access image data");
      {
        let s3, a2, o2;
        void 0 !== t3?.tensorLayout && "NHWC" === t3.tensorLayout ? (s3 = e3.dims[2], a2 = e3.dims[1], o2 = e3.dims[3]) : (s3 = e3.dims[3], a2 = e3.dims[2], o2 = e3.dims[1]);
        const i2 = void 0 !== t3 && void 0 !== t3.format ? t3.format : "RGB", l2 = t3?.norm;
        let d2, u2;
        void 0 === l2 || void 0 === l2.mean ? d2 = [255, 255, 255, 255] : "number" == typeof l2.mean ? d2 = [l2.mean, l2.mean, l2.mean, l2.mean] : (d2 = [l2.mean[0], l2.mean[1], l2.mean[2], 255], void 0 !== l2.mean[3] && (d2[3] = l2.mean[3])), void 0 === l2 || void 0 === l2.bias ? u2 = [0, 0, 0, 0] : "number" == typeof l2.bias ? u2 = [l2.bias, l2.bias, l2.bias, l2.bias] : (u2 = [l2.bias[0], l2.bias[1], l2.bias[2], 0], void 0 !== l2.bias[3] && (u2[3] = l2.bias[3]));
        const c2 = a2 * s3;
        if (void 0 !== t3 && (void 0 !== t3.format && 4 === o2 && "RGBA" !== t3.format || 3 === o2 && "RGB" !== t3.format && "BGR" !== t3.format)) throw new Error("Tensor format doesn't match input tensor dims");
        const p2 = 4;
        let m2 = 0, h2 = 1, f2 = 2, _2 = 3, g2 = 0, w2 = c2, b2 = 2 * c2, y2 = -1;
        "RGBA" === i2 ? (g2 = 0, w2 = c2, b2 = 2 * c2, y2 = 3 * c2) : "RGB" === i2 ? (g2 = 0, w2 = c2, b2 = 2 * c2) : "RBG" === i2 && (g2 = 0, b2 = c2, w2 = 2 * c2), r3 = n3.createImageData(s3, a2);
        for (let t4 = 0; t4 < a2 * s3; m2 += p2, h2 += p2, f2 += p2, _2 += p2, t4++) r3.data[m2] = (e3.data[g2++] - u2[0]) * d2[0], r3.data[h2] = (e3.data[w2++] - u2[1]) * d2[1], r3.data[f2] = (e3.data[b2++] - u2[2]) * d2[2], r3.data[_2] = -1 === y2 ? 255 : (e3.data[y2++] - u2[3]) * d2[3];
      }
      return r3;
    };
  }, "./node_modules/onnxruntime-common/dist/esm/tensor-conversion.js": (e2, t2, n2) => {
    n2.r(t2);
  }, "./node_modules/onnxruntime-common/dist/esm/tensor-factory-impl.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { bufferToTensor: () => s2, tensorFromGpuBuffer: () => i2, tensorFromImage: () => a2, tensorFromMLTensor: () => l2, tensorFromPinnedBuffer: () => d2, tensorFromTexture: () => o2 });
    var r2 = n2("./node_modules/onnxruntime-common/dist/esm/tensor-impl.js");
    const s2 = (e3, t3) => {
      if (void 0 === e3) throw new Error("Image buffer must be defined");
      if (void 0 === t3.height || void 0 === t3.width) throw new Error("Image height and width must be defined");
      if ("NHWC" === t3.tensorLayout) throw new Error("NHWC Tensor layout is not supported yet");
      const { height: n3, width: s3 } = t3, a3 = t3.norm ?? { mean: 255, bias: 0 };
      let o3, i3;
      o3 = "number" == typeof a3.mean ? [a3.mean, a3.mean, a3.mean, a3.mean] : [a3.mean[0], a3.mean[1], a3.mean[2], a3.mean[3] ?? 255], i3 = "number" == typeof a3.bias ? [a3.bias, a3.bias, a3.bias, a3.bias] : [a3.bias[0], a3.bias[1], a3.bias[2], a3.bias[3] ?? 0];
      const l3 = void 0 !== t3.format ? t3.format : "RGBA", d3 = void 0 !== t3.tensorFormat && void 0 !== t3.tensorFormat ? t3.tensorFormat : "RGB", u2 = n3 * s3, c2 = "RGBA" === d3 ? new Float32Array(4 * u2) : new Float32Array(3 * u2);
      let p2 = 4, m2 = 0, h2 = 1, f2 = 2, _2 = 3, g2 = 0, w2 = u2, b2 = 2 * u2, y2 = -1;
      "RGB" === l3 && (p2 = 3, m2 = 0, h2 = 1, f2 = 2, _2 = -1), "RGBA" === d3 ? y2 = 3 * u2 : "RBG" === d3 ? (g2 = 0, b2 = u2, w2 = 2 * u2) : "BGR" === d3 && (b2 = 0, w2 = u2, g2 = 2 * u2);
      for (let t4 = 0; t4 < u2; t4++, m2 += p2, f2 += p2, h2 += p2, _2 += p2) c2[g2++] = (e3[m2] + i3[0]) / o3[0], c2[w2++] = (e3[h2] + i3[1]) / o3[1], c2[b2++] = (e3[f2] + i3[2]) / o3[2], -1 !== y2 && -1 !== _2 && (c2[y2++] = (e3[_2] + i3[3]) / o3[3]);
      return "RGBA" === d3 ? new r2.Tensor("float32", c2, [1, 4, n3, s3]) : new r2.Tensor("float32", c2, [1, 3, n3, s3]);
    }, a2 = async (e3, t3) => {
      const n3 = "undefined" != typeof HTMLImageElement && e3 instanceof HTMLImageElement, r3 = "undefined" != typeof ImageData && e3 instanceof ImageData, a3 = "undefined" != typeof ImageBitmap && e3 instanceof ImageBitmap, o3 = "string" == typeof e3;
      let i3, l3 = t3 ?? {};
      const d3 = () => {
        if ("undefined" != typeof document) return document.createElement("canvas");
        if ("undefined" != typeof OffscreenCanvas) return new OffscreenCanvas(1, 1);
        throw new Error("Canvas is not supported");
      }, u2 = (e4) => "undefined" != typeof HTMLCanvasElement && e4 instanceof HTMLCanvasElement || e4 instanceof OffscreenCanvas ? e4.getContext("2d") : null;
      if (n3) {
        const n4 = d3();
        n4.width = e3.width, n4.height = e3.height;
        const r4 = u2(n4);
        if (null == r4) throw new Error("Can not access image data");
        {
          let n5 = e3.height, s3 = e3.width;
          if (void 0 !== t3 && void 0 !== t3.resizedHeight && void 0 !== t3.resizedWidth && (n5 = t3.resizedHeight, s3 = t3.resizedWidth), void 0 !== t3) {
            if (l3 = t3, void 0 !== t3.tensorFormat) throw new Error("Image input config format must be RGBA for HTMLImageElement");
            l3.tensorFormat = "RGBA", l3.height = n5, l3.width = s3;
          } else l3.tensorFormat = "RGBA", l3.height = n5, l3.width = s3;
          r4.drawImage(e3, 0, 0), i3 = r4.getImageData(0, 0, s3, n5).data;
        }
      } else {
        if (!r3) {
          if (a3) {
            if (void 0 === t3) throw new Error("Please provide image config with format for Imagebitmap");
            const n4 = d3();
            n4.width = e3.width, n4.height = e3.height;
            const r4 = u2(n4);
            if (null != r4) {
              const t4 = e3.height, n5 = e3.width;
              return r4.drawImage(e3, 0, 0, n5, t4), i3 = r4.getImageData(0, 0, n5, t4).data, l3.height = t4, l3.width = n5, s2(i3, l3);
            }
            throw new Error("Can not access image data");
          }
          if (o3) return new Promise(((t4, n4) => {
            const r4 = d3(), a4 = u2(r4);
            if (!e3 || !a4) return n4();
            const o4 = new Image();
            o4.crossOrigin = "Anonymous", o4.src = e3, o4.onload = () => {
              r4.width = o4.width, r4.height = o4.height, a4.drawImage(o4, 0, 0, r4.width, r4.height);
              const e4 = a4.getImageData(0, 0, r4.width, r4.height);
              l3.height = r4.height, l3.width = r4.width, t4(s2(e4.data, l3));
            };
          }));
          throw new Error("Input data provided is not supported - aborted tensor creation");
        }
        {
          let n4, r4;
          if (void 0 !== t3 && void 0 !== t3.resizedWidth && void 0 !== t3.resizedHeight ? (n4 = t3.resizedHeight, r4 = t3.resizedWidth) : (n4 = e3.height, r4 = e3.width), void 0 !== t3 && (l3 = t3), l3.format = "RGBA", l3.height = n4, l3.width = r4, void 0 !== t3) {
            const t4 = d3();
            t4.width = r4, t4.height = n4;
            const s3 = u2(t4);
            if (null == s3) throw new Error("Can not access image data");
            s3.putImageData(e3, 0, 0), i3 = s3.getImageData(0, 0, r4, n4).data;
          } else i3 = e3.data;
        }
      }
      if (void 0 !== i3) return s2(i3, l3);
      throw new Error("Input data provided is not supported - aborted tensor creation");
    }, o2 = (e3, t3) => {
      const { width: n3, height: s3, download: a3, dispose: o3 } = t3, i3 = [1, s3, n3, 4];
      return new r2.Tensor({ location: "texture", type: "float32", texture: e3, dims: i3, download: a3, dispose: o3 });
    }, i2 = (e3, t3) => {
      const { dataType: n3, dims: s3, download: a3, dispose: o3 } = t3;
      return new r2.Tensor({ location: "gpu-buffer", type: n3 ?? "float32", gpuBuffer: e3, dims: s3, download: a3, dispose: o3 });
    }, l2 = (e3, t3) => {
      const { dataType: n3, dims: s3, download: a3, dispose: o3 } = t3;
      return new r2.Tensor({ location: "ml-tensor", type: n3 ?? "float32", mlTensor: e3, dims: s3, download: a3, dispose: o3 });
    }, d2 = (e3, t3, n3) => new r2.Tensor({ location: "cpu-pinned", type: e3, data: t3, dims: n3 ?? [t3.length] });
  }, "./node_modules/onnxruntime-common/dist/esm/tensor-factory.js": (e2, t2, n2) => {
    n2.r(t2);
  }, "./node_modules/onnxruntime-common/dist/esm/tensor-impl-type-mapping.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP: () => s2, NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP: () => r2, checkTypedArray: () => o2 });
    const r2 = /* @__PURE__ */ new Map([["float32", Float32Array], ["uint8", Uint8Array], ["int8", Int8Array], ["uint16", Uint16Array], ["int16", Int16Array], ["int32", Int32Array], ["bool", Uint8Array], ["float64", Float64Array], ["uint32", Uint32Array], ["int4", Uint8Array], ["uint4", Uint8Array]]), s2 = /* @__PURE__ */ new Map([[Float32Array, "float32"], [Uint8Array, "uint8"], [Int8Array, "int8"], [Uint16Array, "uint16"], [Int16Array, "int16"], [Int32Array, "int32"], [Float64Array, "float64"], [Uint32Array, "uint32"]]);
    let a2 = false;
    const o2 = () => {
      if (!a2) {
        a2 = true;
        const e3 = "undefined" != typeof BigInt64Array && BigInt64Array.from, t3 = "undefined" != typeof BigUint64Array && BigUint64Array.from, n3 = globalThis.Float16Array, o3 = void 0 !== n3 && n3.from;
        e3 && (r2.set("int64", BigInt64Array), s2.set(BigInt64Array, "int64")), t3 && (r2.set("uint64", BigUint64Array), s2.set(BigUint64Array, "uint64")), o3 ? (r2.set("float16", n3), s2.set(n3, "float16")) : r2.set("float16", Uint16Array);
      }
    };
  }, "./node_modules/onnxruntime-common/dist/esm/tensor-impl.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Tensor: () => i2 });
    var r2 = n2("./node_modules/onnxruntime-common/dist/esm/tensor-conversion-impl.js"), s2 = n2("./node_modules/onnxruntime-common/dist/esm/tensor-factory-impl.js"), a2 = n2("./node_modules/onnxruntime-common/dist/esm/tensor-impl-type-mapping.js"), o2 = n2("./node_modules/onnxruntime-common/dist/esm/tensor-utils-impl.js");
    class i2 {
      constructor(e3, t3, n3) {
        let r3, s3;
        if ((0, a2.checkTypedArray)(), "object" == typeof e3 && "location" in e3) switch (this.dataLocation = e3.location, r3 = e3.type, s3 = e3.dims, e3.location) {
          case "cpu-pinned": {
            const t4 = a2.NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(r3);
            if (!t4) throw new TypeError(`unsupported type "${r3}" to create tensor from pinned buffer`);
            if (!(e3.data instanceof t4)) throw new TypeError(`buffer should be of type ${t4.name}`);
            this.cpuData = e3.data;
            break;
          }
          case "texture":
            if ("float32" !== r3) throw new TypeError(`unsupported type "${r3}" to create tensor from texture`);
            this.gpuTextureData = e3.texture, this.downloader = e3.download, this.disposer = e3.dispose;
            break;
          case "gpu-buffer":
            if ("float32" !== r3 && "float16" !== r3 && "int32" !== r3 && "int64" !== r3 && "uint32" !== r3 && "uint8" !== r3 && "bool" !== r3 && "uint4" !== r3 && "int4" !== r3) throw new TypeError(`unsupported type "${r3}" to create tensor from gpu buffer`);
            this.gpuBufferData = e3.gpuBuffer, this.downloader = e3.download, this.disposer = e3.dispose;
            break;
          case "ml-tensor":
            if ("float32" !== r3 && "float16" !== r3 && "int32" !== r3 && "int64" !== r3 && "uint32" !== r3 && "uint64" !== r3 && "int8" !== r3 && "uint8" !== r3 && "bool" !== r3 && "uint4" !== r3 && "int4" !== r3) throw new TypeError(`unsupported type "${r3}" to create tensor from MLTensor`);
            this.mlTensorData = e3.mlTensor, this.downloader = e3.download, this.disposer = e3.dispose;
            break;
          default:
            throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);
        }
        else {
          let o3, i4;
          if ("string" == typeof e3) if (r3 = e3, i4 = n3, "string" === e3) {
            if (!Array.isArray(t3)) throw new TypeError("A string tensor's data must be a string array.");
            o3 = t3;
          } else {
            const n4 = a2.NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(e3);
            if (void 0 === n4) throw new TypeError(`Unsupported tensor type: ${e3}.`);
            if (Array.isArray(t3)) {
              if ("float16" === e3 && n4 === Uint16Array || "uint4" === e3 || "int4" === e3) throw new TypeError(`Creating a ${e3} tensor from number array is not supported. Please use ${n4.name} as data.`);
              o3 = "uint64" === e3 || "int64" === e3 ? n4.from(t3, BigInt) : n4.from(t3);
            } else if (t3 instanceof n4) o3 = t3;
            else if (t3 instanceof Uint8ClampedArray) {
              if ("uint8" !== e3) throw new TypeError("A Uint8ClampedArray tensor's data must be type of uint8");
              o3 = Uint8Array.from(t3);
            } else {
              if (!("float16" === e3 && t3 instanceof Uint16Array && n4 !== Uint16Array)) throw new TypeError(`A ${r3} tensor's data must be type of ${n4}`);
              o3 = new globalThis.Float16Array(t3.buffer, t3.byteOffset, t3.length);
            }
          }
          else if (i4 = t3, Array.isArray(e3)) {
            if (0 === e3.length) throw new TypeError("Tensor type cannot be inferred from an empty array.");
            const t4 = typeof e3[0];
            if ("string" === t4) r3 = "string", o3 = e3;
            else {
              if ("boolean" !== t4) throw new TypeError(`Invalid element type of data array: ${t4}.`);
              r3 = "bool", o3 = Uint8Array.from(e3);
            }
          } else if (e3 instanceof Uint8ClampedArray) r3 = "uint8", o3 = Uint8Array.from(e3);
          else {
            const t4 = a2.NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(e3.constructor);
            if (void 0 === t4) throw new TypeError(`Unsupported type for tensor data: ${e3.constructor}.`);
            r3 = t4, o3 = e3;
          }
          if (void 0 === i4) i4 = [o3.length];
          else if (!Array.isArray(i4)) throw new TypeError("A tensor's dims must be a number array");
          s3 = i4, this.cpuData = o3, this.dataLocation = "cpu";
        }
        const i3 = (0, o2.calculateSize)(s3);
        if (this.cpuData && i3 !== this.cpuData.length && ("uint4" !== r3 && "int4" !== r3 || Math.ceil(i3 / 2) !== this.cpuData.length)) throw new Error(`Tensor's size(${i3}) does not match data length(${this.cpuData.length}).`);
        this.type = r3, this.dims = s3, this.size = i3;
      }
      static async fromImage(e3, t3) {
        return (0, s2.tensorFromImage)(e3, t3);
      }
      static fromTexture(e3, t3) {
        return (0, s2.tensorFromTexture)(e3, t3);
      }
      static fromGpuBuffer(e3, t3) {
        return (0, s2.tensorFromGpuBuffer)(e3, t3);
      }
      static fromMLTensor(e3, t3) {
        return (0, s2.tensorFromMLTensor)(e3, t3);
      }
      static fromPinnedBuffer(e3, t3, n3) {
        return (0, s2.tensorFromPinnedBuffer)(e3, t3, n3);
      }
      toDataURL(e3) {
        return (0, r2.tensorToDataURL)(this, e3);
      }
      toImageData(e3) {
        return (0, r2.tensorToImageData)(this, e3);
      }
      get data() {
        if (this.ensureValid(), !this.cpuData) throw new Error("The data is not on CPU. Use `getData()` to download GPU data to CPU, or use `texture` or `gpuBuffer` property to access the GPU data directly.");
        return this.cpuData;
      }
      get location() {
        return this.dataLocation;
      }
      get texture() {
        if (this.ensureValid(), !this.gpuTextureData) throw new Error("The data is not stored as a WebGL texture.");
        return this.gpuTextureData;
      }
      get gpuBuffer() {
        if (this.ensureValid(), !this.gpuBufferData) throw new Error("The data is not stored as a WebGPU buffer.");
        return this.gpuBufferData;
      }
      get mlTensor() {
        if (this.ensureValid(), !this.mlTensorData) throw new Error("The data is not stored as a WebNN MLTensor.");
        return this.mlTensorData;
      }
      async getData(e3) {
        switch (this.ensureValid(), this.dataLocation) {
          case "cpu":
          case "cpu-pinned":
            return this.data;
          case "texture":
          case "gpu-buffer":
          case "ml-tensor":
            if (!this.downloader) throw new Error("The current tensor is not created with a specified data downloader.");
            if (this.isDownloading) throw new Error("The current tensor is being downloaded.");
            try {
              this.isDownloading = true;
              const t3 = await this.downloader();
              return this.downloader = void 0, this.dataLocation = "cpu", this.cpuData = t3, e3 && this.disposer && (this.disposer(), this.disposer = void 0), t3;
            } finally {
              this.isDownloading = false;
            }
          default:
            throw new Error(`cannot get data from location: ${this.dataLocation}`);
        }
      }
      dispose() {
        if (this.isDownloading) throw new Error("The current tensor is being downloaded.");
        this.disposer && (this.disposer(), this.disposer = void 0), this.cpuData = void 0, this.gpuTextureData = void 0, this.gpuBufferData = void 0, this.mlTensorData = void 0, this.downloader = void 0, this.isDownloading = void 0, this.dataLocation = "none";
      }
      ensureValid() {
        if ("none" === this.dataLocation) throw new Error("The tensor is disposed.");
      }
      reshape(e3) {
        if (this.ensureValid(), this.downloader || this.disposer) throw new Error("Cannot reshape a tensor that owns GPU resource.");
        return (0, o2.tensorReshape)(this, e3);
      }
    }
  }, "./node_modules/onnxruntime-common/dist/esm/tensor-utils-impl.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { calculateSize: () => s2, tensorReshape: () => a2 });
    var r2 = n2("./node_modules/onnxruntime-common/dist/esm/tensor-impl.js");
    const s2 = (e3) => {
      let t3 = 1;
      for (let n3 = 0; n3 < e3.length; n3++) {
        const r3 = e3[n3];
        if ("number" != typeof r3 || !Number.isSafeInteger(r3)) throw new TypeError(`dims[${n3}] must be an integer, got: ${r3}`);
        if (r3 < 0) throw new RangeError(`dims[${n3}] must be a non-negative integer, got: ${r3}`);
        t3 *= r3;
      }
      return t3;
    }, a2 = (e3, t3) => {
      switch (e3.location) {
        case "cpu":
          return new r2.Tensor(e3.type, e3.data, t3);
        case "cpu-pinned":
          return new r2.Tensor({ location: "cpu-pinned", data: e3.data, type: e3.type, dims: t3 });
        case "texture":
          return new r2.Tensor({ location: "texture", texture: e3.texture, type: e3.type, dims: t3 });
        case "gpu-buffer":
          return new r2.Tensor({ location: "gpu-buffer", gpuBuffer: e3.gpuBuffer, type: e3.type, dims: t3 });
        case "ml-tensor":
          return new r2.Tensor({ location: "ml-tensor", mlTensor: e3.mlTensor, type: e3.type, dims: t3 });
        default:
          throw new Error(`tensorReshape: tensor location ${e3.location} is not supported`);
      }
    };
  }, "./node_modules/onnxruntime-common/dist/esm/tensor.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Tensor: () => r2 });
    const r2 = n2("./node_modules/onnxruntime-common/dist/esm/tensor-impl.js").Tensor;
  }, "./node_modules/onnxruntime-common/dist/esm/trace.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { TRACE: () => s2, TRACE_FUNC_BEGIN: () => o2, TRACE_FUNC_END: () => i2 });
    var r2 = n2("./node_modules/onnxruntime-common/dist/esm/env-impl.js");
    const s2 = (e3, t3) => {
      (void 0 === r2.env.trace ? r2.env.wasm.trace : r2.env.trace) && console.timeStamp(`${e3}::ORT::${t3}`);
    }, a2 = (e3, t3) => {
      const n3 = new Error().stack?.split(/\r\n|\r|\n/g) || [];
      let r3 = false;
      for (let a3 = 0; a3 < n3.length; a3++) {
        if (r3 && !n3[a3].includes("TRACE_FUNC")) {
          let r4 = `FUNC_${e3}::${n3[a3].trim().split(" ")[1]}`;
          return t3 && (r4 += `::${t3}`), void s2("CPU", r4);
        }
        n3[a3].includes("TRACE_FUNC") && (r3 = true);
      }
    }, o2 = (e3) => {
      (void 0 === r2.env.trace ? r2.env.wasm.trace : r2.env.trace) && a2("BEGIN", e3);
    }, i2 = (e3) => {
      (void 0 === r2.env.trace ? r2.env.wasm.trace : r2.env.trace) && a2("END", e3);
    };
  }, "./node_modules/onnxruntime-common/dist/esm/version.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { version: () => r2 });
    const r2 = "1.21.0";
  }, "./node_modules/onnxruntime-web/dist/ort.bundle.min.mjs?3a96": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { InferenceSession: () => z2, TRACE: () => S2, TRACE_FUNC_BEGIN: () => E2, TRACE_FUNC_END: () => I2, Tensor: () => C2, default: () => bc2, env: () => p2, registerBackend: () => o2 });
    var r2, s2, a2, o2, i2, l2, d2, u2, c2, p2, m2, h2, f2, _2, g2, w2, b2, y2, M2, x2, v2, T2, k2, P2, $2, C2, S2, F2, E2, I2, A2, z2, L2 = Object.defineProperty, O2 = Object.getOwnPropertyDescriptor, D2 = Object.getOwnPropertyNames, B2 = Object.prototype.hasOwnProperty, N2 = (r2 = function(e3) {
      if (typeof __require < "u") return __require.apply(this, arguments);
      throw Error('Dynamic require of "' + e3 + '" is not supported');
    }, typeof __require < "u" ? __require : typeof Proxy < "u" ? new Proxy(r2, { get: (e3, t3) => (typeof __require < "u" ? __require : e3)[t3] }) : r2), j2 = (e3, t3) => () => (e3 && (t3 = e3(e3 = 0)), t3), R2 = (e3, t3) => {
      for (var n3 in t3) L2(e3, n3, { get: t3[n3], enumerable: true });
    }, V2 = (e3) => ((e4, t3, n3, r3) => {
      if (t3 && "object" == typeof t3 || "function" == typeof t3) for (let s3 of D2(t3)) !B2.call(e4, s3) && s3 !== n3 && L2(e4, s3, { get: () => t3[s3], enumerable: !(r3 = O2(t3, s3)) || r3.enumerable });
      return e4;
    })(L2({}, "__esModule", { value: true }), e3), G2 = j2((() => {
      s2 = /* @__PURE__ */ new Map(), a2 = [], o2 = (e3, t3, n3) => {
        if (!t3 || "function" != typeof t3.init || "function" != typeof t3.createInferenceSessionHandler) throw new TypeError("not a valid backend");
        {
          let r3 = s2.get(e3);
          if (void 0 === r3) s2.set(e3, { backend: t3, priority: n3 });
          else {
            if (r3.priority > n3) return;
            if (r3.priority === n3 && r3.backend !== t3) throw new Error(`cannot register backend "${e3}" using priority ${n3}`);
          }
          if (n3 >= 0) {
            let t4 = a2.indexOf(e3);
            -1 !== t4 && a2.splice(t4, 1);
            for (let t5 = 0; t5 < a2.length; t5++) if (s2.get(a2[t5]).priority <= n3) return void a2.splice(t5, 0, e3);
            a2.push(e3);
          }
        }
      }, i2 = async (e3) => {
        let t3 = s2.get(e3);
        if (!t3) return "backend not found.";
        if (t3.initialized) return t3.backend;
        if (t3.aborted) return t3.error;
        {
          let n3 = !!t3.initPromise;
          try {
            return n3 || (t3.initPromise = t3.backend.init(e3)), await t3.initPromise, t3.initialized = true, t3.backend;
          } catch (e4) {
            return n3 || (t3.error = `${e4}`, t3.aborted = true), t3.error;
          } finally {
            delete t3.initPromise;
          }
        }
      }, l2 = async (e3) => {
        let t3, n3 = e3.executionProviders || [], r3 = n3.map(((e4) => "string" == typeof e4 ? e4 : e4.name)), s3 = 0 === r3.length ? a2 : r3, o3 = [], l3 = /* @__PURE__ */ new Set();
        for (let e4 of s3) {
          let n4 = await i2(e4);
          "string" == typeof n4 ? o3.push({ name: e4, err: n4 }) : (t3 || (t3 = n4), t3 === n4 && l3.add(e4));
        }
        if (!t3) throw new Error(`no available backend found. ERR: ${o3.map(((e4) => `[${e4.name}] ${e4.err}`)).join(", ")}`);
        for (let { name: e4, err: t4 } of o3) r3.includes(e4) && console.warn(`removing requested execution provider "${e4}" from session options because it is not available: ${t4}`);
        let d3 = n3.filter(((e4) => l3.has("string" == typeof e4 ? e4 : e4.name)));
        return [t3, new Proxy(e3, { get: (e4, t4) => "executionProviders" === t4 ? d3 : Reflect.get(e4, t4) })];
      };
    })), q2 = j2((() => {
      G2();
    })), U2 = j2((() => {
      d2 = "1.22.0-dev.20250409-89f8206ba4";
    })), W2 = j2((() => {
      U2(), u2 = "warning", c2 = { wasm: {}, webgl: {}, webgpu: {}, versions: { common: d2 }, set logLevel(e3) {
        if (void 0 !== e3) {
          if ("string" != typeof e3 || -1 === ["verbose", "info", "warning", "error", "fatal"].indexOf(e3)) throw new Error(`Unsupported logging level: ${e3}`);
          u2 = e3;
        }
      }, get logLevel() {
        return u2;
      } }, Object.defineProperty(c2, "logLevel", { enumerable: true });
    })), H2 = j2((() => {
      W2(), p2 = c2;
    })), Q2 = j2((() => {
      m2 = (e3, t3) => {
        let n3 = typeof document < "u" ? document.createElement("canvas") : new OffscreenCanvas(1, 1);
        n3.width = e3.dims[3], n3.height = e3.dims[2];
        let r3 = n3.getContext("2d");
        if (null != r3) {
          let s3, a3;
          void 0 !== t3?.tensorLayout && "NHWC" === t3.tensorLayout ? (s3 = e3.dims[2], a3 = e3.dims[3]) : (s3 = e3.dims[3], a3 = e3.dims[2]);
          let o3, i3, l3 = void 0 !== t3?.format ? t3.format : "RGB", d3 = t3?.norm;
          void 0 === d3 || void 0 === d3.mean ? o3 = [255, 255, 255, 255] : "number" == typeof d3.mean ? o3 = [d3.mean, d3.mean, d3.mean, d3.mean] : (o3 = [d3.mean[0], d3.mean[1], d3.mean[2], 0], void 0 !== d3.mean[3] && (o3[3] = d3.mean[3])), void 0 === d3 || void 0 === d3.bias ? i3 = [0, 0, 0, 0] : "number" == typeof d3.bias ? i3 = [d3.bias, d3.bias, d3.bias, d3.bias] : (i3 = [d3.bias[0], d3.bias[1], d3.bias[2], 0], void 0 !== d3.bias[3] && (i3[3] = d3.bias[3]));
          let u3 = a3 * s3, c3 = 0, p3 = u3, m3 = 2 * u3, h3 = -1;
          "RGBA" === l3 ? (c3 = 0, p3 = u3, m3 = 2 * u3, h3 = 3 * u3) : "RGB" === l3 ? (c3 = 0, p3 = u3, m3 = 2 * u3) : "RBG" === l3 && (c3 = 0, m3 = u3, p3 = 2 * u3);
          for (let t4 = 0; t4 < a3; t4++) for (let n4 = 0; n4 < s3; n4++) {
            let s4 = (e3.data[c3++] - i3[0]) * o3[0], a4 = (e3.data[p3++] - i3[1]) * o3[1], l4 = (e3.data[m3++] - i3[2]) * o3[2], d4 = -1 === h3 ? 255 : (e3.data[h3++] - i3[3]) * o3[3];
            r3.fillStyle = "rgba(" + s4 + "," + a4 + "," + l4 + "," + d4 + ")", r3.fillRect(n4, t4, 1, 1);
          }
          if ("toDataURL" in n3) return n3.toDataURL();
          throw new Error("toDataURL is not supported");
        }
        throw new Error("Can not access image data");
      }, h2 = (e3, t3) => {
        let n3, r3 = typeof document < "u" ? document.createElement("canvas").getContext("2d") : new OffscreenCanvas(1, 1).getContext("2d");
        if (null == r3) throw new Error("Can not access image data");
        {
          let s3, a3, o3;
          void 0 !== t3?.tensorLayout && "NHWC" === t3.tensorLayout ? (s3 = e3.dims[2], a3 = e3.dims[1], o3 = e3.dims[3]) : (s3 = e3.dims[3], a3 = e3.dims[2], o3 = e3.dims[1]);
          let i3, l3, d3 = void 0 !== t3 && void 0 !== t3.format ? t3.format : "RGB", u3 = t3?.norm;
          void 0 === u3 || void 0 === u3.mean ? i3 = [255, 255, 255, 255] : "number" == typeof u3.mean ? i3 = [u3.mean, u3.mean, u3.mean, u3.mean] : (i3 = [u3.mean[0], u3.mean[1], u3.mean[2], 255], void 0 !== u3.mean[3] && (i3[3] = u3.mean[3])), void 0 === u3 || void 0 === u3.bias ? l3 = [0, 0, 0, 0] : "number" == typeof u3.bias ? l3 = [u3.bias, u3.bias, u3.bias, u3.bias] : (l3 = [u3.bias[0], u3.bias[1], u3.bias[2], 0], void 0 !== u3.bias[3] && (l3[3] = u3.bias[3]));
          let c3 = a3 * s3;
          if (void 0 !== t3 && (void 0 !== t3.format && 4 === o3 && "RGBA" !== t3.format || 3 === o3 && "RGB" !== t3.format && "BGR" !== t3.format)) throw new Error("Tensor format doesn't match input tensor dims");
          let p3 = 4, m3 = 0, h3 = 1, f3 = 2, _3 = 3, g3 = 0, w3 = c3, b3 = 2 * c3, y3 = -1;
          "RGBA" === d3 ? (g3 = 0, w3 = c3, b3 = 2 * c3, y3 = 3 * c3) : "RGB" === d3 ? (g3 = 0, w3 = c3, b3 = 2 * c3) : "RBG" === d3 && (g3 = 0, b3 = c3, w3 = 2 * c3), n3 = r3.createImageData(s3, a3);
          for (let t4 = 0; t4 < a3 * s3; m3 += p3, h3 += p3, f3 += p3, _3 += p3, t4++) n3.data[m3] = (e3.data[g3++] - l3[0]) * i3[0], n3.data[h3] = (e3.data[w3++] - l3[1]) * i3[1], n3.data[f3] = (e3.data[b3++] - l3[2]) * i3[2], n3.data[_3] = -1 === y3 ? 255 : (e3.data[y3++] - l3[3]) * i3[3];
        }
        return n3;
      };
    })), K2 = j2((() => {
      Y2(), f2 = (e3, t3) => {
        if (void 0 === e3) throw new Error("Image buffer must be defined");
        if (void 0 === t3.height || void 0 === t3.width) throw new Error("Image height and width must be defined");
        if ("NHWC" === t3.tensorLayout) throw new Error("NHWC Tensor layout is not supported yet");
        let n3, r3, { height: s3, width: a3 } = t3, o3 = t3.norm ?? { mean: 255, bias: 0 };
        n3 = "number" == typeof o3.mean ? [o3.mean, o3.mean, o3.mean, o3.mean] : [o3.mean[0], o3.mean[1], o3.mean[2], o3.mean[3] ?? 255], r3 = "number" == typeof o3.bias ? [o3.bias, o3.bias, o3.bias, o3.bias] : [o3.bias[0], o3.bias[1], o3.bias[2], o3.bias[3] ?? 0];
        let i3 = void 0 !== t3.format ? t3.format : "RGBA", l3 = void 0 !== t3.tensorFormat && void 0 !== t3.tensorFormat ? t3.tensorFormat : "RGB", d3 = s3 * a3, u3 = "RGBA" === l3 ? new Float32Array(4 * d3) : new Float32Array(3 * d3), c3 = 4, p3 = 0, m3 = 1, h3 = 2, f3 = 3, _3 = 0, g3 = d3, w3 = 2 * d3, b3 = -1;
        "RGB" === i3 && (c3 = 3, p3 = 0, m3 = 1, h3 = 2, f3 = -1), "RGBA" === l3 ? b3 = 3 * d3 : "RBG" === l3 ? (_3 = 0, w3 = d3, g3 = 2 * d3) : "BGR" === l3 && (w3 = 0, g3 = d3, _3 = 2 * d3);
        for (let t4 = 0; t4 < d3; t4++, p3 += c3, h3 += c3, m3 += c3, f3 += c3) u3[_3++] = (e3[p3] + r3[0]) / n3[0], u3[g3++] = (e3[m3] + r3[1]) / n3[1], u3[w3++] = (e3[h3] + r3[2]) / n3[2], -1 !== b3 && -1 !== f3 && (u3[b3++] = (e3[f3] + r3[3]) / n3[3]);
        return new $2("float32", u3, "RGBA" === l3 ? [1, 4, s3, a3] : [1, 3, s3, a3]);
      }, _2 = async (e3, t3) => {
        let n3, r3 = typeof HTMLImageElement < "u" && e3 instanceof HTMLImageElement, s3 = typeof ImageData < "u" && e3 instanceof ImageData, a3 = typeof ImageBitmap < "u" && e3 instanceof ImageBitmap, o3 = "string" == typeof e3, i3 = t3 ?? {}, l3 = () => {
          if (typeof document < "u") return document.createElement("canvas");
          if (typeof OffscreenCanvas < "u") return new OffscreenCanvas(1, 1);
          throw new Error("Canvas is not supported");
        }, d3 = (e4) => typeof HTMLCanvasElement < "u" && e4 instanceof HTMLCanvasElement || e4 instanceof OffscreenCanvas ? e4.getContext("2d") : null;
        if (r3) {
          let r4 = l3();
          r4.width = e3.width, r4.height = e3.height;
          let s4 = d3(r4);
          if (null == s4) throw new Error("Can not access image data");
          {
            let r5 = e3.height, a4 = e3.width;
            if (void 0 !== t3 && void 0 !== t3.resizedHeight && void 0 !== t3.resizedWidth && (r5 = t3.resizedHeight, a4 = t3.resizedWidth), void 0 !== t3) {
              if (i3 = t3, void 0 !== t3.tensorFormat) throw new Error("Image input config format must be RGBA for HTMLImageElement");
              i3.tensorFormat = "RGBA", i3.height = r5, i3.width = a4;
            } else i3.tensorFormat = "RGBA", i3.height = r5, i3.width = a4;
            s4.drawImage(e3, 0, 0), n3 = s4.getImageData(0, 0, a4, r5).data;
          }
        } else {
          if (!s3) {
            if (a3) {
              if (void 0 === t3) throw new Error("Please provide image config with format for Imagebitmap");
              let r4 = l3();
              r4.width = e3.width, r4.height = e3.height;
              let s4 = d3(r4);
              if (null != s4) {
                let t4 = e3.height, r5 = e3.width;
                return s4.drawImage(e3, 0, 0, r5, t4), n3 = s4.getImageData(0, 0, r5, t4).data, i3.height = t4, i3.width = r5, f2(n3, i3);
              }
              throw new Error("Can not access image data");
            }
            if (o3) return new Promise(((t4, n4) => {
              let r4 = l3(), s4 = d3(r4);
              if (!e3 || !s4) return n4();
              let a4 = new Image();
              a4.crossOrigin = "Anonymous", a4.src = e3, a4.onload = () => {
                r4.width = a4.width, r4.height = a4.height, s4.drawImage(a4, 0, 0, r4.width, r4.height);
                let e4 = s4.getImageData(0, 0, r4.width, r4.height);
                i3.height = r4.height, i3.width = r4.width, t4(f2(e4.data, i3));
              };
            }));
            throw new Error("Input data provided is not supported - aborted tensor creation");
          }
          {
            let r4, s4;
            if (void 0 !== t3 && void 0 !== t3.resizedWidth && void 0 !== t3.resizedHeight ? (r4 = t3.resizedHeight, s4 = t3.resizedWidth) : (r4 = e3.height, s4 = e3.width), void 0 !== t3 && (i3 = t3), i3.format = "RGBA", i3.height = r4, i3.width = s4, void 0 !== t3) {
              let t4 = l3();
              t4.width = s4, t4.height = r4;
              let a4 = d3(t4);
              if (null == a4) throw new Error("Can not access image data");
              a4.putImageData(e3, 0, 0), n3 = a4.getImageData(0, 0, s4, r4).data;
            } else n3 = e3.data;
          }
        }
        if (void 0 !== n3) return f2(n3, i3);
        throw new Error("Input data provided is not supported - aborted tensor creation");
      }, g2 = (e3, t3) => {
        let { width: n3, height: r3, download: s3, dispose: a3 } = t3;
        return new $2({ location: "texture", type: "float32", texture: e3, dims: [1, r3, n3, 4], download: s3, dispose: a3 });
      }, w2 = (e3, t3) => {
        let { dataType: n3, dims: r3, download: s3, dispose: a3 } = t3;
        return new $2({ location: "gpu-buffer", type: n3 ?? "float32", gpuBuffer: e3, dims: r3, download: s3, dispose: a3 });
      }, b2 = (e3, t3) => {
        let { dataType: n3, dims: r3, download: s3, dispose: a3 } = t3;
        return new $2({ location: "ml-tensor", type: n3 ?? "float32", mlTensor: e3, dims: r3, download: s3, dispose: a3 });
      }, y2 = (e3, t3, n3) => new $2({ location: "cpu-pinned", type: e3, data: t3, dims: n3 ?? [t3.length] });
    })), X2 = j2((() => {
      M2 = /* @__PURE__ */ new Map([["float32", Float32Array], ["uint8", Uint8Array], ["int8", Int8Array], ["uint16", Uint16Array], ["int16", Int16Array], ["int32", Int32Array], ["bool", Uint8Array], ["float64", Float64Array], ["uint32", Uint32Array], ["int4", Uint8Array], ["uint4", Uint8Array]]), x2 = /* @__PURE__ */ new Map([[Float32Array, "float32"], [Uint8Array, "uint8"], [Int8Array, "int8"], [Uint16Array, "uint16"], [Int16Array, "int16"], [Int32Array, "int32"], [Float64Array, "float64"], [Uint32Array, "uint32"]]), v2 = false, T2 = () => {
        if (!v2) {
          v2 = true;
          let e3 = typeof BigInt64Array < "u" && BigInt64Array.from, t3 = typeof BigUint64Array < "u" && BigUint64Array.from, n3 = globalThis.Float16Array, r3 = typeof n3 < "u" && n3.from;
          e3 && (M2.set("int64", BigInt64Array), x2.set(BigInt64Array, "int64")), t3 && (M2.set("uint64", BigUint64Array), x2.set(BigUint64Array, "uint64")), r3 ? (M2.set("float16", n3), x2.set(n3, "float16")) : M2.set("float16", Uint16Array);
        }
      };
    })), J2 = j2((() => {
      Y2(), k2 = (e3) => {
        let t3 = 1;
        for (let n3 = 0; n3 < e3.length; n3++) {
          let r3 = e3[n3];
          if ("number" != typeof r3 || !Number.isSafeInteger(r3)) throw new TypeError(`dims[${n3}] must be an integer, got: ${r3}`);
          if (r3 < 0) throw new RangeError(`dims[${n3}] must be a non-negative integer, got: ${r3}`);
          t3 *= r3;
        }
        return t3;
      }, P2 = (e3, t3) => {
        switch (e3.location) {
          case "cpu":
            return new $2(e3.type, e3.data, t3);
          case "cpu-pinned":
            return new $2({ location: "cpu-pinned", data: e3.data, type: e3.type, dims: t3 });
          case "texture":
            return new $2({ location: "texture", texture: e3.texture, type: e3.type, dims: t3 });
          case "gpu-buffer":
            return new $2({ location: "gpu-buffer", gpuBuffer: e3.gpuBuffer, type: e3.type, dims: t3 });
          case "ml-tensor":
            return new $2({ location: "ml-tensor", mlTensor: e3.mlTensor, type: e3.type, dims: t3 });
          default:
            throw new Error(`tensorReshape: tensor location ${e3.location} is not supported`);
        }
      };
    })), Y2 = j2((() => {
      Q2(), K2(), X2(), J2(), $2 = class {
        constructor(e3, t3, n3) {
          let r3, s3;
          if (T2(), "object" == typeof e3 && "location" in e3) switch (this.dataLocation = e3.location, r3 = e3.type, s3 = e3.dims, e3.location) {
            case "cpu-pinned": {
              let t4 = M2.get(r3);
              if (!t4) throw new TypeError(`unsupported type "${r3}" to create tensor from pinned buffer`);
              if (!(e3.data instanceof t4)) throw new TypeError(`buffer should be of type ${t4.name}`);
              this.cpuData = e3.data;
              break;
            }
            case "texture":
              if ("float32" !== r3) throw new TypeError(`unsupported type "${r3}" to create tensor from texture`);
              this.gpuTextureData = e3.texture, this.downloader = e3.download, this.disposer = e3.dispose;
              break;
            case "gpu-buffer":
              if ("float32" !== r3 && "float16" !== r3 && "int32" !== r3 && "int64" !== r3 && "uint32" !== r3 && "uint8" !== r3 && "bool" !== r3 && "uint4" !== r3 && "int4" !== r3) throw new TypeError(`unsupported type "${r3}" to create tensor from gpu buffer`);
              this.gpuBufferData = e3.gpuBuffer, this.downloader = e3.download, this.disposer = e3.dispose;
              break;
            case "ml-tensor":
              if ("float32" !== r3 && "float16" !== r3 && "int32" !== r3 && "int64" !== r3 && "uint32" !== r3 && "uint64" !== r3 && "int8" !== r3 && "uint8" !== r3 && "bool" !== r3 && "uint4" !== r3 && "int4" !== r3) throw new TypeError(`unsupported type "${r3}" to create tensor from MLTensor`);
              this.mlTensorData = e3.mlTensor, this.downloader = e3.download, this.disposer = e3.dispose;
              break;
            default:
              throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);
          }
          else {
            let a4, o3;
            if ("string" == typeof e3) if (r3 = e3, o3 = n3, "string" === e3) {
              if (!Array.isArray(t3)) throw new TypeError("A string tensor's data must be a string array.");
              a4 = t3;
            } else {
              let n4 = M2.get(e3);
              if (void 0 === n4) throw new TypeError(`Unsupported tensor type: ${e3}.`);
              if (Array.isArray(t3)) {
                if ("float16" === e3 && n4 === Uint16Array || "uint4" === e3 || "int4" === e3) throw new TypeError(`Creating a ${e3} tensor from number array is not supported. Please use ${n4.name} as data.`);
                a4 = "uint64" === e3 || "int64" === e3 ? n4.from(t3, BigInt) : n4.from(t3);
              } else if (t3 instanceof n4) a4 = t3;
              else if (t3 instanceof Uint8ClampedArray) {
                if ("uint8" !== e3) throw new TypeError("A Uint8ClampedArray tensor's data must be type of uint8");
                a4 = Uint8Array.from(t3);
              } else {
                if (!("float16" === e3 && t3 instanceof Uint16Array && n4 !== Uint16Array)) throw new TypeError(`A ${r3} tensor's data must be type of ${n4}`);
                a4 = new globalThis.Float16Array(t3.buffer, t3.byteOffset, t3.length);
              }
            }
            else if (o3 = t3, Array.isArray(e3)) {
              if (0 === e3.length) throw new TypeError("Tensor type cannot be inferred from an empty array.");
              let t4 = typeof e3[0];
              if ("string" === t4) r3 = "string", a4 = e3;
              else {
                if ("boolean" !== t4) throw new TypeError(`Invalid element type of data array: ${t4}.`);
                r3 = "bool", a4 = Uint8Array.from(e3);
              }
            } else if (e3 instanceof Uint8ClampedArray) r3 = "uint8", a4 = Uint8Array.from(e3);
            else {
              let t4 = x2.get(e3.constructor);
              if (void 0 === t4) throw new TypeError(`Unsupported type for tensor data: ${e3.constructor}.`);
              r3 = t4, a4 = e3;
            }
            if (void 0 === o3) o3 = [a4.length];
            else if (!Array.isArray(o3)) throw new TypeError("A tensor's dims must be a number array");
            s3 = o3, this.cpuData = a4, this.dataLocation = "cpu";
          }
          let a3 = k2(s3);
          if (this.cpuData && a3 !== this.cpuData.length && ("uint4" !== r3 && "int4" !== r3 || Math.ceil(a3 / 2) !== this.cpuData.length)) throw new Error(`Tensor's size(${a3}) does not match data length(${this.cpuData.length}).`);
          this.type = r3, this.dims = s3, this.size = a3;
        }
        static async fromImage(e3, t3) {
          return _2(e3, t3);
        }
        static fromTexture(e3, t3) {
          return g2(e3, t3);
        }
        static fromGpuBuffer(e3, t3) {
          return w2(e3, t3);
        }
        static fromMLTensor(e3, t3) {
          return b2(e3, t3);
        }
        static fromPinnedBuffer(e3, t3, n3) {
          return y2(e3, t3, n3);
        }
        toDataURL(e3) {
          return m2(this, e3);
        }
        toImageData(e3) {
          return h2(this, e3);
        }
        get data() {
          if (this.ensureValid(), !this.cpuData) throw new Error("The data is not on CPU. Use `getData()` to download GPU data to CPU, or use `texture` or `gpuBuffer` property to access the GPU data directly.");
          return this.cpuData;
        }
        get location() {
          return this.dataLocation;
        }
        get texture() {
          if (this.ensureValid(), !this.gpuTextureData) throw new Error("The data is not stored as a WebGL texture.");
          return this.gpuTextureData;
        }
        get gpuBuffer() {
          if (this.ensureValid(), !this.gpuBufferData) throw new Error("The data is not stored as a WebGPU buffer.");
          return this.gpuBufferData;
        }
        get mlTensor() {
          if (this.ensureValid(), !this.mlTensorData) throw new Error("The data is not stored as a WebNN MLTensor.");
          return this.mlTensorData;
        }
        async getData(e3) {
          switch (this.ensureValid(), this.dataLocation) {
            case "cpu":
            case "cpu-pinned":
              return this.data;
            case "texture":
            case "gpu-buffer":
            case "ml-tensor":
              if (!this.downloader) throw new Error("The current tensor is not created with a specified data downloader.");
              if (this.isDownloading) throw new Error("The current tensor is being downloaded.");
              try {
                this.isDownloading = true;
                let t3 = await this.downloader();
                return this.downloader = void 0, this.dataLocation = "cpu", this.cpuData = t3, e3 && this.disposer && (this.disposer(), this.disposer = void 0), t3;
              } finally {
                this.isDownloading = false;
              }
            default:
              throw new Error(`cannot get data from location: ${this.dataLocation}`);
          }
        }
        dispose() {
          if (this.isDownloading) throw new Error("The current tensor is being downloaded.");
          this.disposer && (this.disposer(), this.disposer = void 0), this.cpuData = void 0, this.gpuTextureData = void 0, this.gpuBufferData = void 0, this.mlTensorData = void 0, this.downloader = void 0, this.isDownloading = void 0, this.dataLocation = "none";
        }
        ensureValid() {
          if ("none" === this.dataLocation) throw new Error("The tensor is disposed.");
        }
        reshape(e3) {
          if (this.ensureValid(), this.downloader || this.disposer) throw new Error("Cannot reshape a tensor that owns GPU resource.");
          return P2(this, e3);
        }
      };
    })), Z2 = j2((() => {
      Y2(), C2 = $2;
    })), ee2 = j2((() => {
      W2(), S2 = (e3, t3) => {
        (typeof c2.trace > "u" ? !c2.wasm.trace : !c2.trace) || console.timeStamp(`${e3}::ORT::${t3}`);
      }, F2 = (e3, t3) => {
        let n3 = new Error().stack?.split(/\r\n|\r|\n/g) || [], r3 = false;
        for (let s3 = 0; s3 < n3.length; s3++) {
          if (r3 && !n3[s3].includes("TRACE_FUNC")) {
            let r4 = `FUNC_${e3}::${n3[s3].trim().split(" ")[1]}`;
            return t3 && (r4 += `::${t3}`), void S2("CPU", r4);
          }
          n3[s3].includes("TRACE_FUNC") && (r3 = true);
        }
      }, E2 = (e3) => {
        (typeof c2.trace > "u" ? !c2.wasm.trace : !c2.trace) || F2("BEGIN", e3);
      }, I2 = (e3) => {
        (typeof c2.trace > "u" ? !c2.wasm.trace : !c2.trace) || F2("END", e3);
      };
    })), te2 = j2((() => {
      G2(), Z2(), ee2(), A2 = class e3 {
        constructor(e4) {
          this.handler = e4;
        }
        async run(e4, t3, n3) {
          E2();
          let r3 = {}, s3 = {};
          if ("object" != typeof e4 || null === e4 || e4 instanceof C2 || Array.isArray(e4)) throw new TypeError("'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.");
          let a3 = true;
          if ("object" == typeof t3) {
            if (null === t3) throw new TypeError("Unexpected argument[1]: cannot be null.");
            if (t3 instanceof C2) throw new TypeError("'fetches' cannot be a Tensor");
            if (Array.isArray(t3)) {
              if (0 === t3.length) throw new TypeError("'fetches' cannot be an empty array.");
              a3 = false;
              for (let e5 of t3) {
                if ("string" != typeof e5) throw new TypeError("'fetches' must be a string array or an object.");
                if (-1 === this.outputNames.indexOf(e5)) throw new RangeError(`'fetches' contains invalid output name: ${e5}.`);
                r3[e5] = null;
              }
              if ("object" == typeof n3 && null !== n3) s3 = n3;
              else if (typeof n3 < "u") throw new TypeError("'options' must be an object.");
            } else {
              let e5 = false, o4 = Object.getOwnPropertyNames(t3);
              for (let n4 of this.outputNames) if (-1 !== o4.indexOf(n4)) {
                let s4 = t3[n4];
                (null === s4 || s4 instanceof C2) && (e5 = true, a3 = false, r3[n4] = s4);
              }
              if (e5) {
                if ("object" == typeof n3 && null !== n3) s3 = n3;
                else if (typeof n3 < "u") throw new TypeError("'options' must be an object.");
              } else s3 = t3;
            }
          } else if (typeof t3 < "u") throw new TypeError("Unexpected argument[1]: must be 'fetches' or 'options'.");
          for (let t4 of this.inputNames) if (typeof e4[t4] > "u") throw new Error(`input '${t4}' is missing in 'feeds'.`);
          if (a3) for (let e5 of this.outputNames) r3[e5] = null;
          let o3 = await this.handler.run(e4, r3, s3), i3 = {};
          for (let e5 in o3) if (Object.hasOwnProperty.call(o3, e5)) {
            let t4 = o3[e5];
            i3[e5] = t4 instanceof C2 ? t4 : new C2(t4.type, t4.data, t4.dims);
          }
          return I2(), i3;
        }
        async release() {
          return this.handler.dispose();
        }
        static async create(t3, n3, r3, s3) {
          E2();
          let a3, o3 = {};
          if ("string" == typeof t3) {
            if (a3 = t3, "object" == typeof n3 && null !== n3) o3 = n3;
            else if (typeof n3 < "u") throw new TypeError("'options' must be an object.");
          } else if (t3 instanceof Uint8Array) {
            if (a3 = t3, "object" == typeof n3 && null !== n3) o3 = n3;
            else if (typeof n3 < "u") throw new TypeError("'options' must be an object.");
          } else {
            if (!(t3 instanceof ArrayBuffer || typeof SharedArrayBuffer < "u" && t3 instanceof SharedArrayBuffer)) throw new TypeError("Unexpected argument[0]: must be 'path' or 'buffer'.");
            {
              let e4 = t3, i4 = 0, l3 = t3.byteLength;
              if ("object" == typeof n3 && null !== n3) o3 = n3;
              else if ("number" == typeof n3) {
                if (i4 = n3, !Number.isSafeInteger(i4)) throw new RangeError("'byteOffset' must be an integer.");
                if (i4 < 0 || i4 >= e4.byteLength) throw new RangeError(`'byteOffset' is out of range [0, ${e4.byteLength}).`);
                if (l3 = t3.byteLength - i4, "number" == typeof r3) {
                  if (l3 = r3, !Number.isSafeInteger(l3)) throw new RangeError("'byteLength' must be an integer.");
                  if (l3 <= 0 || i4 + l3 > e4.byteLength) throw new RangeError(`'byteLength' is out of range (0, ${e4.byteLength - i4}].`);
                  if ("object" == typeof s3 && null !== s3) o3 = s3;
                  else if (typeof s3 < "u") throw new TypeError("'options' must be an object.");
                } else if (typeof r3 < "u") throw new TypeError("'byteLength' must be a number.");
              } else if (typeof n3 < "u") throw new TypeError("'options' must be an object.");
              a3 = new Uint8Array(e4, i4, l3);
            }
          }
          let [i3, d3] = await l2(o3), u3 = await i3.createInferenceSessionHandler(a3, d3);
          return I2(), new e3(u3);
        }
        startProfiling() {
          this.handler.startProfiling();
        }
        endProfiling() {
          this.handler.endProfiling();
        }
        get inputNames() {
          return this.handler.inputNames;
        }
        get outputNames() {
          return this.handler.outputNames;
        }
        get inputMetadata() {
          return this.handler.inputMetadata;
        }
        get outputMetadata() {
          return this.handler.outputMetadata;
        }
      };
    })), ne2 = j2((() => {
      te2(), z2 = A2;
    })), re2 = j2((() => {
    })), se2 = j2((() => {
    })), ae2 = j2((() => {
    })), oe2 = j2((() => {
    })), ie2 = {};
    R2(ie2, { InferenceSession: () => z2, TRACE: () => S2, TRACE_FUNC_BEGIN: () => E2, TRACE_FUNC_END: () => I2, Tensor: () => C2, env: () => p2, registerBackend: () => o2 });
    var le2 = j2((() => {
      q2(), H2(), ne2(), Z2(), re2(), se2(), ee2(), ae2(), oe2();
    })), de2 = j2((() => {
    })), ue2 = {};
    R2(ue2, { default: () => me2 });
    var ce2, pe2, me2, he2 = j2((() => {
      cc2(), ad2(), sd2(), ce2 = "ort-wasm-proxy-worker", (pe2 = globalThis.self?.name === ce2) && (self.onmessage = (e3) => {
        let { type: t3, in: n3 } = e3.data;
        try {
          switch (t3) {
            case "init-wasm":
              Re2(n3.wasm).then((() => {
                Eu2(n3).then((() => {
                  postMessage({ type: t3 });
                }), ((e4) => {
                  postMessage({ type: t3, err: e4 });
                }));
              }), ((e4) => {
                postMessage({ type: t3, err: e4 });
              }));
              break;
            case "init-ep": {
              let { epName: e4, env: r3 } = n3;
              Iu2(r3, e4).then((() => {
                postMessage({ type: t3 });
              }), ((e5) => {
                postMessage({ type: t3, err: e5 });
              }));
              break;
            }
            case "copy-from": {
              let { buffer: e4 } = n3, r3 = Ou2(e4);
              postMessage({ type: t3, out: r3 });
              break;
            }
            case "create": {
              let { model: e4, options: r3 } = n3;
              Du2(e4, r3).then(((e5) => {
                postMessage({ type: t3, out: e5 });
              }), ((e5) => {
                postMessage({ type: t3, err: e5 });
              }));
              break;
            }
            case "release":
              Bu2(n3), postMessage({ type: t3 });
              break;
            case "run": {
              let { sessionId: e4, inputIndices: r3, inputs: s3, outputIndices: a3, options: o3 } = n3;
              ju2(e4, r3, s3, a3, new Array(a3.length).fill(null), o3).then(((e5) => {
                e5.some(((e6) => "cpu" !== e6[3])) ? postMessage({ type: t3, err: "Proxy does not support non-cpu tensor location." }) : postMessage({ type: t3, out: e5 }, Vu2([...s3, ...e5]));
              }), ((e5) => {
                postMessage({ type: t3, err: e5 });
              }));
              break;
            }
            case "end-profiling":
              Ru2(n3), postMessage({ type: t3 });
          }
        } catch (e4) {
          postMessage({ type: t3, err: e4 });
        }
      }), me2 = pe2 ? null : (e3) => new Worker(e3 ?? ve2, { type: "module", name: ce2 });
    })), fe2 = {};
    R2(fe2, { default: () => we2 });
    var _e2, ge2, we2, be2, ye2, Me2, xe2, ve2, Te2, ke2, Pe2, $e2, Ce2, Se2, Fe2, Ee2, Ie2, Ae2, ze2, Le2, Oe2, De2, Be2, Ne2, je2, Re2, Ve2, Ge2, qe2, Ue2, We2, He2, Qe2, Ke2, Xe2, Je2, Ye2, Ze2, et2, tt2, nt2, rt2, st2, at2, ot2, it2, lt2, dt2, ut2, ct2, pt2, mt2, ht2, ft2, _t2, gt2, wt2, bt2, yt2, Mt2, xt2, vt2, Tt2, kt2, Pt2, $t2, Ct2, St2, Ft2, Et2, It2, At2, zt2, Lt2, Ot2, Dt2, Bt2, Nt2, jt2, Rt2, Vt2, Gt2, qt2, Ut2, Wt2, Ht2, Qt2, Kt2, Xt2, Jt2, Yt2, Zt2, en2, tn2, nn2, rn2, sn2, an2, on2, ln2, dn2, un2, cn2, pn2, mn2, hn2, fn2, _n2, gn2, wn2, bn2, yn2, Mn2, xn2, vn2, Tn2, kn2, Pn2, $n2, Cn2, Sn2, Fn2, En2, In2, An2, zn2, Ln2, On2, Dn2, Bn2, Nn2, jn2, Rn2, Vn2, Gn2, qn2, Un2, Wn2, Hn2, Qn2, Kn2, Xn2, Jn2, Yn2, Zn2, er2, tr2, nr2, rr2, sr2, ar2, or2, ir2, lr2, dr2, ur2, cr2, pr2, mr2, hr2, fr2, _r2, gr2, wr2, br2, yr2, Mr2, xr2, vr2, Tr2, kr2, Pr2, $r2, Cr2, Sr2, Fr2, Er2, Ir2, Ar2, zr2, Lr2, Or2, Dr2, Br2, Nr2, jr2, Rr2, Vr2, Gr2, qr2, Ur2, Wr2, Hr2, Qr2, Kr2, Xr2, Jr2, Yr2, Zr2, es2, ts2, ns2, rs2, ss2, as2, os2, is2, ls2, ds2, us2, cs2, ps2, ms2, hs2, fs2, _s2, gs2, ws2, bs2, ys2, Ms2, xs2, vs2, Ts2, ks2, Ps2, $s2, Cs2, Ss2, Fs2, Es2, Is2, As2, zs2, Ls2, Os2, Ds2, Bs2, Ns2, js2, Rs2, Vs2, Gs2, qs2, Us2, Ws2, Hs2, Qs2, Ks2, Xs2, Js2, Ys2, Zs2, ea2, ta2, na2, ra2, sa2, aa2, oa2, ia2, la2, da2, ua2, ca2, pa2, ma2, ha2, fa2, _a2, ga2, wa2, ba2, ya2, Ma2, xa2, va2, Ta2, ka2, Pa2, $a2, Ca2, Sa2, Fa2, Ea2, Ia2, Aa2, za2, La2, Oa2, Da2, Ba2, Na2, ja2, Ra2, Va2, Ga2, qa2, Ua2, Wa2, Ha2, Qa2, Ka2, Xa2, Ja2, Ya2, Za2, eo2, to2, no2, ro2, so2, ao2, oo2, io2, lo2, uo2, co2, po2, mo2, ho2, fo2, _o2, go2, wo2, bo2, yo2, Mo2, xo2, vo2, To2, ko2, Po2, $o2, Co2, So2, Fo2, Eo2, Io2, Ao2, zo2, Lo2, Oo2, Do2, Bo2, No2, jo2, Ro2, Vo2, Go2, qo2, Uo2, Wo2, Ho2, Qo2, Ko2, Xo2, Jo2, Yo2, Zo2, ei2, ti2, ni2, ri2, si2, ai2, oi2, ii2, li2, di2, ui2, ci2, pi2, mi2, hi2, fi2, _i2, gi2, wi2, bi2, yi2, Mi2, xi2, vi2, Ti2, ki2, Pi2, $i2, Ci2, Si2, Fi2, Ei2, Ii2, Ai2, zi2, Li2, Oi2, Di2, Bi2, Ni2, ji2, Ri2, Vi2, Gi2, qi2, Ui2, Wi2, Hi2, Qi2, Ki2, Xi2, Ji2, Yi2, Zi2, el2, tl2, nl2, rl2, sl2, al2, ol2, il2, ll2, dl2, ul2, cl2, pl2, ml2, hl2, fl2, _l2, gl2, wl2, bl2, yl2, Ml2, xl2, vl2, Tl2, kl2, Pl2, $l2, Cl2, Sl2, Fl2, El2, Il2, Al2, zl2, Ll2, Ol2, Dl2, Bl2, Nl2, jl2, Rl2, Vl2, Gl2, ql2, Ul2, Wl2, Hl2, Ql2, Kl2, Xl2, Jl2, Yl2, Zl2, ed2, td2, nd2, rd2 = j2((() => {
      _e2 = import_meta.url, ge2 = async function(e3 = {}) {
        var t3, r3, s3 = e3, a3 = new Promise(((e4, n3) => {
          t3 = e4, r3 = n3;
        })), o3 = "object" == typeof window, i3 = typeof WorkerGlobalScope < "u", l3 = i3 && self.name?.startsWith("em-pthread");
        s3.mountExternalData = (e4, t4) => {
          e4.startsWith("./") && (e4 = e4.substring(2)), (s3.Eb || (s3.Eb = /* @__PURE__ */ new Map())).set(e4, t4);
        }, s3.unmountExternalData = () => {
          delete s3.Eb;
        };
        var d3 = globalThis.SharedArrayBuffer ?? new WebAssembly.Memory({ initial: 0, maximum: 0, pc: true }).buffer.constructor;
        let u3 = (e4) => async (...t4) => {
          try {
            if (s3.Fb) throw Error("Session already started");
            let n3 = s3.Fb = { dc: t4[0], errors: [] }, r4 = await e4(...t4);
            if (s3.Fb !== n3) throw Error("Session mismatch");
            s3.Jb?.flush();
            let a4 = n3.errors;
            if (0 < a4.length) {
              let e5 = await Promise.all(a4);
              if (e5 = e5.filter(((e6) => e6)), 0 < e5.length) throw Error(e5.join("\n"));
            }
            return r4;
          } finally {
            s3.Fb = null;
          }
        };
        s3.jsepInit = (e4, t4) => {
          if ("webgpu" === e4) {
            [s3.Jb, s3.Ub, s3.Yb, s3.Kb, s3.Xb, s3.jb, s3.Zb, s3.ac, s3.Vb, s3.Wb, s3.$b] = t4;
            let e5 = s3.Jb;
            s3.jsepRegisterBuffer = (t5, n3, r4, s4) => e5.registerBuffer(t5, n3, r4, s4), s3.jsepGetBuffer = (t5) => e5.getBuffer(t5), s3.jsepCreateDownloader = (t5, n3, r4) => e5.createDownloader(t5, n3, r4), s3.jsepOnCreateSession = (t5) => {
              e5.onCreateSession(t5);
            }, s3.jsepOnReleaseSession = (t5) => {
              e5.onReleaseSession(t5);
            }, s3.jsepOnRunStart = (t5) => e5.onRunStart(t5), s3.bc = (t5, n3) => {
              e5.upload(t5, n3);
            };
          } else if ("webnn" === e4) {
            let e5 = t4[0];
            [s3.nc, s3.Nb, s3.webnnEnsureTensor, s3.Ob, s3.webnnDownloadTensor] = t4.slice(1), s3.webnnReleaseTensorId = s3.Nb, s3.webnnUploadTensor = s3.Ob, s3.webnnOnRunStart = (t5) => e5.onRunStart(t5), s3.webnnOnRunEnd = e5.onRunEnd.bind(e5), s3.webnnRegisterMLContext = (t5, n3) => {
              e5.registerMLContext(t5, n3);
            }, s3.webnnOnReleaseSession = (t5) => {
              e5.onReleaseSession(t5);
            }, s3.webnnCreateMLTensorDownloader = (t5, n3) => e5.createMLTensorDownloader(t5, n3), s3.webnnRegisterMLTensor = (t5, n3, r4, s4) => e5.registerMLTensor(t5, n3, r4, s4), s3.webnnCreateMLContext = (t5) => e5.createMLContext(t5), s3.webnnRegisterMLConstant = (t5, n3, r4, a4, o4, i4) => e5.registerMLConstant(t5, n3, r4, a4, o4, s3.Eb, i4), s3.webnnRegisterGraphInput = e5.registerGraphInput.bind(e5), s3.webnnIsGraphInput = e5.isGraphInput.bind(e5), s3.webnnCreateTemporaryTensor = e5.createTemporaryTensor.bind(e5), s3.webnnIsInt64Supported = e5.isInt64Supported.bind(e5);
          }
        };
        let c3 = () => {
          let e4 = (e5, t4, n3) => (...r4) => {
            let s4 = Vt3, a4 = t4?.();
            r4 = e5(...r4);
            let o4 = t4?.();
            return a4 !== o4 && (e5 = o4, n3(a4), t4 = n3 = null), Vt3 != s4 ? new Promise(((e6, t5) => {
              Qt3 = { resolve: e6, reject: t5 };
            })) : r4;
          };
          (() => {
            for (let t4 of ["_OrtAppendExecutionProvider", "_OrtCreateSession", "_OrtRun", "_OrtRunWithBinding", "_OrtBindInput"]) s3[t4] = e4(s3[t4], (() => s3[t4]), ((e5) => s3[t4] = e5));
          })(), void 0 !== u3 && (s3._OrtRun = u3(s3._OrtRun), s3._OrtRunWithBinding = u3(s3._OrtRunWithBinding)), c3 = void 0;
        };
        s3.asyncInit = () => {
          c3?.();
        };
        var p3, m3, h3 = Object.assign({}, s3), f3 = (e4, t4) => {
          throw t4;
        }, _3 = "";
        (o3 || i3) && (i3 ? _3 = self.location.href : typeof document < "u" && document.currentScript && (_3 = document.currentScript.src), _e2 && (_3 = _e2), _3 = _3.startsWith("blob:") ? "" : _3.slice(0, _3.replace(/[?#].*/, "").lastIndexOf("/") + 1), i3 && (m3 = (e4) => {
          var t4 = new XMLHttpRequest();
          return t4.open("GET", e4, false), t4.responseType = "arraybuffer", t4.send(null), new Uint8Array(t4.response);
        }), p3 = async (e4) => {
          if (O3(e4)) return new Promise(((t5, n3) => {
            var r4 = new XMLHttpRequest();
            r4.open("GET", e4, true), r4.responseType = "arraybuffer", r4.onload = () => {
              200 == r4.status || 0 == r4.status && r4.response ? t5(r4.response) : n3(r4.status);
            }, r4.onerror = n3, r4.send(null);
          }));
          var t4 = await fetch(e4, { credentials: "same-origin" });
          if (t4.ok) return t4.arrayBuffer();
          throw Error(t4.status + " : " + t4.url);
        });
        var g3 = console.log.bind(console), w3 = console.error.bind(console), b3 = g3, y3 = w3;
        Object.assign(s3, h3), h3 = null;
        var M3, x3, v3, T3, k3, P3, $3, C3, S3, F3, E3, I3, A3, z3 = s3.wasmBinary, L3 = false, O3 = (e4) => e4.startsWith("file://");
        function D3() {
          return M3.buffer != T3.buffer && H3(), T3;
        }
        function B3() {
          return M3.buffer != T3.buffer && H3(), k3;
        }
        function N3() {
          return M3.buffer != T3.buffer && H3(), P3;
        }
        function j3() {
          return M3.buffer != T3.buffer && H3(), $3;
        }
        function R3() {
          return M3.buffer != T3.buffer && H3(), C3;
        }
        function V3() {
          return M3.buffer != T3.buffer && H3(), S3;
        }
        function G3() {
          return M3.buffer != T3.buffer && H3(), F3;
        }
        function q3() {
          return M3.buffer != T3.buffer && H3(), A3;
        }
        if (l3) {
          let e4 = function(t4) {
            try {
              var n3 = t4.data, r4 = n3.Bb;
              if ("load" === r4) {
                let t5 = [];
                self.onmessage = (e5) => t5.push(e5), self.startWorker = () => {
                  postMessage({ Bb: "loaded" });
                  for (let n4 of t5) e4(n4);
                  self.onmessage = e4;
                };
                for (let e5 of n3.Rb) s3[e5] && !s3[e5].proxy || (s3[e5] = (...t6) => {
                  postMessage({ Bb: "callHandler", Qb: e5, args: t6 });
                }, "print" == e5 && (b3 = s3[e5]), "printErr" == e5 && (y3 = s3[e5]));
                M3 = n3.kc, H3(), U3(n3.lc);
              } else if ("run" === r4) {
                xe3(n3.Ab), _r3(n3.Ab, 0, 0, 1, 0, 0), be3(), Ct3(n3.Ab), W3 || (pr3(), W3 = true);
                try {
                  ve3(n3.fc, n3.Hb);
                } catch (e5) {
                  if ("unwind" != e5) throw e5;
                }
              } else "setimmediate" !== n3.target && ("checkMailbox" === r4 ? W3 && St3() : r4 && (y3(`worker: received unknown command ${r4}`), y3(n3)));
            } catch (e5) {
              throw gr3(), e5;
            }
          };
          var U3, W3 = false;
          y3 = function(...e5) {
            e5 = e5.join(" "), console.error(e5);
          }, self.alert = function(...e5) {
            postMessage({ Bb: "alert", text: e5.join(" "), ic: mr3() });
          }, self.onunhandledrejection = (e5) => {
            throw e5.reason || e5;
          }, self.onmessage = e4;
        }
        function H3() {
          var e4 = M3.buffer;
          s3.HEAP8 = T3 = new Int8Array(e4), s3.HEAP16 = P3 = new Int16Array(e4), s3.HEAPU8 = k3 = new Uint8Array(e4), s3.HEAPU16 = $3 = new Uint16Array(e4), s3.HEAP32 = C3 = new Int32Array(e4), s3.HEAPU32 = S3 = new Uint32Array(e4), s3.HEAPF32 = F3 = new Float32Array(e4), s3.HEAPF64 = A3 = new Float64Array(e4), s3.HEAP64 = E3 = new BigInt64Array(e4), s3.HEAPU64 = I3 = new BigUint64Array(e4);
        }
        function Q3() {
          l3 ? startWorker(s3) : dr3.Ca();
        }
        l3 || (M3 = new WebAssembly.Memory({ initial: 256, maximum: 65536, shared: true }), H3());
        var K3, X3 = 0, J3 = null;
        function Y3() {
          if (0 == --X3 && J3) {
            var e4 = J3;
            J3 = null, e4();
          }
        }
        function Z3(e4) {
          throw y3(e4 = "Aborted(" + e4 + ")"), L3 = true, e4 = new WebAssembly.RuntimeError(e4 + ". Build with -sASSERTIONS for more info."), r3(e4), e4;
        }
        function ee3() {
          return { a: { L: re3, Aa: ne3, b: ke3, $: $e3, A: Ee3, pa: Ie3, X: Le3, Z: Oe3, qa: De3, na: Be3, ga: Ne3, ma: je3, J: Re3, Y: Ve3, V: Ge3, oa: qe3, W: Ue3, va: Qe3, E: tt3, Q: rt3, O: ct3, D: mt3, u: ht3, r: ft3, P: _t3, z: Tt3, R: kt3, ja: Pt3, T: Ft3, aa: It3, M: At3, F: zt3, ia: Ct3, sa: Lt3, t: Bt3, Ba: Nt3, w: Jt3, o: Zt3, l: nn3, c: ot3, n: sn3, j: dn3, v: un3, p: cn3, f: pn3, s: mn3, m: hn3, e: fn3, k: _n3, i: gn3, g: wn3, d: bn3, da: yn3, ea: Tn3, fa: kn3, ba: Pn3, ca: $n3, N: Fn3, xa: En3, ua: zn3, h: Dn3, C: Bn3, G: Nn3, ta: In3, x: jn3, ra: Rn3, U: Vn3, q: Sn3, y: Gn3, K: qn3, S: Un3, za: Kn3, ya: Xn3, ka: er3, la: tr3, _: pe3, B: nr3, I: rr3, ha: sr3, H: or3, a: M3, wa: ue3 } };
        }
        var te3 = { 829644: (e4, t4, n3, r4, a4) => {
          if (void 0 === s3 || !s3.Eb) return 1;
          if ((e4 = Fe3(Number(e4 >>> 0))).startsWith("./") && (e4 = e4.substring(2)), !(e4 = s3.Eb.get(e4))) return 2;
          if (t4 = Number(t4 >>> 0), n3 = Number(n3 >>> 0), r4 = Number(r4 >>> 0), t4 + n3 > e4.byteLength) return 3;
          try {
            let o4 = e4.subarray(t4, t4 + n3);
            switch (a4) {
              case 0:
                B3().set(o4, r4 >>> 0);
                break;
              case 1:
                s3.mc ? s3.mc(r4, o4) : s3.bc(r4, o4);
                break;
              default:
                return 4;
            }
            return 0;
          } catch {
            return 4;
          }
        }, 830468: (e4, t4, n3) => {
          s3.Ob(e4, B3().subarray(t4 >>> 0, t4 + n3 >>> 0));
        }, 830532: () => s3.nc(), 830574: (e4) => {
          s3.Nb(e4);
        }, 830611: () => {
          s3.Vb();
        }, 830642: () => {
          s3.Wb();
        }, 830671: () => {
          s3.$b();
        }, 830696: (e4) => s3.Ub(e4), 830729: (e4) => s3.Yb(e4), 830761: (e4, t4, n3) => {
          s3.Kb(Number(e4), Number(t4), Number(n3), true);
        }, 830824: (e4, t4, n3) => {
          s3.Kb(Number(e4), Number(t4), Number(n3));
        }, 830881: () => typeof wasmOffsetConverter < "u", 830938: (e4) => {
          s3.jb("Abs", e4, void 0);
        }, 830989: (e4) => {
          s3.jb("Neg", e4, void 0);
        }, 831040: (e4) => {
          s3.jb("Floor", e4, void 0);
        }, 831093: (e4) => {
          s3.jb("Ceil", e4, void 0);
        }, 831145: (e4) => {
          s3.jb("Reciprocal", e4, void 0);
        }, 831203: (e4) => {
          s3.jb("Sqrt", e4, void 0);
        }, 831255: (e4) => {
          s3.jb("Exp", e4, void 0);
        }, 831306: (e4) => {
          s3.jb("Erf", e4, void 0);
        }, 831357: (e4) => {
          s3.jb("Sigmoid", e4, void 0);
        }, 831412: (e4, t4, n3) => {
          s3.jb("HardSigmoid", e4, { alpha: t4, beta: n3 });
        }, 831491: (e4) => {
          s3.jb("Log", e4, void 0);
        }, 831542: (e4) => {
          s3.jb("Sin", e4, void 0);
        }, 831593: (e4) => {
          s3.jb("Cos", e4, void 0);
        }, 831644: (e4) => {
          s3.jb("Tan", e4, void 0);
        }, 831695: (e4) => {
          s3.jb("Asin", e4, void 0);
        }, 831747: (e4) => {
          s3.jb("Acos", e4, void 0);
        }, 831799: (e4) => {
          s3.jb("Atan", e4, void 0);
        }, 831851: (e4) => {
          s3.jb("Sinh", e4, void 0);
        }, 831903: (e4) => {
          s3.jb("Cosh", e4, void 0);
        }, 831955: (e4) => {
          s3.jb("Asinh", e4, void 0);
        }, 832008: (e4) => {
          s3.jb("Acosh", e4, void 0);
        }, 832061: (e4) => {
          s3.jb("Atanh", e4, void 0);
        }, 832114: (e4) => {
          s3.jb("Tanh", e4, void 0);
        }, 832166: (e4) => {
          s3.jb("Not", e4, void 0);
        }, 832217: (e4, t4, n3) => {
          s3.jb("Clip", e4, { min: t4, max: n3 });
        }, 832286: (e4) => {
          s3.jb("Clip", e4, void 0);
        }, 832338: (e4, t4) => {
          s3.jb("Elu", e4, { alpha: t4 });
        }, 832396: (e4) => {
          s3.jb("Gelu", e4, void 0);
        }, 832448: (e4) => {
          s3.jb("Relu", e4, void 0);
        }, 832500: (e4, t4) => {
          s3.jb("LeakyRelu", e4, { alpha: t4 });
        }, 832564: (e4, t4) => {
          s3.jb("ThresholdedRelu", e4, { alpha: t4 });
        }, 832634: (e4, t4) => {
          s3.jb("Cast", e4, { to: t4 });
        }, 832692: (e4) => {
          s3.jb("Add", e4, void 0);
        }, 832743: (e4) => {
          s3.jb("Sub", e4, void 0);
        }, 832794: (e4) => {
          s3.jb("Mul", e4, void 0);
        }, 832845: (e4) => {
          s3.jb("Div", e4, void 0);
        }, 832896: (e4) => {
          s3.jb("Pow", e4, void 0);
        }, 832947: (e4) => {
          s3.jb("Equal", e4, void 0);
        }, 833e3: (e4) => {
          s3.jb("Greater", e4, void 0);
        }, 833055: (e4) => {
          s3.jb("GreaterOrEqual", e4, void 0);
        }, 833117: (e4) => {
          s3.jb("Less", e4, void 0);
        }, 833169: (e4) => {
          s3.jb("LessOrEqual", e4, void 0);
        }, 833228: (e4, t4, n3, r4, a4) => {
          s3.jb("ReduceMean", e4, { keepDims: !!t4, noopWithEmptyAxes: !!n3, axes: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [] });
        }, 833403: (e4, t4, n3, r4, a4) => {
          s3.jb("ReduceMax", e4, { keepDims: !!t4, noopWithEmptyAxes: !!n3, axes: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [] });
        }, 833577: (e4, t4, n3, r4, a4) => {
          s3.jb("ReduceMin", e4, { keepDims: !!t4, noopWithEmptyAxes: !!n3, axes: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [] });
        }, 833751: (e4, t4, n3, r4, a4) => {
          s3.jb("ReduceProd", e4, { keepDims: !!t4, noopWithEmptyAxes: !!n3, axes: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [] });
        }, 833926: (e4, t4, n3, r4, a4) => {
          s3.jb("ReduceSum", e4, { keepDims: !!t4, noopWithEmptyAxes: !!n3, axes: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [] });
        }, 834100: (e4, t4, n3, r4, a4) => {
          s3.jb("ReduceL1", e4, { keepDims: !!t4, noopWithEmptyAxes: !!n3, axes: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [] });
        }, 834273: (e4, t4, n3, r4, a4) => {
          s3.jb("ReduceL2", e4, { keepDims: !!t4, noopWithEmptyAxes: !!n3, axes: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [] });
        }, 834446: (e4, t4, n3, r4, a4) => {
          s3.jb("ReduceLogSum", e4, { keepDims: !!t4, noopWithEmptyAxes: !!n3, axes: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [] });
        }, 834623: (e4, t4, n3, r4, a4) => {
          s3.jb("ReduceSumSquare", e4, { keepDims: !!t4, noopWithEmptyAxes: !!n3, axes: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [] });
        }, 834803: (e4, t4, n3, r4, a4) => {
          s3.jb("ReduceLogSumExp", e4, { keepDims: !!t4, noopWithEmptyAxes: !!n3, axes: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [] });
        }, 834983: (e4) => {
          s3.jb("Where", e4, void 0);
        }, 835036: (e4, t4, n3) => {
          s3.jb("Transpose", e4, { perm: t4 ? Array.from(R3().subarray(Number(t4) >>> 0, Number(n3) >>> 0)) : [] });
        }, 835160: (e4, t4, n3, r4) => {
          s3.jb("DepthToSpace", e4, { blocksize: t4, mode: Fe3(n3), format: r4 ? "NHWC" : "NCHW" });
        }, 835293: (e4, t4, n3, r4) => {
          s3.jb("DepthToSpace", e4, { blocksize: t4, mode: Fe3(n3), format: r4 ? "NHWC" : "NCHW" });
        }, 835426: (e4, t4, n3, r4, a4, o4, i4, l4, d4, u4, c4, p4, m4, h4, f4) => {
          s3.jb("ConvTranspose", e4, { format: d4 ? "NHWC" : "NCHW", autoPad: t4, dilations: [n3], group: r4, kernelShape: [a4], pads: [o4, i4], strides: [l4], wIsConst: () => !!D3()[u4 >>> 0], outputPadding: c4 ? Array.from(R3().subarray(Number(c4) >>> 0, Number(p4) >>> 0)) : [], outputShape: m4 ? Array.from(R3().subarray(Number(m4) >>> 0, Number(h4) >>> 0)) : [], activation: Fe3(f4) });
        }, 835859: (e4, t4, n3, r4, a4, o4, i4, l4, d4, u4, c4, p4, m4, h4) => {
          s3.jb("ConvTranspose", e4, { format: l4 ? "NHWC" : "NCHW", autoPad: t4, dilations: Array.from(R3().subarray(Number(n3) >>> 0, 2 + (Number(n3) >>> 0) >>> 0)), group: r4, kernelShape: Array.from(R3().subarray(Number(a4) >>> 0, 2 + (Number(a4) >>> 0) >>> 0)), pads: Array.from(R3().subarray(Number(o4) >>> 0, 4 + (Number(o4) >>> 0) >>> 0)), strides: Array.from(R3().subarray(Number(i4) >>> 0, 2 + (Number(i4) >>> 0) >>> 0)), wIsConst: () => !!D3()[d4 >>> 0], outputPadding: u4 ? Array.from(R3().subarray(Number(u4) >>> 0, Number(c4) >>> 0)) : [], outputShape: p4 ? Array.from(R3().subarray(Number(p4) >>> 0, Number(m4) >>> 0)) : [], activation: Fe3(h4) });
        }, 836520: (e4, t4, n3, r4, a4, o4, i4, l4, d4, u4, c4, p4, m4, h4, f4) => {
          s3.jb("ConvTranspose", e4, { format: d4 ? "NHWC" : "NCHW", autoPad: t4, dilations: [n3], group: r4, kernelShape: [a4], pads: [o4, i4], strides: [l4], wIsConst: () => !!D3()[u4 >>> 0], outputPadding: c4 ? Array.from(R3().subarray(Number(c4) >>> 0, Number(p4) >>> 0)) : [], outputShape: m4 ? Array.from(R3().subarray(Number(m4) >>> 0, Number(h4) >>> 0)) : [], activation: Fe3(f4) });
        }, 836953: (e4, t4, n3, r4, a4, o4, i4, l4, d4, u4, c4, p4, m4, h4) => {
          s3.jb("ConvTranspose", e4, { format: l4 ? "NHWC" : "NCHW", autoPad: t4, dilations: Array.from(R3().subarray(Number(n3) >>> 0, 2 + (Number(n3) >>> 0) >>> 0)), group: r4, kernelShape: Array.from(R3().subarray(Number(a4) >>> 0, 2 + (Number(a4) >>> 0) >>> 0)), pads: Array.from(R3().subarray(Number(o4) >>> 0, 4 + (Number(o4) >>> 0) >>> 0)), strides: Array.from(R3().subarray(Number(i4) >>> 0, 2 + (Number(i4) >>> 0) >>> 0)), wIsConst: () => !!D3()[d4 >>> 0], outputPadding: u4 ? Array.from(R3().subarray(Number(u4) >>> 0, Number(c4) >>> 0)) : [], outputShape: p4 ? Array.from(R3().subarray(Number(p4) >>> 0, Number(m4) >>> 0)) : [], activation: Fe3(h4) });
        }, 837614: (e4, t4) => {
          s3.jb("GlobalAveragePool", e4, { format: t4 ? "NHWC" : "NCHW" });
        }, 837705: (e4, t4, n3, r4, a4, o4, i4, l4, d4, u4, c4, p4, m4, h4) => {
          s3.jb("AveragePool", e4, { format: h4 ? "NHWC" : "NCHW", auto_pad: t4, ceil_mode: n3, count_include_pad: r4, storage_order: a4, dilations: o4 ? Array.from(R3().subarray(Number(o4) >>> 0, Number(i4) >>> 0)) : [], kernel_shape: l4 ? Array.from(R3().subarray(Number(l4) >>> 0, Number(d4) >>> 0)) : [], pads: u4 ? Array.from(R3().subarray(Number(u4) >>> 0, Number(c4) >>> 0)) : [], strides: p4 ? Array.from(R3().subarray(Number(p4) >>> 0, Number(m4) >>> 0)) : [] });
        }, 838184: (e4, t4) => {
          s3.jb("GlobalAveragePool", e4, { format: t4 ? "NHWC" : "NCHW" });
        }, 838275: (e4, t4, n3, r4, a4, o4, i4, l4, d4, u4, c4, p4, m4, h4) => {
          s3.jb("AveragePool", e4, { format: h4 ? "NHWC" : "NCHW", auto_pad: t4, ceil_mode: n3, count_include_pad: r4, storage_order: a4, dilations: o4 ? Array.from(R3().subarray(Number(o4) >>> 0, Number(i4) >>> 0)) : [], kernel_shape: l4 ? Array.from(R3().subarray(Number(l4) >>> 0, Number(d4) >>> 0)) : [], pads: u4 ? Array.from(R3().subarray(Number(u4) >>> 0, Number(c4) >>> 0)) : [], strides: p4 ? Array.from(R3().subarray(Number(p4) >>> 0, Number(m4) >>> 0)) : [] });
        }, 838754: (e4, t4) => {
          s3.jb("GlobalMaxPool", e4, { format: t4 ? "NHWC" : "NCHW" });
        }, 838841: (e4, t4, n3, r4, a4, o4, i4, l4, d4, u4, c4, p4, m4, h4) => {
          s3.jb("MaxPool", e4, { format: h4 ? "NHWC" : "NCHW", auto_pad: t4, ceil_mode: n3, count_include_pad: r4, storage_order: a4, dilations: o4 ? Array.from(R3().subarray(Number(o4) >>> 0, Number(i4) >>> 0)) : [], kernel_shape: l4 ? Array.from(R3().subarray(Number(l4) >>> 0, Number(d4) >>> 0)) : [], pads: u4 ? Array.from(R3().subarray(Number(u4) >>> 0, Number(c4) >>> 0)) : [], strides: p4 ? Array.from(R3().subarray(Number(p4) >>> 0, Number(m4) >>> 0)) : [] });
        }, 839316: (e4, t4) => {
          s3.jb("GlobalMaxPool", e4, { format: t4 ? "NHWC" : "NCHW" });
        }, 839403: (e4, t4, n3, r4, a4, o4, i4, l4, d4, u4, c4, p4, m4, h4) => {
          s3.jb("MaxPool", e4, { format: h4 ? "NHWC" : "NCHW", auto_pad: t4, ceil_mode: n3, count_include_pad: r4, storage_order: a4, dilations: o4 ? Array.from(R3().subarray(Number(o4) >>> 0, Number(i4) >>> 0)) : [], kernel_shape: l4 ? Array.from(R3().subarray(Number(l4) >>> 0, Number(d4) >>> 0)) : [], pads: u4 ? Array.from(R3().subarray(Number(u4) >>> 0, Number(c4) >>> 0)) : [], strides: p4 ? Array.from(R3().subarray(Number(p4) >>> 0, Number(m4) >>> 0)) : [] });
        }, 839878: (e4, t4, n3, r4, a4) => {
          s3.jb("Gemm", e4, { alpha: t4, beta: n3, transA: r4, transB: a4 });
        }, 839982: (e4) => {
          s3.jb("MatMul", e4, void 0);
        }, 840036: (e4, t4, n3, r4) => {
          s3.jb("ArgMax", e4, { keepDims: !!t4, selectLastIndex: !!n3, axis: r4 });
        }, 840144: (e4, t4, n3, r4) => {
          s3.jb("ArgMin", e4, { keepDims: !!t4, selectLastIndex: !!n3, axis: r4 });
        }, 840252: (e4, t4) => {
          s3.jb("Softmax", e4, { axis: t4 });
        }, 840315: (e4, t4) => {
          s3.jb("Concat", e4, { axis: t4 });
        }, 840375: (e4, t4, n3, r4, a4) => {
          s3.jb("Split", e4, { axis: t4, numOutputs: n3, splitSizes: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [] });
        }, 840531: (e4) => {
          s3.jb("Expand", e4, void 0);
        }, 840585: (e4, t4) => {
          s3.jb("Gather", e4, { axis: Number(t4) });
        }, 840656: (e4, t4) => {
          s3.jb("GatherElements", e4, { axis: Number(t4) });
        }, 840735: (e4, t4) => {
          s3.jb("GatherND", e4, { batch_dims: Number(t4) });
        }, 840814: (e4, t4, n3, r4, a4, o4, i4, l4, d4, u4, c4) => {
          s3.jb("Resize", e4, { antialias: t4, axes: n3 ? Array.from(R3().subarray(Number(n3) >>> 0, Number(r4) >>> 0)) : [], coordinateTransformMode: Fe3(a4), cubicCoeffA: o4, excludeOutside: i4, extrapolationValue: l4, keepAspectRatioPolicy: Fe3(d4), mode: Fe3(u4), nearestMode: Fe3(c4) });
        }, 841176: (e4, t4, n3, r4, a4, o4, i4) => {
          s3.jb("Slice", e4, { starts: t4 ? Array.from(R3().subarray(Number(t4) >>> 0, Number(n3) >>> 0)) : [], ends: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [], axes: o4 ? Array.from(R3().subarray(Number(o4) >>> 0, Number(i4) >>> 0)) : [] });
        }, 841440: (e4) => {
          s3.jb("Tile", e4, void 0);
        }, 841492: (e4, t4, n3) => {
          s3.jb("InstanceNormalization", e4, { epsilon: t4, format: n3 ? "NHWC" : "NCHW" });
        }, 841606: (e4, t4, n3) => {
          s3.jb("InstanceNormalization", e4, { epsilon: t4, format: n3 ? "NHWC" : "NCHW" });
        }, 841720: (e4) => {
          s3.jb("Range", e4, void 0);
        }, 841773: (e4, t4) => {
          s3.jb("Einsum", e4, { equation: Fe3(t4) });
        }, 841854: (e4, t4, n3, r4, a4) => {
          s3.jb("Pad", e4, { mode: t4, value: n3, pads: r4 ? Array.from(R3().subarray(Number(r4) >>> 0, Number(a4) >>> 0)) : [] });
        }, 841997: (e4, t4, n3, r4, a4, o4) => {
          s3.jb("BatchNormalization", e4, { epsilon: t4, momentum: n3, spatial: !!a4, trainingMode: !!r4, format: o4 ? "NHWC" : "NCHW" });
        }, 842166: (e4, t4, n3, r4, a4, o4) => {
          s3.jb("BatchNormalization", e4, { epsilon: t4, momentum: n3, spatial: !!a4, trainingMode: !!r4, format: o4 ? "NHWC" : "NCHW" });
        }, 842335: (e4, t4, n3) => {
          s3.jb("CumSum", e4, { exclusive: Number(t4), reverse: Number(n3) });
        }, 842432: (e4, t4, n3) => {
          s3.jb("DequantizeLinear", e4, { axis: t4, blockSize: n3 });
        }, 842522: (e4, t4, n3, r4, a4) => {
          s3.jb("GridSample", e4, { align_corners: t4, mode: Fe3(n3), padding_mode: Fe3(r4), format: a4 ? "NHWC" : "NCHW" });
        }, 842692: (e4, t4, n3, r4, a4) => {
          s3.jb("GridSample", e4, { align_corners: t4, mode: Fe3(n3), padding_mode: Fe3(r4), format: a4 ? "NHWC" : "NCHW" });
        }, 842862: (e4, t4) => {
          s3.jb("ScatterND", e4, { reduction: Fe3(t4) });
        }, 842947: (e4, t4, n3, r4, a4, o4, i4, l4, d4) => {
          s3.jb("Attention", e4, { numHeads: t4, isUnidirectional: n3, maskFilterValue: r4, scale: a4, doRotary: o4, qkvHiddenSizes: i4 ? Array.from(R3().subarray(Number(l4) >>> 0, Number(l4) + i4 >>> 0)) : [], pastPresentShareBuffer: !!d4 });
        }, 843219: (e4) => {
          s3.jb("BiasAdd", e4, void 0);
        }, 843274: (e4) => {
          s3.jb("BiasSplitGelu", e4, void 0);
        }, 843335: (e4) => {
          s3.jb("FastGelu", e4, void 0);
        }, 843391: (e4, t4, n3, r4, a4, o4, i4, l4, d4, u4, c4, p4, m4, h4, f4, _4) => {
          s3.jb("Conv", e4, { format: p4 ? "NHWC" : "NCHW", auto_pad: t4, dilations: n3 ? Array.from(R3().subarray(Number(n3) >>> 0, Number(r4) >>> 0)) : [], group: a4, kernel_shape: o4 ? Array.from(R3().subarray(Number(o4) >>> 0, Number(i4) >>> 0)) : [], pads: l4 ? Array.from(R3().subarray(Number(l4) >>> 0, Number(d4) >>> 0)) : [], strides: u4 ? Array.from(R3().subarray(Number(u4) >>> 0, Number(c4) >>> 0)) : [], w_is_const: () => !!D3()[Number(m4) >>> 0], activation: Fe3(h4), activation_params: f4 ? Array.from(G3().subarray(Number(f4) >>> 0, Number(_4) >>> 0)) : [] });
        }, 843975: (e4) => {
          s3.jb("Gelu", e4, void 0);
        }, 844027: (e4, t4, n3, r4, a4, o4, i4, l4, d4) => {
          s3.jb("GroupQueryAttention", e4, { numHeads: t4, kvNumHeads: n3, scale: r4, softcap: a4, doRotary: o4, rotaryInterleaved: i4, smoothSoftmax: l4, localWindowSize: d4 });
        }, 844244: (e4, t4, n3, r4) => {
          s3.jb("LayerNormalization", e4, { axis: t4, epsilon: n3, simplified: !!r4 });
        }, 844355: (e4, t4, n3, r4) => {
          s3.jb("LayerNormalization", e4, { axis: t4, epsilon: n3, simplified: !!r4 });
        }, 844466: (e4, t4, n3, r4, a4, o4) => {
          s3.jb("MatMulNBits", e4, { k: t4, n: n3, accuracyLevel: r4, bits: a4, blockSize: o4 });
        }, 844593: (e4, t4, n3, r4, a4, o4) => {
          s3.jb("MultiHeadAttention", e4, { numHeads: t4, isUnidirectional: n3, maskFilterValue: r4, scale: a4, doRotary: o4 });
        }, 844752: (e4, t4) => {
          s3.jb("QuickGelu", e4, { alpha: t4 });
        }, 844816: (e4, t4, n3, r4, a4) => {
          s3.jb("RotaryEmbedding", e4, { interleaved: !!t4, numHeads: n3, rotaryEmbeddingDim: r4, scale: a4 });
        }, 844955: (e4, t4, n3) => {
          s3.jb("SkipLayerNormalization", e4, { epsilon: t4, simplified: !!n3 });
        }, 845057: (e4, t4, n3) => {
          s3.jb("SkipLayerNormalization", e4, { epsilon: t4, simplified: !!n3 });
        }, 845159: (e4, t4, n3, r4) => {
          s3.jb("GatherBlockQuantized", e4, { gatherAxis: t4, quantizeAxis: n3, blockSize: r4 });
        }, 845280: (e4) => {
          s3.Zb(e4);
        }, 845314: (e4, t4) => s3.ac(Number(e4), Number(t4), s3.Fb.dc, s3.Fb.errors) };
        function ne3(e4, t4, n3) {
          return Xt3((async () => {
            await s3.Xb(Number(e4), Number(t4), Number(n3));
          }));
        }
        function re3() {
          return typeof wasmOffsetConverter < "u";
        }
        class se3 {
          name = "ExitStatus";
          constructor(e4) {
            this.message = `Program terminated with exit(${e4})`, this.status = e4;
          }
        }
        var ae3 = (e4) => {
          e4.terminate(), e4.onmessage = () => {
          };
        }, oe3 = [], ie3 = (e4) => {
          0 == me3.length && (Me3(), ye3(me3[0]));
          var t4 = me3.pop();
          if (!t4) return 6;
          he3.push(t4), ge3[e4.Ab] = t4, t4.Ab = e4.Ab;
          var n3 = { Bb: "run", fc: e4.ec, Hb: e4.Hb, Ab: e4.Ab };
          return t4.postMessage(n3, e4.Mb), 0;
        }, le3 = 0, de3 = (e4, t4, ...n3) => {
          for (var r4 = 2 * n3.length, s4 = Pr3(), a4 = kr3(8 * r4), o4 = a4 >>> 3, i4 = 0; i4 < n3.length; i4++) {
            var l4 = n3[i4];
            "bigint" == typeof l4 ? (E3[o4 + 2 * i4] = 1n, E3[o4 + 2 * i4 + 1] = l4) : (E3[o4 + 2 * i4] = 0n, q3()[o4 + 2 * i4 + 1 >>> 0] = l4);
          }
          return e4 = wr3(e4, 0, r4, a4, t4), Tr3(s4), e4;
        };
        function ue3(e4) {
          if (l3) return de3(0, 1, e4);
          if (v3 = e4, !(0 < le3)) {
            for (var t4 of he3) ae3(t4);
            for (t4 of me3) ae3(t4);
            me3 = [], he3 = [], ge3 = {}, L3 = true;
          }
          f3(0, new se3(e4));
        }
        function ce3(e4) {
          if (l3) return de3(1, 0, e4);
          pe3(e4);
        }
        var pe3 = (e4) => {
          if (v3 = e4, l3) throw ce3(e4), "unwind";
          ue3(e4);
        }, me3 = [], he3 = [], fe3 = [], ge3 = {}, we3 = (e4) => {
          var t4 = e4.Ab;
          delete ge3[t4], me3.push(e4), he3.splice(he3.indexOf(e4), 1), e4.Ab = 0, br3(t4);
        };
        function be3() {
          fe3.forEach(((e4) => e4()));
        }
        var ye3 = (e4) => new Promise(((t4) => {
          e4.onmessage = (n4) => {
            var r5 = (n4 = n4.data).Bb;
            if (n4.Gb && n4.Gb != mr3()) {
              var a4 = ge3[n4.Gb];
              a4 ? a4.postMessage(n4, n4.Mb) : y3(`Internal error! Worker sent a message "${r5}" to target pthread ${n4.Gb}, but that thread no longer exists!`);
            } else "checkMailbox" === r5 ? St3() : "spawnThread" === r5 ? ie3(n4) : "cleanupThread" === r5 ? we3(ge3[n4.hc]) : "loaded" === r5 ? (e4.loaded = true, t4(e4)) : "alert" === r5 ? alert(`Thread ${n4.ic}: ${n4.text}`) : "setimmediate" === n4.target ? e4.postMessage(n4) : "callHandler" === r5 ? s3[n4.Qb](...n4.args) : r5 && y3(`worker sent an unknown command ${r5}`);
          }, e4.onerror = (e5) => {
            throw y3(`worker sent an error! ${e5.filename}:${e5.lineno}: ${e5.message}`), e5;
          };
          var n3, r4 = [];
          for (n3 of []) s3.propertyIsEnumerable(n3) && r4.push(n3);
          e4.postMessage({ Bb: "load", Rb: r4, kc: M3, lc: x3 });
        }));
        function Me3() {
          var e4 = new Worker((() => {
            let e5 = URL;
            return import_meta.url > "file:" && import_meta.url < "file;" ? new e5(n2("./node_modules/onnxruntime-web/dist/ort.bundle.min.mjs?46eb"), n2.b) : new URL(import_meta.url);
          })(), { type: "module", workerData: "em-pthread", name: "em-pthread" });
          me3.push(e4);
        }
        var xe3 = (e4) => {
          H3();
          var t4 = V3()[e4 + 52 >>> 2 >>> 0];
          e4 = V3()[e4 + 56 >>> 2 >>> 0], vr3(t4, t4 - e4), Tr3(t4);
        }, ve3 = (e4, t4) => {
          le3 = 0, e4 = $r3(e4, t4), 0 < le3 ? v3 = e4 : yr3(e4);
        };
        class Te3 {
          constructor(e4) {
            this.Ib = e4 - 24;
          }
        }
        function ke3(e4, t4, n3) {
          var r4 = new Te3(e4 >>>= 0);
          throw t4 >>>= 0, n3 >>>= 0, V3()[r4.Ib + 16 >>> 2 >>> 0] = 0, V3()[r4.Ib + 4 >>> 2 >>> 0] = t4, V3()[r4.Ib + 8 >>> 2 >>> 0] = n3, e4;
        }
        function Pe3(e4, t4, n3, r4) {
          return l3 ? de3(2, 1, e4, t4, n3, r4) : $e3(e4, t4, n3, r4);
        }
        function $e3(e4, t4, n3, r4) {
          if (e4 >>>= 0, n3 >>>= 0, r4 >>>= 0, void 0 === d3) return 6;
          var s4 = [];
          return l3 && 0 === s4.length ? Pe3(e4, t4 >>>= 0, n3, r4) : (e4 = { ec: n3, Ab: e4, Hb: r4, Mb: s4 }, l3 ? (e4.Bb = "spawnThread", postMessage(e4, s4), 0) : ie3(e4));
        }
        var Ce3 = typeof TextDecoder < "u" ? new TextDecoder() : void 0, Se3 = (e4, t4 = 0, n3 = NaN) => {
          var r4 = (t4 >>>= 0) + n3;
          for (n3 = t4; e4[n3] && !(n3 >= r4); ) ++n3;
          if (16 < n3 - t4 && e4.buffer && Ce3) return Ce3.decode(e4.buffer instanceof ArrayBuffer ? e4.subarray(t4, n3) : e4.slice(t4, n3));
          for (r4 = ""; t4 < n3; ) {
            var s4 = e4[t4++];
            if (128 & s4) {
              var a4 = 63 & e4[t4++];
              if (192 == (224 & s4)) r4 += String.fromCharCode((31 & s4) << 6 | a4);
              else {
                var o4 = 63 & e4[t4++];
                65536 > (s4 = 224 == (240 & s4) ? (15 & s4) << 12 | a4 << 6 | o4 : (7 & s4) << 18 | a4 << 12 | o4 << 6 | 63 & e4[t4++]) ? r4 += String.fromCharCode(s4) : (s4 -= 65536, r4 += String.fromCharCode(55296 | s4 >> 10, 56320 | 1023 & s4));
              }
            } else r4 += String.fromCharCode(s4);
          }
          return r4;
        }, Fe3 = (e4, t4) => (e4 >>>= 0) ? Se3(B3(), e4, t4) : "";
        function Ee3(e4, t4, n3) {
          return l3 ? de3(3, 1, e4, t4, n3) : 0;
        }
        function Ie3(e4, t4) {
          if (l3) return de3(4, 1, e4, t4);
        }
        var Ae3 = (e4) => {
          for (var t4 = 0, n3 = 0; n3 < e4.length; ++n3) {
            var r4 = e4.charCodeAt(n3);
            127 >= r4 ? t4++ : 2047 >= r4 ? t4 += 2 : 55296 <= r4 && 57343 >= r4 ? (t4 += 4, ++n3) : t4 += 3;
          }
          return t4;
        }, ze3 = (e4, t4, n3) => {
          var r4 = B3();
          if (t4 >>>= 0, 0 < n3) {
            var s4 = t4;
            n3 = t4 + n3 - 1;
            for (var a4 = 0; a4 < e4.length; ++a4) {
              var o4 = e4.charCodeAt(a4);
              if (55296 <= o4 && 57343 >= o4 && (o4 = 65536 + ((1023 & o4) << 10) | 1023 & e4.charCodeAt(++a4)), 127 >= o4) {
                if (t4 >= n3) break;
                r4[t4++ >>> 0] = o4;
              } else {
                if (2047 >= o4) {
                  if (t4 + 1 >= n3) break;
                  r4[t4++ >>> 0] = 192 | o4 >> 6;
                } else {
                  if (65535 >= o4) {
                    if (t4 + 2 >= n3) break;
                    r4[t4++ >>> 0] = 224 | o4 >> 12;
                  } else {
                    if (t4 + 3 >= n3) break;
                    r4[t4++ >>> 0] = 240 | o4 >> 18, r4[t4++ >>> 0] = 128 | o4 >> 12 & 63;
                  }
                  r4[t4++ >>> 0] = 128 | o4 >> 6 & 63;
                }
                r4[t4++ >>> 0] = 128 | 63 & o4;
              }
            }
            r4[t4 >>> 0] = 0, e4 = t4 - s4;
          } else e4 = 0;
          return e4;
        };
        function Le3(e4, t4) {
          if (l3) return de3(5, 1, e4, t4);
        }
        function Oe3(e4, t4, n3) {
          if (l3) return de3(6, 1, e4, t4, n3);
        }
        function De3(e4, t4, n3) {
          return l3 ? de3(7, 1, e4, t4, n3) : 0;
        }
        function Be3(e4, t4) {
          if (l3) return de3(8, 1, e4, t4);
        }
        function Ne3(e4, t4, n3) {
          if (l3) return de3(9, 1, e4, t4, n3);
        }
        function je3(e4, t4, n3, r4) {
          if (l3) return de3(10, 1, e4, t4, n3, r4);
        }
        function Re3(e4, t4, n3, r4) {
          if (l3) return de3(11, 1, e4, t4, n3, r4);
        }
        function Ve3(e4, t4, n3, r4) {
          if (l3) return de3(12, 1, e4, t4, n3, r4);
        }
        function Ge3(e4) {
          if (l3) return de3(13, 1, e4);
        }
        function qe3(e4, t4) {
          if (l3) return de3(14, 1, e4, t4);
        }
        function Ue3(e4, t4, n3) {
          if (l3) return de3(15, 1, e4, t4, n3);
        }
        var We3, He3, Qe3 = () => Z3(""), Ke3 = (e4) => {
          for (var t4 = ""; B3()[e4 >>> 0]; ) t4 += We3[B3()[e4++ >>> 0]];
          return t4;
        }, Xe3 = {}, Je3 = {}, Ye3 = {};
        function Ze3(e4, t4, n3 = {}) {
          return (function(e5, t5, n4 = {}) {
            var r4 = t5.name;
            if (!e5) throw new He3(`type "${r4}" must have a positive integer typeid pointer`);
            if (Je3.hasOwnProperty(e5)) {
              if (n4.Sb) return;
              throw new He3(`Cannot register type '${r4}' twice`);
            }
            Je3[e5] = t5, delete Ye3[e5], Xe3.hasOwnProperty(e5) && (t5 = Xe3[e5], delete Xe3[e5], t5.forEach(((e6) => e6())));
          })(e4, t4, n3);
        }
        var et3 = (e4, t4, n3) => {
          switch (t4) {
            case 1:
              return n3 ? (e5) => D3()[e5 >>> 0] : (e5) => B3()[e5 >>> 0];
            case 2:
              return n3 ? (e5) => N3()[e5 >>> 1 >>> 0] : (e5) => j3()[e5 >>> 1 >>> 0];
            case 4:
              return n3 ? (e5) => R3()[e5 >>> 2 >>> 0] : (e5) => V3()[e5 >>> 2 >>> 0];
            case 8:
              return n3 ? (e5) => E3[e5 >>> 3] : (e5) => I3[e5 >>> 3];
            default:
              throw new TypeError(`invalid integer width (${t4}): ${e4}`);
          }
        };
        function tt3(e4, t4, n3) {
          n3 >>>= 0, Ze3(e4 >>>= 0, { name: t4 = Ke3(t4 >>> 0), fromWireType: (e5) => e5, toWireType: function(e5, t5) {
            if ("bigint" != typeof t5 && "number" != typeof t5) throw t5 = null === t5 ? "null" : "object" == (e5 = typeof t5) || "array" === e5 || "function" === e5 ? t5.toString() : "" + t5, new TypeError(`Cannot convert "${t5}" to ${this.name}`);
            return "number" == typeof t5 && (t5 = BigInt(t5)), t5;
          }, Cb: nt3, readValueFromPointer: et3(t4, n3, -1 == t4.indexOf("u")), Db: null });
        }
        var nt3 = 8;
        function rt3(e4, t4, n3, r4) {
          Ze3(e4 >>>= 0, { name: t4 = Ke3(t4 >>> 0), fromWireType: function(e5) {
            return !!e5;
          }, toWireType: function(e5, t5) {
            return t5 ? n3 : r4;
          }, Cb: nt3, readValueFromPointer: function(e5) {
            return this.fromWireType(B3()[e5 >>> 0]);
          }, Db: null });
        }
        var st3 = [], at3 = [];
        function ot3(e4) {
          9 < (e4 >>>= 0) && 0 == --at3[e4 + 1] && (at3[e4] = void 0, st3.push(e4));
        }
        var it3 = (e4) => {
          if (!e4) throw new He3("Cannot use deleted val. handle = " + e4);
          return at3[e4];
        }, lt3 = (e4) => {
          switch (e4) {
            case void 0:
              return 2;
            case null:
              return 4;
            case true:
              return 6;
            case false:
              return 8;
            default:
              let t4 = st3.pop() || at3.length;
              return at3[t4] = e4, at3[t4 + 1] = 1, t4;
          }
        };
        function dt3(e4) {
          return this.fromWireType(V3()[e4 >>> 2 >>> 0]);
        }
        var ut3 = { name: "emscripten::val", fromWireType: (e4) => {
          var t4 = it3(e4);
          return ot3(e4), t4;
        }, toWireType: (e4, t4) => lt3(t4), Cb: nt3, readValueFromPointer: dt3, Db: null };
        function ct3(e4) {
          return Ze3(e4 >>> 0, ut3);
        }
        var pt3 = (e4, t4) => {
          switch (t4) {
            case 4:
              return function(e5) {
                return this.fromWireType(G3()[e5 >>> 2 >>> 0]);
              };
            case 8:
              return function(e5) {
                return this.fromWireType(q3()[e5 >>> 3 >>> 0]);
              };
            default:
              throw new TypeError(`invalid float width (${t4}): ${e4}`);
          }
        };
        function mt3(e4, t4, n3) {
          n3 >>>= 0, Ze3(e4 >>>= 0, { name: t4 = Ke3(t4 >>> 0), fromWireType: (e5) => e5, toWireType: (e5, t5) => t5, Cb: nt3, readValueFromPointer: pt3(t4, n3), Db: null });
        }
        function ht3(e4, t4, n3, r4, s4) {
          if (e4 >>>= 0, n3 >>>= 0, t4 = Ke3(t4 >>> 0), -1 === s4 && (s4 = 4294967295), s4 = (e5) => e5, 0 === r4) {
            var a4 = 32 - 8 * n3;
            s4 = (e5) => e5 << a4 >>> a4;
          }
          var o4 = t4.includes("unsigned") ? function(e5, t5) {
            return t5 >>> 0;
          } : function(e5, t5) {
            return t5;
          };
          Ze3(e4, { name: t4, fromWireType: s4, toWireType: o4, Cb: nt3, readValueFromPointer: et3(t4, n3, 0 !== r4), Db: null });
        }
        function ft3(e4, t4, n3) {
          function r4(e5) {
            var t5 = V3()[e5 >>> 2 >>> 0];
            return e5 = V3()[e5 + 4 >>> 2 >>> 0], new s4(D3().buffer, e5, t5);
          }
          var s4 = [Int8Array, Uint8Array, Int16Array, Uint16Array, Int32Array, Uint32Array, Float32Array, Float64Array, BigInt64Array, BigUint64Array][t4];
          Ze3(e4 >>>= 0, { name: n3 = Ke3(n3 >>> 0), fromWireType: r4, Cb: nt3, readValueFromPointer: r4 }, { Sb: true });
        }
        function _t3(e4, t4) {
          Ze3(e4 >>>= 0, { name: t4 = Ke3(t4 >>> 0), fromWireType: function(e5) {
            for (var t5, n3 = V3()[e5 >>> 2 >>> 0], r4 = e5 + 4, s4 = r4, a4 = 0; a4 <= n3; ++a4) {
              var o4 = r4 + a4;
              a4 != n3 && 0 != B3()[o4 >>> 0] || (s4 = Fe3(s4, o4 - s4), void 0 === t5 ? t5 = s4 : (t5 += "\0", t5 += s4), s4 = o4 + 1);
            }
            return hr3(e5), t5;
          }, toWireType: function(e5, t5) {
            t5 instanceof ArrayBuffer && (t5 = new Uint8Array(t5));
            var n3 = "string" == typeof t5;
            if (!(n3 || t5 instanceof Uint8Array || t5 instanceof Uint8ClampedArray || t5 instanceof Int8Array)) throw new He3("Cannot pass non-string to std::string");
            var r4 = n3 ? Ae3(t5) : t5.length, s4 = fr3(4 + r4 + 1), a4 = s4 + 4;
            if (V3()[s4 >>> 2 >>> 0] = r4, n3) ze3(t5, a4, r4 + 1);
            else if (n3) for (n3 = 0; n3 < r4; ++n3) {
              var o4 = t5.charCodeAt(n3);
              if (255 < o4) throw hr3(s4), new He3("String has UTF-16 code units that do not fit in 8 bits");
              B3()[a4 + n3 >>> 0] = o4;
            }
            else for (n3 = 0; n3 < r4; ++n3) B3()[a4 + n3 >>> 0] = t5[n3];
            return null !== e5 && e5.push(hr3, s4), s4;
          }, Cb: nt3, readValueFromPointer: dt3, Db(e5) {
            hr3(e5);
          } });
        }
        var gt3 = typeof TextDecoder < "u" ? new TextDecoder("utf-16le") : void 0, wt3 = (e4, t4) => {
          for (var n3 = e4 >> 1, r4 = n3 + t4 / 2; !(n3 >= r4) && j3()[n3 >>> 0]; ) ++n3;
          if (32 < (n3 <<= 1) - e4 && gt3) return gt3.decode(B3().slice(e4, n3));
          for (n3 = "", r4 = 0; !(r4 >= t4 / 2); ++r4) {
            var s4 = N3()[e4 + 2 * r4 >>> 1 >>> 0];
            if (0 == s4) break;
            n3 += String.fromCharCode(s4);
          }
          return n3;
        }, bt3 = (e4, t4, n3) => {
          if (n3 ??= 2147483647, 2 > n3) return 0;
          var r4 = t4;
          n3 = (n3 -= 2) < 2 * e4.length ? n3 / 2 : e4.length;
          for (var s4 = 0; s4 < n3; ++s4) {
            var a4 = e4.charCodeAt(s4);
            N3()[t4 >>> 1 >>> 0] = a4, t4 += 2;
          }
          return N3()[t4 >>> 1 >>> 0] = 0, t4 - r4;
        }, yt3 = (e4) => 2 * e4.length, Mt3 = (e4, t4) => {
          for (var n3 = 0, r4 = ""; !(n3 >= t4 / 4); ) {
            var s4 = R3()[e4 + 4 * n3 >>> 2 >>> 0];
            if (0 == s4) break;
            ++n3, 65536 <= s4 ? (s4 -= 65536, r4 += String.fromCharCode(55296 | s4 >> 10, 56320 | 1023 & s4)) : r4 += String.fromCharCode(s4);
          }
          return r4;
        }, xt3 = (e4, t4, n3) => {
          if (t4 >>>= 0, n3 ??= 2147483647, 4 > n3) return 0;
          var r4 = t4;
          n3 = r4 + n3 - 4;
          for (var s4 = 0; s4 < e4.length; ++s4) {
            var a4 = e4.charCodeAt(s4);
            if (55296 <= a4 && 57343 >= a4 && (a4 = 65536 + ((1023 & a4) << 10) | 1023 & e4.charCodeAt(++s4)), R3()[t4 >>> 2 >>> 0] = a4, (t4 += 4) + 4 > n3) break;
          }
          return R3()[t4 >>> 2 >>> 0] = 0, t4 - r4;
        }, vt3 = (e4) => {
          for (var t4 = 0, n3 = 0; n3 < e4.length; ++n3) {
            var r4 = e4.charCodeAt(n3);
            55296 <= r4 && 57343 >= r4 && ++n3, t4 += 4;
          }
          return t4;
        };
        function Tt3(e4, t4, n3) {
          if (e4 >>>= 0, t4 >>>= 0, n3 = Ke3(n3 >>>= 0), 2 === t4) var r4 = wt3, s4 = bt3, a4 = yt3, o4 = (e5) => j3()[e5 >>> 1 >>> 0];
          else 4 === t4 && (r4 = Mt3, s4 = xt3, a4 = vt3, o4 = (e5) => V3()[e5 >>> 2 >>> 0]);
          Ze3(e4, { name: n3, fromWireType: (e5) => {
            for (var n4, s5 = V3()[e5 >>> 2 >>> 0], a5 = e5 + 4, i4 = 0; i4 <= s5; ++i4) {
              var l4 = e5 + 4 + i4 * t4;
              i4 != s5 && 0 != o4(l4) || (a5 = r4(a5, l4 - a5), void 0 === n4 ? n4 = a5 : (n4 += "\0", n4 += a5), a5 = l4 + t4);
            }
            return hr3(e5), n4;
          }, toWireType: (e5, r5) => {
            if ("string" != typeof r5) throw new He3(`Cannot pass non-string to C++ string type ${n3}`);
            var o5 = a4(r5), i4 = fr3(4 + o5 + t4);
            return V3()[i4 >>> 2 >>> 0] = o5 / t4, s4(r5, i4 + 4, o5 + t4), null !== e5 && e5.push(hr3, i4), i4;
          }, Cb: nt3, readValueFromPointer: dt3, Db(e5) {
            hr3(e5);
          } });
        }
        function kt3(e4, t4) {
          Ze3(e4 >>>= 0, { Tb: true, name: t4 = Ke3(t4 >>> 0), Cb: 0, fromWireType: () => {
          }, toWireType: () => {
          } });
        }
        function Pt3(e4) {
          _r3(e4 >>> 0, !i3, 1, !o3, 131072, false), be3();
        }
        var $t3 = (e4) => {
          if (!L3) try {
            if (e4(), !(0 < le3)) try {
              l3 ? yr3(v3) : pe3(v3);
            } catch (e5) {
              e5 instanceof se3 || "unwind" == e5 || f3(0, e5);
            }
          } catch (e5) {
            e5 instanceof se3 || "unwind" == e5 || f3(0, e5);
          }
        };
        function Ct3(e4) {
          e4 >>>= 0, "function" == typeof Atomics.jc && (Atomics.jc(R3(), e4 >>> 2, e4).value.then(St3), e4 += 128, Atomics.store(R3(), e4 >>> 2, 1));
        }
        var St3 = () => {
          var e4 = mr3();
          e4 && (Ct3(e4), $t3(xr3));
        };
        function Ft3(e4, t4) {
          (e4 >>>= 0) == t4 >>> 0 ? setTimeout(St3) : l3 ? postMessage({ Gb: e4, Bb: "checkMailbox" }) : (e4 = ge3[e4]) && e4.postMessage({ Bb: "checkMailbox" });
        }
        var Et3 = [];
        function It3(e4, t4, n3, r4, s4) {
          for (t4 >>>= 0, r4 /= 2, Et3.length = r4, n3 = s4 >>> 0 >>> 3, s4 = 0; s4 < r4; s4++) Et3[s4] = E3[n3 + 2 * s4] ? E3[n3 + 2 * s4 + 1] : q3()[n3 + 2 * s4 + 1 >>> 0];
          return (t4 ? te3[t4] : ur3[e4])(...Et3);
        }
        var At3 = () => {
          le3 = 0;
        };
        function zt3(e4) {
          e4 >>>= 0, l3 ? postMessage({ Bb: "cleanupThread", hc: e4 }) : we3(ge3[e4]);
        }
        function Lt3(e4) {
        }
        var Ot3 = (e4, t4) => {
          var n3 = Je3[e4];
          if (void 0 === n3) throw e4 = cr3(e4), n3 = Ke3(e4), hr3(e4), new He3(`${t4} has unknown type ${n3}`);
          return n3;
        }, Dt3 = (e4, t4, n3) => {
          var r4 = [];
          return e4 = e4.toWireType(r4, n3), r4.length && (V3()[t4 >>> 2 >>> 0] = lt3(r4)), e4;
        };
        function Bt3(e4, t4, n3) {
          return t4 >>>= 0, n3 >>>= 0, e4 = it3(e4 >>> 0), t4 = Ot3(t4, "emval::as"), Dt3(t4, n3, e4);
        }
        function Nt3(e4, t4) {
          return t4 >>>= 0, e4 = it3(e4 >>> 0), (t4 = Ot3(t4, "emval::as")).toWireType(null, e4);
        }
        var jt3 = (e4) => {
          try {
            e4();
          } catch (e5) {
            Z3(e5);
          }
        }, Rt3 = 0, Vt3 = null, Gt3 = 0, qt3 = [], Ut3 = {}, Wt3 = {}, Ht3 = 0, Qt3 = null, Kt3 = [];
        function Xt3(e4) {
          return (function() {
            if (!L3) {
              if (0 === Rt3) {
                var t4 = false, n3 = false;
                ((t5) => {
                  e4().then(t5);
                })(((e5 = 0) => {
                  if (!L3 && (Gt3 = e5, t4 = true, n3)) {
                    Rt3 = 2, jt3((() => Fr3(Vt3))), typeof MainLoop < "u" && MainLoop.Pb && MainLoop.resume(), e5 = false;
                    try {
                      var r4 = (o4 = R3()[Vt3 + 8 >>> 2 >>> 0], o4 = dr3[Wt3[o4]], --le3, o4());
                    } catch (o5) {
                      r4 = o5, e5 = true;
                    }
                    var s4 = false;
                    if (!Vt3) {
                      var a4 = Qt3;
                      a4 && (Qt3 = null, (e5 ? a4.reject : a4.resolve)(r4), s4 = true);
                    }
                    if (e5 && !s4) throw r4;
                  }
                  var o4;
                })), n3 = true, t4 || (Rt3 = 1, Vt3 = (function() {
                  var e5 = fr3(65548), t5 = e5 + 12;
                  V3()[e5 >>> 2 >>> 0] = t5, V3()[e5 + 4 >>> 2 >>> 0] = t5 + 65536, t5 = qt3[0];
                  var n4 = Ut3[t5];
                  return void 0 === n4 && (n4 = Ht3++, Ut3[t5] = n4, Wt3[n4] = t5), t5 = n4, R3()[e5 + 8 >>> 2 >>> 0] = t5, e5;
                })(), typeof MainLoop < "u" && MainLoop.Pb && MainLoop.pause(), jt3((() => Cr3(Vt3))));
              } else 2 === Rt3 ? (Rt3 = 0, jt3(Er3), hr3(Vt3), Vt3 = null, Kt3.forEach($t3)) : Z3(`invalid state: ${Rt3}`);
              return Gt3;
            }
          })();
        }
        function Jt3(e4) {
          return e4 >>>= 0, Xt3((async () => {
            var t4 = await it3(e4);
            return lt3(t4);
          }));
        }
        var Yt3 = [];
        function Zt3(e4, t4, n3, r4) {
          return n3 >>>= 0, r4 >>>= 0, (e4 = Yt3[e4 >>> 0])(null, t4 = it3(t4 >>> 0), n3, r4);
        }
        var en3 = {}, tn3 = (e4) => {
          var t4 = en3[e4];
          return void 0 === t4 ? Ke3(e4) : t4;
        };
        function nn3(e4, t4, n3, r4, s4) {
          return n3 >>>= 0, r4 >>>= 0, s4 >>>= 0, (e4 = Yt3[e4 >>> 0])(t4 = it3(t4 >>> 0), t4[n3 = tn3(n3)], r4, s4);
        }
        var rn3 = () => "object" == typeof globalThis ? globalThis : Function("return this")();
        function sn3(e4) {
          return 0 == (e4 >>>= 0) ? lt3(rn3()) : (e4 = tn3(e4), lt3(rn3()[e4]));
        }
        var an3 = (e4) => {
          var t4 = Yt3.length;
          return Yt3.push(e4), t4;
        }, on3 = (e4, t4) => {
          for (var n3 = Array(e4), r4 = 0; r4 < e4; ++r4) n3[r4] = Ot3(V3()[t4 + 4 * r4 >>> 2 >>> 0], "parameter " + r4);
          return n3;
        }, ln3 = (e4, t4) => Object.defineProperty(t4, "name", { value: e4 });
        function dn3(e4, t4, n3) {
          var r4 = (t4 = on3(e4, t4 >>> 0)).shift();
          e4--;
          var s4 = "return function (obj, func, destructorsRef, args) {\n", a4 = 0, o4 = [];
          0 === n3 && o4.push("obj");
          for (var i4 = ["retType"], l4 = [r4], d4 = 0; d4 < e4; ++d4) o4.push("arg" + d4), i4.push("argType" + d4), l4.push(t4[d4]), s4 += `  var arg${d4} = argType${d4}.readValueFromPointer(args${a4 ? "+" + a4 : ""});
`, a4 += t4[d4].Cb;
          return s4 += `  var rv = ${1 === n3 ? "new func" : "func.call"}(${o4.join(", ")});
`, r4.Tb || (i4.push("emval_returnValue"), l4.push(Dt3), s4 += "  return emval_returnValue(retType, destructorsRef, rv);\n"), i4.push(s4 + "};\n"), e4 = (function(e5) {
            var t5 = Function;
            if (!(t5 instanceof Function)) throw new TypeError(`new_ called with constructor type ${typeof t5} which is not a function`);
            var n4 = ln3(t5.name || "unknownFunctionName", (function() {
            }));
            return n4.prototype = t5.prototype, n4 = new n4(), (e5 = t5.apply(n4, e5)) instanceof Object ? e5 : n4;
          })(i4)(...l4), n3 = `methodCaller<(${t4.map(((e5) => e5.name)).join(", ")}) => ${r4.name}>`, an3(ln3(n3, e4));
        }
        function un3(e4) {
          return e4 = tn3(e4 >>> 0), lt3(s3[e4]);
        }
        function cn3(e4, t4) {
          return t4 >>>= 0, e4 = it3(e4 >>> 0), t4 = it3(t4), lt3(e4[t4]);
        }
        function pn3(e4) {
          9 < (e4 >>>= 0) && (at3[e4 + 1] += 1);
        }
        function mn3() {
          return lt3([]);
        }
        function hn3(e4) {
          e4 = it3(e4 >>> 0);
          for (var t4 = Array(e4.length), n3 = 0; n3 < e4.length; n3++) t4[n3] = e4[n3];
          return lt3(t4);
        }
        function fn3(e4) {
          return lt3(tn3(e4 >>> 0));
        }
        function _n3() {
          return lt3({});
        }
        function gn3(e4) {
          for (var t4 = it3(e4 >>>= 0); t4.length; ) {
            var n3 = t4.pop();
            t4.pop()(n3);
          }
          ot3(e4);
        }
        function wn3(e4, t4, n3) {
          t4 >>>= 0, n3 >>>= 0, e4 = it3(e4 >>> 0), t4 = it3(t4), n3 = it3(n3), e4[t4] = n3;
        }
        function bn3(e4, t4) {
          return t4 >>>= 0, e4 = (e4 = Ot3(e4 >>> 0, "_emval_take_value")).readValueFromPointer(t4), lt3(e4);
        }
        function yn3(e4, t4) {
          e4 = -9007199254740992 > e4 || 9007199254740992 < e4 ? NaN : Number(e4), t4 >>>= 0, e4 = new Date(1e3 * e4), R3()[t4 >>> 2 >>> 0] = e4.getUTCSeconds(), R3()[t4 + 4 >>> 2 >>> 0] = e4.getUTCMinutes(), R3()[t4 + 8 >>> 2 >>> 0] = e4.getUTCHours(), R3()[t4 + 12 >>> 2 >>> 0] = e4.getUTCDate(), R3()[t4 + 16 >>> 2 >>> 0] = e4.getUTCMonth(), R3()[t4 + 20 >>> 2 >>> 0] = e4.getUTCFullYear() - 1900, R3()[t4 + 24 >>> 2 >>> 0] = e4.getUTCDay(), e4 = (e4.getTime() - Date.UTC(e4.getUTCFullYear(), 0, 1, 0, 0, 0, 0)) / 864e5 | 0, R3()[t4 + 28 >>> 2 >>> 0] = e4;
        }
        var Mn3 = (e4) => e4 % 4 == 0 && (e4 % 100 != 0 || e4 % 400 == 0), xn3 = [0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335], vn3 = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334];
        function Tn3(e4, t4) {
          e4 = -9007199254740992 > e4 || 9007199254740992 < e4 ? NaN : Number(e4), t4 >>>= 0, e4 = new Date(1e3 * e4), R3()[t4 >>> 2 >>> 0] = e4.getSeconds(), R3()[t4 + 4 >>> 2 >>> 0] = e4.getMinutes(), R3()[t4 + 8 >>> 2 >>> 0] = e4.getHours(), R3()[t4 + 12 >>> 2 >>> 0] = e4.getDate(), R3()[t4 + 16 >>> 2 >>> 0] = e4.getMonth(), R3()[t4 + 20 >>> 2 >>> 0] = e4.getFullYear() - 1900, R3()[t4 + 24 >>> 2 >>> 0] = e4.getDay();
          var n3 = (Mn3(e4.getFullYear()) ? xn3 : vn3)[e4.getMonth()] + e4.getDate() - 1 | 0;
          R3()[t4 + 28 >>> 2 >>> 0] = n3, R3()[t4 + 36 >>> 2 >>> 0] = -60 * e4.getTimezoneOffset(), n3 = new Date(e4.getFullYear(), 6, 1).getTimezoneOffset();
          var r4 = new Date(e4.getFullYear(), 0, 1).getTimezoneOffset();
          e4 = 0 | (n3 != r4 && e4.getTimezoneOffset() == Math.min(r4, n3)), R3()[t4 + 32 >>> 2 >>> 0] = e4;
        }
        function kn3(e4) {
          e4 >>>= 0;
          var t4 = new Date(R3()[e4 + 20 >>> 2 >>> 0] + 1900, R3()[e4 + 16 >>> 2 >>> 0], R3()[e4 + 12 >>> 2 >>> 0], R3()[e4 + 8 >>> 2 >>> 0], R3()[e4 + 4 >>> 2 >>> 0], R3()[e4 >>> 2 >>> 0], 0), n3 = R3()[e4 + 32 >>> 2 >>> 0], r4 = t4.getTimezoneOffset(), s4 = new Date(t4.getFullYear(), 6, 1).getTimezoneOffset(), a4 = new Date(t4.getFullYear(), 0, 1).getTimezoneOffset(), o4 = Math.min(a4, s4);
          return 0 > n3 ? R3()[e4 + 32 >>> 2 >>> 0] = +(s4 != a4 && o4 == r4) : 0 < n3 != (o4 == r4) && (s4 = Math.max(a4, s4), t4.setTime(t4.getTime() + 6e4 * ((0 < n3 ? o4 : s4) - r4))), R3()[e4 + 24 >>> 2 >>> 0] = t4.getDay(), n3 = (Mn3(t4.getFullYear()) ? xn3 : vn3)[t4.getMonth()] + t4.getDate() - 1 | 0, R3()[e4 + 28 >>> 2 >>> 0] = n3, R3()[e4 >>> 2 >>> 0] = t4.getSeconds(), R3()[e4 + 4 >>> 2 >>> 0] = t4.getMinutes(), R3()[e4 + 8 >>> 2 >>> 0] = t4.getHours(), R3()[e4 + 12 >>> 2 >>> 0] = t4.getDate(), R3()[e4 + 16 >>> 2 >>> 0] = t4.getMonth(), R3()[e4 + 20 >>> 2 >>> 0] = t4.getYear(), e4 = t4.getTime(), BigInt(isNaN(e4) ? -1 : e4 / 1e3);
        }
        function Pn3(e4, t4, n3, r4, s4, a4, o4) {
          return l3 ? de3(16, 1, e4, t4, n3, r4, s4, a4, o4) : -52;
        }
        function $n3(e4, t4, n3, r4, s4, a4) {
          if (l3) return de3(17, 1, e4, t4, n3, r4, s4, a4);
        }
        var Cn3 = {}, Sn3 = () => performance.timeOrigin + performance.now();
        function Fn3(e4, t4) {
          if (l3) return de3(18, 1, e4, t4);
          if (Cn3[e4] && (clearTimeout(Cn3[e4].id), delete Cn3[e4]), !t4) return 0;
          var n3 = setTimeout((() => {
            delete Cn3[e4], $t3((() => Mr3(e4, performance.timeOrigin + performance.now())));
          }), t4);
          return Cn3[e4] = { id: n3, qc: t4 }, 0;
        }
        function En3(e4, t4, n3, r4) {
          e4 >>>= 0, t4 >>>= 0, n3 >>>= 0, r4 >>>= 0;
          var s4 = (/* @__PURE__ */ new Date()).getFullYear(), a4 = new Date(s4, 0, 1).getTimezoneOffset();
          s4 = new Date(s4, 6, 1).getTimezoneOffset();
          var o4 = Math.max(a4, s4);
          V3()[e4 >>> 2 >>> 0] = 60 * o4, R3()[t4 >>> 2 >>> 0] = +(a4 != s4), e4 = (t4 = (e5) => {
            var t5 = Math.abs(e5);
            return `UTC${0 <= e5 ? "-" : "+"}${String(Math.floor(t5 / 60)).padStart(2, "0")}${String(t5 % 60).padStart(2, "0")}`;
          })(a4), t4 = t4(s4), s4 < a4 ? (ze3(e4, n3, 17), ze3(t4, r4, 17)) : (ze3(e4, r4, 17), ze3(t4, n3, 17));
        }
        var In3 = () => Date.now(), An3 = 1;
        function zn3(e4, t4, n3) {
          if (!(0 <= e4 && 3 >= e4)) return 28;
          if (0 === e4) e4 = Date.now();
          else {
            if (!An3) return 52;
            e4 = performance.timeOrigin + performance.now();
          }
          return E3[n3 >>> 0 >>> 3] = BigInt(Math.round(1e6 * e4)), 0;
        }
        var Ln3 = [], On3 = (e4, t4) => {
          Ln3.length = 0;
          for (var n3; n3 = B3()[e4++ >>> 0]; ) {
            var r4 = 105 != n3;
            t4 += (r4 &= 112 != n3) && t4 % 8 ? 4 : 0, Ln3.push(112 == n3 ? V3()[t4 >>> 2 >>> 0] : 106 == n3 ? E3[t4 >>> 3] : 105 == n3 ? R3()[t4 >>> 2 >>> 0] : q3()[t4 >>> 3 >>> 0]), t4 += r4 ? 8 : 4;
          }
          return Ln3;
        };
        function Dn3(e4, t4, n3) {
          return e4 >>>= 0, t4 = On3(t4 >>> 0, n3 >>> 0), te3[e4](...t4);
        }
        function Bn3(e4, t4, n3) {
          return e4 >>>= 0, t4 = On3(t4 >>> 0, n3 >>> 0), te3[e4](...t4);
        }
        var Nn3 = () => {
        };
        function jn3(e4, t4) {
          return y3(Fe3(e4 >>> 0, t4 >>> 0));
        }
        var Rn3 = () => {
          throw le3 += 1, "unwind";
        };
        function Vn3() {
          return 4294901760;
        }
        var Gn3 = () => navigator.hardwareConcurrency;
        function qn3() {
          return Z3("Cannot use emscripten_pc_get_function without -sUSE_OFFSET_CONVERTER"), 0;
        }
        function Un3(e4) {
          e4 >>>= 0;
          var t4 = B3().length;
          if (e4 <= t4 || 4294901760 < e4) return false;
          for (var n3 = 1; 4 >= n3; n3 *= 2) {
            var r4 = t4 * (1 + 0.2 / n3);
            r4 = Math.min(r4, e4 + 100663296);
            e: {
              r4 = (Math.min(4294901760, 65536 * Math.ceil(Math.max(e4, r4) / 65536)) - M3.buffer.byteLength + 65535) / 65536 | 0;
              try {
                M3.grow(r4), H3();
                var s4 = 1;
                break e;
              } catch {
              }
              s4 = void 0;
            }
            if (s4) return true;
          }
          return false;
        }
        var Wn3 = () => (Z3("Cannot use convertFrameToPC (needed by __builtin_return_address) without -sUSE_OFFSET_CONVERTER"), 0), Hn3 = {}, Qn3 = (e4) => {
          e4.forEach(((e5) => {
            var t4 = Wn3();
            t4 && (Hn3[t4] = e5);
          }));
        };
        function Kn3() {
          var e4 = Error().stack.toString().split("\n");
          return "Error" == e4[0] && e4.shift(), Qn3(e4), Hn3.Lb = Wn3(), Hn3.cc = e4, Hn3.Lb;
        }
        function Xn3(e4, t4, n3) {
          if (e4 >>>= 0, t4 >>>= 0, Hn3.Lb == e4) var r4 = Hn3.cc;
          else "Error" == (r4 = Error().stack.toString().split("\n"))[0] && r4.shift(), Qn3(r4);
          for (var s4 = 3; r4[s4] && Wn3() != e4; ) ++s4;
          for (e4 = 0; e4 < n3 && r4[e4 + s4]; ++e4) R3()[t4 + 4 * e4 >>> 2 >>> 0] = Wn3();
          return e4;
        }
        var Jn3, Yn3 = {}, Zn3 = () => {
          if (!Jn3) {
            var e4, t4 = { USER: "web_user", LOGNAME: "web_user", PATH: "/", PWD: "/", HOME: "/home/web_user", LANG: ("object" == typeof navigator && navigator.languages && navigator.languages[0] || "C").replace("-", "_") + ".UTF-8", _: "./this.program" };
            for (e4 in Yn3) void 0 === Yn3[e4] ? delete t4[e4] : t4[e4] = Yn3[e4];
            var n3 = [];
            for (e4 in t4) n3.push(`${e4}=${t4[e4]}`);
            Jn3 = n3;
          }
          return Jn3;
        };
        function er3(e4, t4) {
          if (l3) return de3(19, 1, e4, t4);
          e4 >>>= 0, t4 >>>= 0;
          var n3 = 0;
          return Zn3().forEach(((r4, s4) => {
            var a4 = t4 + n3;
            for (s4 = V3()[e4 + 4 * s4 >>> 2 >>> 0] = a4, a4 = 0; a4 < r4.length; ++a4) D3()[s4++ >>> 0] = r4.charCodeAt(a4);
            D3()[s4 >>> 0] = 0, n3 += r4.length + 1;
          })), 0;
        }
        function tr3(e4, t4) {
          if (l3) return de3(20, 1, e4, t4);
          e4 >>>= 0, t4 >>>= 0;
          var n3 = Zn3();
          V3()[e4 >>> 2 >>> 0] = n3.length;
          var r4 = 0;
          return n3.forEach(((e5) => r4 += e5.length + 1)), V3()[t4 >>> 2 >>> 0] = r4, 0;
        }
        function nr3(e4) {
          return l3 ? de3(21, 1, e4) : 52;
        }
        function rr3(e4, t4, n3, r4) {
          return l3 ? de3(22, 1, e4, t4, n3, r4) : 52;
        }
        function sr3(e4, t4, n3, r4) {
          return l3 ? de3(23, 1, e4, t4, n3, r4) : 70;
        }
        var ar3 = [null, [], []];
        function or3(e4, t4, n3, r4) {
          if (l3) return de3(24, 1, e4, t4, n3, r4);
          t4 >>>= 0, n3 >>>= 0, r4 >>>= 0;
          for (var s4 = 0, a4 = 0; a4 < n3; a4++) {
            var o4 = V3()[t4 >>> 2 >>> 0], i4 = V3()[t4 + 4 >>> 2 >>> 0];
            t4 += 8;
            for (var d4 = 0; d4 < i4; d4++) {
              var u4 = B3()[o4 + d4 >>> 0], c4 = ar3[e4];
              0 === u4 || 10 === u4 ? ((1 === e4 ? b3 : y3)(Se3(c4)), c4.length = 0) : c4.push(u4);
            }
            s4 += i4;
          }
          return V3()[r4 >>> 2 >>> 0] = s4, 0;
        }
        l3 || (function() {
          for (var e4 = s3.numThreads - 1; e4--; ) Me3();
          oe3.unshift((() => {
            var e5;
            X3++, e5 = () => Y3(), l3 ? e5() : Promise.all(me3.map(ye3)).then(e5);
          }));
        })();
        for (var ir3 = Array(256), lr3 = 0; 256 > lr3; ++lr3) ir3[lr3] = String.fromCharCode(lr3);
        We3 = ir3, He3 = s3.BindingError = class extends Error {
          constructor(e4) {
            super(e4), this.name = "BindingError";
          }
        }, s3.InternalError = class extends Error {
          constructor(e4) {
            super(e4), this.name = "InternalError";
          }
        }, at3.push(0, 1, void 0, 1, null, 1, true, 1, false, 1), s3.count_emval_handles = () => at3.length / 2 - 5 - st3.length;
        var dr3, ur3 = [ue3, ce3, Pe3, Ee3, Ie3, Le3, Oe3, De3, Be3, Ne3, je3, Re3, Ve3, Ge3, qe3, Ue3, Pn3, $n3, Fn3, er3, tr3, nr3, rr3, sr3, or3];
        !(async function() {
          function e4(e5, t5) {
            return dr3 = e5.exports, dr3 = (function() {
              var e6 = dr3, t6 = {};
              for (let [n4, r5] of Object.entries(e6)) t6[n4] = "function" == typeof r5 ? (...e7) => {
                qt3.push(n4);
                try {
                  return r5(...e7);
                } finally {
                  L3 || (qt3.pop(), Vt3 && 1 === Rt3 && 0 === qt3.length && (Rt3 = 0, le3 += 1, jt3(Sr3), typeof Fibers < "u" && Fibers.rc()));
                }
              } : r5;
              return t6;
            })(), n3 = dr3, r4 = (e6) => (t6) => e6(t6) >>> 0, s4 = (e6) => () => e6() >>> 0, (n3 = Object.assign({}, n3)).Da = r4(n3.Da), n3.fb = s4(n3.fb), n3.hb = r4(n3.hb), n3.tb = r4(n3.tb), n3.ub = s4(n3.ub), n3.__cxa_get_exception_ptr = r4(n3.__cxa_get_exception_ptr), dr3 = n3, fe3.push(dr3.ib), x3 = t5, Y3(), dr3;
            var n3, r4, s4;
          }
          X3++;
          var t4 = ee3();
          if (s3.instantiateWasm) return new Promise(((n3) => {
            s3.instantiateWasm(t4, ((t5, r4) => {
              e4(t5, r4), n3(t5.exports);
            }));
          }));
          if (l3) return new Promise(((t5) => {
            U3 = (n3) => {
              var r4 = new WebAssembly.Instance(n3, ee3());
              t5(e4(r4, n3));
            };
          }));
          K3 ??= s3.locateFile ? s3.locateFile ? s3.locateFile("ort-wasm-simd-threaded.jsep.wasm", _3) : _3 + "ort-wasm-simd-threaded.jsep.wasm" : new URL(n2("./node_modules/onnxruntime-web/dist/ort-wasm-simd-threaded.jsep.wasm"), n2.b).href;
          try {
            var a4 = await (async function(e5) {
              var t5 = K3;
              if (!z3 && "function" == typeof WebAssembly.instantiateStreaming && !O3(t5)) try {
                var n3 = fetch(t5, { credentials: "same-origin" });
                return await WebAssembly.instantiateStreaming(n3, e5);
              } catch (e6) {
                y3(`wasm streaming compile failed: ${e6}`), y3("falling back to ArrayBuffer instantiation");
              }
              return (async function(e6, t6) {
                try {
                  var n4 = await (async function(e7) {
                    if (!z3) try {
                      var t7 = await p3(e7);
                      return new Uint8Array(t7);
                    } catch {
                    }
                    if (e7 == K3 && z3) e7 = new Uint8Array(z3);
                    else {
                      if (!m3) throw "both async and sync fetching of the wasm failed";
                      e7 = m3(e7);
                    }
                    return e7;
                  })(e6);
                  return await WebAssembly.instantiate(n4, t6);
                } catch (e7) {
                  y3(`failed to asynchronously prepare wasm: ${e7}`), Z3(e7);
                }
              })(t5, e5);
            })(t4);
            return e4(a4.instance, a4.module);
          } catch (e5) {
            return r3(e5), Promise.reject(e5);
          }
        })();
        var cr3 = (e4) => (cr3 = dr3.Da)(e4), pr3 = () => (pr3 = dr3.Ea)();
        s3._OrtInit = (e4, t4) => (s3._OrtInit = dr3.Fa)(e4, t4), s3._OrtGetLastError = (e4, t4) => (s3._OrtGetLastError = dr3.Ga)(e4, t4), s3._OrtCreateSessionOptions = (e4, t4, n3, r4, a4, o4, i4, l4, d4, u4) => (s3._OrtCreateSessionOptions = dr3.Ha)(e4, t4, n3, r4, a4, o4, i4, l4, d4, u4), s3._OrtAppendExecutionProvider = (e4, t4, n3, r4, a4) => (s3._OrtAppendExecutionProvider = dr3.Ia)(e4, t4, n3, r4, a4), s3._OrtAddFreeDimensionOverride = (e4, t4, n3) => (s3._OrtAddFreeDimensionOverride = dr3.Ja)(e4, t4, n3), s3._OrtAddSessionConfigEntry = (e4, t4, n3) => (s3._OrtAddSessionConfigEntry = dr3.Ka)(e4, t4, n3), s3._OrtReleaseSessionOptions = (e4) => (s3._OrtReleaseSessionOptions = dr3.La)(e4), s3._OrtCreateSession = (e4, t4, n3) => (s3._OrtCreateSession = dr3.Ma)(e4, t4, n3), s3._OrtReleaseSession = (e4) => (s3._OrtReleaseSession = dr3.Na)(e4), s3._OrtGetInputOutputCount = (e4, t4, n3) => (s3._OrtGetInputOutputCount = dr3.Oa)(e4, t4, n3), s3._OrtGetInputOutputMetadata = (e4, t4, n3, r4) => (s3._OrtGetInputOutputMetadata = dr3.Pa)(e4, t4, n3, r4), s3._OrtFree = (e4) => (s3._OrtFree = dr3.Qa)(e4), s3._OrtCreateTensor = (e4, t4, n3, r4, a4, o4) => (s3._OrtCreateTensor = dr3.Ra)(e4, t4, n3, r4, a4, o4), s3._OrtGetTensorData = (e4, t4, n3, r4, a4) => (s3._OrtGetTensorData = dr3.Sa)(e4, t4, n3, r4, a4), s3._OrtReleaseTensor = (e4) => (s3._OrtReleaseTensor = dr3.Ta)(e4), s3._OrtCreateRunOptions = (e4, t4, n3, r4) => (s3._OrtCreateRunOptions = dr3.Ua)(e4, t4, n3, r4), s3._OrtAddRunConfigEntry = (e4, t4, n3) => (s3._OrtAddRunConfigEntry = dr3.Va)(e4, t4, n3), s3._OrtReleaseRunOptions = (e4) => (s3._OrtReleaseRunOptions = dr3.Wa)(e4), s3._OrtCreateBinding = (e4) => (s3._OrtCreateBinding = dr3.Xa)(e4), s3._OrtBindInput = (e4, t4, n3) => (s3._OrtBindInput = dr3.Ya)(e4, t4, n3), s3._OrtBindOutput = (e4, t4, n3, r4) => (s3._OrtBindOutput = dr3.Za)(e4, t4, n3, r4), s3._OrtClearBoundOutputs = (e4) => (s3._OrtClearBoundOutputs = dr3._a)(e4), s3._OrtReleaseBinding = (e4) => (s3._OrtReleaseBinding = dr3.$a)(e4), s3._OrtRunWithBinding = (e4, t4, n3, r4, a4) => (s3._OrtRunWithBinding = dr3.ab)(e4, t4, n3, r4, a4), s3._OrtRun = (e4, t4, n3, r4, a4, o4, i4, l4) => (s3._OrtRun = dr3.bb)(e4, t4, n3, r4, a4, o4, i4, l4), s3._OrtEndProfiling = (e4) => (s3._OrtEndProfiling = dr3.cb)(e4), s3._JsepOutput = (e4, t4, n3) => (s3._JsepOutput = dr3.db)(e4, t4, n3), s3._JsepGetNodeName = (e4) => (s3._JsepGetNodeName = dr3.eb)(e4);
        var mr3 = () => (mr3 = dr3.fb)(), hr3 = s3._free = (e4) => (hr3 = s3._free = dr3.gb)(e4), fr3 = s3._malloc = (e4) => (fr3 = s3._malloc = dr3.hb)(e4), _r3 = (e4, t4, n3, r4, s4, a4) => (_r3 = dr3.kb)(e4, t4, n3, r4, s4, a4), gr3 = () => (gr3 = dr3.lb)(), wr3 = (e4, t4, n3, r4, s4) => (wr3 = dr3.mb)(e4, t4, n3, r4, s4), br3 = (e4) => (br3 = dr3.nb)(e4), yr3 = (e4) => (yr3 = dr3.ob)(e4), Mr3 = (e4, t4) => (Mr3 = dr3.pb)(e4, t4), xr3 = () => (xr3 = dr3.qb)(), vr3 = (e4, t4) => (vr3 = dr3.rb)(e4, t4), Tr3 = (e4) => (Tr3 = dr3.sb)(e4), kr3 = (e4) => (kr3 = dr3.tb)(e4), Pr3 = () => (Pr3 = dr3.ub)(), $r3 = s3.dynCall_ii = (e4, t4) => ($r3 = s3.dynCall_ii = dr3.vb)(e4, t4), Cr3 = (e4) => (Cr3 = dr3.wb)(e4), Sr3 = () => (Sr3 = dr3.xb)(), Fr3 = (e4) => (Fr3 = dr3.yb)(e4), Er3 = () => (Er3 = dr3.zb)();
        return s3.stackSave = () => Pr3(), s3.stackRestore = (e4) => Tr3(e4), s3.stackAlloc = (e4) => kr3(e4), s3.setValue = function(e4, t4, n3 = "i8") {
          switch (n3.endsWith("*") && (n3 = "*"), n3) {
            case "i1":
            case "i8":
              D3()[e4 >>> 0] = t4;
              break;
            case "i16":
              N3()[e4 >>> 1 >>> 0] = t4;
              break;
            case "i32":
              R3()[e4 >>> 2 >>> 0] = t4;
              break;
            case "i64":
              E3[e4 >>> 3] = BigInt(t4);
              break;
            case "float":
              G3()[e4 >>> 2 >>> 0] = t4;
              break;
            case "double":
              q3()[e4 >>> 3 >>> 0] = t4;
              break;
            case "*":
              V3()[e4 >>> 2 >>> 0] = t4;
              break;
            default:
              Z3(`invalid type for setValue: ${n3}`);
          }
        }, s3.getValue = function(e4, t4 = "i8") {
          switch (t4.endsWith("*") && (t4 = "*"), t4) {
            case "i1":
            case "i8":
              return D3()[e4 >>> 0];
            case "i16":
              return N3()[e4 >>> 1 >>> 0];
            case "i32":
              return R3()[e4 >>> 2 >>> 0];
            case "i64":
              return E3[e4 >>> 3];
            case "float":
              return G3()[e4 >>> 2 >>> 0];
            case "double":
              return q3()[e4 >>> 3 >>> 0];
            case "*":
              return V3()[e4 >>> 2 >>> 0];
            default:
              Z3(`invalid type for getValue: ${t4}`);
          }
        }, s3.UTF8ToString = Fe3, s3.stringToUTF8 = ze3, s3.lengthBytesUTF8 = Ae3, (function e4() {
          if (0 < X3) J3 = e4;
          else if (l3) t3(s3), Q3();
          else {
            for (; 0 < oe3.length; ) oe3.shift()(s3);
            0 < X3 ? J3 = e4 : (s3.calledRun = true, L3 || (Q3(), t3(s3)));
          }
        })(), s3.PTR_SIZE = 4, a3;
      }, we2 = ge2, be2 = globalThis.self?.name?.startsWith("em-pthread"), be2 && ge2();
    })), sd2 = j2((() => {
      de2(), ye2 = typeof location > "u" ? void 0 : location.origin, Me2 = import_meta.url > "file:" && import_meta.url < "file;", xe2 = () => {
        if (Me2) {
          let e3 = URL;
          return new URL(new e3(n2("./node_modules/onnxruntime-web/dist/ort.bundle.min.mjs?46eb"), n2.b).href, ye2).href;
        }
        return import_meta.url;
      }, ve2 = xe2(), Te2 = () => {
        if (ve2 && !ve2.startsWith("blob:")) return ve2.substring(0, ve2.lastIndexOf("/") + 1);
      }, ke2 = (e3, t3) => {
        try {
          let n3 = t3 ?? ve2;
          return (n3 ? new URL(e3, n3) : new URL(e3)).origin === ye2;
        } catch {
          return false;
        }
      }, Pe2 = (e3, t3) => {
        let n3 = t3 ?? ve2;
        try {
          return (n3 ? new URL(e3, n3) : new URL(e3)).href;
        } catch {
          return;
        }
      }, $e2 = (e3, t3) => `${t3 ?? "./"}${e3}`, Ce2 = async (e3) => {
        let t3 = await (await fetch(e3, { credentials: "same-origin" })).blob();
        return URL.createObjectURL(t3);
      }, Se2 = async (e3) => (await import(e3)).default, Fe2 = (he2(), V2(ue2)).default, Ee2 = async () => {
        if (!ve2) throw new Error("Failed to load proxy worker: cannot determine the script source URL.");
        if (ke2(ve2)) return [void 0, Fe2()];
        let e3 = await Ce2(ve2);
        return [e3, Fe2(e3)];
      }, Ie2 = (rd2(), V2(fe2)).default, Ae2 = async (e3, t3, n3) => {
        if (!e3 && !t3 && Ie2 && ve2 && ke2(ve2)) return [void 0, Ie2];
        {
          let r3 = "ort-wasm-simd-threaded.jsep.mjs", s3 = e3 ?? Pe2(r3, t3), a3 = n3 && s3 && !ke2(s3, t3), o3 = a3 ? await Ce2(s3) : s3 ?? $e2(r3, t3);
          return [a3 ? o3 : void 0, await Se2(o3)];
        }
      };
    })), ad2 = j2((() => {
      sd2(), Le2 = false, Oe2 = false, De2 = false, Be2 = () => {
        if (typeof SharedArrayBuffer > "u") return false;
        try {
          return typeof MessageChannel < "u" && new MessageChannel().port1.postMessage(new SharedArrayBuffer(1)), WebAssembly.validate(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 5, 4, 1, 3, 1, 1, 10, 11, 1, 9, 0, 65, 0, 254, 16, 2, 0, 26, 11]));
        } catch {
          return false;
        }
      }, Ne2 = () => {
        try {
          return WebAssembly.validate(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1, 28, 0, 65, 0, 253, 15, 253, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 253, 186, 1, 26, 11]));
        } catch {
          return false;
        }
      }, je2 = () => {
        try {
          return WebAssembly.validate(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 123, 3, 2, 1, 0, 10, 19, 1, 17, 0, 65, 1, 253, 15, 65, 2, 253, 15, 65, 3, 253, 15, 253, 147, 2, 11]));
        } catch {
          return false;
        }
      }, Re2 = async (e3) => {
        if (Le2) return Promise.resolve();
        if (Oe2) throw new Error("multiple calls to 'initializeWebAssembly()' detected.");
        if (De2) throw new Error("previous call to 'initializeWebAssembly()' failed.");
        Oe2 = true;
        let t3 = e3.initTimeout, n3 = e3.numThreads;
        if (false !== e3.simd) {
          if ("relaxed" === e3.simd) {
            if (!je2()) throw new Error("Relaxed WebAssembly SIMD is not supported in the current environment.");
          } else if (!Ne2()) throw new Error("WebAssembly SIMD is not supported in the current environment.");
        }
        let r3 = Be2();
        n3 > 1 && !r3 && (typeof self < "u" && !self.crossOriginIsolated && console.warn("env.wasm.numThreads is set to " + n3 + ", but this will not work unless you enable crossOriginIsolated mode. See https://web.dev/cross-origin-isolation-guide/ for more info."), console.warn("WebAssembly multi-threading is not supported in the current environment. Falling back to single-threading."), e3.numThreads = n3 = 1);
        let s3 = e3.wasmPaths, a3 = "string" == typeof s3 ? s3 : void 0, o3 = s3?.mjs, i3 = o3?.href ?? o3, l3 = s3?.wasm, d3 = l3?.href ?? l3, u3 = e3.wasmBinary, [c3, p3] = await Ae2(i3, a3, n3 > 1), m3 = false, h3 = [];
        if (t3 > 0 && h3.push(new Promise(((e4) => {
          setTimeout((() => {
            m3 = true, e4();
          }), t3);
        }))), h3.push(new Promise(((e4, t4) => {
          let r4 = { numThreads: n3 };
          if (u3) r4.wasmBinary = u3;
          else if (d3 || a3) r4.locateFile = (e5) => d3 ?? a3 + e5;
          else if (i3 && 0 !== i3.indexOf("blob:")) r4.locateFile = (e5) => new URL(e5, i3).href;
          else if (c3) {
            let e5 = Te2();
            e5 && (r4.locateFile = (t5) => e5 + t5);
          }
          p3(r4).then(((t5) => {
            Oe2 = false, Le2 = true, ze2 = t5, e4(), c3 && URL.revokeObjectURL(c3);
          }), ((e5) => {
            Oe2 = false, De2 = true, t4(e5);
          }));
        }))), await Promise.race(h3), m3) throw new Error(`WebAssembly backend initializing failed due to timeout: ${t3}ms`);
      }, Ve2 = () => {
        if (Le2 && ze2) return ze2;
        throw new Error("WebAssembly is not initialized yet.");
      };
    })), od2 = j2((() => {
      ad2(), Ge2 = (e3, t3) => {
        let n3 = Ve2(), r3 = n3.lengthBytesUTF8(e3) + 1, s3 = n3._malloc(r3);
        return n3.stringToUTF8(e3, s3, r3), t3.push(s3), s3;
      }, qe2 = (e3, t3, n3, r3) => {
        if ("object" == typeof e3 && null !== e3) {
          if (n3.has(e3)) throw new Error("Circular reference in options");
          n3.add(e3);
        }
        Object.entries(e3).forEach((([e4, s3]) => {
          let a3 = t3 ? t3 + e4 : e4;
          if ("object" == typeof s3) qe2(s3, a3 + ".", n3, r3);
          else if ("string" == typeof s3 || "number" == typeof s3) r3(a3, s3.toString());
          else {
            if ("boolean" != typeof s3) throw new Error("Can't handle extra config type: " + typeof s3);
            r3(a3, s3 ? "1" : "0");
          }
        }));
      }, Ue2 = (e3) => {
        let t3 = Ve2(), n3 = t3.stackSave();
        try {
          let n4 = t3.PTR_SIZE, r3 = t3.stackAlloc(2 * n4);
          t3._OrtGetLastError(r3, r3 + n4);
          let s3 = Number(t3.getValue(r3, 4 === n4 ? "i32" : "i64")), a3 = t3.getValue(r3 + n4, "*"), o3 = a3 ? t3.UTF8ToString(a3) : "";
          throw new Error(`${e3} ERROR_CODE: ${s3}, ERROR_MESSAGE: ${o3}`);
        } finally {
          t3.stackRestore(n3);
        }
      };
    })), id2 = j2((() => {
      ad2(), od2(), We2 = (e3) => {
        let t3 = Ve2(), n3 = 0, r3 = [], s3 = e3 || {};
        try {
          if (void 0 === e3?.logSeverityLevel) s3.logSeverityLevel = 2;
          else if ("number" != typeof e3.logSeverityLevel || !Number.isInteger(e3.logSeverityLevel) || e3.logSeverityLevel < 0 || e3.logSeverityLevel > 4) throw new Error(`log serverity level is not valid: ${e3.logSeverityLevel}`);
          if (void 0 === e3?.logVerbosityLevel) s3.logVerbosityLevel = 0;
          else if ("number" != typeof e3.logVerbosityLevel || !Number.isInteger(e3.logVerbosityLevel)) throw new Error(`log verbosity level is not valid: ${e3.logVerbosityLevel}`);
          void 0 === e3?.terminate && (s3.terminate = false);
          let a3 = 0;
          return void 0 !== e3?.tag && (a3 = Ge2(e3.tag, r3)), n3 = t3._OrtCreateRunOptions(s3.logSeverityLevel, s3.logVerbosityLevel, !!s3.terminate, a3), 0 === n3 && Ue2("Can't create run options."), void 0 !== e3?.extra && qe2(e3.extra, "", /* @__PURE__ */ new WeakSet(), ((e4, s4) => {
            let a4 = Ge2(e4, r3), o3 = Ge2(s4, r3);
            0 !== t3._OrtAddRunConfigEntry(n3, a4, o3) && Ue2(`Can't set a run config entry: ${e4} - ${s4}.`);
          })), [n3, r3];
        } catch (e4) {
          throw 0 !== n3 && t3._OrtReleaseRunOptions(n3), r3.forEach(((e5) => t3._free(e5))), e4;
        }
      };
    })), ld2 = j2((() => {
      ad2(), od2(), He2 = (e3) => {
        switch (e3) {
          case "disabled":
            return 0;
          case "basic":
            return 1;
          case "extended":
            return 2;
          case "all":
            return 99;
          default:
            throw new Error(`unsupported graph optimization level: ${e3}`);
        }
      }, Qe2 = (e3) => {
        switch (e3) {
          case "sequential":
            return 0;
          case "parallel":
            return 1;
          default:
            throw new Error(`unsupported execution mode: ${e3}`);
        }
      }, Ke2 = (e3) => {
        e3.extra || (e3.extra = {}), e3.extra.session || (e3.extra.session = {});
        let t3 = e3.extra.session;
        t3.use_ort_model_bytes_directly || (t3.use_ort_model_bytes_directly = "1"), e3.executionProviders && e3.executionProviders.some(((e4) => "webgpu" === ("string" == typeof e4 ? e4 : e4.name))) && (e3.enableMemPattern = false);
      }, Xe2 = (e3, t3, n3, r3) => {
        let s3 = Ge2(t3, r3), a3 = Ge2(n3, r3);
        0 !== Ve2()._OrtAddSessionConfigEntry(e3, s3, a3) && Ue2(`Can't set a session config entry: ${t3} - ${n3}.`);
      }, Je2 = async (e3, t3, n3) => {
        for (let r3 of t3) {
          let t4 = "string" == typeof r3 ? r3 : r3.name, s3 = [];
          switch (t4) {
            case "webnn":
              if (t4 = "WEBNN", "string" != typeof r3) {
                let t5 = r3?.deviceType;
                t5 && Xe2(e3, "deviceType", t5, n3);
              }
              break;
            case "webgpu":
              if (t4 = "JS", "string" != typeof r3) {
                let t5 = r3;
                if (t5?.preferredLayout) {
                  if ("NCHW" !== t5.preferredLayout && "NHWC" !== t5.preferredLayout) throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${t5.preferredLayout}`);
                  Xe2(e3, "preferredLayout", t5.preferredLayout, n3);
                }
              }
              break;
            case "wasm":
            case "cpu":
              continue;
            default:
              throw new Error(`not supported execution provider: ${t4}`);
          }
          let a3 = Ge2(t4, n3), o3 = s3.length, i3 = 0, l3 = 0;
          if (o3 > 0) {
            i3 = Ve2()._malloc(o3 * Ve2().PTR_SIZE), n3.push(i3), l3 = Ve2()._malloc(o3 * Ve2().PTR_SIZE), n3.push(l3);
            for (let e4 = 0; e4 < o3; e4++) Ve2().setValue(i3 + e4 * Ve2().PTR_SIZE, s3[e4][0], "*"), Ve2().setValue(l3 + e4 * Ve2().PTR_SIZE, s3[e4][1], "*");
          }
          0 !== await Ve2()._OrtAppendExecutionProvider(e3, a3, i3, l3, o3) && Ue2(`Can't append execution provider: ${t4}.`);
        }
      }, Ye2 = async (e3) => {
        let t3 = Ve2(), n3 = 0, r3 = [], s3 = e3 || {};
        Ke2(s3);
        try {
          let e4 = He2(s3.graphOptimizationLevel ?? "all"), a3 = Qe2(s3.executionMode ?? "sequential"), o3 = "string" == typeof s3.logId ? Ge2(s3.logId, r3) : 0, i3 = s3.logSeverityLevel ?? 2;
          if (!Number.isInteger(i3) || i3 < 0 || i3 > 4) throw new Error(`log serverity level is not valid: ${i3}`);
          let l3 = s3.logVerbosityLevel ?? 0;
          if (!Number.isInteger(l3) || l3 < 0 || l3 > 4) throw new Error(`log verbosity level is not valid: ${l3}`);
          let d3 = "string" == typeof s3.optimizedModelFilePath ? Ge2(s3.optimizedModelFilePath, r3) : 0;
          if (n3 = t3._OrtCreateSessionOptions(e4, !!s3.enableCpuMemArena, !!s3.enableMemPattern, a3, !!s3.enableProfiling, 0, o3, i3, l3, d3), 0 === n3 && Ue2("Can't create session options."), s3.executionProviders && await Je2(n3, s3.executionProviders, r3), void 0 !== s3.enableGraphCapture) {
            if ("boolean" != typeof s3.enableGraphCapture) throw new Error(`enableGraphCapture must be a boolean value: ${s3.enableGraphCapture}`);
            Xe2(n3, "enableGraphCapture", s3.enableGraphCapture.toString(), r3);
          }
          if (s3.freeDimensionOverrides) for (let [e5, a4] of Object.entries(s3.freeDimensionOverrides)) {
            if ("string" != typeof e5) throw new Error(`free dimension override name must be a string: ${e5}`);
            if ("number" != typeof a4 || !Number.isInteger(a4) || a4 < 0) throw new Error(`free dimension override value must be a non-negative integer: ${a4}`);
            let s4 = Ge2(e5, r3);
            0 !== t3._OrtAddFreeDimensionOverride(n3, s4, a4) && Ue2(`Can't set a free dimension override: ${e5} - ${a4}.`);
          }
          return void 0 !== s3.extra && qe2(s3.extra, "", /* @__PURE__ */ new WeakSet(), ((e5, t4) => {
            Xe2(n3, e5, t4, r3);
          })), [n3, r3];
        } catch (e4) {
          throw 0 !== n3 && 0 !== t3._OrtReleaseSessionOptions(n3) && Ue2("Can't release session options."), r3.forEach(((e5) => t3._free(e5))), e4;
        }
      };
    })), dd2 = j2((() => {
      Ze2 = (e3) => {
        switch (e3) {
          case "int8":
            return 3;
          case "uint8":
            return 2;
          case "bool":
            return 9;
          case "int16":
            return 5;
          case "uint16":
            return 4;
          case "int32":
            return 6;
          case "uint32":
            return 12;
          case "float16":
            return 10;
          case "float32":
            return 1;
          case "float64":
            return 11;
          case "string":
            return 8;
          case "int64":
            return 7;
          case "uint64":
            return 13;
          case "int4":
            return 22;
          case "uint4":
            return 21;
          default:
            throw new Error(`unsupported data type: ${e3}`);
        }
      }, et2 = (e3) => {
        switch (e3) {
          case 3:
            return "int8";
          case 2:
            return "uint8";
          case 9:
            return "bool";
          case 5:
            return "int16";
          case 4:
            return "uint16";
          case 6:
            return "int32";
          case 12:
            return "uint32";
          case 10:
            return "float16";
          case 1:
            return "float32";
          case 11:
            return "float64";
          case 8:
            return "string";
          case 7:
            return "int64";
          case 13:
            return "uint64";
          case 22:
            return "int4";
          case 21:
            return "uint4";
          default:
            throw new Error(`unsupported data type: ${e3}`);
        }
      }, tt2 = (e3, t3) => {
        let n3 = [-1, 4, 1, 1, 2, 2, 4, 8, -1, 1, 2, 8, 4, 8, -1, -1, -1, -1, -1, -1, -1, 0.5, 0.5][e3], r3 = "number" == typeof t3 ? t3 : t3.reduce(((e4, t4) => e4 * t4), 1);
        return n3 > 0 ? Math.ceil(r3 * n3) : void 0;
      }, nt2 = (e3) => {
        switch (e3) {
          case "float16":
            return typeof Float16Array < "u" && Float16Array.from ? Float16Array : Uint16Array;
          case "float32":
            return Float32Array;
          case "uint8":
          case "bool":
            return Uint8Array;
          case "int8":
            return Int8Array;
          case "uint16":
            return Uint16Array;
          case "int16":
            return Int16Array;
          case "int32":
            return Int32Array;
          case "float64":
            return Float64Array;
          case "uint32":
            return Uint32Array;
          case "int64":
            return BigInt64Array;
          case "uint64":
            return BigUint64Array;
          default:
            throw new Error(`unsupported type: ${e3}`);
        }
      }, rt2 = (e3) => {
        switch (e3) {
          case "verbose":
            return 0;
          case "info":
            return 1;
          case "warning":
            return 2;
          case "error":
            return 3;
          case "fatal":
            return 4;
          default:
            throw new Error(`unsupported logging level: ${e3}`);
        }
      }, st2 = (e3) => "float32" === e3 || "float16" === e3 || "int32" === e3 || "int64" === e3 || "uint32" === e3 || "uint8" === e3 || "bool" === e3 || "uint4" === e3 || "int4" === e3, at2 = (e3) => "float32" === e3 || "float16" === e3 || "int32" === e3 || "int64" === e3 || "uint32" === e3 || "uint64" === e3 || "int8" === e3 || "uint8" === e3 || "bool" === e3 || "uint4" === e3 || "int4" === e3, ot2 = (e3) => {
        switch (e3) {
          case "none":
            return 0;
          case "cpu":
            return 1;
          case "cpu-pinned":
            return 2;
          case "texture":
            return 3;
          case "gpu-buffer":
            return 4;
          case "ml-tensor":
            return 5;
          default:
            throw new Error(`unsupported data location: ${e3}`);
        }
      };
    })), ud2 = j2((() => {
      de2(), it2 = async (e3) => {
        if ("string" == typeof e3) {
          {
            let t3 = await fetch(e3);
            if (!t3.ok) throw new Error(`failed to load external data file: ${e3}`);
            let n3 = t3.headers.get("Content-Length"), r3 = n3 ? parseInt(n3, 10) : 0;
            if (r3 < 1073741824) return new Uint8Array(await t3.arrayBuffer());
            {
              if (!t3.body) throw new Error(`failed to load external data file: ${e3}, no response body.`);
              let n4, s3 = t3.body.getReader();
              try {
                n4 = new ArrayBuffer(r3);
              } catch (e4) {
                if (!(e4 instanceof RangeError)) throw e4;
                {
                  let e5 = Math.ceil(r3 / 65536);
                  n4 = new WebAssembly.Memory({ initial: e5, maximum: e5 }).buffer;
                }
              }
              let a3 = 0;
              for (; ; ) {
                let { done: e4, value: t4 } = await s3.read();
                if (e4) break;
                let r4 = t4.byteLength;
                new Uint8Array(n4, a3, r4).set(t4), a3 += r4;
              }
              return new Uint8Array(n4, 0, r3);
            }
          }
        }
        return e3 instanceof Blob ? new Uint8Array(await e3.arrayBuffer()) : e3 instanceof Uint8Array ? e3 : new Uint8Array(e3);
      };
    })), cd2 = j2((() => {
      dd2(), lt2 = ["V", "I", "W", "E", "F"], dt2 = (e3, t3) => {
        console.log(`[${lt2[e3]},${(/* @__PURE__ */ new Date()).toISOString()}]${t3}`);
      }, pt2 = (e3, t3) => {
        ut2 = e3, ct2 = t3;
      }, mt2 = (e3, t3) => {
        let n3 = rt2(e3);
        n3 >= rt2(ut2) && dt2(n3, "function" == typeof t3 ? t3() : t3);
      }, ht2 = (...e3) => {
        ct2 && mt2(...e3);
      };
    })), pd2 = j2((() => {
      ft2 = class {
        static calcMatMulShape(e3, t3) {
          return e3[1] !== t3[0] ? void 0 : [e3[0], t3[1]];
        }
      }, _t2 = class {
        static calcShape(e3, t3, n3 = false) {
          let r3 = e3.length, s3 = t3.length;
          if (0 === r3) return t3;
          if (0 === s3) return e3;
          let a3 = Math.max(e3.length, t3.length), o3 = new Array(a3);
          if (n3) {
            if (r3 < 2 || s3 < 2) return;
            let n4 = ft2.calcMatMulShape([e3[r3 - 2], e3[r3 - 1]], [t3[s3 - 2], t3[s3 - 1]]);
            if (void 0 === n4) return;
            [o3[a3 - 2], o3[a3 - 1]] = n4;
          }
          for (let i3 = n3 ? 3 : 1; i3 <= a3; i3++) {
            let n4 = r3 - i3 < 0 ? 1 : e3[r3 - i3], l3 = s3 - i3 < 0 ? 1 : t3[s3 - i3];
            if (n4 !== l3 && n4 > 1 && l3 > 1) return;
            let d3 = Math.max(n4, l3);
            if (n4 && l3) o3[a3 - i3] = Math.max(n4, l3);
            else {
              if (d3 > 1) return;
              o3[a3 - i3] = 0;
            }
          }
          return o3;
        }
        static isValidBroadcast(e3, t3) {
          let n3 = e3.length, r3 = t3.length;
          if (n3 > r3) return false;
          for (let s3 = 1; s3 <= n3; s3++) if (1 !== e3[n3 - s3] && e3[n3 - s3] !== t3[r3 - s3]) return false;
          return true;
        }
      }, gt2 = class e3 {
        static size(t3) {
          return e3.getSizeFromDimensionRange(t3, 0, t3.length);
        }
        static convertShape(e4, t3 = 4) {
          let n3 = e4.length;
          if (0 === n3) return [];
          let r3 = new Array(n3), s3 = n3 - 1;
          for (; s3 >= 0; ) {
            if (e4[s3] % t3 == 0) {
              r3[s3] = e4[s3] / t3;
              break;
            }
            if (t3 % e4[s3] != 0) throw new Error("cannot convert shape");
            r3[s3] = 1, t3 /= e4[s3], s3--;
          }
          for (s3--; s3 >= 0; s3--) r3[s3] = e4[s3];
          return r3;
        }
        static sizeFromDimension(t3, n3) {
          if (n3 < 0 || n3 > t3.length) throw new Error(`invalid dimension of ${n3} for sizeFromDimension as Tensor has ${t3.length} dimensions.`);
          return e3.getSizeFromDimensionRange(t3, n3, t3.length);
        }
        static sizeToDimension(t3, n3) {
          if (n3 < 0 || n3 > t3.length) throw new Error(`invalid dimension of ${n3} for sizeToDimension as Tensor has ${t3.length} dimensions.`);
          return e3.getSizeFromDimensionRange(t3, 0, n3);
        }
        static getSizeFromDimensionRange(e4, t3, n3) {
          let r3 = 1;
          for (let s3 = t3; s3 < n3; s3++) {
            if (e4[s3] < 0) throw new Error("cannot get valid size from specified dimension range. Most likely the range contains negative values in them.");
            r3 *= Number(e4[s3]);
          }
          return r3;
        }
        static computeStrides(e4) {
          let t3 = e4.length;
          if (0 === t3) return [];
          if (1 === t3) return [1];
          let n3 = new Array(t3);
          n3[t3 - 1] = 1, n3[t3 - 2] = e4[t3 - 1];
          for (let r3 = t3 - 3; r3 >= 0; --r3) n3[r3] = n3[r3 + 1] * e4[r3 + 1];
          return n3;
        }
        static normalizeAxis(e4, t3) {
          if (e4 < -t3 && e4 >= t3) throw new Error("unsupported axis for this operation.");
          return e4 < 0 ? e4 + t3 : e4;
        }
        static normalizeAxes(e4, t3) {
          return e4.map(((n3) => this.normalizeAxis(n3, t3 ?? e4.length)));
        }
        static sortBasedOnPerm(e4, t3) {
          return t3 ? t3.map(((t4) => e4[t4])) : e4.slice().reverse();
        }
        static padShape(e4, t3) {
          let n3 = e4.length;
          return e4.map(((e5, r3) => e5 + t3[r3] + t3[r3 + n3]));
        }
        static areEqual(e4, t3) {
          return e4.length === t3.length && e4.every(((e5, n3) => e5 === t3[n3]));
        }
      }, wt2 = class e3 {
        static adjustPoolAttributes(e4, t3, n3, r3, s3, a3) {
          if (!e4 && n3.length !== t3.length - 2) throw new Error("length of specified kernel shapes should be 2 less than length of input dimensions");
          if (e4) for (let e5 = 0; e5 < t3.length - 2; e5++) e5 >= n3.length ? n3.push(t3[e5 + 2]) : n3[e5] = t3[e5 + 2];
          for (let e5 = 0; e5 < n3.length; e5++) if (e5 < r3.length) {
            if (r3[e5] < 0) throw new Error("strides should be greater than or equal to 1");
          } else r3.push(1);
          for (let e5 = 0; e5 < n3.length; e5++) if (e5 < s3.length) {
            if (s3[e5] < 0) throw new Error("dilations should be greater than or equal to 1");
          } else s3.push(1);
          for (let e5 = 0; e5 < 2 * n3.length; e5++) if (e5 < a3.length) {
            if (a3[e5] < 0) throw new Error("pad should be greater than or equal to 1");
          } else a3.push(0);
          for (let e5 = 0; e5 < n3.length; e5++) {
            if (n3[e5] <= 0) throw new Error("kernel shapes need to be greater than 0");
            if (a3[e5] >= n3[e5] || a3[e5 + n3.length] >= n3[e5]) throw new Error("pads should be smaller than kernel");
          }
        }
        static adjustPadsBasedOnAutoPad(t3, n3, r3, s3, a3, o3, i3) {
          if (i3) {
            if (a3.length !== 2 * (t3.length - 2)) throw new Error("length of pads should be twice the length of data dimensions");
            if (n3.length !== t3.length - 2) throw new Error("length of strides should be the length of data dimensions");
            if (s3.length !== t3.length - 2) throw new Error("length of kernel shapes should be the length of data dimensions");
            for (let l3 = 0; l3 < t3.length - 2; l3++) e3.adjustPadAndReturnShape(t3[l3 + (o3 ? 1 : 2)], n3[l3], r3[l3], s3[l3], a3, l3, l3 + t3.length - 2, i3);
          }
        }
        static computePoolOutputShape(t3, n3, r3, s3, a3, o3, i3) {
          if (n3.length <= 0) throw new Error("input shape must be of size greater than 0");
          let l3 = [n3[0], n3[1]];
          return e3.computeShapeHelper(t3, n3, l3, r3, s3, a3, o3, i3), l3;
        }
        static computeConvOutputShape(t3, n3, r3, s3, a3, o3, i3) {
          if (t3.length <= 0 || n3.length <= 0) throw new Error("invalid input tensor dims or invalid filter tensor dims");
          let l3 = [t3[0], n3[0]];
          return e3.computeShapeHelper(false, t3, l3, r3, s3, a3, o3, i3), l3;
        }
        static computeShapeHelper(t3, n3, r3, s3, a3, o3, i3, l3) {
          if (t3) for (let e4 = 0; e4 < n3.length - 2; e4++) r3.push(1);
          else for (let t4 = 0; t4 < n3.length - 2; t4++) r3.push(e3.adjustPadAndReturnShape(n3[t4 + 2], s3[t4], a3[t4], o3[t4], i3, t4, t4 + n3.length - 2, l3));
        }
        static adjustPadAndReturnShape(e4, t3, n3, r3, s3, a3, o3, i3) {
          let l3 = n3 * (r3 - 1) + 1;
          if (!i3 || "NOTSET" === i3) return Math.floor((e4 + s3[a3] + s3[o3] - l3) / t3 + 1);
          switch (i3) {
            case "VALID":
              return s3[a3] = 0, s3[o3] = 0, Math.floor((e4 - l3) / t3 + 1);
            case "SAME_LOWER":
            case "SAME_UPPER":
              if (1 !== n3) throw new Error("Dilation not supported for SAME_UPPER or SAME_LOWER");
              {
                let n4 = ((e4 + t3 - 1) / t3 - 1) * t3 + r3 - e4;
                return s3[a3] = Math.floor("SAME_LOWER" === i3 ? (n4 + 1) / 2 : n4 / 2), s3[o3] = n4 - s3[a3], Math.floor((e4 + n4 - r3) / t3 + 1);
              }
            default:
              throw new Error("Unsupported AutoPad type");
          }
        }
      }, bt2 = class {
        static getShapeOfGemmResult(e3, t3, n3, r3, s3) {
          if (2 !== e3.length || 2 !== n3.length) throw new Error("shape need to be of size 2");
          let a3, o3, i3;
          t3 ? (a3 = e3[1], o3 = e3[0]) : (a3 = e3[0], o3 = e3[1]);
          let l3 = -1;
          if (r3 ? (i3 = n3[0], l3 = 1) : (i3 = n3[1], l3 = 0), n3[l3] !== o3) throw new Error("dimension mismatch");
          if (a3 <= 0 || i3 <= 0 || o3 <= 0) throw new Error("invalid shape specified");
          if (s3 && !_t2.isValidBroadcast(s3, [a3, i3])) throw new Error("gemm: invalid bias shape for broadcast");
          return [a3, i3, o3];
        }
      }, yt2 = -34028234663852886e22, Mt2 = 34028234663852886e22;
    })), md2 = j2((() => {
      dd2(), xt2 = (e3, t3) => new (nt2(t3))(e3);
    })), hd2 = j2((() => {
      cd2(), vt2 = (e3, t3 = true) => {
        if (e3.byteLength % 8 != 0) throw new Error("Invalid Uint8Array length - must be a multiple of 8 (BigInt).");
        let n3 = e3.byteLength / 8, r3 = new BigInt64Array(e3.buffer, e3.byteOffset, n3), s3 = new Int32Array(n3);
        for (let e4 = 0; e4 < n3; e4++) {
          let t4 = r3[e4];
          if (t4 > 2147483647n || t4 < -2147483648n) throw new Error(`Overflow occurred when converting BigInt to Int32 at index ${e4}: ${t4}`);
          s3[e4] = Number(t4);
        }
        return t3 ? new Uint8Array(s3.buffer) : s3;
      }, Tt2 = (e3, t3 = true) => {
        if (e3.byteLength % 4 != 0) throw new Error("Invalid Uint8Array length - must be a multiple of 4 (Int32).");
        let n3 = e3.byteLength / 4, r3 = new Int32Array(e3.buffer, e3.byteOffset, n3), s3 = BigInt64Array.from(r3, BigInt);
        return t3 ? new Uint8Array(s3.buffer) : s3;
      }, kt2 = 1, Pt2 = () => kt2++, $t2 = /* @__PURE__ */ new Map([["float32", 32], ["float16", 16], ["int32", 32], ["uint32", 32], ["int64", 64], ["uint64", 64], ["int8", 8], ["uint8", 8], ["int4", 4], ["uint4", 4]]), Ct2 = (e3, t3) => {
        let n3 = $t2.get(e3);
        if (!n3) throw new Error("Unsupported data type.");
        return t3.length > 0 ? Math.ceil(t3.reduce(((e4, t4) => e4 * t4)) * n3 / 8) : 0;
      }, St2 = class {
        constructor(e3) {
          this.shouldConvertInt64toInt32 = false, this.isInt64ToInt32Converted = false;
          let { sessionId: t3, context: n3, tensor: r3, dataType: s3, shape: a3, shouldConvertInt64toInt32: o3 = false } = e3;
          this.sessionId = t3, this.mlContext = n3, this.mlTensor = r3, this.dataType = s3, this.tensorShape = a3, this.shouldConvertInt64toInt32 = o3;
        }
        get tensor() {
          return this.mlTensor;
        }
        get type() {
          return this.dataType;
        }
        get shape() {
          return this.tensorShape;
        }
        get byteLength() {
          return Ct2(this.dataType, this.tensorShape);
        }
        destroy() {
          ht2("verbose", (() => "[WebNN] TensorWrapper.destroy")), this.mlTensor.destroy();
        }
        write(e3) {
          this.mlContext.writeTensor(this.mlTensor, e3);
        }
        async read(e3, t3) {
          if (e3) {
            let e4 = await this.mlContext.readTensor(this.mlTensor), n3 = Tt2(new Uint8Array(e4));
            return t3 ? void (t3 instanceof ArrayBuffer ? new Uint8Array(t3) : new Uint8Array(t3.buffer, t3.byteOffset, t3.byteLength)).set(n3) : n3.buffer;
          }
          return t3 ? this.mlContext.readTensor(this.mlTensor, t3) : this.mlContext.readTensor(this.mlTensor);
        }
        canReuseTensor(e3, t3, n3) {
          return this.mlContext === e3 && this.dataType === t3 && this.tensorShape.length === n3.length && this.tensorShape.every(((e4, t4) => e4 === n3[t4]));
        }
        setIsInt64ToInt32Converted(e3) {
          this.isInt64ToInt32Converted = e3;
        }
      }, Ft2 = class {
        constructor(e3, t3) {
          this.tensorManager = e3, this.wrapper = t3;
        }
        get tensorWrapper() {
          return this.wrapper;
        }
        releaseTensor() {
          this.tensorWrapper && (this.tensorManager.releaseTensor(this.tensorWrapper), this.wrapper = void 0);
        }
        async ensureTensor(e3, t3, n3, r3) {
          let s3 = t3, a3 = this.tensorManager.getMLContext(e3), o3 = "int64" === s3 && !a3.opSupportLimits().input.dataTypes.includes("int64");
          if (o3 && (s3 = "int32", ht2("verbose", (() => "[WebNN] TensorIdTracker.ensureTensor: convert dataType from int64 to int32"))), this.wrapper) {
            if (this.wrapper.canReuseTensor(a3, s3, n3)) return this.wrapper.tensor;
            if (r3) {
              if (this.wrapper.byteLength !== Ct2(s3, n3)) throw new Error("Unable to copy data to tensor with different size.");
              this.activeUpload = new Uint8Array(await this.wrapper.read());
            }
            this.tensorManager.releaseTensor(this.wrapper);
          }
          let i3 = typeof MLTensorUsage > "u" ? void 0 : MLTensorUsage.READ | MLTensorUsage.WRITE;
          return this.wrapper = await this.tensorManager.getCachedTensor(e3, s3, n3, i3, true, true, o3), r3 && this.activeUpload && (this.wrapper.write(this.activeUpload), this.activeUpload = void 0), this.wrapper.tensor;
        }
        upload(e3) {
          let t3 = e3;
          if (this.wrapper) {
            if (this.wrapper.shouldConvertInt64toInt32 && (t3 = vt2(e3, true), this.wrapper.setIsInt64ToInt32Converted(true)), t3.byteLength === this.wrapper.byteLength) return void this.wrapper.write(t3);
            ht2("verbose", (() => "Data size does not match tensor size. Releasing tensor.")), this.releaseTensor();
          }
          this.activeUpload ? this.activeUpload.set(t3) : this.activeUpload = new Uint8Array(t3);
        }
        async download(e3) {
          if (this.activeUpload) {
            let t3 = this.wrapper?.isInt64ToInt32Converted ? Tt2(this.activeUpload) : this.activeUpload;
            return e3 ? void (e3 instanceof ArrayBuffer ? new Uint8Array(e3).set(t3) : new Uint8Array(e3.buffer, e3.byteOffset, e3.byteLength).set(t3)) : t3.buffer;
          }
          if (!this.wrapper) throw new Error("Tensor has not been created.");
          return e3 ? this.wrapper.read(this.wrapper?.shouldConvertInt64toInt32, e3) : this.wrapper.read(this.wrapper?.shouldConvertInt64toInt32);
        }
      }, Et2 = class {
        constructor(e3) {
          this.backend = e3, this.tensorTrackersById = /* @__PURE__ */ new Map(), this.freeTensors = [], this.externalTensors = /* @__PURE__ */ new Set();
        }
        getMLContext(e3) {
          let t3 = this.backend.getMLContext(e3);
          if (!t3) throw new Error("MLContext not found for session.");
          return t3;
        }
        reserveTensorId() {
          let e3 = Pt2();
          return this.tensorTrackersById.set(e3, new Ft2(this)), e3;
        }
        releaseTensorId(e3) {
          let t3 = this.tensorTrackersById.get(e3);
          t3 && (this.tensorTrackersById.delete(e3), t3.tensorWrapper && this.releaseTensor(t3.tensorWrapper));
        }
        async ensureTensor(e3, t3, n3, r3, s3) {
          ht2("verbose", (() => `[WebNN] TensorManager.ensureTensor {tensorId: ${t3}, dataType: ${n3}, shape: ${r3}, copyOld: ${s3}}`));
          let a3 = this.tensorTrackersById.get(t3);
          if (!a3) throw new Error("Tensor not found.");
          return a3.ensureTensor(e3, n3, r3, s3);
        }
        upload(e3, t3) {
          let n3 = this.tensorTrackersById.get(e3);
          if (!n3) throw new Error("Tensor not found.");
          n3.upload(t3);
        }
        async download(e3, t3) {
          ht2("verbose", (() => `[WebNN] TensorManager.download {tensorId: ${e3}, dstBuffer: ${t3?.byteLength}}`));
          let n3 = this.tensorTrackersById.get(e3);
          if (!n3) throw new Error("Tensor not found.");
          return n3.download(t3);
        }
        releaseTensorsForSession(e3) {
          for (let t3 of this.freeTensors) t3.sessionId === e3 && t3.destroy();
          this.freeTensors = this.freeTensors.filter(((t3) => t3.sessionId !== e3));
        }
        registerTensor(e3, t3, n3, r3) {
          let s3 = this.getMLContext(e3), a3 = Pt2(), o3 = new St2({ sessionId: e3, context: s3, tensor: t3, dataType: n3, shape: r3 });
          return this.tensorTrackersById.set(a3, new Ft2(this, o3)), this.externalTensors.add(o3), a3;
        }
        async getCachedTensor(e3, t3, n3, r3, s3, a3, o3 = false) {
          let i3 = this.getMLContext(e3);
          for (let [r4, s4] of this.freeTensors.entries()) if (s4.canReuseTensor(i3, t3, n3)) {
            ht2("verbose", (() => `[WebNN] Reusing tensor {dataType: ${t3}, shape: ${n3}}`));
            let s5 = this.freeTensors.splice(r4, 1)[0];
            return s5.sessionId = e3, s5;
          }
          ht2("verbose", (() => `[WebNN] MLContext.createTensor {dataType: ${t3}, shape: ${n3}}`));
          let l3 = await i3.createTensor({ dataType: t3, shape: n3, dimensions: n3, usage: r3, writable: s3, readable: a3 });
          return new St2({ sessionId: e3, context: i3, tensor: l3, dataType: t3, shape: n3, shouldConvertInt64toInt32: o3 });
        }
        releaseTensor(e3) {
          this.externalTensors.has(e3) && this.externalTensors.delete(e3), this.freeTensors.push(e3);
        }
      }, It2 = (...e3) => new Et2(...e3);
    })), fd2 = j2((() => {
      dd2(), ad2(), md2(), hd2(), cd2(), At2 = /* @__PURE__ */ new Map([[1, "float32"], [10, "float16"], [6, "int32"], [12, "uint32"], [7, "int64"], [13, "uint64"], [22, "int4"], [21, "uint4"], [3, "int8"], [2, "uint8"], [9, "uint8"]]), zt2 = (e3, t3) => {
        if (e3 === t3) return true;
        if (void 0 === e3 || void 0 === t3) return false;
        let n3 = Object.keys(e3).sort(), r3 = Object.keys(t3).sort();
        return n3.length === r3.length && n3.every(((n4, s3) => n4 === r3[s3] && e3[n4] === t3[n4]));
      }, Lt2 = class {
        constructor(e3) {
          this.tensorManager = It2(this), this.mlContextBySessionId = /* @__PURE__ */ new Map(), this.sessionIdsByMLContext = /* @__PURE__ */ new Map(), this.mlContextCache = [], this.sessionGraphInputs = /* @__PURE__ */ new Map(), this.temporaryGraphInputs = [], this.temporarySessionTensorIds = /* @__PURE__ */ new Map(), pt2(e3.logLevel, !!e3.debug);
        }
        get currentSessionId() {
          if (void 0 === this.activeSessionId) throw new Error("No active session");
          return this.activeSessionId;
        }
        onRunStart(e3) {
          ht2("verbose", (() => `[WebNN] onRunStart {sessionId: ${e3}}`)), this.activeSessionId = e3;
        }
        onRunEnd(e3) {
          ht2("verbose", (() => `[WebNN] onRunEnd {sessionId: ${e3}}`));
          let t3 = this.temporarySessionTensorIds.get(e3);
          if (t3) {
            for (let e4 of t3) ht2("verbose", (() => `[WebNN] releasing temporary tensor {tensorId: ${e4}}`)), this.tensorManager.releaseTensorId(e4);
            this.temporarySessionTensorIds.delete(e3), this.activeSessionId = void 0;
          }
        }
        async createMLContext(e3) {
          if (e3 instanceof GPUDevice) {
            let t4 = this.mlContextCache.findIndex(((t5) => t5.gpuDevice === e3));
            if (-1 !== t4) return this.mlContextCache[t4].mlContext;
            {
              let t5 = await navigator.ml.createContext(e3);
              return this.mlContextCache.push({ gpuDevice: e3, mlContext: t5 }), t5;
            }
          }
          if (void 0 === e3) {
            let e4 = this.mlContextCache.findIndex(((e5) => void 0 === e5.options && void 0 === e5.gpuDevice));
            if (-1 !== e4) return this.mlContextCache[e4].mlContext;
            {
              let e5 = await navigator.ml.createContext();
              return this.mlContextCache.push({ mlContext: e5 }), e5;
            }
          }
          let t3 = this.mlContextCache.findIndex(((t4) => zt2(t4.options, e3)));
          if (-1 !== t3) return this.mlContextCache[t3].mlContext;
          {
            let t4 = await navigator.ml.createContext(e3);
            return this.mlContextCache.push({ options: e3, mlContext: t4 }), t4;
          }
        }
        registerMLContext(e3, t3) {
          this.mlContextBySessionId.set(e3, t3);
          let n3 = this.sessionIdsByMLContext.get(t3);
          n3 || (n3 = /* @__PURE__ */ new Set(), this.sessionIdsByMLContext.set(t3, n3)), n3.add(e3), this.temporaryGraphInputs.length > 0 && (this.sessionGraphInputs.set(e3, this.temporaryGraphInputs), this.temporaryGraphInputs = []);
        }
        onReleaseSession(e3) {
          this.sessionGraphInputs.delete(e3);
          let t3 = this.mlContextBySessionId.get(e3);
          if (!t3) return;
          this.tensorManager.releaseTensorsForSession(e3), this.mlContextBySessionId.delete(e3);
          let n3 = this.sessionIdsByMLContext.get(t3);
          if (n3.delete(e3), 0 === n3.size) {
            this.sessionIdsByMLContext.delete(t3);
            let e4 = this.mlContextCache.findIndex(((e5) => e5.mlContext === t3));
            -1 !== e4 && this.mlContextCache.splice(e4, 1);
          }
        }
        getMLContext(e3) {
          return this.mlContextBySessionId.get(e3);
        }
        reserveTensorId() {
          return this.tensorManager.reserveTensorId();
        }
        releaseTensorId(e3) {
          ht2("verbose", (() => `[WebNN] releaseTensorId {tensorId: ${e3}}`)), this.tensorManager.releaseTensorId(e3);
        }
        async ensureTensor(e3, t3, n3, r3, s3) {
          let a3 = At2.get(n3);
          if (!a3) throw new Error(`Unsupported ONNX data type: ${n3}`);
          return this.tensorManager.ensureTensor(e3 ?? this.currentSessionId, t3, a3, r3, s3);
        }
        async createTemporaryTensor(e3, t3, n3) {
          ht2("verbose", (() => `[WebNN] createTemporaryTensor {onnxDataType: ${t3}, shape: ${n3}}`));
          let r3 = At2.get(t3);
          if (!r3) throw new Error(`Unsupported ONNX data type: ${t3}`);
          let s3 = this.tensorManager.reserveTensorId();
          await this.tensorManager.ensureTensor(e3, s3, r3, n3, false);
          let a3 = this.temporarySessionTensorIds.get(e3);
          return a3 ? a3.push(s3) : this.temporarySessionTensorIds.set(e3, [s3]), s3;
        }
        uploadTensor(e3, t3) {
          if (!Ve2().shouldTransferToMLTensor) throw new Error("Trying to upload to a MLTensor while shouldTransferToMLTensor is false");
          ht2("verbose", (() => `[WebNN] uploadTensor {tensorId: ${e3}, data: ${t3.byteLength}}`)), this.tensorManager.upload(e3, t3);
        }
        async downloadTensor(e3, t3) {
          return this.tensorManager.download(e3, t3);
        }
        createMLTensorDownloader(e3, t3) {
          return async () => {
            let n3 = await this.tensorManager.download(e3);
            return xt2(n3, t3);
          };
        }
        registerMLTensor(e3, t3, n3, r3) {
          let s3 = At2.get(n3);
          if (!s3) throw new Error(`Unsupported ONNX data type: ${n3}`);
          let a3 = this.tensorManager.registerTensor(e3, t3, s3, r3);
          return ht2("verbose", (() => `[WebNN] registerMLTensor {tensor: ${t3}, dataType: ${s3}, dimensions: ${r3}} -> {tensorId: ${a3}}`)), a3;
        }
        registerMLConstant(e3, t3, n3, r3, s3, a3, o3 = false) {
          if (!a3) throw new Error("External mounted files are not available.");
          let i3 = e3;
          e3.startsWith("./") && (i3 = e3.substring(2));
          let l3 = a3.get(i3);
          if (!l3) throw new Error(`File with name ${i3} not found in preloaded files.`);
          if (t3 + n3 > l3.byteLength) throw new Error("Out of bounds: data offset and length exceed the external file data size.");
          let d3, u3 = l3.slice(t3, t3 + n3).buffer;
          switch (s3.dataType) {
            case "float32":
              d3 = new Float32Array(u3);
              break;
            case "float16":
              d3 = typeof Float16Array < "u" && Float16Array.from ? new Float16Array(u3) : new Uint16Array(u3);
              break;
            case "int32":
              d3 = new Int32Array(u3);
              break;
            case "uint32":
              d3 = new Uint32Array(u3);
              break;
            case "int64":
              o3 ? (d3 = vt2(new Uint8Array(u3), false), s3.dataType = "int32") : d3 = new BigInt64Array(u3);
              break;
            case "uint64":
              d3 = new BigUint64Array(u3);
              break;
            case "int8":
              d3 = new Int8Array(u3);
              break;
            case "int4":
            case "uint4":
            case "uint8":
              d3 = new Uint8Array(u3);
              break;
            default:
              throw new Error(`Unsupported data type: ${s3.dataType} in creating WebNN Constant from external data.`);
          }
          return ht2("verbose", (() => `[WebNN] registerMLConstant {dataType: ${s3.dataType}, shape: ${s3.shape}}} ${o3 ? "(Note: it was int64 data type and registered to int32 as workaround)" : ""}`)), r3.constant(s3, d3);
        }
        registerGraphInput(e3) {
          this.temporaryGraphInputs.push(e3);
        }
        isGraphInput(e3, t3) {
          let n3 = this.sessionGraphInputs.get(e3);
          return !!n3 && n3.includes(t3);
        }
        isInt64Supported(e3) {
          return !!this.mlContextBySessionId.get(e3)?.opSupportLimits().input.dataTypes.includes("int64");
        }
        flush() {
        }
      };
    })), _d2 = j2((() => {
    })), gd2 = j2((() => {
      cd2(), _d2(), Ot2 = /* @__PURE__ */ new Map([[64, 250], [128, 200], [256, 200], [512, 200], [2048, 230], [4096, 200], [8192, 50], [16384, 50], [32768, 50], [65536, 50], [131072, 50], [262144, 50], [524288, 50], [1048576, 50], [2097152, 30], [4194304, 20], [8388608, 10], [12582912, 10], [16777216, 10], [26214400, 15], [33554432, 22], [44236800, 2], [58982400, 6], [67108864, 6], [134217728, 6], [167772160, 6]]), Dt2 = [], Bt2 = (e3) => 16 * Math.ceil(Number(e3) / 16), Nt2 = (e3) => {
        for (let t3 = 0; t3 < Dt2.length; t3++) {
          let n3 = Dt2[t3];
          if (e3 <= n3) return n3;
        }
        return 16 * Math.ceil(e3 / 16);
      }, jt2 = 1, Rt2 = () => jt2++, Vt2 = async (e3, t3, n3, r3) => {
        let s3 = Bt2(n3), a3 = e3.device.createBuffer({ size: s3, usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ });
        try {
          let o3 = e3.getCommandEncoder();
          e3.endComputePass(), o3.copyBufferToBuffer(t3, 0, a3, 0, s3), e3.flush(), await a3.mapAsync(GPUMapMode.READ);
          let i3 = a3.getMappedRange();
          if (r3) {
            let e4 = r3();
            return e4.set(new Uint8Array(i3, 0, n3)), e4;
          }
          return new Uint8Array(i3.slice(0, n3));
        } finally {
          a3.destroy();
        }
      }, Gt2 = class {
        constructor(e3) {
          this.backend = e3, this.storageCache = /* @__PURE__ */ new Map(), this.freeBuffers = /* @__PURE__ */ new Map(), this.freeUniformBuffers = /* @__PURE__ */ new Map(), this.buffersPending = [], this.capturedPendingBuffers = /* @__PURE__ */ new Map();
          for (let [e4] of Ot2) Dt2.push(e4), this.freeBuffers.set(e4, []), this.freeUniformBuffers.set(e4, []);
          this.sessionCount = 0;
        }
        upload(e3, t3) {
          let n3 = t3.buffer, r3 = t3.byteOffset, s3 = t3.byteLength, a3 = Bt2(s3), o3 = this.storageCache.get(e3);
          if (!o3) throw new Error("gpu data for uploading does not exist");
          if (Number(o3.originalSize) !== s3) throw new Error(`inconsistent data size. gpu data size=${o3.originalSize}, data size=${s3}`);
          let i3 = this.backend.device.createBuffer({ mappedAtCreation: true, size: a3, usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC }), l3 = i3.getMappedRange();
          new Uint8Array(l3).set(new Uint8Array(n3, r3, s3)), i3.unmap();
          let d3 = this.backend.device.createCommandEncoder();
          d3.copyBufferToBuffer(i3, 0, o3.gpuData.buffer, 0, a3), this.backend.device.queue.submit([d3.finish()]), i3.destroy(), ht2("verbose", (() => `[WebGPU] GpuDataManager.upload(id=${e3})`));
        }
        memcpy(e3, t3) {
          let n3 = this.storageCache.get(e3);
          if (!n3) throw new Error("source gpu data for memcpy does not exist");
          let r3 = this.storageCache.get(t3);
          if (!r3) throw new Error("destination gpu data for memcpy does not exist");
          if (n3.originalSize !== r3.originalSize) throw new Error("inconsistent source and destination gpu data size");
          let s3 = Bt2(n3.originalSize), a3 = this.backend.getCommandEncoder();
          this.backend.endComputePass(), a3.copyBufferToBuffer(n3.gpuData.buffer, 0, r3.gpuData.buffer, 0, s3);
        }
        registerExternalBuffer(e3, t3, n3) {
          let r3;
          if (n3) {
            if (r3 = n3[0], e3 === n3[1]) return ht2("verbose", (() => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${t3}) => id=${r3}, buffer is the same, skip.`)), r3;
            if (this.backend.capturedCommandList.has(this.backend.currentSessionId)) throw new Error("Registering a different external buffer under graph capture mode is not supported yet.\n             Please use the previous external buffer!");
          } else r3 = Rt2();
          return this.storageCache.set(r3, { gpuData: { id: r3, type: 0, buffer: e3 }, originalSize: t3 }), ht2("verbose", (() => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${t3}) => id=${r3}, registered.`)), r3;
        }
        unregisterExternalBuffer(e3) {
          void 0 !== e3 && (this.storageCache.delete(e3), ht2("verbose", (() => `[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${e3}`)));
        }
        create(e3, t3 = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST) {
          let n3, r3 = Nt2(e3), s3 = (t3 & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE, a3 = (t3 & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM;
          if (s3 || a3) {
            let e4 = (s3 ? this.freeBuffers : this.freeUniformBuffers).get(r3);
            n3 = e4 && e4.length > 0 ? e4.pop() : this.backend.device.createBuffer({ size: r3, usage: t3 });
          } else n3 = this.backend.device.createBuffer({ size: r3, usage: t3 });
          let o3 = { id: Rt2(), type: 0, buffer: n3 };
          return this.storageCache.set(o3.id, { gpuData: o3, originalSize: Number(e3) }), ht2("verbose", (() => `[WebGPU] GpuDataManager.create(size=${e3}) => id=${o3.id}`)), o3;
        }
        get(e3) {
          return this.storageCache.get(e3)?.gpuData;
        }
        release(e3) {
          let t3 = "bigint" == typeof e3 ? Number(e3) : e3, n3 = this.storageCache.get(t3);
          if (!n3) {
            if (0 === this.storageCache.size) return 0;
            throw new Error("releasing data does not exist");
          }
          return ht2("verbose", (() => `[WebGPU] GpuDataManager.release(id=${t3}), gpuDataId=${n3.gpuData.id}`)), this.storageCache.delete(t3), this.buffersPending.push(n3.gpuData.buffer), n3.originalSize;
        }
        async download(e3, t3) {
          let n3 = this.storageCache.get(Number(e3));
          if (!n3) throw new Error("data does not exist");
          await Vt2(this.backend, n3.gpuData.buffer, n3.originalSize, t3);
        }
        refreshPendingBuffers() {
          if (0 !== this.buffersPending.length) if ("default" === this.backend.sessionStatus) {
            for (let e3 of this.buffersPending) {
              let t3 = Ot2.get(e3.size);
              if ((e3.usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE) {
                let n3 = this.freeBuffers.get(e3.size) || [];
                void 0 === t3 || n3.length >= t3 ? e3.destroy() : n3.push(e3);
              } else if ((e3.usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM) {
                let n3 = this.freeUniformBuffers.get(e3.size) || [];
                void 0 === t3 || n3.length >= t3 ? e3.destroy() : n3.push(e3);
              } else e3.destroy();
            }
            this.buffersPending = [];
          } else {
            let e3 = this.capturedPendingBuffers.get(this.backend.currentSessionId);
            e3 || (e3 = [], this.capturedPendingBuffers.set(this.backend.currentSessionId, e3));
            for (let t3 of this.buffersPending) e3.push(t3);
            this.buffersPending = [];
          }
        }
        dispose() {
          this.freeBuffers.forEach(((e3) => {
            e3.forEach(((e4) => {
              e4.destroy();
            }));
          })), this.freeUniformBuffers.forEach(((e3) => {
            e3.forEach(((e4) => {
              e4.destroy();
            }));
          })), this.storageCache.forEach(((e3) => {
            e3.gpuData.buffer.destroy();
          })), this.capturedPendingBuffers.forEach(((e3) => {
            e3.forEach(((e4) => {
              e4.destroy();
            }));
          })), this.storageCache = /* @__PURE__ */ new Map(), this.freeBuffers = /* @__PURE__ */ new Map(), this.freeUniformBuffers = /* @__PURE__ */ new Map(), this.capturedPendingBuffers = /* @__PURE__ */ new Map();
        }
        onCreateSession() {
          this.sessionCount += 1;
        }
        onReleaseSession(e3) {
          let t3 = this.capturedPendingBuffers.get(e3);
          t3 && (t3.forEach(((e4) => {
            e4.destroy();
          })), this.capturedPendingBuffers.delete(e3)), this.sessionCount -= 1, 0 === this.sessionCount && (ht2("warning", (() => "[WebGPU] Clearing webgpu buffer cache")), this.storageCache.forEach(((e4) => {
            e4.gpuData.buffer.destroy();
          })), this.storageCache = /* @__PURE__ */ new Map());
        }
      }, qt2 = (...e3) => new Gt2(...e3);
    })), wd2 = j2((() => {
      Ut2 = class {
        constructor(e3) {
          Object.assign(this, e3);
        }
        get cacheKey() {
          return this.key || (this.key = Object.getOwnPropertyNames(this).sort().map(((e3) => `${this[e3]}`)).join(";")), this.key;
        }
      }, Wt2 = (e3) => new Ut2(e3);
    })), bd2 = j2((() => {
      dd2(), pd2(), Ht2 = 64, Qt2 = (e3, t3) => {
        if (3 === t3) throw new Error("vec3 has same alignment as vec4, use vec4 instead");
        switch (Number(e3)) {
          case 10:
            return t3 > 1 ? `vec${t3}<f16>` : "f16";
          case 1:
            return t3 > 1 ? `vec${t3}<f32>` : "f32";
          case 6:
            return t3 > 1 ? `vec${t3}<i32>` : "i32";
          case 12:
            return t3 > 1 ? `vec${t3}<u32>` : "u32";
          case 7:
            if (t3 > 1) throw new Error("currently not supported vecX of uint64 yet");
            return ["vec2<u32>", "i32"];
          case 13:
            if (t3 > 1) throw new Error("currently not supported vecX of uint64 yet");
            return ["vec2<u32>", "u32"];
          case 9:
            if (4 !== t3) throw new Error("bool must be vec4");
            return ["u32", "vec4<bool>"];
          case 22:
            return "i32";
          case 21:
            return "u32";
          default:
            throw new Error(`Unknown data type: ${e3}`);
        }
      }, Kt2 = (e3, t3 = 1) => {
        let n3 = Qt2(e3, t3);
        return "string" == typeof n3 ? n3 : n3[0];
      }, Xt2 = (e3, t3 = 1) => {
        let n3 = Qt2(e3, t3);
        return "string" == typeof n3 ? n3 : n3[1];
      }, Jt2 = (...e3) => {
        let t3 = [];
        return e3.forEach(((e4) => {
          0 !== e4.length && t3.push({ type: 12, data: e4 }, { type: 12, data: gt2.computeStrides(e4) });
        })), t3;
      }, Yt2 = (e3) => e3 % 4 == 0 ? 4 : e3 % 2 == 0 ? 2 : 1, Zt2 = (e3 = "f32", t3, n3 = "0") => t3 && 1 !== t3 ? `vec${t3}<${e3}>(${n3})` : `${e3}(${n3})`, en2 = (e3, t3, n3) => "f32" === e3 ? n3 : 1 === t3 ? `f32(${n3})` : `vec${t3}<f32>(${n3})`, tn2 = (e3, t3) => 4 === t3 ? `(${e3}.x + ${e3}.y + ${e3}.z + ${e3}.w)` : 2 === t3 ? `(${e3}.x + ${e3}.y)` : 3 === t3 ? `(${e3}.x + ${e3}.y + ${e3}.z)` : e3, nn2 = (e3, t3, n3, r3) => e3.startsWith("uniforms.") && n3 > 4 ? "string" == typeof t3 ? "f16" === r3 ? `${e3}[(${t3}) / 8][(${t3}) % 8 / 4][(${t3}) % 8 % 4]` : `${e3}[(${t3}) / 4][(${t3}) % 4]` : "f16" === r3 ? `${e3}[${Math.floor(t3 / 8)}][${Math.floor(t3 % 8 / 4)}][${t3 % 8 % 4}]` : `${e3}[${Math.floor(t3 / 4)}][${t3 % 4}]` : n3 > 1 ? `${e3}[${t3}]` : e3, rn2 = (e3, t3, n3, r3, s3) => {
        let a3 = "number" == typeof n3, o3 = a3 ? n3 : n3.length, i3 = [...new Array(o3).keys()], l3 = o3 < 2 ? "u32" : o3 <= 4 ? `vec${o3}<u32>` : `array<u32, ${o3}>`, d3 = Qt2(t3, s3), u3 = "string" == typeof d3 ? d3 : d3[1], c3 = "string" == typeof d3 ? d3 : d3[0], p3 = { indices: l3, value: u3, storage: c3, tensor: t3 }, m3 = (e4) => "string" == typeof e4 ? e4 : `${e4}u`, h3 = { offsetToIndices: false, indicesToOffset: false, broadcastedIndicesToOffset: false, set: false, setByIndices: false, get: false, getByIndices: false }, f3 = a3 ? "uniforms." : "", _3 = `${f3}${e3}_shape`, g3 = `${f3}${e3}_strides`, w3 = "";
        for (let e4 = 0; e4 < o3 - 1; e4++) w3 += `
    let dim${e4} = current / ${nn2(g3, e4, o3)};
    let rest${e4} = current % ${nn2(g3, e4, o3)};
    indices[${e4}] = dim${e4};
    current = rest${e4};
    `;
        w3 += `indices[${o3 - 1}] = current;`;
        let b3 = o3 < 2 ? "" : `
  fn o2i_${e3}(offset: u32) -> ${p3.indices} {
    var indices: ${p3.indices};
    var current = offset;
    ${w3}
    return indices;
  }`, y3 = [];
        if (o3 >= 2) for (let e4 = o3 - 1; e4 >= 0; e4--) y3.push(`${nn2(g3, e4, o3)} * (indices[${e4}])`);
        let M3 = o3 < 2 ? "" : `
  fn i2o_${e3}(indices: ${p3.indices}) -> u32 {
    return ${y3.join("+")};
  }`, x3 = (...e4) => 0 === o3 ? "0u" : `${p3.indices}(${e4.map(m3).join(",")})`, v3 = (e4, t4) => o3 < 2 ? `${e4}` : `${nn2(e4, t4, o3)}`, T3 = {}, k3 = (t4, n4) => (() => {
          if (p3.storage === p3.value) return `${e3}[${t4}]=${n4};`;
          if ("vec2<u32>" === p3.storage && "i32" === p3.value) return `${e3}[${t4}]=vec2<u32>(u32(${n4}), select(0u, 0xFFFFFFFFu, ${n4} < 0));`;
          if ("vec2<u32>" === p3.storage && "u32" === p3.value) return `${e3}[${t4}]=vec2<u32>(u32(${n4}), 0u);`;
          if ("u32" === p3.storage && "vec4<bool>" === p3.value) return `${e3}[${t4}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${n4}));`;
          throw new Error(`not supported combination of storage type ${p3.storage} and value type ${p3.value} yet`);
        })(), P3 = (t4) => (() => {
          if (p3.storage === p3.value) return `${e3}[${t4}]`;
          if ("vec2<u32>" === p3.storage && "i32" === p3.value) return `i32(${e3}[${t4}].x)`;
          if ("vec2<u32>" === p3.storage && "u32" === p3.value) return `u32(${e3}[${t4}].x)`;
          if ("u32" === p3.storage && "vec4<bool>" === p3.value) return `vec4<bool>(bool(${e3}[${t4}] & 0xFFu), bool(${e3}[${t4}] & 0xFF00u), bool(${e3}[${t4}] & 0xFF0000u), bool(${e3}[${t4}] & 0xFF000000u))`;
          throw new Error(`not supported combination of storage type ${p3.storage} and value type ${p3.value} yet`);
        })(), $3 = o3 < 2 ? "" : `
  fn get_${e3}ByIndices(indices: ${p3.indices}) -> ${u3} {
    return ${P3(`i2o_${e3}(indices)`)};
  }`, C3 = o3 < 2 ? "" : (() => {
          let t4 = i3.map(((e4) => `d${e4}: u32`)).join(", "), n4 = i3.map(((e4) => `d${e4}`)).join(", ");
          return `
  fn get_${e3}(${t4}) -> ${u3} {
    return get_${e3}ByIndices(${x3(n4)});
  }`;
        })(), S3 = o3 < 2 ? "" : `
  fn set_${e3}ByIndices(indices: ${p3.indices}, value: ${u3}) {
    ${k3(`i2o_${e3}(indices)`, "value")}
  }`, F3 = o3 < 2 ? "" : (() => {
          let t4 = i3.map(((e4) => `d${e4}: u32`)).join(", "), n4 = i3.map(((e4) => `d${e4}`)).join(", ");
          return `
  fn set_${e3}(${t4}, value: ${u3}) {
    set_${e3}ByIndices(${x3(n4)}, value);
  }`;
        })();
        return { impl: () => {
          let e4 = [], t4 = false;
          return h3.offsetToIndices && (e4.push(b3), t4 = true), h3.indicesToOffset && (e4.push(M3), t4 = true), h3.broadcastedIndicesToOffset && (Object.values(T3).forEach(((t5) => e4.push(t5))), t4 = true), h3.set && (e4.push(F3), t4 = true), h3.setByIndices && (e4.push(S3), t4 = true), h3.get && (e4.push(C3), t4 = true), h3.getByIndices && (e4.push($3), t4 = true), !a3 && t4 && e4.unshift(`const ${_3} = ${p3.indices}(${n3.join(",")});`, `const ${g3} = ${p3.indices}(${gt2.computeStrides(n3).join(",")});`), e4.join("\n");
        }, type: p3, offsetToIndices: (t4) => (h3.offsetToIndices = true, o3 < 2 ? t4 : `o2i_${e3}(${t4})`), indicesToOffset: (t4) => (h3.indicesToOffset = true, o3 < 2 ? t4 : `i2o_${e3}(${t4})`), broadcastedIndicesToOffset: (t4, n4) => {
          h3.broadcastedIndicesToOffset = true;
          let r4 = `${n4.name}broadcastedIndicesTo${e3}Offset`;
          if (r4 in T3) return `${r4}(${t4})`;
          let s4 = [];
          for (let e4 = o3 - 1; e4 >= 0; e4--) {
            let t5 = n4.indicesGet("outputIndices", e4 + n4.rank - o3);
            s4.push(`${v3(g3, e4)} * (${t5} % ${v3(_3, e4)})`);
          }
          return T3[r4] = `fn ${r4}(outputIndices: ${n4.type.indices}) -> u32 {
             return ${s4.length > 0 ? s4.join("+") : "0u"};
           }`, `${r4}(${t4})`;
        }, indices: x3, indicesGet: v3, indicesSet: (e4, t4, n4) => o3 < 2 ? `${e4}=${n4};` : `${nn2(e4, t4, o3)}=${n4};`, set: (...t4) => {
          if (t4.length !== o3 + 1) throw new Error(`indices length must be ${o3}`);
          let n4 = t4[o3];
          if ("string" != typeof n4) throw new Error("value must be string");
          let r4 = t4.slice(0, o3).map(m3).join(",");
          return 0 === o3 ? k3("0u", n4) : 1 === o3 ? k3(r4[0], n4) : (h3.set = true, h3.setByIndices = true, h3.indicesToOffset = true, `set_${e3}(${r4}, ${n4})`);
        }, setByOffset: k3, setByIndices: (t4, n4) => o3 < 2 ? k3(t4, n4) : (h3.setByIndices = true, h3.indicesToOffset = true, `set_${e3}ByIndices(${t4}, ${n4});`), get: (...t4) => {
          if (t4.length !== o3) throw new Error(`indices length must be ${o3}`);
          let n4 = t4.map(m3).join(",");
          return 0 === o3 ? P3("0u") : 1 === o3 ? P3(n4[0]) : (h3.get = true, h3.getByIndices = true, h3.indicesToOffset = true, `get_${e3}(${n4})`);
        }, getByOffset: P3, getByIndices: (t4) => o3 < 2 ? P3(t4) : (h3.getByIndices = true, h3.indicesToOffset = true, `get_${e3}ByIndices(${t4})`), usage: r3, name: e3, strides: g3, shape: _3, rank: o3 };
      }, sn2 = (e3, t3, n3, r3 = 1) => rn2(e3, t3, n3, "input", r3), an2 = (e3, t3, n3, r3 = 1) => rn2(e3, t3, n3, "output", r3), on2 = (e3, t3, n3) => rn2(e3, t3, n3, "atomicOutput", 1), ln2 = (e3, t3, n3, r3 = 1) => rn2(e3, t3, n3, "internal", r3), dn2 = class {
        constructor(e3, t3) {
          this.normalizedDispatchGroup = e3, this.limits = t3, this.internalVariables = [], this.variables = [], this.uniforms = [], this.variableIndex = 0;
        }
        guardAgainstOutOfBoundsWorkgroupSizes(e3) {
          return `if (global_idx >= ${"number" == typeof e3 ? `${e3}u` : e3}) { return; }`;
        }
        mainStart(e3 = Ht2) {
          let t3 = "number" == typeof e3 ? e3 : e3[0], n3 = "number" == typeof e3 ? 1 : e3[1], r3 = "number" == typeof e3 ? 1 : e3[2];
          if (t3 > this.limits.maxComputeWorkgroupSizeX || n3 > this.limits.maxComputeWorkgroupSizeY || r3 > this.limits.maxComputeWorkgroupSizeZ) throw new Error(`workgroup size [${t3}, ${n3}, ${r3}] exceeds the maximum workgroup size [${this.limits.maxComputeWorkgroupSizeX}, ${this.limits.maxComputeWorkgroupSizeY}, ${this.limits.maxComputeWorkgroupSizeZ}].`);
          if (t3 * n3 * r3 > this.limits.maxComputeInvocationsPerWorkgroup) throw new Error(`workgroup size [${t3}, ${n3}, ${r3}] exceeds the maximum workgroup invocations ${this.limits.maxComputeInvocationsPerWorkgroup}.`);
          let s3 = 1 === this.normalizedDispatchGroup[1] && 1 === this.normalizedDispatchGroup[2];
          return `@compute @workgroup_size(${t3}, ${n3}, ${r3})
  fn main(${s3 ? "@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(local_invocation_index) local_idx : u32,\n    @builtin(local_invocation_id) local_id : vec3<u32>" : "@builtin(global_invocation_id) global_id : vec3<u32>,\n                                             @builtin(local_invocation_id) local_id : vec3<u32>,\n    @builtin(local_invocation_index) local_idx : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(num_workgroups) num_workgroups : vec3<u32>"}) {
    ${s3 ? "let global_idx = global_id.x;\n         let workgroup_index = workgroup_id.x;" : `let workgroup_index = workgroup_id.z * num_workgroups[0] * num_workgroups[1] +
             workgroup_id.y * num_workgroups[0] + workgroup_id.x;
         let global_idx = workgroup_index * ${t3 * n3 * r3}u + local_idx;`}
  `;
        }
        appendVariableUniforms(e3) {
          0 !== e3.rank && (e3.shape.startsWith("uniforms.") && this.uniforms.push({ name: e3.shape.replace("uniforms.", ""), type: "u32", length: e3.rank }), e3.strides.startsWith("uniforms.") && this.uniforms.push({ name: e3.strides.replace("uniforms.", ""), type: "u32", length: e3.rank }));
        }
        declareVariable(e3, t3) {
          if ("internal" === e3.usage) throw new Error("cannot use internal variable with declareVariable(). use registerInternalVariables() instead.");
          this.variables.push(e3), this.appendVariableUniforms(e3);
          let n3 = "input" === e3.usage ? "read" : "read_write", r3 = "atomicOutput" === e3.usage ? "atomic<i32>" : e3.type.storage;
          return `@group(0) @binding(${t3}) var<storage, ${n3}> ${e3.name}: array<${r3}>;`;
        }
        declareVariables(...e3) {
          return e3.map(((e4) => this.declareVariable(e4, this.variableIndex++))).join("\n");
        }
        registerInternalVariable(e3) {
          if ("internal" !== e3.usage) throw new Error("cannot use input or output variable with registerInternalVariable(). use declareVariables() instead.");
          this.internalVariables.push(e3), this.appendVariableUniforms(e3);
        }
        registerInternalVariables(...e3) {
          return e3.forEach(((e4) => this.registerInternalVariable(e4))), this;
        }
        registerUniform(e3, t3, n3 = 1) {
          return this.uniforms.push({ name: e3, type: t3, length: n3 }), this;
        }
        registerUniforms(e3) {
          return this.uniforms = this.uniforms.concat(e3), this;
        }
        uniformDeclaration() {
          if (0 === this.uniforms.length) return "";
          let e3 = [];
          for (let { name: t3, type: n3, length: r3 } of this.uniforms) if (r3 && r3 > 4) "f16" === n3 ? e3.push(`@align(16) ${t3}:array<mat2x4<${n3}>, ${Math.ceil(r3 / 8)}>`) : e3.push(`${t3}:array<vec4<${n3}>, ${Math.ceil(r3 / 4)}>`);
          else {
            let s3 = null == r3 || 1 === r3 ? n3 : `vec${r3}<${n3}>`;
            e3.push(`${t3}:${s3}`);
          }
          return `
      struct Uniforms { ${e3.join(", ")} };
      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`;
        }
        get additionalImplementations() {
          return this.uniformDeclaration() + this.variables.map(((e3) => e3.impl())).join("\n") + this.internalVariables.map(((e3) => e3.impl())).join("\n");
        }
        get variablesInfo() {
          if (0 === this.uniforms.length) return;
          let e3 = (e4) => [12, 10, 1, 6][["u32", "f16", "f32", "i32"].indexOf(e4)];
          return this.uniforms.map(((t3) => [e3(t3.type), t3.length ?? 1]));
        }
      }, un2 = (e3, t3) => new dn2(e3, t3);
    })), yd2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), cn2 = (e3, t3) => {
        if (!e3 || 1 !== e3.length) throw new Error("Transpose requires 1 input.");
        if (0 !== t3.length && t3.length !== e3[0].dims.length) throw new Error(`perm size ${t3.length} does not match input rank ${e3[0].dims.length}`);
      }, pn2 = (e3, t3) => 0 !== t3.length ? t3 : [...new Array(e3).keys()].reverse(), mn2 = (e3, t3) => gt2.sortBasedOnPerm(e3, pn2(e3.length, t3)), hn2 = (e3, t3, n3, r3) => {
        let s3 = `fn perm(i: ${r3.type.indices}) -> ${n3.type.indices} {
    var a: ${n3.type.indices};`;
        for (let n4 = 0; n4 < t3; ++n4) s3 += `a[${e3[n4]}]=i[${n4}];`;
        return s3 + "return a;}";
      }, fn2 = (e3, t3) => {
        let n3 = [], r3 = [];
        for (let s3 = 0; s3 < e3.length; ++s3) 1 !== e3[s3] && n3.push(e3[s3]), 1 !== e3[t3[s3]] && r3.push(t3[s3]);
        return { newShape: n3, newPerm: r3 };
      }, _n2 = (e3, t3) => {
        let n3 = 0;
        for (let r3 = 0; r3 < e3.length; ++r3) if (1 !== t3[e3[r3]]) {
          if (e3[r3] < n3) return false;
          n3 = e3[r3];
        }
        return true;
      }, gn2 = (e3, t3) => {
        let n3, r3 = e3.dataType, s3 = e3.dims.length, a3 = pn2(s3, t3), o3 = mn2(e3.dims, a3), i3 = e3.dims, l3 = o3;
        if (s3 < 2 || _n2(a3, e3.dims)) return n3 = (e4) => {
          let t4 = sn2("input", r3, i3, 4), n4 = an2("output", r3, l3, 4);
          return `
  ${e4.registerUniform("output_size", "u32").declareVariables(t4, n4)}
  ${e4.mainStart()}
    ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
    output[global_idx] = input[global_idx];
  }`;
        }, { name: "TransposeCopy", shaderCache: { inputDependencies: ["type"] }, getRunData: () => {
          let t4 = gt2.size(o3);
          return { outputs: [{ dims: o3, dataType: e3.dataType }], dispatchGroup: { x: Math.ceil(t4 / 64 / 4) }, programUniforms: [{ type: 12, data: Math.ceil(t4 / 4) }] };
        }, getShaderSource: n3 };
        let { newShape: d3, newPerm: u3 } = fn2(e3.dims, a3), c3 = gt2.areEqual(u3, [2, 3, 1]), p3 = gt2.areEqual(u3, [3, 1, 2]);
        if (2 === d3.length || c3 || p3) {
          i3 = c3 ? [d3[0], d3[1] * d3[2]] : p3 ? [d3[0] * d3[1], d3[2]] : d3, l3 = [i3[1], i3[0]];
          let t4 = 16;
          return n3 = (e4) => {
            let n4 = sn2("a", r3, i3.length), s4 = an2("output", r3, l3.length);
            return `
  ${e4.registerUniform("output_size", "u32").declareVariables(n4, s4)}
  var<workgroup> tile : array<array<${s4.type.value}, ${t4 + 1}>, ${t4}>;
  ${e4.mainStart([t4, t4, 1])}
    let stride = (uniforms.output_shape[1] - 1) / ${t4} + 1;
    let workgroup_id_x = workgroup_index % stride;
    let workgroup_id_y = workgroup_index / stride;
    let input_col = workgroup_id_y * ${t4}u + local_id.x;
    let input_row = workgroup_id_x * ${t4}u + local_id.y;
    if (input_row < uniforms.a_shape[0] && input_col < uniforms.a_shape[1]) {
      tile[local_id.y][local_id.x] = ${n4.getByIndices(`${n4.type.indices}(input_row, input_col)`)};
    }
    workgroupBarrier();

    let output_col = workgroup_id_x * ${t4}u + local_id.x;
    let output_row = workgroup_id_y * ${t4}u + local_id.y;
    if (output_row < uniforms.output_shape[0] && output_col < uniforms.output_shape[1]) {
      ${s4.setByIndices(`${s4.type.indices}(output_row, output_col)`, "tile[local_id.x][local_id.y]")}
    }
  }`;
          }, { name: "TransposeShared", shaderCache: { inputDependencies: ["type"] }, getRunData: () => {
            let n4 = gt2.size(o3);
            return { outputs: [{ dims: o3, dataType: e3.dataType }], dispatchGroup: { x: Math.ceil(l3[1] / t4), y: Math.ceil(l3[0] / t4) }, programUniforms: [{ type: 12, data: n4 }, ...Jt2(i3, l3)] };
          }, getShaderSource: n3 };
        }
        return n3 = (e4) => {
          let t4 = sn2("a", r3, i3.length), n4 = an2("output", r3, l3.length);
          return `
  ${e4.registerUniform("output_size", "u32").declareVariables(t4, n4)}

  ${hn2(a3, s3, t4, n4)}

  ${e4.mainStart()}
    ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}

    let indices = ${n4.offsetToIndices("global_idx")};
    let aIndices = perm(indices);

    ${n4.setByOffset("global_idx", t4.getByIndices("aIndices"))}
  }`;
        }, { name: "Transpose", shaderCache: { hint: `${t3}`, inputDependencies: ["rank"] }, getRunData: () => {
          let t4 = gt2.size(o3);
          return { outputs: [{ dims: o3, dataType: e3.dataType }], dispatchGroup: { x: Math.ceil(t4 / 64) }, programUniforms: [{ type: 12, data: t4 }, ...Jt2(i3, l3)] };
        }, getShaderSource: n3 };
      }, wn2 = (e3, t3) => {
        cn2(e3.inputs, t3.perm), e3.compute(gn2(e3.inputs[0], t3.perm));
      }, bn2 = (e3) => Wt2({ perm: e3.perm });
    })), Md2 = j2((() => {
      dd2(), pd2(), bd2(), xd2(), yd2(), yn2 = { max: "select(bestValue, candidate, candidate > bestValue)", min: "select(bestValue, candidate, candidate < bestValue)", mean: "bestValue + candidate", sum: "bestValue + candidate", prod: "bestValue * candidate", sumSquare: "bestValue + candidate * candidate", logSumExp: "bestValue + exp(candidate)", l1: "bestValue + abs(candidate)", l2: "bestValue + candidate * candidate", logSum: "bestValue + candidate" }, Mn2 = { max: "select(bestValue, candidate, candidate > bestValue)", min: "select(bestValue, candidate, candidate < bestValue)", mean: "bestValue + candidate", sum: "bestValue + candidate", prod: "bestValue * candidate", sumSquare: "bestValue + candidate", logSumExp: "bestValue + candidate", l1: "bestValue + candidate", l2: "bestValue + candidate", logSum: "bestValue + candidate" }, xn2 = { max: "_A[offset]", min: "_A[offset]", mean: "0", sum: "0", prod: "1", sumSquare: "0", logSumExp: "0", l1: "0", l2: "0", logSum: "0" }, vn2 = { max: "bestValue", min: "bestValue", sum: "bestValue", prod: "bestValue", sumSquare: "bestValue", logSumExp: "log(bestValue)", l1: "bestValue", l2: "sqrt(bestValue)", logSum: "log(bestValue)" }, Tn2 = (e3, t3) => {
        let n3 = [];
        for (let r3 = t3 - e3; r3 < t3; ++r3) n3.push(r3);
        return n3;
      }, kn2 = (e3, t3) => {
        let n3 = [], r3 = e3.length;
        for (let s3 = 0; s3 < r3; s3++) -1 === t3.indexOf(s3) && n3.push(e3[s3]);
        return [n3, t3.map(((t4) => e3[t4]))];
      }, Pn2 = (e3, t3) => {
        let n3 = e3.length + t3.length, r3 = [], s3 = 0;
        for (let a3 = 0; a3 < n3; a3++) -1 === t3.indexOf(a3) ? r3.push(e3[s3++]) : r3.push(1);
        return r3;
      }, $n2 = (e3, t3) => {
        for (let n3 = 0; n3 < e3.length; ++n3) if (e3[e3.length - n3 - 1] !== t3 - 1 - n3) return false;
        return true;
      }, Cn2 = (e3, t3) => {
        let n3 = [];
        if (!$n2(e3, t3)) {
          for (let r3 = 0; r3 < t3; ++r3) -1 === e3.indexOf(r3) && n3.push(r3);
          e3.forEach(((e4) => n3.push(e4)));
        }
        return n3;
      }, Sn2 = (e3, t3, n3, r3, s3, a3, o3) => {
        let i3 = n3[0].dims, l3 = gt2.size(a3), d3 = gt2.size(o3), u3 = sn2("_A", n3[0].dataType, i3), c3 = an2("output", s3, a3), p3 = 64;
        1 === l3 && (p3 = 256);
        let m3 = `
          var<workgroup> aBestValues : array<f32, ${p3}>;
       `;
        return { name: e3, shaderCache: { hint: `${t3};${p3}`, inputDependencies: ["type"] }, getShaderSource: (e4) => `
        ${e4.registerUniform("reduceSize", "u32").declareVariables(u3, c3)}
        ${m3}
        fn DIV_CEIL(a : u32, b : u32) -> u32 {
          return ((a - 1u) / b + 1u);
         }
         ${e4.mainStart(p3)}

          let outputIndex = global_idx / ${p3};
          let offset = outputIndex * uniforms.reduceSize;

          var bestValue = f32(${xn2[r3]});
          let Length = uniforms.reduceSize;
          for (var k = local_idx; k < Length; k = k + ${p3}) {
           let candidate = f32(${u3.getByOffset("offset + k")});
           bestValue = ${yn2[r3]};
          }
          aBestValues[local_idx] = bestValue;
          workgroupBarrier();

         var reduceSize = min(Length, ${p3}u);
         for (var currentSize = reduceSize / 2u; reduceSize > 1u;
             currentSize = reduceSize / 2u) {
           let interval = DIV_CEIL(reduceSize, 2u);
           if (local_idx < currentSize) {
            let candidate = aBestValues[local_idx + interval];
            bestValue = ${Mn2[r3]};
            aBestValues[local_idx] = bestValue;
           }
           reduceSize = interval;
           workgroupBarrier();
         }

         if (local_idx == 0u) {
          ${c3.setByOffset("outputIndex", "mean" === r3 ? `${c3.type.storage}(bestValue / f32(uniforms.reduceSize))` : `${c3.type.storage}(${vn2[r3]})`)};
         }
        }`, getRunData: () => ({ outputs: [{ dims: a3, dataType: s3 }], dispatchGroup: { x: l3 }, programUniforms: [{ type: 12, data: d3 }] }) };
      }, Fn2 = (e3, t3, n3, r3) => {
        let s3 = 1 === e3.inputs.length ? n3 : qn2(e3.inputs, n3), a3 = s3.axes;
        0 === a3.length && !s3.noopWithEmptyAxes && (a3 = e3.inputs[0].dims.map(((e4, t4) => t4)));
        let o3 = gt2.normalizeAxes(a3, e3.inputs[0].dims.length), i3 = o3, l3 = e3.inputs[0], d3 = Cn2(i3, e3.inputs[0].dims.length);
        d3.length > 0 && (l3 = e3.compute(gn2(e3.inputs[0], d3), { inputs: [0], outputs: [-1] })[0], i3 = Tn2(i3.length, l3.dims.length));
        let [u3, c3] = kn2(l3.dims, i3), p3 = u3;
        s3.keepDims && (p3 = Pn2(u3, o3)), e3.compute(Sn2(t3, s3.cacheKey, [l3], r3, e3.inputs[0].dataType, p3, c3), { inputs: [l3] });
      }, En2 = (e3, t3) => {
        Fn2(e3, "ReduceMeanShared", t3, "mean");
      }, In2 = (e3, t3) => {
        Fn2(e3, "ReduceL1Shared", t3, "l1");
      }, An2 = (e3, t3) => {
        Fn2(e3, "ReduceL2Shared", t3, "l2");
      }, zn2 = (e3, t3) => {
        Fn2(e3, "ReduceLogSumExpShared", t3, "logSumExp");
      }, Ln2 = (e3, t3) => {
        Fn2(e3, "ReduceMaxShared", t3, "max");
      }, On2 = (e3, t3) => {
        Fn2(e3, "ReduceMinShared", t3, "min");
      }, Dn2 = (e3, t3) => {
        Fn2(e3, "ReduceProdShared", t3, "prod");
      }, Bn2 = (e3, t3) => {
        Fn2(e3, "ReduceSumShared", t3, "sum");
      }, Nn2 = (e3, t3) => {
        Fn2(e3, "ReduceSumSquareShared", t3, "sumSquare");
      }, jn2 = (e3, t3) => {
        Fn2(e3, "ReduceLogSumShared", t3, "logSum");
      };
    })), xd2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), Md2(), Rn2 = (e3) => {
        if (!e3 || 0 === e3.length || e3.length > 2) throw new Error("Reduce op requires 1 or 2 inputs.");
        if (2 === e3.length && 1 !== e3[1].dims.length) throw new Error("Invalid axes input dims.");
      }, Vn2 = (e3) => ["", "", `var value = ${e3.getByIndices("input_indices")};`, ""], Gn2 = (e3, t3, n3, r3, s3, a3, o3 = false, i3 = false) => {
        let l3 = [], d3 = n3[0].dims, u3 = d3.length, c3 = gt2.normalizeAxes(s3, u3), p3 = !i3 && 0 === c3.length;
        d3.forEach(((e4, t4) => {
          p3 || c3.indexOf(t4) >= 0 ? o3 && l3.push(1) : l3.push(e4);
        }));
        let m3 = l3.length, h3 = gt2.size(l3);
        return { name: e3, shaderCache: t3, getShaderSource: (e4) => {
          let t4 = [], s4 = sn2("_A", n3[0].dataType, u3), i4 = an2("output", a3, m3), l4 = r3(s4, i4, c3), h4 = l4[2];
          for (let e5 = 0, n4 = 0; e5 < u3; e5++) p3 || c3.indexOf(e5) >= 0 ? (o3 && n4++, h4 = `for(var j${e5}: u32 = 0; j${e5} < ${d3[e5]}; j${e5}++) {
                  ${l4[2].includes("last_index") ? `let last_index = j${e5};` : ""}
                  ${s4.indicesSet("input_indices", e5, `j${e5}`)}
                  ${h4}
                }`) : (t4.push(`${s4.indicesSet("input_indices", e5, i4.indicesGet("output_indices", n4))};`), n4++);
          return `

        ${e4.registerUniform("output_size", "u32").declareVariables(s4, i4)}

        ${e4.mainStart()}
          ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
          var input_indices: ${s4.type.indices};
          let output_indices = ${i4.offsetToIndices("global_idx")};

          ${t4.join("\n")}
          ${l4[0]}       // init ops for reduce max/min
          ${l4[1]}
          ${h4}
          ${l4[3]}
          ${4 === l4.length ? i4.setByOffset("global_idx", "value") : l4.slice(4).join("\n")}
        }`;
        }, getRunData: () => ({ outputs: [{ dims: l3, dataType: a3 }], dispatchGroup: { x: Math.ceil(h3 / 64) }, programUniforms: [{ type: 12, data: h3 }, ...Jt2(d3, l3)] }) };
      }, qn2 = (e3, t3) => {
        let n3 = [];
        return e3[1].dims[0] > 0 && e3[1].getBigInt64Array().forEach(((e4) => n3.push(Number(e4)))), Wt2({ axes: n3, keepDims: t3.keepDims, noopWithEmptyAxes: t3.noopWithEmptyAxes });
      }, Un2 = (e3, t3, n3, r3) => {
        let s3 = e3.inputs, a3 = 1 === s3.length ? n3 : qn2(s3, n3);
        e3.compute(Gn2(t3, { hint: a3.cacheKey, inputDependencies: ["rank"] }, [s3[0]], a3.noopWithEmptyAxes && 0 === a3.axes.length ? Vn2 : r3, a3.axes, s3[0].dataType, a3.keepDims, a3.noopWithEmptyAxes), { inputs: [0] });
      }, Wn2 = (e3, t3) => {
        Rn2(e3.inputs), Un2(e3, "ReduceLogSum", t3, ((e4, t4) => [`var value = ${t4.type.storage}(0);`, "", `value += ${e4.getByIndices("input_indices")};`, "value = log(value);"]));
      }, Hn2 = (e3, t3) => {
        Rn2(e3.inputs), Un2(e3, "ReduceL1", t3, ((e4, t4) => [`var value = ${t4.type.storage}(0);`, "", `value += abs(${e4.getByIndices("input_indices")});`, ""]));
      }, Qn2 = (e3, t3) => {
        Rn2(e3.inputs), Un2(e3, "ReduceL2", t3, ((e4, t4) => [`var t = ${t4.type.value}(0); var value = ${t4.type.value}(0);`, "", `t = ${e4.getByIndices("input_indices")}; value += (t * t);`, "value = sqrt(value);"]));
      }, Kn2 = (e3, t3) => {
        Rn2(e3.inputs), Un2(e3, "ReduceLogSumExp", t3, ((e4, t4) => [`var value = ${t4.type.storage}(0);`, "", `value += exp(${e4.getByIndices("input_indices")});`, "value = log(value);"]));
      }, Xn2 = (e3, t3) => {
        Rn2(e3.inputs), Un2(e3, "ReduceMax", t3, ((e4, t4, n3) => {
          let r3 = [];
          for (let t5 = 0; t5 < e4.rank; t5++) (n3.indexOf(t5) >= 0 || 0 === n3.length) && r3.push(e4.indicesSet("input_indices", t5, 0));
          return [`${r3.join("\n")}`, `var value = ${e4.getByIndices("input_indices")};`, `value = max(value, ${e4.getByIndices("input_indices")});`, ""];
        }));
      }, Jn2 = (e3, t3) => {
        Rn2(e3.inputs), Un2(e3, "ReduceMean", t3, ((t4, n3, r3) => {
          let s3 = 1;
          for (let n4 = 0; n4 < t4.rank; n4++) (r3.indexOf(n4) >= 0 || 0 === r3.length) && (s3 *= e3.inputs[0].dims[n4]);
          return ["var sum = f32(0);", "", `sum += f32(${t4.getByIndices("input_indices")});`, `let value = ${n3.type.value}(sum / ${s3});`];
        }));
      }, Yn2 = (e3, t3) => {
        Rn2(e3.inputs), Un2(e3, "ReduceMin", t3, ((e4, t4, n3) => {
          let r3 = [];
          for (let t5 = 0; t5 < e4.rank; t5++) (n3.indexOf(t5) >= 0 || 0 === n3.length) && r3.push(`input_indices[${t5}] = 0;`);
          return [`${r3.join("\n")}`, `var value = ${e4.getByIndices("input_indices")};`, `value = min(value, ${e4.getByIndices("input_indices")});`, ""];
        }));
      }, Zn2 = (e3, t3) => {
        Rn2(e3.inputs), Un2(e3, "ReduceProd", t3, ((e4, t4) => [`var value = ${t4.type.storage}(1);`, "", `value *= ${e4.getByIndices("input_indices")};`, ""]));
      }, er2 = (e3, t3) => {
        Rn2(e3.inputs), Un2(e3, "ReduceSum", t3, ((e4, t4) => [`var value = ${t4.type.storage}(0);`, "", `value += ${e4.getByIndices("input_indices")};`, ""]));
      }, tr2 = (e3, t3) => {
        Rn2(e3.inputs), Un2(e3, "ReduceSumSquare", t3, ((e4, t4) => [`var t = ${t4.type.value}(0); var value = ${t4.type.value}(0);`, "", `t = ${e4.getByIndices("input_indices")}; value += t * t;`, ""]));
      }, nr2 = (e3, t3, n3) => {
        if (0 === t3.length) return n3;
        let r3 = 1, s3 = 1;
        for (let n4 = 0; n4 < t3.length; n4++) -1 === t3.indexOf(n4) ? r3 *= e3[n4] : s3 *= e3[n4];
        return s3 < 32 && r3 > 1024;
      }, rr2 = (e3, t3) => {
        nr2(e3.inputs[0].dims, t3.axes, t3.noopWithEmptyAxes) ? Jn2(e3, t3) : En2(e3, t3);
      }, sr2 = (e3, t3) => {
        nr2(e3.inputs[0].dims, t3.axes, t3.noopWithEmptyAxes) ? Hn2(e3, t3) : In2(e3, t3);
      }, ar2 = (e3, t3) => {
        nr2(e3.inputs[0].dims, t3.axes, t3.noopWithEmptyAxes) ? Qn2(e3, t3) : An2(e3, t3);
      }, or2 = (e3, t3) => {
        nr2(e3.inputs[0].dims, t3.axes, t3.noopWithEmptyAxes) ? Kn2(e3, t3) : zn2(e3, t3);
      }, ir2 = (e3, t3) => {
        nr2(e3.inputs[0].dims, t3.axes, t3.noopWithEmptyAxes) ? Xn2(e3, t3) : Ln2(e3, t3);
      }, lr2 = (e3, t3) => {
        nr2(e3.inputs[0].dims, t3.axes, t3.noopWithEmptyAxes) ? Yn2(e3, t3) : On2(e3, t3);
      }, dr2 = (e3, t3) => {
        nr2(e3.inputs[0].dims, t3.axes, t3.noopWithEmptyAxes) ? Zn2(e3, t3) : Dn2(e3, t3);
      }, ur2 = (e3, t3) => {
        nr2(e3.inputs[0].dims, t3.axes, t3.noopWithEmptyAxes) ? er2(e3, t3) : Bn2(e3, t3);
      }, cr2 = (e3, t3) => {
        nr2(e3.inputs[0].dims, t3.axes, t3.noopWithEmptyAxes) ? tr2(e3, t3) : Nn2(e3, t3);
      }, pr2 = (e3, t3) => {
        nr2(e3.inputs[0].dims, t3.axes, t3.noopWithEmptyAxes) ? Wn2(e3, t3) : jn2(e3, t3);
      };
    })), vd2 = j2((() => {
      dd2(), wd2(), xd2(), mr2 = (e3) => {
        if (!e3 || 0 === e3.length || e3.length > 2) throw new Error("ArgMinMaxOp op requires 1 or 2 inputs.");
        if (1 !== e3[0].dataType) throw new Error("Invalid input type.");
      }, hr2 = (e3, t3) => {
        mr2(e3.inputs);
        e3.compute(Gn2("ArgMin", { hint: t3.cacheKey, inputDependencies: ["rank"] }, [e3.inputs[0]], ((e4, n3, r3) => {
          let s3 = [];
          for (let t4 = 0; t4 < e4.rank; t4++) (r3.indexOf(t4) >= 0 || 0 === r3.length) && s3.push(`input_indices[${t4}] = 0;`);
          return [`${s3.join("\n")}`, `var value = ${e4.getByIndices("input_indices")};
var best_index : i32 = 0;`, `if (${e4.getByIndices("input_indices")} ${t3.selectLastIndex > 0 ? "<=" : "<"} value) {
         value = ${e4.getByIndices("input_indices")};
         best_index = i32(last_index);
       }`, "", n3.setByOffset("global_idx", "best_index")];
        }), [t3.axis], 7, t3.keepDims), { inputs: [0] });
      }, fr2 = (e3, t3) => {
        mr2(e3.inputs);
        e3.compute(Gn2("argMax", { hint: t3.cacheKey, inputDependencies: ["rank"] }, [e3.inputs[0]], ((e4, n3, r3) => {
          let s3 = [];
          for (let t4 = 0; t4 < e4.rank; t4++) (r3.indexOf(t4) >= 0 || 0 === r3.length) && s3.push(`input_indices[${t4}] = 0;`);
          return [`${s3.join("\n")}`, `var value = ${e4.getByIndices("input_indices")};
var best_index : i32 = 0;`, `if (${e4.getByIndices("input_indices")} ${t3.selectLastIndex > 0 ? ">=" : ">"} value) {
         value = ${e4.getByIndices("input_indices")};
         best_index = i32(last_index);
       }`, "", n3.setByOffset("global_idx", "best_index")];
        }), [t3.axis], 7, t3.keepDims), { inputs: [0] });
      }, _r2 = (e3) => Wt2(e3);
    })), Td2 = j2((() => {
      dd2(), pd2(), _d2(), bd2(), gr2 = (e3, t3) => {
        let n3 = e3[0], r3 = e3[1], s3 = e3[2], a3 = e3[3], o3 = e3[4], i3 = e3[5];
        if (o3 && i3) throw new Error("Attention cannot have both past and attention_bias");
        if (3 !== n3.dims.length) throw new Error('Input "input" must have 3 dimensions');
        let l3 = n3.dims[0], d3 = n3.dims[1], u3 = n3.dims[2];
        if (1 !== s3.dims.length) throw new Error('Input "bias" is expected to have 1 dimensions');
        if (2 !== r3.dims.length) throw new Error('Input "weights" is expected to have 2 dimensions');
        if (r3.dims[0] !== u3) throw new Error("Input 1 dimension 0 should have same length as dimension 2 of input 0");
        if (s3.dims[0] !== r3.dims[1]) throw new Error('Input "bias" dimension 0 should have same length as dimension 1 of input "weights"');
        let c3 = s3.dims[0] / 3, p3 = c3, m3 = p3;
        if (t3.qkvHiddenSizes.length > 0) {
          if (3 !== t3.qkvHiddenSizes.length) throw new Error("qkv_hidden_sizes attribute should have 3 elements");
          for (let e4 of t3.qkvHiddenSizes) if (e4 % t3.numHeads != 0) throw new Error("qkv_hidden_sizes should be divisible by num_heads");
          c3 = t3.qkvHiddenSizes[0], p3 = t3.qkvHiddenSizes[1], m3 = t3.qkvHiddenSizes[2];
        }
        let h3 = d3;
        if (c3 !== p3) throw new Error("qkv_hidden_sizes first element should be same as the second");
        if (s3.dims[0] !== c3 + p3 + m3) throw new Error('Input "bias" dimension 0 should have same length as sum of Q/K/V hidden sizes');
        let f3 = 0;
        if (o3) {
          if (p3 !== m3) throw new Error('Input "past" expect k_hidden_size == v_hidden_size');
          if (5 !== o3.dims.length) throw new Error('Input "past" must have 5 dimensions');
          if (2 !== o3.dims[0]) throw new Error('Input "past" first dimension must be 2');
          if (o3.dims[1] !== l3) throw new Error('Input "past" second dimension must be batch_size');
          if (o3.dims[2] !== t3.numHeads) throw new Error('Input "past" third dimension must be num_heads');
          if (o3.dims[4] !== p3 / t3.numHeads) throw new Error('Input "past" fifth dimension must be k_hidden_size / num_heads');
          t3.pastPresentShareBuffer || (f3 = o3.dims[3]);
        }
        let _3 = h3 + f3;
        if (a3) throw new Error("Mask not supported");
        if (o3) throw new Error("past is not supported");
        if (i3) {
          if (4 !== i3.dims.length) throw new Error('Input "attention_bias" must have 4 dimensions');
          if (i3.dims[0] !== l3 || i3.dims[1] !== t3.numHeads || i3.dims[2] !== d3 || i3.dims[3] !== _3) throw new Error('Expect "attention_bias" shape (batch_size, num_heads, sequence_length, total_sequence_length)');
        }
        return { batchSize: l3, sequenceLength: d3, pastSequenceLength: f3, kvSequenceLength: h3, totalSequenceLength: _3, maxSequenceLength: -1, inputHiddenSize: u3, hiddenSize: c3, vHiddenSize: m3, headSize: Math.floor(c3 / t3.numHeads), vHeadSize: Math.floor(m3 / t3.numHeads), numHeads: t3.numHeads, isUnidirectional: false, pastPresentShareBuffer: false, maskFilterValue: t3.maskFilterValue, maskType: 0, scale: t3.scale, broadcastResPosBias: false, passPastInKv: false, qkvFormat: 1 };
      }, wr2 = (e3, t3, n3) => t3 && e3 ? `
      let total_sequence_length_input = u32(${t3.getByOffset("0")});
      let present_sequence_length = max(total_sequence_length_input, uniforms.past_sequence_length);
      let is_subsequent_prompt: bool = sequence_length > 1 && sequence_length != total_sequence_length_input;
      let is_first_prompt: bool = is_subsequent_prompt == false && sequence_length == total_sequence_length_input;
      total_sequence_length = u32(${e3?.getByOffset("batchIdx")}) + 1;
      var past_sequence_length: u32 = 0;
      if (is_first_prompt == false) {
        past_sequence_length = total_sequence_length - sequence_length;
      }
       ` : `
    ${n3 ? "let past_sequence_length = uniforms.past_sequence_length" : ""};
    let present_sequence_length = total_sequence_length;
    `, br2 = (e3, t3, n3, r3, s3, a3, o3, i3) => {
        let l3 = Yt2(o3 ? 1 : a3), d3 = 64, u3 = a3 / l3;
        u3 < d3 && (d3 = 32);
        let c3 = Math.ceil(a3 / l3 / d3), p3 = [{ type: 12, data: t3 }, { type: 12, data: n3 }, { type: 12, data: r3 }, { type: 12, data: s3 }, { type: 12, data: u3 }, { type: 12, data: c3 }], m3 = Kt2(e3.dataType, l3), h3 = Xt2(1, l3), f3 = ["type"];
        o3 && f3.push("type"), i3 && f3.push("type");
        return { name: "AttentionProbsSoftmax", shaderCache: { hint: `${d3};${m3};${l3}`, inputDependencies: f3 }, getShaderSource: (t4) => {
          let n4 = an2("x", e3.dataType, e3.dims, l3), r4 = [n4], s4 = o3 ? sn2("seq_lens", o3.dataType, o3.dims) : void 0;
          s4 && r4.push(s4);
          let a4 = i3 ? sn2("total_sequence_length_input", i3.dataType, i3.dims) : void 0;
          a4 && r4.push(a4);
          let u4 = Xt2(e3.dataType);
          return `
  var<workgroup> thread_max: array<f32, ${d3}>;
  var<workgroup> thread_sum: array<f32, ${d3}>;
  ${t4.registerUniforms([{ name: "batch_size", type: "u32" }, { name: "num_heads", type: "u32" }, { name: "past_sequence_length", type: "u32" }, { name: "sequence_length", type: "u32" }, { name: "total_sequence_length", type: "u32" }, { name: "elements_per_thread", type: "u32" }]).declareVariables(...r4)}
  ${t4.mainStart([d3, 1, 1])}
    let batchIdx = workgroup_id.z / uniforms.num_heads;
    let headIdx = workgroup_id.z % uniforms.num_heads;
    let sequence_length = uniforms.sequence_length;
    var total_sequence_length = uniforms.total_sequence_length;
    ${wr2(s4, a4, false)}
    let local_offset = local_idx * uniforms.elements_per_thread;
    let offset = (global_idx / ${d3}) * uniforms.total_sequence_length + local_offset;
    let seq_causal_length = ${o3 ? "u32(past_sequence_length + workgroup_id.y + 1)" : "total_sequence_length"};
    var thread_max_vector = ${h3}(-3.402823e+38f);
    for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {
      thread_max_vector = max(${h3}(x[offset + i]), thread_max_vector);
    }
    thread_max[local_idx] = ${(() => {
            switch (l3) {
              case 1:
                return "thread_max_vector";
              case 2:
                return "max(thread_max_vector.x, thread_max_vector.y)";
              case 4:
                return "max(max(thread_max_vector.x, thread_max_vector.y), max(thread_max_vector.z, thread_max_vector.w))";
              default:
                throw new Error(`Unsupported components: ${l3}`);
            }
          })()};
    workgroupBarrier();

    var max_value =  f32(-3.402823e+38f);
    for (var i = 0u; i < ${d3}; i++) {
      max_value = max(thread_max[i], max_value);
    }

    var sum_vector = ${h3}(0);
    for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {
      sum_vector += exp(${h3}(x[offset + i]) - max_value);
    }
    thread_sum[local_idx] = ${(() => {
            switch (l3) {
              case 1:
                return "sum_vector";
              case 2:
                return "sum_vector.x + sum_vector.y";
              case 4:
                return "sum_vector.x + sum_vector.y + sum_vector.z + sum_vector.w";
              default:
                throw new Error(`Unsupported components: ${l3}`);
            }
          })()};
    workgroupBarrier();

    var sum: f32 = 0;
    for (var i = 0u; i < ${d3}; i++) {
      sum += thread_sum[i];
    }

    if (sum == 0) {
      for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {
        x[offset + i] = ${n4.type.value}(${u4}(1.0) / ${u4}(seq_causal_length));
      }
    } else {
      for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {
        var f32input = ${h3}(x[offset + i]);
        x[offset + i] = ${n4.type.value}(exp(f32input - max_value) / sum);
      }
    }
      ${o3 ? `
        for (var total_seq_id: u32 = seq_causal_length; total_seq_id + local_offset < uniforms.total_sequence_length; total_seq_id++) {
          x[offset + total_seq_id] = ${n4.type.value}(${u4}(0));
        }` : ""};
  }`;
        }, getRunData: () => ({ outputs: [], dispatchGroup: { x: 1, y: s3, z: t3 * n3 }, programUniforms: p3 }) };
      }, yr2 = (e3, t3, n3, r3, s3, a3, o3, i3, l3) => {
        let d3 = o3 + a3.kvSequenceLength, u3 = [a3.batchSize, a3.numHeads, a3.sequenceLength, d3], c3 = e3 > 1 && r3, p3 = a3.kvNumHeads ? a3.kvNumHeads : a3.numHeads, m3 = c3 ? [a3.batchSize, p3, d3, a3.headSize] : void 0, h3 = a3.nReps ? a3.nReps : 1, f3 = 0 === a3.scale ? 1 / Math.sqrt(a3.headSize) : a3.scale, _3 = Yt2(a3.headSize), g3 = a3.headSize / _3, w3 = 12, b3 = { x: Math.ceil(d3 / w3), y: Math.ceil(a3.sequenceLength / w3), z: a3.batchSize * a3.numHeads }, y3 = [{ type: 12, data: a3.sequenceLength }, { type: 12, data: g3 }, { type: 12, data: d3 }, { type: 12, data: a3.numHeads }, { type: 12, data: a3.headSize }, { type: 1, data: f3 }, { type: 12, data: o3 }, { type: 12, data: a3.kvSequenceLength }, { type: 12, data: h3 }], M3 = c3 && r3 && gt2.size(r3.dims) > 0, x3 = ["type", "type"];
        M3 && x3.push("type"), s3 && x3.push("type"), i3 && x3.push("type"), l3 && x3.push("type");
        let v3 = [{ dims: u3, dataType: t3.dataType, gpuDataType: 0 }];
        c3 && v3.push({ dims: m3, dataType: t3.dataType, gpuDataType: 0 });
        return { name: "AttentionProbs", shaderCache: { hint: `${_3};${void 0 !== s3};${void 0 !== r3};${e3}`, inputDependencies: x3 }, getRunData: () => ({ outputs: v3, dispatchGroup: b3, programUniforms: y3 }), getShaderSource: (e4) => {
          let a4 = sn2("q", t3.dataType, t3.dims, _3), o4 = [a4, sn2("key", n3.dataType, n3.dims, _3)];
          if (M3) {
            let e5 = sn2("past_key", r3.dataType, r3.dims, _3);
            o4.push(e5);
          }
          s3 && o4.push(sn2("attention_bias", s3.dataType, s3.dims));
          let d4 = i3 ? sn2("seq_lens", i3.dataType, i3.dims) : void 0;
          d4 && o4.push(d4);
          let p4 = l3 ? sn2("total_sequence_length_input", l3.dataType, l3.dims) : void 0;
          p4 && o4.push(p4);
          let f4 = an2("output", t3.dataType, u3), g4 = [f4];
          c3 && g4.push(an2("present_key", t3.dataType, m3, _3));
          let b4 = Xt2(1, _3);
          return `
  const TILE_SIZE = 12u;

  var<workgroup> tileQ: array<${a4.type.storage}, 144>;
  var<workgroup> tileK: array<${a4.type.storage}, 144>;
  ${e4.registerUniforms([{ name: "M", type: "u32" }, { name: "K", type: "u32" }, { name: "N", type: "u32" }, { name: "num_heads", type: "u32" }, { name: "head_size", type: "u32" }, { name: "alpha", type: "f32" }, { name: "past_sequence_length", type: "u32" }, { name: "kv_sequence_length", type: "u32" }, { name: "n_reps", type: "u32" }]).declareVariables(...o4, ...g4)}
  ${e4.mainStart([w3, w3, 1])}
    // x holds the N and y holds the M
    let headIdx = workgroup_id.z % uniforms.num_heads;
    let kvHeadIdx = ${1 === h3 ? "headIdx" : "headIdx / uniforms.n_reps"};
    let kv_num_heads = ${1 === h3 ? "uniforms.num_heads" : "uniforms.num_heads / uniforms.n_reps"};
    let batchIdx = workgroup_id.z / uniforms.num_heads;
    let m = workgroup_id.y * TILE_SIZE;
    let n = workgroup_id.x * TILE_SIZE;
    let sequence_length = uniforms.M;
    var total_sequence_length = uniforms.N;
    ${wr2(d4, p4, true)}
    let absKvHeadIdx = batchIdx * kv_num_heads + kvHeadIdx;
    let qOffset = workgroup_id.z * uniforms.M * uniforms.K + m * uniforms.K;
    ${M3 && c3 ? "let pastKeyOffset = absKvHeadIdx * uniforms.past_sequence_length * uniforms.K;" : ""};
    let kOffset = absKvHeadIdx * uniforms.kv_sequence_length * uniforms.K;
    ${c3 ? "let presentKeyOffset = absKvHeadIdx * uniforms.N * uniforms.K;" : ""}
    var value = ${b4}(0);
    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {
      if (global_id.y < uniforms.M && w + local_id.x < uniforms.K) {
        tileQ[TILE_SIZE * local_id.y + local_id.x] = q[qOffset + local_id.y * uniforms.K + w + local_id.x];
      }
      if (n + local_id.y < uniforms.N && w + local_id.x < uniforms.K) {
        var idx = TILE_SIZE * local_id.y + local_id.x;
      ${M3 && c3 ? "\n              if (n + local_id.y < past_sequence_length) {\n                tileK[idx] = past_key[pastKeyOffset + (n + local_id.y) * uniforms.K + w + local_id.x];\n              } else if (n + local_id.y - past_sequence_length < uniforms.kv_sequence_length) {\n                tileK[idx] = key[kOffset + (n + local_id.y - past_sequence_length) * uniforms.K + w + local_id.x];\n              }" : "\n          if (n + local_id.y < uniforms.kv_sequence_length) {\n            tileK[idx] = key[kOffset + (n + local_id.y) * uniforms.K + w + local_id.x];\n          }"}
      ${c3 ? "if (n + local_id.y < present_sequence_length) {\n        present_key[presentKeyOffset + (n + local_id.y) * uniforms.K + w + local_id.x] = tileK[idx];\n      }" : ""}
      }
      workgroupBarrier();

      for (var k: u32 = 0u; k < TILE_SIZE && w+k < uniforms.K; k++) {
          value += ${b4}(tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * local_id.x + k]);
      }

      workgroupBarrier();
    }

    if (global_id.y < uniforms.M && global_id.x < total_sequence_length) {
      let headOffset = workgroup_id.z * uniforms.M * uniforms.N;
      let outputIdx = headOffset + global_id.y * uniforms.N + global_id.x;
      var sum: f32 = ${(() => {
            switch (_3) {
              case 1:
                return "value";
              case 2:
                return "value.x + value.y";
              case 4:
                return "value.x + value.y + value.z + value.w";
              default:
                throw new Error(`Unsupported components: ${_3}`);
            }
          })()};
        output[outputIdx] = ${f4.type.value} (sum * uniforms.alpha) + ${s3 ? "attention_bias[outputIdx]" : "0.0"};
    }
  }`;
        } };
      }, Mr2 = (e3, t3, n3, r3, s3, a3, o3 = void 0, i3 = void 0) => {
        let l3 = a3 + s3.kvSequenceLength, d3 = s3.nReps ? s3.nReps : 1, u3 = s3.vHiddenSize * d3, c3 = e3 > 1 && r3, p3 = s3.kvNumHeads ? s3.kvNumHeads : s3.numHeads, m3 = c3 ? [s3.batchSize, p3, l3, s3.headSize] : void 0, h3 = [s3.batchSize, s3.sequenceLength, u3], f3 = 12, _3 = { x: Math.ceil(s3.vHeadSize / f3), y: Math.ceil(s3.sequenceLength / f3), z: s3.batchSize * s3.numHeads }, g3 = [{ type: 12, data: s3.sequenceLength }, { type: 12, data: l3 }, { type: 12, data: s3.vHeadSize }, { type: 12, data: s3.numHeads }, { type: 12, data: s3.headSize }, { type: 12, data: u3 }, { type: 12, data: a3 }, { type: 12, data: s3.kvSequenceLength }, { type: 12, data: d3 }], w3 = c3 && r3 && gt2.size(r3.dims) > 0, b3 = ["type", "type"];
        w3 && b3.push("type"), o3 && b3.push("type"), i3 && b3.push("type");
        let y3 = [{ dims: h3, dataType: t3.dataType, gpuDataType: 0 }];
        c3 && y3.push({ dims: m3, dataType: t3.dataType, gpuDataType: 0 });
        return { name: "AttentionScore", shaderCache: { hint: `${void 0 !== r3};${e3}`, inputDependencies: b3 }, getRunData: () => ({ outputs: y3, dispatchGroup: _3, programUniforms: g3 }), getShaderSource: (e4) => {
          let s4 = sn2("probs", t3.dataType, t3.dims), a4 = [s4, sn2("v", n3.dataType, n3.dims)];
          w3 && a4.push(sn2("past_value", r3.dataType, r3.dims));
          let l4 = o3 ? sn2("seq_lens", o3.dataType, o3.dims) : void 0;
          o3 && a4.push(l4);
          let u4 = i3 ? sn2("total_sequence_length_input", i3.dataType, i3.dims) : void 0;
          i3 && a4.push(u4);
          let p4 = [an2("output", t3.dataType, h3)];
          c3 && p4.push(an2("present_value", t3.dataType, m3));
          return `
  const TILE_SIZE = 12u;
  var<workgroup> tileQ: array<${s4.type.value}, 144>;
  var<workgroup> tileV: array<${s4.type.value}, 144>;
  ${e4.registerUniforms([{ name: "M", type: "u32" }, { name: "K", type: "u32" }, { name: "N", type: "u32" }, { name: "num_heads", type: "u32" }, { name: "head_size", type: "u32" }, { name: "v_hidden_size", type: "u32" }, { name: "past_sequence_length", type: "u32" }, { name: "kv_sequence_length", type: "u32" }, { name: "n_reps", type: "u32" }]).declareVariables(...a4, ...p4)}
  ${e4.mainStart([f3, f3, 1])}
   let headIdx = workgroup_id.z % uniforms.num_heads;
   let batchIdx = workgroup_id.z / uniforms.num_heads;
   let kvHeadIdx = ${1 === d3 ? "headIdx" : "headIdx / uniforms.n_reps"};
   let kv_num_heads = ${1 === d3 ? "uniforms.num_heads" : "uniforms.num_heads / uniforms.n_reps"};
   let m = global_id.y;
   let n = global_id.x;
   let sequence_length = uniforms.M;
   var total_sequence_length = uniforms.K;
   ${wr2(l4, u4, true)}
   let offsetA = workgroup_id.z * uniforms.M * uniforms.K + m * uniforms.K;
   let absKvHeadIdx = batchIdx * kv_num_heads + kvHeadIdx; // kvHeadIdx is relative to the batch
   ${w3 && c3 ? "let pastValueOffset = absKvHeadIdx * uniforms.N * uniforms.past_sequence_length + n;" : ""};
   let vOffset = absKvHeadIdx * uniforms.N * uniforms.kv_sequence_length + n;
   ${c3 ? "let presentValueOffset = absKvHeadIdx * uniforms.N * uniforms.K + n;" : ""}
   var value = ${s4.type.storage}(0);
   for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {
      if (m < uniforms.M && w + local_id.x < uniforms.K) {
        tileQ[TILE_SIZE * local_id.y + local_id.x] = probs[offsetA + w + local_id.x];
      }
      if (n < uniforms.N && w + local_id.y < uniforms.K) {
        var idx = TILE_SIZE * local_id.y + local_id.x;
        ${w3 && c3 ? "\n        if (w + local_id.y < past_sequence_length) {\n          tileV[idx] = past_value[pastValueOffset + (w + local_id.y) * uniforms.N];\n        } else if (w + local_id.y - past_sequence_length < uniforms.kv_sequence_length) {\n          tileV[idx] = v[vOffset + (w + local_id.y - past_sequence_length) * uniforms.N];\n        }\n      " : "\n            if (w + local_id.y < uniforms.kv_sequence_length) {\n              tileV[idx] = v[vOffset + (w + local_id.y) * uniforms.N];\n            }"}
        ${c3 ? "\n            if (w + local_id.y < present_sequence_length) {\n          present_value[presentValueOffset + (w + local_id.y) * uniforms.N] = tileV[idx];\n        }" : ""}
      }
     workgroupBarrier();
     for (var k: u32 = 0u; k < TILE_SIZE && w+k < total_sequence_length; k++) {
       value += tileQ[TILE_SIZE * local_id.y + k] * tileV[TILE_SIZE * k + local_id.x];
     }
     workgroupBarrier();
   }

   // we need to transpose output from BNSH_v to BSND_v
   if (m < uniforms.M && n < uniforms.N) {
     let outputIdx = batchIdx * uniforms.M * uniforms.v_hidden_size + m * uniforms.v_hidden_size
       + headIdx * uniforms.N + n;
     output[outputIdx] = value;
   }
  }`;
        } };
      }, xr2 = (e3, t3, n3, r3, s3, a3, o3, i3, l3, d3, u3 = void 0, c3 = void 0) => {
        let p3 = Math.min(e3.outputCount, 1 + (o3 ? 1 : 0) + (i3 ? 1 : 0)), m3 = p3 > 1 ? d3.pastSequenceLength : 0, h3 = m3 + d3.kvSequenceLength, f3 = l3 && gt2.size(l3.dims) > 0 ? l3 : void 0, _3 = [t3, n3];
        p3 > 1 && o3 && gt2.size(o3.dims) > 0 && _3.push(o3), f3 && _3.push(f3), u3 && _3.push(u3), c3 && _3.push(c3);
        let g3 = e3.compute(yr2(p3, t3, n3, o3, f3, d3, m3, u3, c3), { inputs: _3, outputs: p3 > 1 ? [-1, 1] : [-1] })[0];
        e3.compute(br2(g3, d3.batchSize, d3.numHeads, m3, d3.sequenceLength, h3, u3, c3), { inputs: u3 && c3 ? [g3, u3, c3] : [g3], outputs: [] });
        let w3 = [g3, r3];
        p3 > 1 && i3 && gt2.size(i3.dims) > 0 && w3.push(i3), u3 && w3.push(u3), c3 && w3.push(c3), e3.compute(Mr2(p3, g3, r3, i3, d3, m3, u3, c3), { inputs: w3, outputs: p3 > 1 ? [0, 2] : [0] });
      }, vr2 = (e3, t3) => {
        let n3 = [t3.batchSize, t3.numHeads, t3.sequenceLength, t3.headSize], r3 = t3.sequenceLength, s3 = t3.inputHiddenSize, a3 = t3.headSize, o3 = 12, i3 = { x: Math.ceil(t3.headSize / o3), y: Math.ceil(t3.sequenceLength / o3), z: t3.batchSize * t3.numHeads }, l3 = [e3.inputs[0], e3.inputs[1], e3.inputs[2]], d3 = [{ type: 12, data: r3 }, { type: 12, data: s3 }, { type: 12, data: a3 }, { type: 12, data: t3.numHeads }, { type: 12, data: t3.headSize }, { type: 12, data: t3.hiddenSize }, { type: 12, data: t3.hiddenSize + t3.hiddenSize + t3.vHiddenSize }];
        return e3.compute({ name: "AttentionPrepare", shaderCache: { inputDependencies: ["type", "type", "type"] }, getRunData: () => ({ outputs: [{ dims: n3, dataType: e3.inputs[0].dataType, gpuDataType: 0 }, { dims: n3, dataType: e3.inputs[0].dataType, gpuDataType: 0 }, { dims: n3, dataType: e3.inputs[0].dataType, gpuDataType: 0 }], dispatchGroup: i3, programUniforms: d3 }), getShaderSource: (e4) => {
          let t4 = an2("output_q", l3[0].dataType, n3), r4 = an2("output_k", l3[0].dataType, n3), s4 = an2("output_v", l3[0].dataType, n3), a4 = sn2("input", l3[0].dataType, l3[0].dims), i4 = sn2("weight", l3[1].dataType, l3[1].dims), d4 = sn2("bias", l3[2].dataType, l3[2].dims), u3 = a4.type.storage;
          return `
  const TILE_SIZE = 12u;
  var<workgroup> tileInput: array<${u3}, 144>;
  var<workgroup> tileWeightQ: array<${u3}, 144>;
  var<workgroup> tileWeightK: array<${u3}, 144>;
  var<workgroup> tileWeightV: array<${u3}, 144>;
  ${e4.registerUniforms([{ name: "M", type: "u32" }, { name: "K", type: "u32" }, { name: "N", type: "u32" }, { name: "num_heads", type: "u32" }, { name: "head_size", type: "u32" }, { name: "hidden_size", type: "u32" }, { name: "ldb", type: "u32" }]).declareVariables(a4, i4, d4, t4, r4, s4)}
  ${e4.mainStart([o3, o3, 1])}
    let batchIndex = workgroup_id.z / uniforms.num_heads;
    let headNumber = workgroup_id.z % uniforms.num_heads;
    let m = global_id.y;
    let n = global_id.x;

    let inputOffset = batchIndex * (uniforms.M * uniforms.K) + m * uniforms.K;
    let biasOffsetQ = headNumber * uniforms.head_size;
    let biasOffsetK = uniforms.hidden_size + biasOffsetQ;
    let biasOffsetV = uniforms.hidden_size + biasOffsetK;

    var valueQ = ${u3}(0);
    var valueK = ${u3}(0);
    var valueV = ${u3}(0);
    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {
      if (m < uniforms.M && w + local_id.x < uniforms.K) {
        tileInput[TILE_SIZE * local_id.y + local_id.x] = input[inputOffset + w + local_id.x];
      }
      if (n < uniforms.N && w + local_id.y < uniforms.K) {
        let offset = n + (w + local_id.y) * uniforms.ldb;
        tileWeightQ[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetQ + offset];
        tileWeightK[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetK + offset];
        tileWeightV[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetV + offset];
      }
      workgroupBarrier();
      for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {
        let inputTileOffset = TILE_SIZE * local_id.y + k;
        let weightTileOffset = TILE_SIZE * k + local_id.x;
        valueQ += tileInput[inputTileOffset] * tileWeightQ[weightTileOffset];
        valueK += tileInput[inputTileOffset] * tileWeightK[weightTileOffset];
        valueV += tileInput[inputTileOffset] * tileWeightV[weightTileOffset];
      }

      workgroupBarrier();
    }

    let headOffset = (m * uniforms.N + n) % uniforms.head_size;
    valueQ += bias[headOffset + biasOffsetQ];
    valueK += bias[headOffset + biasOffsetK];
    valueV += bias[headOffset + biasOffsetV];

    let offset = workgroup_id.z * uniforms.M * uniforms.N;
    if (m < uniforms.M && n < uniforms.N) {
      let outputIdx = offset + m * uniforms.N + n;
      output_q[outputIdx] = valueQ;
      output_k[outputIdx] = valueK;
      output_v[outputIdx] = valueV;
    }
  }`;
        } }, { inputs: l3, outputs: [-1, -1, -1] });
      }, Tr2 = (e3, t3) => {
        let n3 = gr2(e3.inputs, t3), [r3, s3, a3] = vr2(e3, n3);
        return xr2(e3, r3, s3, a3, e3.inputs[4], void 0, void 0, void 0, e3.inputs[5], n3);
      };
    })), kd2 = j2((() => {
      le2(), dd2(), pd2(), wd2(), bd2(), kr2 = (e3, t3) => {
        if (!e3 || 5 !== e3.length) throw new Error("BatchNormalization requires 5 inputs");
        let n3 = (e4, t4, n4) => {
          let r3 = t4.length;
          if (r3 !== e4.length) throw new Error(`${n4}: num dimensions != ${r3}`);
          t4.forEach(((t5, r4) => {
            if (t5 !== e4[r4]) throw new Error(`${n4}: dim[${r4}] do not match`);
          }));
        };
        if (e3[0].dims.length > 1) {
          let r3 = "NHWC" === t3.format ? t3.spatial ? e3[0].dims.slice(-1) : e3[0].dims.slice(-1).concat(e3[0].dims.slice(1, e3[0].dims.length - 1)) : e3[0].dims.slice(1, t3.spatial ? 2 : void 0);
          n3(e3[1].dims, r3, "Invalid input scale"), n3(e3[2].dims, r3, "Invalid input B"), n3(e3[3].dims, r3, "Invalid input mean"), n3(e3[4].dims, r3, "Invalid input var");
        } else n3(e3[1].dims, [1], "Invalid input scale"), n3(e3[2].dims, [1], "Invalid input B"), n3(e3[3].dims, [1], "Invalid input mean"), n3(e3[4].dims, [1], "Invalid input var");
      }, Pr2 = (e3, t3) => {
        let { epsilon: n3, spatial: r3, format: s3 } = t3, a3 = e3[0].dims, o3 = r3 ? Yt2(a3[a3.length - 1]) : 1, i3 = "NHWC" === s3 && a3.length > 1 ? o3 : 1, l3 = gt2.size(a3) / o3, d3 = r3, u3 = d3 ? a3.length : a3, c3 = sn2("x", e3[0].dataType, e3[0].dims, o3), p3 = sn2("scale", e3[1].dataType, e3[1].dims, i3), m3 = sn2("bias", e3[2].dataType, e3[2].dims, i3), h3 = sn2("inputMean", e3[3].dataType, e3[3].dims, i3), f3 = sn2("inputVar", e3[4].dataType, e3[4].dims, i3), _3 = an2("y", e3[0].dataType, u3, o3);
        return { name: "BatchNormalization", shaderCache: { hint: `${t3.epsilon}_${t3.format}_${r3}_${o3}`, inputDependencies: d3 ? ["rank", "type", "type", "type", "type"] : void 0 }, getShaderSource: (e4) => `
  const epsilon = ${n3};
  ${e4.registerUniform("outputSize", "u32").declareVariables(c3, p3, m3, h3, f3, _3)}
  ${e4.mainStart()}
  ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
    var outputIndices = ${_3.offsetToIndices(`global_idx * ${o3}`)};
    ${(() => {
          let e5 = "";
          if (r3) e5 = `let cOffset = ${1 === a3.length ? "0u" : "NHWC" === s3 ? `outputIndices[${a3.length - 1}] / ${o3}` : "outputIndices[1]"};`;
          else if ("NCHW" === s3) e5 = `
            ${_3.indicesSet("outputIndices", "0", "0")}
            let cOffset = ${_3.indicesToOffset("outputIndices")};`;
          else {
            e5 = `var cIndices = ${p3.type.indices}(0);
                       cIndices[0] = outputIndices[${a3.length - 1}];`;
            for (let t4 = 1; t4 < p3.rank; t4++) e5 += `cIndices[${t4}] = outputIndices[${t4}];`;
            e5 += `let cOffset = ${p3.indicesToOffset("cIndices")};`;
          }
          return e5;
        })()}
    let scale = ${p3.getByOffset("cOffset")};
    let bias = ${m3.getByOffset("cOffset")};
    let inputMean = ${h3.getByOffset("cOffset")};
    let inputVar = ${f3.getByOffset("cOffset")};
    let x = ${c3.getByOffset("global_idx")};
    let value = (x - inputMean) * inverseSqrt(inputVar + epsilon) * scale + bias;
    ${_3.setByOffset("global_idx", "value")}
  }`, getRunData: () => ({ outputs: [{ dims: e3[0].dims, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(l3 / 64) }, programUniforms: d3 ? [{ type: 12, data: l3 }, ...Jt2(a3)] : [{ type: 12, data: l3 }] }) };
      }, $r2 = (e3) => Wt2(e3), Cr2 = (e3, t3) => {
        let { inputs: n3, outputCount: r3 } = e3, s3 = $r2({ ...t3, outputCount: r3 });
        if (p2.webgpu.validateInputContent && kr2(n3, s3), t3.trainingMode) throw new Error("BatchNormalization trainingMode is not supported yet.");
        e3.compute(Pr2(n3, s3));
      };
    })), Pd2 = j2((() => {
      pd2(), bd2(), Sr2 = (e3) => {
        if (3 !== e3[0].dims.length) throw new Error("input should have 3 dimensions");
        if (![320, 640, 1280].includes(e3[0].dims[2])) throw new Error("number of channels should be 320, 640 or 1280");
        if (1 !== e3[1].dims.length) throw new Error("bias is expected to have 1 dimensions");
        if (e3[0].dims[2] !== e3[1].dims[0]) throw new Error("last dimension of input and bias are not the same");
      }, Fr2 = (e3) => {
        let t3 = e3[0].dims, n3 = e3[0].dims[2], r3 = gt2.size(t3) / 4, s3 = e3[0].dataType, a3 = sn2("input", s3, t3, 4), o3 = sn2("bias", s3, [n3], 4), i3 = sn2("residual", s3, t3, 4), l3 = an2("output", s3, t3, 4);
        return { name: "BiasAdd", getRunData: () => ({ outputs: [{ dims: t3, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(r3 / 64) } }), getShaderSource: (e4) => `
  const channels = ${n3}u / 4;
  ${e4.declareVariables(a3, o3, i3, l3)}

  ${e4.mainStart()}
    ${e4.guardAgainstOutOfBoundsWorkgroupSizes(r3)}
    let value = ${a3.getByOffset("global_idx")}
      + ${o3.getByOffset("global_idx % channels")} + ${i3.getByOffset("global_idx")};
    ${l3.setByOffset("global_idx", "value")}
  }` };
      }, Er2 = (e3) => {
        Sr2(e3.inputs), e3.compute(Fr2(e3.inputs));
      };
    })), $d2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), Ir2 = (e3, t3, n3, r3, s3, a3, o3) => {
        let i3 = Math.ceil(t3 / 4), l3 = "";
        l3 = "string" == typeof s3 ? `${s3}(a)` : s3("a");
        let d3 = sn2("inputData", n3, [i3], 4), u3 = an2("outputData", r3, [i3], 4), c3 = [{ name: "vec_size", type: "u32" }];
        return o3 && c3.push(...o3), `
      ${e3.registerUniforms(c3).declareVariables(d3, u3)}

  ${a3 ?? ""}

  ${e3.mainStart()}
    ${e3.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}

    let a = ${d3.getByOffset("global_idx")};
    ${u3.setByOffset("global_idx", l3)}
  }`;
      }, Ar2 = (e3, t3, n3, r3, s3, a3 = e3.dataType, o3, i3) => {
        let l3 = [{ type: 12, data: Math.ceil(gt2.size(e3.dims) / 4) }];
        return o3 && l3.push(...o3), { name: t3, shaderCache: { hint: s3, inputDependencies: ["type"] }, getShaderSource: (t4) => Ir2(t4, gt2.size(e3.dims), e3.dataType, a3, n3, r3, i3), getRunData: (t4) => ({ outputs: [{ dims: e3.dims, dataType: a3 }], dispatchGroup: { x: Math.ceil(gt2.size(t4[0].dims) / 64 / 4) }, programUniforms: l3 }) };
      }, zr2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Abs", "abs"));
      }, Lr2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Acos", "acos"));
      }, Or2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Acosh", "acosh"));
      }, Dr2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Asin", "asin"));
      }, Br2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Asinh", "asinh"));
      }, Nr2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Atan", "atan"));
      }, jr2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Atanh", "atanh"));
      }, Rr2 = (e3) => Wt2(e3), Vr2 = (e3, t3) => {
        let n3;
        switch (t3.to) {
          case 10:
            n3 = "vec4<f16>";
            break;
          case 1:
            n3 = "vec4<f32>";
            break;
          case 12:
            n3 = "vec4<u32>";
            break;
          case 6:
            n3 = "vec4<i32>";
            break;
          case 9:
            n3 = "vec4<bool>";
            break;
          default:
            throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${t3.to}`);
        }
        e3.compute(Ar2(e3.inputs[0], "Cast", n3, void 0, t3.cacheKey, t3.to));
      }, Gr2 = (e3) => {
        let t3, n3, r3 = e3.length >= 2 && 0 !== e3[1].data, s3 = e3.length >= 3 && 0 !== e3[2].data;
        switch (e3[0].dataType) {
          case 1:
            t3 = r3 ? e3[1].getFloat32Array()[0] : -34028234663852886e22, n3 = s3 ? e3[2].getFloat32Array()[0] : 34028234663852886e22;
            break;
          case 10:
            t3 = r3 ? e3[1].getUint16Array()[0] : 64511, n3 = s3 ? e3[2].getUint16Array()[0] : 31743;
            break;
          default:
            throw new Error("Unsupport data type");
        }
        return Wt2({ min: t3, max: n3 });
      }, qr2 = (e3, t3) => {
        let n3 = t3 || Gr2(e3.inputs), r3 = Xt2(e3.inputs[0].dataType);
        e3.compute(Ar2(e3.inputs[0], "Clip", ((e4) => `clamp(${e4}, vec4<${r3}>(uniforms.min), vec4<${r3}>(uniforms.max))`), void 0, n3.cacheKey, void 0, [{ type: e3.inputs[0].dataType, data: n3.min }, { type: e3.inputs[0].dataType, data: n3.max }], [{ name: "min", type: r3 }, { name: "max", type: r3 }]), { inputs: [0] });
      }, Ur2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Ceil", "ceil"));
      }, Wr2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Cos", "cos"));
      }, Hr2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Cosh", "cosh"));
      }, Qr2 = (e3) => Wt2(e3), Kr2 = (e3, t3) => {
        let n3 = Xt2(e3.inputs[0].dataType);
        e3.compute(Ar2(e3.inputs[0], "Elu", ((e4) => `elu_vf32(${e4})`), `
  const elu_alpha_ = ${n3}(${t3.alpha});

  fn elu_f32(a: ${n3}) -> ${n3} {
  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);
  }

  fn elu_vf32(v: vec4<${n3}>) -> vec4<${n3}> {
  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));
  }`, t3.cacheKey));
      }, Xr2 = (e3 = "f32") => `
const r0: ${e3} = 0.3275911;
const r1: ${e3} = 0.254829592;
const r2: ${e3} = -0.284496736;
const r3: ${e3} = 1.421413741;
const r4: ${e3} = -1.453152027;
const r5: ${e3} = 1.061405429;

fn erf_vf32(v: vec4<${e3}>) -> vec4<${e3}> {
  let absv = abs(v);
  let x = 1.0 / (1.0 + r0 * absv);
  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));
}`, Jr2 = (e3) => {
        let t3 = Xt2(e3.inputs[0].dataType);
        e3.compute(Ar2(e3.inputs[0], "Erf", ((e4) => `erf_vf32(${e4})`), Xr2(t3)));
      }, Yr2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Exp", "exp"));
      }, Zr2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Floor", "floor"));
      }, es2 = (e3) => {
        let t3 = Xt2(e3.inputs[0].dataType);
        e3.compute(Ar2(e3.inputs[0], "Gelu", ((e4) => `0.5 * ${e4} * (1.0 + erf_vf32(${e4} * 0.7071067811865475))`), Xr2(t3)));
      }, ts2 = (e3, t3) => {
        let n3 = Xt2(e3.inputs[0].dataType);
        e3.compute(Ar2(e3.inputs[0], "LeakyRelu", ((e4) => `select(leaky_relu_alpha_ * ${e4}, ${e4}, ${e4} >= vec4<${n3}>(0.0))`), `const leaky_relu_alpha_ = ${n3}(${t3.alpha});`, t3.cacheKey));
      }, ns2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Not", ((e4) => `!${e4}`)));
      }, rs2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Neg", ((e4) => `-${e4}`)));
      }, ss2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Reciprocal", ((e4) => `1.0/${e4}`)));
      }, as2 = (e3) => {
        let t3 = Xt2(e3.inputs[0].dataType);
        e3.compute(Ar2(e3.inputs[0], "Relu", ((e4) => `select(vec4<${t3}>(0.0), ${e4}, ${e4} > vec4<${t3}>(0.0))`)));
      }, os2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Sigmoid", ((e4) => `(1.0 / (1.0 + exp(-${e4})))`)));
      }, is2 = (e3) => Wt2(e3), ls2 = (e3, t3) => {
        let n3 = Xt2(e3.inputs[0].dataType);
        e3.compute(Ar2(e3.inputs[0], "HardSigmoid", ((e4) => `max(vec4<${n3}>(0.0), min(vec4<${n3}>(1.0), ${t3.alpha} * ${e4} + vec4<${n3}>(${t3.beta})))`), void 0, t3.cacheKey));
      }, ds2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Sin", "sin"));
      }, us2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Sinh", "sinh"));
      }, cs2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Sqrt", "sqrt"));
      }, ps2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Tan", "tan"));
      }, ms2 = (e3) => `sign(${e3}) * (1 - exp(-2 * abs(${e3}))) / (1 + exp(-2 * abs(${e3})))`, hs2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Tanh", ms2));
      }, fs2 = (e3 = "f32") => `
const fast_gelu_a: ${e3} = 0.5;
const fast_gelu_b: ${e3} = 0.7978845608028654;
const fast_gelu_c: ${e3} = 0.035677408136300125;

fn tanh_v(v: vec4<${e3}>) -> vec4<${e3}> {
  return ${ms2("v")};
}
`, _s2 = (e3) => `(fast_gelu_a + fast_gelu_a * tanh_v(${e3} * (fast_gelu_c * ${e3} * ${e3} + fast_gelu_b))) * ${e3}`, gs2 = (e3) => {
        let t3 = Xt2(e3.inputs[0].dataType);
        e3.compute(Ar2(e3.inputs[0], "FastGelu", _s2, fs2(t3), void 0, e3.inputs[0].dataType));
      }, ws2 = (e3, t3) => {
        let n3 = Xt2(e3.inputs[0].dataType);
        return e3.compute(Ar2(e3.inputs[0], "ThresholdedRelu", ((e4) => `select(vec4<${n3}>(0.0), ${e4}, ${e4} > thresholded_relu_alpha_)`), `const thresholded_relu_alpha_ = vec4<${n3}>(${t3.alpha});`, t3.cacheKey)), 0;
      }, bs2 = (e3) => {
        e3.compute(Ar2(e3.inputs[0], "Log", "log"));
      }, ys2 = (e3, t3) => `
const alpha = vec4<${e3}>(${t3});
const one = ${e3}(1.0);
const zero = ${e3}(0.0);

fn quick_gelu_impl(x: vec4<${e3}>) -> vec4<${e3}> {
  let v = x *alpha;
  var x1 : vec4<${e3}>;
  for (var i = 0; i < 4; i = i + 1) {
    if (v[i] >= zero) {
      x1[i] = one / (one + exp(-v[i]));
    } else {
      x1[i] = one - one / (one + exp(v[i]));
    }
  }
  return x * x1;
}
`, Ms2 = (e3) => `quick_gelu_impl(${e3})`, xs2 = (e3, t3) => {
        let n3 = Xt2(e3.inputs[0].dataType);
        e3.compute(Ar2(e3.inputs[0], "QuickGelu", Ms2, ys2(n3, t3.alpha), t3.cacheKey, e3.inputs[0].dataType));
      };
    })), Cd2 = j2((() => {
      pd2(), bd2(), $d2(), vs2 = (e3) => {
        if (3 !== e3[0].dims.length) throw new Error("input should have 3 dimensions");
        if (![2560, 5120, 10240].includes(e3[0].dims[2])) throw new Error("hidden state should be 2560, 5120 or 10240");
        if (1 !== e3[1].dims.length) throw new Error("bias is expected to have 1 dimensions");
        if (e3[0].dims[2] !== e3[1].dims[0]) throw new Error("last dimension of input and bias are not the same");
      }, Ts2 = (e3) => {
        let t3 = e3[0].dims.slice();
        t3[2] = t3[2] / 2;
        let n3 = sn2("input", e3[0].dataType, e3[0].dims, 4), r3 = sn2("bias", e3[0].dataType, [e3[0].dims[2]], 4), s3 = an2("output", e3[0].dataType, t3, 4), a3 = gt2.size(t3) / 4, o3 = Kt2(e3[0].dataType);
        return { name: "BiasSplitGelu", getRunData: () => ({ outputs: [{ dims: t3, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(a3 / 64) } }), getShaderSource: (t4) => `
  const M_SQRT2 = sqrt(2.0);
  const halfChannels = ${e3[0].dims[2] / 4 / 2}u;

  ${t4.declareVariables(n3, r3, s3)}

  ${Xr2(o3)}

  ${t4.mainStart()}
    ${t4.guardAgainstOutOfBoundsWorkgroupSizes(a3)}
    let biasIdx = global_idx % halfChannels;
    let batchIndex = global_idx / halfChannels;
    let inputOffset = biasIdx + batchIndex * halfChannels * 2;
    let valueLeft = input[inputOffset] + bias[biasIdx];
    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];
    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);

    ${s3.setByOffset("global_idx", "valueLeft * geluRight")}
  }` };
      }, ks2 = (e3) => {
        vs2(e3.inputs), e3.compute(Ts2(e3.inputs));
      };
    })), Sd2 = j2((() => {
      dd2(), pd2(), bd2(), Ps2 = (e3, t3, n3, r3, s3, a3, o3, i3, l3, d3, u3, c3) => {
        let p3, m3;
        "string" == typeof i3 ? p3 = m3 = (e4, t4) => `${i3}((${e4}),(${t4}))` : "function" == typeof i3 ? p3 = m3 = i3 : (p3 = i3.scalar, m3 = i3.vector);
        let h3, f3 = an2("outputData", u3, r3.length, 4), _3 = sn2("aData", l3, t3.length, 4), g3 = sn2("bData", d3, n3.length, 4);
        if (s3) if (a3) {
          let e4 = 1 === gt2.size(t3), r4 = 1 === gt2.size(n3), s4 = t3.length > 0 && t3[t3.length - 1] % 4 == 0, a4 = n3.length > 0 && n3[n3.length - 1] % 4 == 0;
          h3 = e4 || r4 ? f3.setByOffset("global_idx", m3(e4 ? `${_3.type.value}(${_3.getByOffset("0")}.x)` : _3.getByOffset("global_idx"), r4 ? `${g3.type.value}(${g3.getByOffset("0")}.x)` : g3.getByOffset("global_idx"))) : `
            let outputIndices = ${f3.offsetToIndices("global_idx * 4u")};
            let offsetA = ${_3.broadcastedIndicesToOffset("outputIndices", f3)};
            let offsetB = ${g3.broadcastedIndicesToOffset("outputIndices", f3)};
            ${f3.setByOffset("global_idx", m3(o3 || s4 ? _3.getByOffset("offsetA / 4u") : `${_3.type.value}(${_3.getByOffset("offsetA / 4u")}[offsetA % 4u])`, o3 || a4 ? g3.getByOffset("offsetB / 4u") : `${g3.type.value}(${g3.getByOffset("offsetB / 4u")}[offsetB % 4u])`))}
          `;
        } else h3 = f3.setByOffset("global_idx", m3(_3.getByOffset("global_idx"), g3.getByOffset("global_idx")));
        else {
          if (!a3) throw new Error("no necessary to use scalar implementation for element-wise binary op implementation.");
          let e4 = (e5, t4, n4 = "") => {
            let r4 = `aData[indexA${t4}][componentA${t4}]`, s4 = `bData[indexB${t4}][componentB${t4}]`;
            return `
            let outputIndices${t4} = ${f3.offsetToIndices(`global_idx * 4u + ${t4}u`)};
            let offsetA${t4} = ${_3.broadcastedIndicesToOffset(`outputIndices${t4}`, f3)};
            let offsetB${t4} = ${g3.broadcastedIndicesToOffset(`outputIndices${t4}`, f3)};
            let indexA${t4} = offsetA${t4} / 4u;
            let indexB${t4} = offsetB${t4} / 4u;
            let componentA${t4} = offsetA${t4} % 4u;
            let componentB${t4} = offsetB${t4} % 4u;
            ${e5}[${t4}] = ${n4}(${p3(r4, s4)});
          `;
          };
          h3 = 9 === u3 ? `
            var data = vec4<u32>(0);
            ${e4("data", 0, "u32")}
            ${e4("data", 1, "u32")}
            ${e4("data", 2, "u32")}
            ${e4("data", 3, "u32")}
            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));` : `
            ${e4("outputData[global_idx]", 0)}
            ${e4("outputData[global_idx]", 1)}
            ${e4("outputData[global_idx]", 2)}
            ${e4("outputData[global_idx]", 3)}
          `;
        }
        return `
        ${e3.registerUniform("vec_size", "u32").declareVariables(_3, g3, f3)}

        ${c3 ?? ""}

        ${e3.mainStart()}
        ${e3.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}
        ${h3}
      }`;
      }, $s2 = (e3, t3, n3, r3, s3, a3, o3 = n3.dataType) => {
        let i3 = n3.dims.map(((e4) => Number(e4) ?? 1)), l3 = r3.dims.map(((e4) => Number(e4) ?? 1)), d3 = !gt2.areEqual(i3, l3), u3 = i3, c3 = gt2.size(i3), p3 = false, m3 = false, h3 = [d3];
        if (d3) {
          let e4 = _t2.calcShape(i3, l3, false);
          if (!e4) throw new Error("Can't perform binary op on the given tensors");
          u3 = e4.slice(), c3 = gt2.size(u3);
          let t4 = 1 === gt2.size(i3), n4 = 1 === gt2.size(l3), r4 = i3.length > 0 && i3[i3.length - 1] % 4 == 0, s4 = l3.length > 0 && l3[l3.length - 1] % 4 == 0;
          h3.push(t4), h3.push(n4), h3.push(r4), h3.push(s4);
          let a4 = 1;
          for (let e5 = 1; e5 < u3.length; e5++) {
            let t5 = i3[i3.length - e5];
            if (t5 !== l3[l3.length - e5]) break;
            a4 *= t5;
          }
          a4 % 4 == 0 ? (m3 = true, p3 = true) : (t4 || n4 || r4 || s4) && (p3 = true);
        } else p3 = true;
        return h3.push(p3), { name: e3, shaderCache: { hint: t3 + h3.map(((e4) => e4.toString())).join("_"), inputDependencies: ["rank", "rank"] }, getShaderSource: (e4) => Ps2(e4, i3, l3, u3, p3, d3, m3, s3, n3.dataType, r3.dataType, o3, a3), getRunData: () => ({ outputs: [{ dims: u3, dataType: o3 }], dispatchGroup: { x: Math.ceil(c3 / 64 / 4) }, programUniforms: [{ type: 12, data: Math.ceil(gt2.size(u3) / 4) }, ...Jt2(i3, l3, u3)] }) };
      }, Cs2 = (e3, t3, n3, r3, s3, a3) => {
        e3.compute($s2(t3, s3 ?? "", e3.inputs[0], e3.inputs[1], n3, r3, a3));
      }, Ss2 = (e3) => {
        Cs2(e3, "Add", ((e4, t3) => `${e4}+${t3}`));
      }, Fs2 = (e3) => {
        Cs2(e3, "Div", ((e4, t3) => `${e4}/${t3}`));
      }, Es2 = (e3) => {
        Cs2(e3, "Equal", { scalar: (e4, t3) => `u32(${e4}==${t3})`, vector: (e4, t3) => `vec4<u32>(${e4}==${t3})` }, void 0, void 0, 9);
      }, Is2 = (e3) => {
        Cs2(e3, "Mul", ((e4, t3) => `${e4}*${t3}`));
      }, As2 = (e3) => {
        let t3 = sn2("input", e3.inputs[0].dataType, e3.inputs[0].dims).type.value;
        Cs2(e3, "Pow", { scalar: (e4, t4) => `pow_custom(${e4},${t4})`, vector: (e4, t4) => `pow_vector_custom(${e4},${t4})` }, `
    fn pow_custom(a : ${t3}, b : ${t3}) -> ${t3} {
      if (b == ${t3}(0.0)) {
        return ${t3}(1.0);
      } else if (a < ${t3}(0.0) && f32(b) != floor(f32(b))) {
        return ${t3}(pow(f32(a), f32(b))); // NaN
      }
      return select(sign(a), ${t3}(1.0), round(f32(abs(b) % ${t3}(2.0))) != 1.0) * ${t3}(${"i32" === t3 ? "round" : ""}(pow(f32(abs(a)), f32(b))));
    }
    fn pow_vector_custom(a : vec4<${t3}>, b : vec4<${t3}>) -> vec4<${t3}> {
      // TODO: implement vectorized pow
      return vec4<${t3}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));
    }
      `);
      }, zs2 = (e3) => {
        Cs2(e3, "Sub", ((e4, t3) => `${e4}-${t3}`));
      }, Ls2 = (e3) => {
        Cs2(e3, "Greater", { scalar: (e4, t3) => `u32(${e4}>${t3})`, vector: (e4, t3) => `vec4<u32>(${e4}>${t3})` }, void 0, void 0, 9);
      }, Os2 = (e3) => {
        Cs2(e3, "Less", { scalar: (e4, t3) => `u32(${e4}<${t3})`, vector: (e4, t3) => `vec4<u32>(${e4}<${t3})` }, void 0, void 0, 9);
      }, Ds2 = (e3) => {
        Cs2(e3, "GreaterOrEqual", { scalar: (e4, t3) => `u32(${e4}>=${t3})`, vector: (e4, t3) => `vec4<u32>(${e4}>=${t3})` }, void 0, void 0, 9);
      }, Bs2 = (e3) => {
        Cs2(e3, "LessOrEqual", { scalar: (e4, t3) => `u32(${e4}<=${t3})`, vector: (e4, t3) => `vec4<u32>(${e4}<=${t3})` }, void 0, void 0, 9);
      };
    })), Fd2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), Ns2 = (e3, t3) => {
        if (!e3 || e3.length < 1) throw new Error("too few inputs");
        let n3 = e3[0], r3 = n3.dataType, s3 = n3.dims.length;
        e3.forEach(((e4, a3) => {
          if (0 !== a3) {
            if (e4.dataType !== r3) throw new Error("input tensors should be one type");
            if (e4.dims.length !== s3) throw new Error("input tensors should have the same shape");
            e4.dims.forEach(((e5, r4) => {
              if (r4 !== t3 && e5 !== n3.dims[r4]) throw new Error("non concat dimensions must match");
            }));
          }
        }));
      }, js2 = (e3, t3) => `
  fn calculateInputIndex(index: u32) -> u32 {
    let sizeInConcatAxis = array<u32, ${e3}u>(${t3});
    for (var i: u32 = 0u; i < ${e3}; i += 1u ) {
      if (index < sizeInConcatAxis[i]) {
        return i;
      }
    }
    return ${e3}u;
  }`, Rs2 = (e3, t3) => {
        let n3 = e3.length, r3 = [];
        for (let s3 = 0; s3 < n3; ++s3) {
          let a3 = t3.setByOffset("global_idx", e3[s3].getByIndices("indices"));
          1 === n3 ? r3.push(a3) : 0 === s3 ? r3.push(`if (inputIndex == ${s3}u) { ${a3} }`) : s3 === n3 - 1 ? r3.push(`else { ${a3} }`) : r3.push(`else if (inputIndex == ${s3}) { ${a3} }`);
        }
        return r3.join("\n");
      }, Vs2 = (e3, t3, n3, r3) => {
        let s3 = gt2.size(n3), a3 = new Array(e3.length), o3 = new Array(e3.length), i3 = 0, l3 = [], d3 = [], u3 = [{ type: 12, data: s3 }];
        for (let n4 = 0; n4 < e3.length; ++n4) i3 += e3[n4].dims[t3], a3[n4] = i3, d3.push(e3[n4].dims.length), o3[n4] = sn2(`input${n4}`, r3, d3[n4]), l3.push("rank"), u3.push({ type: 12, data: a3[n4] });
        for (let t4 = 0; t4 < e3.length; ++t4) u3.push(...Jt2(e3[t4].dims));
        u3.push(...Jt2(n3));
        let c3 = an2("output", r3, n3.length), p3 = c3.indicesGet("indices", t3), m3 = Array.from(Array(a3.length).keys()).map(((e4) => `uniforms.sizeInConcatAxis${e4}`)).join(",");
        return { name: "Concat", shaderCache: { hint: `${t3}`, inputDependencies: l3 }, getRunData: () => ({ outputs: [{ dims: n3, dataType: r3 }], dispatchGroup: { x: Math.ceil(s3 / 64) }, programUniforms: u3 }), getShaderSource: (t4) => `

  ${(() => {
          t4.registerUniform("outputSize", "u32");
          for (let n4 = 0; n4 < e3.length; n4++) t4.registerUniform(`sizeInConcatAxis${n4}`, "u32");
          return t4.declareVariables(...o3, c3);
        })()}

  ${js2(a3.length, m3)}

  ${t4.mainStart()}
    ${t4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}

    var indices = ${c3.offsetToIndices("global_idx")};

    let inputIndex = calculateInputIndex(${p3});
    if (inputIndex != 0u) {
      let sizeInConcatAxis = array<u32, ${a3.length}u>(${m3});
      ${p3} -= sizeInConcatAxis[inputIndex - 1u];
    }

    ${Rs2(o3, c3)}
  }` };
      }, Gs2 = (e3, t3) => {
        let n3 = e3.inputs, r3 = n3[0].dims, s3 = gt2.normalizeAxis(t3.axis, r3.length);
        Ns2(n3, s3);
        let a3 = r3.slice();
        a3[s3] = n3.reduce(((e4, t4) => e4 + (t4.dims.length > s3 ? t4.dims[s3] : 0)), 0);
        let o3 = n3.filter(((e4) => gt2.size(e4.dims) > 0));
        e3.compute(Vs2(o3, s3, a3, n3[0].dataType), { inputs: o3 });
      }, qs2 = (e3) => Wt2({ axis: e3.axis });
    })), Ed2 = j2((() => {
      dd2(), pd2(), Us2 = (e3, t3, n3 = "f32") => {
        switch (e3.activation) {
          case "Relu":
            return `value = max(value, ${t3}(0.0));`;
          case "Sigmoid":
            return `value = (${t3}(1.0) / (${t3}(1.0) + exp(-value)));`;
          case "Clip":
            return `value = clamp(value, ${t3}(${n3}(uniforms.clip_min)), ${t3}(${n3}(uniforms.clip_max)));`;
          case "HardSigmoid":
            return `value = max(${t3}(0.0), min(${t3}(1.0), ${n3}(uniforms.alpha) * value + ${n3}(uniforms.beta)));`;
          case "LeakyRelu":
            return `value = select(${n3}(uniforms.alpha) * value, value, value >= ${t3}(0.0));`;
          case "Tanh":
            return "let e2x = exp(-2.0 * abs(value));\n              value = sign(value) * (1.0 - e2x) / (1.0 + e2x);\n        ";
          case "":
            return "";
          default:
            throw new Error(`Unsupported activation ${e3.activation}`);
        }
      }, Ws2 = (e3, t3) => {
        "Clip" === e3.activation ? t3.push({ type: 1, data: e3.clipMax }, { type: 1, data: e3.clipMin }) : "HardSigmoid" === e3.activation ? t3.push({ type: 1, data: e3.alpha }, { type: 1, data: e3.beta }) : "LeakyRelu" === e3.activation && t3.push({ type: 1, data: e3.alpha });
      }, Hs2 = (e3, t3) => {
        "Clip" === e3.activation ? t3.push({ name: "clip_max", type: "f32" }, { name: "clip_min", type: "f32" }) : "HardSigmoid" === e3.activation ? t3.push({ name: "alpha", type: "f32" }, { name: "beta", type: "f32" }) : "LeakyRelu" === e3.activation && t3.push({ name: "alpha", type: "f32" });
      }, Qs2 = (e3) => {
        let t3 = e3?.activation || "";
        if ("HardSigmoid" === t3) {
          let [n3, r3] = e3?.activation_params || [0.2, 0.5];
          return { activation: t3, alpha: n3, beta: r3 };
        }
        if ("Clip" === t3) {
          let [n3, r3] = e3?.activation_params || [yt2, Mt2];
          return { activation: t3, clipMax: r3, clipMin: n3 };
        }
        if ("LeakyRelu" === t3) {
          let [n3] = e3?.activation_params || [0.01];
          return { activation: t3, alpha: n3 };
        }
        return { activation: t3 };
      };
    })), Id2 = j2((() => {
      Ks2 = (e3, t3) => {
        switch (e3) {
          case 1:
            return t3;
          case 2:
            return `vec2<${t3}>`;
          case 3:
            return `vec3<${t3}>`;
          case 4:
            return `vec4<${t3}>`;
          default:
            throw new Error(`${e3}-component is not supported.`);
        }
      }, Xs2 = (e3) => `
      ${e3 ? "value = value + getBiasByOutputCoords(coords);" : ""}
      `;
    })), Ad2 = j2((() => {
      Js2 = (e3) => `
fn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {
  return dot(coords, vec4<i32>(
      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));
}
fn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {
  return dot(coords, vec4<i32>(
    i32(${e3}.x), i32(${e3}.y), i32(${e3}.z), 1));
}
`;
    })), zd2 = j2((() => {
      dd2(), pd2(), bd2(), Ed2(), Ys2 = (e3, t3, n3, r3, s3) => {
        let a3 = r3 - n3;
        return `
      ${Array.from({ length: n3 }).map(((n4, o3) => `
      if (${nn2(t3.shape, o3, t3.rank)} != 1) {
        ${t3.indicesSet(e3, o3, nn2(s3, o3 + a3, r3))}
      } else {
        ${t3.indicesSet(e3, o3, 0)}
      }`)).join("")}
`;
      }, Zs2 = (e3, t3, n3, r3, s3 = false, a3) => {
        let o3 = e3[0].dims, i3 = e3[1].dims, l3 = o3[o3.length - 2], d3 = i3[i3.length - 1], u3 = o3[o3.length - 1], c3 = Yt2(d3), p3 = Yt2(u3), m3 = Yt2(l3), h3 = gt2.size(n3) / c3 / m3, f3 = e3.length > 2, _3 = r3 ? r3.slice(0, -2) : n3.slice(0, -2), g3 = [gt2.size(_3), l3, d3], w3 = [{ type: 12, data: h3 }, { type: 12, data: l3 }, { type: 12, data: d3 }, { type: 12, data: u3 }];
        Ws2(t3, w3), w3.push(...Jt2(_3, o3, i3)), f3 && w3.push(...Jt2(e3[2].dims)), w3.push(...Jt2(g3));
        return { name: "MatMulNaive", shaderCache: { hint: `${t3.activation};${c3};${p3};${m3};${s3}`, inputDependencies: f3 ? ["rank", "rank", "rank"] : ["rank", "rank"] }, getRunData: () => ({ outputs: [{ dims: a3 ? a3(n3) : n3, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(h3 / 64) }, programUniforms: w3 }), getShaderSource: (r4) => {
          let a4 = ln2("batch_dims", e3[0].dataType, _3.length), l4 = sn2("a", e3[0].dataType, o3.length, p3), d4 = sn2("b", e3[1].dataType, i3.length, c3), u4 = an2("output", e3[0].dataType, g3.length, c3), h4 = Kt2(u4.type.tensor), w4 = Us2(t3, u4.type.value, h4), b3 = [l4, d4], y3 = "";
          if (f3) {
            let t4 = s3 ? c3 : 1;
            b3.push(sn2("bias", e3[2].dataType, e3[2].dims.length, t4)), y3 = s3 ? `value += bias[col / ${t4}];` : `value += ${u4.type.value}(bias[row + i]);`;
          }
          let M3 = [{ name: "output_size", type: "u32" }, { name: "M", type: "u32" }, { name: "N", type: "u32" }, { name: "K", type: "u32" }];
          Hs2(t3, M3);
          return `
  ${r4.registerUniforms(M3).registerInternalVariables(a4).declareVariables(...b3, u4)}
  ${r4.mainStart()}
    ${r4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
    let col = (global_idx % (uniforms.N / ${c3})) * ${c3};
    var index1 = global_idx / (uniforms.N / ${c3});
    let stride1 = uniforms.M / ${m3};
    let row = (index1 % stride1) * ${m3};
    let batch = index1 / stride1;

    ${2 === n3.length ? "" : `let batch_indices = ${a4.offsetToIndices("batch")};`}

    var a_indices: ${l4.type.indices};
    ${Ys2("a_indices", l4, l4.rank - 2, a4.rank, "batch_indices")}
    ${l4.indicesSet("a_indices", l4.rank - 2, 0)}
    ${l4.indicesSet("a_indices", l4.rank - 1, 0)}
    let a_offset = ${l4.indicesToOffset("a_indices")};

    var b_indices: ${d4.type.indices};
    ${Ys2("b_indices", d4, d4.rank - 2, a4.rank, "batch_indices")}
    ${d4.indicesSet("b_indices", d4.rank - 2, 0)}
    ${d4.indicesSet("b_indices", d4.rank - 1, 0)}
    let b_offset = ${d4.indicesToOffset("b_indices")};
    var values: array<${u4.type.value}, ${m3}>;
    for (var k: u32 = 0u; k < uniforms.K; k = k + ${p3}) {
      ${(() => {
            let e4 = `var a_data: ${l4.type.value};`;
            for (let t4 = 0; t4 < p3; t4++) e4 += `
              let b_data${t4} = b[(b_offset + (k + ${t4}) * uniforms.N + col) / ${c3}];`;
            for (let t4 = 0; t4 < m3; t4++) {
              e4 += `a_data = a[(a_offset + (row + ${t4}) * uniforms.K + k) / ${p3}];`;
              for (let n4 = 0; n4 < p3; n4++) e4 += `
            values[${t4}] = fma(${d4.type.value}(a_data${1 === p3 ? "" : `[${n4}]`}), b_data${n4}, values[${t4}]);
`;
            }
            return e4;
          })()}
    }
    for (var i = 0u; i < ${m3}u; i++) {
      var value = values[i];
      ${y3}
      ${w4}
      let cur_indices = ${u4.type.indices}(batch, row + i, col);
      let offset = ${u4.indicesToOffset("cur_indices")};
      ${u4.setByOffset(`offset / ${c3}`, "value")};
    }
  }
  `;
        } };
      };
    })), Ld2 = j2((() => {
      dd2(), pd2(), bd2(), Ed2(), zd2(), Id2(), ea2 = (e3, t3) => e3 ? `
        mm_Asub[inputRow][inputCol] = mm_readA(batch,
          kStart + inputRow,
          globalRowStart / innerElementSize + inputCol${t3 ? ", batchIndices" : ""});
        ` : `
        mm_Asub[inputRow][inputCol] = mm_readA(batch,
          globalRow + innerRow,
          kStart / innerElementSize + inputCol${t3 ? ", batchIndices" : ""});
        `, ta2 = (e3, t3) => e3 ? `
        let ACached0 = mm_Asub[k * innerElementSize][localRow];
        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];
        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];
        ${3 === t3 ? "" : "let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];"}
        for (var i = 0; i < rowPerThread; i = i + 1) {
          acc[i] = BCached0 * ACached0[i] + acc[i];
          acc[i] = BCached1 * ACached1[i] + acc[i];
          acc[i] = BCached2 * ACached2[i] + acc[i];
          ${3 === t3 ? "" : "acc[i] = BCached3 * ACached3[i] + acc[i];"}
        }` : `
        for (var i = 0; i < rowPerThread; i = i + 1) {
          let ACached = mm_Asub[tileRow + i][k];
          acc[i] = BCached0 * ACached.x + acc[i];
          acc[i] = BCached1 * ACached.y + acc[i];
          acc[i] = BCached2 * ACached.z + acc[i];
          ${3 === t3 ? "" : "acc[i] = BCached3 * ACached.w + acc[i];"}
        }`, na2 = (e3, t3, n3 = "f32", r3, s3 = false, a3 = 32, o3 = false, i3 = 32) => {
        let l3 = t3[1] * e3[1], d3 = t3[0] * e3[0], u3 = s3 ? l3 : a3, c3 = s3 ? a3 : l3, p3 = u3 / t3[0], m3 = a3 / t3[1];
        if ((!s3 || 4 !== p3 || 4 !== e3[1]) && (s3 || 3 !== p3 && 4 !== p3) || u3 % t3[0] != 0 || a3 % t3[1] != 0 || 4 !== e3[0]) throw new Error(`If transposeA ${s3} is true, innerElementSize ${p3} and workPerThread[1] ${e3[1]} must be 4.
      Otherwise, innerElementSize ${p3} must be 3 or 4.
  tileAWidth ${u3} must be divisible by workgroupSize[0]${t3[0]}. tileInner ${a3} must be divisible by workgroupSize[1] ${t3[1]}. colPerThread ${e3[0]} must be 4.`);
        return `
var<workgroup> mm_Asub: array<array<vec${p3}<${n3}>, ${u3 / p3}>, ${c3}>;
var<workgroup> mm_Bsub: array<array<vec4<${n3}>, ${d3 / e3[0]}>, ${a3}>;

const rowPerThread = ${e3[1]};
const colPerThread = ${e3[0]};
const innerElementSize = ${p3};
const tileInner = ${a3};

@compute @workgroup_size(${t3[0]}, ${t3[1]}, ${t3[2]})
fn main(@builtin(local_invocation_id) localId : vec3<u32>,
        @builtin(global_invocation_id) globalId : vec3<u32>,
        @builtin(workgroup_id) workgroupId : vec3<u32>) {
  let localRow = i32(localId.y);
  let tileRow = localRow * rowPerThread;
  let tileCol = i32(localId.x);

  let globalRow =i32(globalId.y) * rowPerThread;
  let globalCol = i32(globalId.x);
  let batch = ${o3 ? "0" : "i32(globalId.z)"};
  ${r3 ? `let batchIndices = ${r3.offsetToIndices("u32(batch)")};` : ""}
  let globalRowStart = i32(workgroupId.y) * ${l3};

  let num_tiles = ${o3 ? `${Math.ceil(i3 / a3)}` : "(uniforms.dim_inner - 1) / tileInner + 1"};
  var kStart = ${o3 ? `i32(globalId.z) * ${i3}` : "0"};

  var acc: array<vec4<${n3}>, rowPerThread>;

  // Loop over shared dimension.
  let tileRowB = localRow * ${m3};
  for (var t = 0; t < num_tiles; t = t + 1) {
      // Load one tile of A into local memory.
      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {
          let inputRow = tileRow + innerRow;
          let inputCol = tileCol;
          ${ea2(s3, r3)}
      }

      // Load one tile of B into local memory.
      for (var innerRow = 0; innerRow < ${m3}; innerRow = innerRow + 1) {
          let inputRow = tileRowB + innerRow;
          let inputCol = tileCol;
          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${r3 ? ", batchIndices" : ""});
      }
      kStart = kStart + tileInner;
      workgroupBarrier();

      // Compute acc values for a single thread.
      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {
          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];
          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];
          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];
          ${3 === p3 ? "" : "let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];"}

          ${ta2(s3, p3)}
      }

      workgroupBarrier();
  }

  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {
      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);
  }
}`;
      }, ra2 = (e3, t3) => e3 ? `
            mm_Asub[inputRow][inputCol] = mm_readA(batch,
              kStart + inputRow,
              globalRowStart + inputCol${t3 ? ", batchIndices" : ""});
            ` : `
            mm_Asub[inputRow][inputCol] = mm_readA(batch,
              globalRowStart + inputRow,
              kStart + inputCol${t3 ? ", batchIndices" : ""});
            `, sa2 = (e3) => e3 ? "let ACached = mm_Asub[k][tileRow + innerRow];" : "let ACached = mm_Asub[tileRow + innerRow][k];", aa2 = (e3, t3, n3 = "f32", r3, s3 = false, a3 = 32, o3 = false, i3 = 32, l3 = false) => {
        let d3 = e3[1] * t3[1], u3 = e3[0] * t3[0], c3 = s3 ? d3 : a3, p3 = s3 ? a3 : d3;
        if (p3 % t3[1] != 0 || c3 % t3[0] != 0 || a3 % t3[1] != 0) throw new Error(`tileAHight ${p3} must be divisible by workgroupSize[1]${t3[1]}, tileAWidth ${c3} must be divisible by workgroupSize[0]${t3[0]}, tileInner ${a3} must be divisible by workgroupSize[1]${t3[1]}`);
        let m3 = p3 / t3[1], h3 = c3 / t3[0], f3 = a3 / t3[1], _3 = l3 ? `
    let localRow = i32(localId.y);
    let localCol = i32(localId.x);
    let globalRowStart = i32(workgroupId.y) * ${d3};
    let globalColStart = i32(workgroupId.x) * ${u3};

    // Loop over shared dimension.
    for (var t = 0; t < num_tiles; t = t + 1) {
      // Load one tile of A into local memory.
      for (var inputRow = localRow; inputRow < ${p3}; inputRow = inputRow + ${t3[1]}) {
        for (var inputCol = localCol; inputCol < ${c3}; inputCol = inputCol + ${t3[0]}) {
          ${ra2(s3, r3)}
        }
      }
      // Load one tile of B into local memory.
      for (var inputRow = localRow; inputRow < ${a3}; inputRow = inputRow + ${t3[1]}) {
            for (var inputCol = localCol; inputCol < ${u3}; inputCol = inputCol + ${t3[0]}) {
          mm_Bsub[inputRow][inputCol] = mm_readB(batch,
            kStart + inputRow,
            globalColStart + inputCol${r3 ? ", batchIndices" : ""});
        }
      }
      kStart = kStart + tileInner;
      workgroupBarrier();

      // Compute acc values for a single thread.
      var BCached : array<${n3}, colPerThread>;
      for (var k = 0; k < tileInner; k = k + 1) {
        for (var inner = 0; inner < colPerThread; inner = inner + 1) {
          BCached[inner] = mm_Bsub[k][localCol + inner * ${t3[0]}];
        }
        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {
          let ACached = ${s3 ? `mm_Asub[k][localRow + innerRow * ${t3[1]}];` : `mm_Asub[localRow + innerRow * ${t3[1]}][k];`}
          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {
            acc[innerRow][innerCol] = acc[innerRow][innerCol] +
                ACached * BCached[innerCol];
          }
        }
      }
      workgroupBarrier();
    }
    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {
      let gRow = globalRowStart + localRow + innerRow * ${t3[1]};
      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {
        let gCol = globalColStart + localCol + innerCol * ${t3[0]};
        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);
      }
    }
    ` : `
let tileRow = i32(localId.y) * rowPerThread;
let tileCol = i32(localId.x) * colPerThread;

let globalRow = i32(globalId.y) * rowPerThread;
let globalCol = i32(globalId.x) * colPerThread;
let globalRowStart = i32(workgroupId.y) * ${d3};

let tileRowA = i32(localId.y) * ${m3};
let tileColA = i32(localId.x) * ${h3};
let tileRowB = i32(localId.y) * ${f3};
// Loop over shared dimension.
for (var t = 0; t < num_tiles; t = t + 1) {
  // Load one tile of A into local memory.
  for (var innerRow = 0; innerRow < ${m3}; innerRow = innerRow + 1) {
    for (var innerCol = 0; innerCol < ${h3}; innerCol = innerCol + 1) {
      let inputRow = tileRowA + innerRow;
      let inputCol = tileColA + innerCol;
      ${ra2(s3, r3)}
    }
  }

  // Load one tile of B into local memory.
  for (var innerRow = 0; innerRow < ${f3}; innerRow = innerRow + 1) {
    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {
      let inputRow = tileRowB + innerRow;
      let inputCol = tileCol + innerCol;
      mm_Bsub[inputRow][inputCol] = mm_readB(batch,
        kStart + inputRow,
        globalCol + innerCol${r3 ? ", batchIndices" : ""});
    }
  }
  kStart = kStart + tileInner;
  workgroupBarrier();

  // Compute acc values for a single thread.
  var BCached : array<${n3}, colPerThread>;
  for (var k = 0; k < tileInner; k = k + 1) {
    for (var inner = 0; inner < colPerThread; inner = inner + 1) {
      BCached[inner] = mm_Bsub[k][tileCol + inner];
    }

    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {
      ${sa2(s3)}
      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {
        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];
      }
    }
  }

  workgroupBarrier();
}

for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {
  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {
    mm_write(batch, globalRow + innerRow, globalCol + innerCol,
        acc[innerRow][innerCol]);
  }
}
`;
        return `
  var<workgroup> mm_Asub : array<array<${n3}, ${c3}>, ${p3}>;
  var<workgroup> mm_Bsub : array<array<${n3}, ${u3}>, ${a3}>;
  const rowPerThread = ${e3[1]};
  const colPerThread = ${e3[0]};
  const tileInner = ${a3};

@compute @workgroup_size(${t3[0]}, ${t3[1]}, ${t3[2]})
fn main(@builtin(local_invocation_id) localId : vec3<u32>,
        @builtin(global_invocation_id) globalId : vec3<u32>,
        @builtin(workgroup_id) workgroupId : vec3<u32>) {
    let batch = ${o3 ? "0" : "i32(globalId.z)"};
    ${r3 ? `let batchIndices = ${r3.offsetToIndices("u32(batch)")};` : ""}
    let num_tiles = ${o3 ? `${Math.ceil(i3 / a3)}` : "(uniforms.dim_inner - 1) / tileInner + 1"};
    var kStart = ${o3 ? `i32(globalId.z) * ${i3}` : "0"};

    var acc : array<array<${n3}, colPerThread>, rowPerThread>;
    ${_3}
  }
`;
      }, oa2 = (e3, t3, n3, r3, s3 = false) => {
        let [a3, o3, i3, l3] = r3, d3 = Kt2(r3[0].type.tensor);
        return `
    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${a3.type.indices}) -> ${Ks2(e3, d3)} {
      var value = ${Ks2(e3, d3)}(0.0);
      let col = colIn * ${e3};
      if(row < uniforms.dim_a_outer && col < uniforms.dim_inner)
      {
        var aIndices: ${o3.type.indices};
        ${Ys2("aIndices", o3, o3.rank - 2, a3.rank, "batchIndices")}
        ${o3.indicesSet("aIndices", o3.rank - 2, "u32(row)")}
        ${o3.indicesSet("aIndices", o3.rank - 1, "u32(colIn)")}
        value = ${o3.getByIndices("aIndices")};
      }
      return value;
    }

    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${a3.type.indices}) -> ${Ks2(e3, d3)} {
      var value = ${Ks2(e3, d3)}(0.0);
      let col = colIn * ${e3};
      if(row < uniforms.dim_inner && col < uniforms.dim_b_outer)
      {
        var bIndices: ${i3.type.indices};
        ${Ys2("bIndices", i3, i3.rank - 2, a3.rank, "batchIndices")}
        ${i3.indicesSet("bIndices", i3.rank - 2, "u32(row)")}
        ${i3.indicesSet("bIndices", i3.rank - 1, "u32(colIn)")}
        value = ${i3.getByIndices("bIndices")};
      }
      return value;
    }

    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${Ks2(e3, d3)}) {
      let col = colIn * ${e3};
      if (row < uniforms.dim_a_outer && col < uniforms.dim_b_outer) {
        var value = valueIn;
        let coords = vec3<i32>(batch, row, colIn);
        ${t3 ? `value = value + ${s3 ? "bias[colIn]" : `${Ks2(e3, d3)}(bias[row])`};` : ""}
        ${n3}
        ${l3.setByIndices("vec3<u32>(coords)", "value")}
      }
    }
    `;
      }, ia2 = (e3, t3, n3, r3, s3 = false, a3) => {
        let o3 = e3[0].dims, i3 = e3[1].dims, l3 = o3.slice(0, -2), d3 = i3.slice(0, -2), u3 = r3 ? r3.slice(0, -2) : n3.slice(0, -2), c3 = gt2.size(u3), p3 = o3[o3.length - 2], m3 = o3[o3.length - 1], h3 = i3[i3.length - 1], f3 = m3 % 4 == 0 && h3 % 4 == 0, _3 = p3 <= 8 ? [4, 1, 1] : [4, 4, 1], g3 = [8, 8, 1], w3 = [Math.ceil(h3 / g3[0] / _3[0]), Math.ceil(p3 / g3[1] / _3[1]), Math.ceil(c3 / g3[2] / _3[2])], b3 = f3 ? 4 : 1, y3 = [...l3, p3, m3 / b3], M3 = y3.length, x3 = [...d3, m3, h3 / b3], v3 = x3.length, T3 = [c3, p3, h3 / b3], k3 = [{ type: 6, data: p3 }, { type: 6, data: h3 }, { type: 6, data: m3 }];
        Ws2(t3, k3), k3.push(...Jt2(u3, y3, x3));
        let P3 = ["rank", "rank"], $3 = e3.length > 2;
        $3 && (k3.push(...Jt2(e3[2].dims)), P3.push("rank")), k3.push(...Jt2(T3));
        return { name: "MatMul", shaderCache: { hint: `${_3};${t3.activation};${f3};${s3}`, inputDependencies: P3 }, getRunData: () => ({ outputs: [{ dims: a3 ? a3(n3) : n3, dataType: e3[0].dataType }], dispatchGroup: { x: w3[0], y: w3[1], z: w3[2] }, programUniforms: k3 }), getShaderSource: (n4) => {
          let r4 = u3.length, a4 = ln2("batchDims", e3[0].dataType, r4, 1), o4 = Kt2(e3[0].dataType), i4 = sn2("a", e3[0].dataType, M3, b3), l4 = sn2("b", e3[1].dataType, v3, b3), d4 = an2("result", e3[0].dataType, T3.length, b3), c4 = [i4, l4];
          if ($3) {
            let t4 = s3 ? b3 : 1;
            c4.push(sn2("bias", e3[2].dataType, e3[2].dims.length, t4));
          }
          let p4 = [{ name: "dim_a_outer", type: "i32" }, { name: "dim_b_outer", type: "i32" }, { name: "dim_inner", type: "i32" }];
          Hs2(t3, p4);
          let m4 = Kt2(d4.type.tensor), h4 = Us2(t3, d4.type.value, m4), w4 = oa2(b3, $3, h4, [a4, i4, l4, d4], s3);
          return `
  ${n4.registerUniforms(p4).registerInternalVariables(a4).declareVariables(...c4, d4)}
  ${w4}
  ${f3 ? na2(_3, g3, o4, a4) : aa2(_3, g3, o4, a4)}
                   `;
        } };
      };
    })), Od2 = j2((() => {
      dd2(), cd2(), bd2(), Ed2(), Id2(), Ad2(), Ld2(), la2 = (e3, t3, n3, r3, s3 = false, a3, o3 = 4, i3 = 4, l3 = 4, d3 = "f32") => {
        let u3 = (e4) => {
          switch (e4) {
            case 1:
              return "return w[row * i32(uniforms.w_shape[3]) + colIn];";
            case 4:
              return "return w[row * i32(uniforms.w_shape[3]) / 4 + colIn];";
            default:
              throw new Error(`innerElementSize ${e4} is not supported.`);
          }
        }, c3 = e3 ? "\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    " : "\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    ", p3 = e3 ? "\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    " : "\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    ", m3 = e3 ? "i32(uniforms.x_shape[1])" : "i32(uniforms.x_shape[2])", h3 = e3 ? "i32(uniforms.x_shape[2])" : "i32(uniforms.x_shape[3])", f3 = e3 ? "row" : "col", _3 = e3 ? "col" : "row", g3 = `
    let inChannels = i32(uniforms.w_shape[2]);
    let outWidth = ${e3 ? "i32(uniforms.result_shape[2])" : "i32(uniforms.result_shape[3])"};
    let outRow = ${f3} / outWidth;
    let outCol = ${f3} % outWidth;

    let WRow = ${_3} / (i32(uniforms.w_shape[1]) * inChannels);
    let WCol = ${_3} / inChannels % i32(uniforms.w_shape[1]);
    let xRow = outRow * uniforms.stride[0] + uniforms.dilation[0] * WRow - uniforms.pad[0];
    let xCol = outCol * uniforms.stride[1] + uniforms.dilation[1] * WCol - uniforms.pad[1];
    let xCh = ${_3} % inChannels;
    var resData = ${Ks2(o3, d3)}(0.0);
    // The bounds checking is always needed since we use it to pad zero for
    // the 'same' padding type.
    if (xRow >= 0 && xRow < ${m3} && xCol >= 0 && xCol < ${h3}) {
      ${c3}
      let xIndex = getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape));
      ${((e4) => {
          switch (e4) {
            case 1:
              return "resData = x[xIndex];";
            case 3:
              return `resData = vec3<${d3}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;
            case 4:
              return "resData = x[xIndex / 4];";
            default:
              throw new Error(`innerElementSize ${e4} is not supported.`);
          }
        })(o3)}
    }
    return resData;`, w3 = e3 ? t3 && r3 ? `
    let col = colIn * ${o3};
    ${g3}` : `
    let col = colIn * ${o3};
    if (row < uniforms.dim_a_outer && col < uniforms.dim_inner) {
      ${g3}
    }
    return ${Ks2(o3, d3)}(0.0);` : r3 && n3 ? `
    let col = colIn * ${o3};
    ${g3}` : `
    let col = colIn * ${o3};
    if (row < uniforms.dim_inner && col < uniforms.dim_b_outer) {
      ${g3}
    }
    return ${Ks2(o3, d3)}(0.0);`, b3 = e3 ? r3 && n3 ? u3(i3) : `
    let col = colIn * ${i3};
    if (row < uniforms.dim_inner && col < uniforms.dim_b_outer) {
      ${u3(i3)}
    }
    return ${Ks2(i3, d3)}(0.0);` : `
    let col = colIn * ${i3};
    if (row < uniforms.dim_inner && col < uniforms.dim_a_outer) {
      ${u3(i3)}
    }
    return ${Ks2(i3, d3)}(0.0);`, y3 = Ks2(l3, d3), M3 = Ks2(e3 ? o3 : i3, d3), x3 = Ks2(e3 ? i3 : o3, d3), v3 = Us2(a3, y3, d3);
        return `
    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${M3} {
      ${e3 ? w3 : b3}
    }

    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${x3} {
      ${e3 ? b3 : w3}
    }

    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${y3}) {
      let col = colIn * ${l3};
      if (row < uniforms.dim_a_outer && col < uniforms.dim_b_outer)
      {
      var value = valueIn;
      let outWidth = ${e3 ? "i32(uniforms.result_shape[2])" : "i32(uniforms.result_shape[3])"};
      ${p3}
      ${Xs2(s3)}
      ${v3}
      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);
      }
    }`;
      }, da2 = (e3, t3, n3, r3, s3, a3, o3, i3, l3) => {
        let d3 = "NHWC" === t3.format, u3 = d3 ? e3[0].dims[3] : e3[0].dims[1], c3 = n3[0], p3 = d3 ? n3[2] : n3[3], m3 = d3 ? n3[1] : n3[2], h3 = d3 ? n3[3] : n3[1], f3 = d3 && (u3 % 4 == 0 || u3 % 3 == 0) && h3 % 4 == 0, _3 = d3 ? h3 : p3 * m3, g3 = d3 ? p3 * m3 : h3, w3 = [8, 8, 1], b3 = r3 <= 8 ? [4, 1, 1] : [4, 4, 1], y3 = [Math.ceil(_3 / w3[0] / b3[0]), Math.ceil(g3 / w3[1] / b3[1]), Math.ceil(c3 / w3[2] / b3[2])];
        ht2("verbose", (() => `[conv2d_mm_webgpu] dispatch = ${y3}`));
        let M3 = f3 ? d3 && u3 % 4 != 0 ? 3 : 4 : 1, x3 = w3[1] * b3[1], v3 = w3[0] * b3[0], T3 = Math.max(w3[0] * M3, w3[1]), k3 = r3 % x3 == 0, P3 = s3 % v3 == 0, $3 = a3 % T3 == 0, C3 = f3 ? [M3, 4, 4] : [1, 1, 1], S3 = [{ type: 6, data: r3 }, { type: 6, data: s3 }, { type: 6, data: a3 }, { type: 6, data: [t3.pads[0], t3.pads[1]] }, { type: 6, data: t3.strides }, { type: 6, data: t3.dilations }];
        Ws2(t3, S3), S3.push(...Jt2(e3[0].dims, e3[1].dims));
        let F3 = ["rank", "rank"];
        o3 && (S3.push(...Jt2(e3[2].dims)), F3.push("rank")), S3.push(...Jt2(n3));
        return { name: "Conv2DMatMul", shaderCache: { hint: `${t3.cacheKey};${M3};${f3};${k3};${P3};${$3};${x3};${v3};${T3}`, inputDependencies: F3 }, getRunData: () => ({ outputs: [{ dims: l3 ? l3(n3) : n3, dataType: e3[0].dataType }], dispatchGroup: { x: y3[0], y: y3[1], z: y3[2] }, programUniforms: S3 }), getShaderSource: (r4) => {
          let s4 = [{ name: "dim_a_outer", type: "i32" }, { name: "dim_b_outer", type: "i32" }, { name: "dim_inner", type: "i32" }, { name: "pad", type: "i32", length: 2 }, { name: "stride", type: "i32", length: 2 }, { name: "dilation", type: "i32", length: 2 }];
          Hs2(t3, s4);
          let a4 = f3 ? 4 : 1, l4 = Kt2(e3[0].dataType), u4 = `
      fn setOutputAtIndex(flatIndex : i32, value : ${f3 ? `vec4<${l4}>` : l4}) {
        result[flatIndex] = ${f3 ? `vec4<${l4}>` : l4}(value);
      }
      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${f3 ? `vec4<${l4}>` : l4}) {
        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));
        setOutputAtIndex(flatIndex ${f3 ? "/ 4" : ""}, value);
      }`, c4 = [sn2("x", e3[0].dataType, e3[0].dims.length, 3 === M3 ? 1 : M3), sn2("w", e3[1].dataType, e3[1].dims.length, a4)], p4 = an2("result", e3[0].dataType, n3.length, a4);
          if (o3) {
            let t4 = sn2("bias", e3[2].dataType, e3[2].dims.length, a4);
            c4.push(t4), u4 += `
        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${f3 ? `vec4<${l4}>` : l4} {
          return bias[coords.${d3 ? "w" : "y"}${f3 ? "/ 4" : ""}];
        }`;
          }
          return `
        ${Js2("uniforms.result_strides")}
        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,
        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,
        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };
        ${r4.registerUniforms(s4).declareVariables(...c4, p4)}
        ${u4}
        ${la2(d3, k3, P3, $3, o3, t3, C3[0], C3[1], C3[2], l4)}
        ${f3 ? na2(b3, w3, l4, void 0, !d3, T3) : aa2(b3, w3, l4, void 0, !d3, T3, false, void 0, i3)}`;
        } };
      };
    })), Dd2 = j2((() => {
      dd2(), cd2(), pd2(), bd2(), Ed2(), Id2(), ua2 = (e3) => {
        let t3 = 1;
        for (let n3 = 0; n3 < e3.length; n3++) t3 *= e3[n3];
        return t3;
      }, ca2 = (e3) => "number" == typeof e3 ? [e3, e3, e3] : e3, pa2 = (e3, t3) => t3 <= 1 ? e3 : e3 + (e3 - 1) * (t3 - 1), ma2 = (e3, t3, n3, r3 = 1) => {
        let s3 = pa2(t3, r3);
        return Math.floor((e3[0] * (n3 - 1) - n3 + s3) / 2);
      }, ha2 = (e3, t3, n3, r3, s3) => {
        null == s3 && (s3 = ma2(e3, t3[0], r3[0]));
        let a3 = [0, 0, 0, n3];
        for (let n4 = 0; n4 < 3; n4++) e3[n4] + 2 * s3 >= t3[n4] && (a3[n4] = Math.trunc((e3[n4] - t3[n4] + 2 * s3) / r3[n4] + 1));
        return a3;
      }, fa2 = (e3, t3, n3, r3, s3, a3, o3, i3, l3, d3) => {
        let u3, c3, p3, m3;
        if ("VALID" === e3 && (e3 = 0), "number" == typeof e3) {
          u3 = { top: e3, bottom: e3, left: e3, right: e3, front: e3, back: e3 };
          let h3 = ha2([t3, n3, r3, 1], [i3, l3, d3], 1, [s3, a3, o3], e3);
          c3 = h3[0], p3 = h3[1], m3 = h3[2];
        } else if (Array.isArray(e3)) {
          if (!e3.every(((e4, t4, n4) => e4 === n4[0]))) throw Error(`Unsupported padding parameter: ${e3}`);
          u3 = { top: e3[0], bottom: e3[1], left: e3[2], right: e3[3], front: e3[4], back: e3[5] };
          let h3 = ha2([t3, n3, r3, 1], [i3, l3, d3], 1, [s3, a3, o3], e3[0]);
          c3 = h3[0], p3 = h3[1], m3 = h3[2];
        } else {
          if ("SAME_UPPER" !== e3) throw Error(`Unknown padding parameter: ${e3}`);
          {
            c3 = Math.ceil(t3 / s3), p3 = Math.ceil(n3 / a3), m3 = Math.ceil(r3 / o3);
            let e4 = (c3 - 1) * s3 + i3 - t3, h3 = (p3 - 1) * a3 + l3 - n3, f3 = (m3 - 1) * o3 + d3 - r3, _3 = Math.floor(e4 / 2), g3 = e4 - _3, w3 = Math.floor(h3 / 2), b3 = h3 - w3, y3 = Math.floor(f3 / 2);
            u3 = { top: w3, bottom: b3, left: y3, right: f3 - y3, front: _3, back: g3 };
          }
        }
        return { padInfo: u3, outDepth: c3, outHeight: p3, outWidth: m3 };
      }, _a2 = (e3, t3, n3, r3, s3, a3 = false, o3 = "channelsLast") => {
        let i3, l3, d3, u3, c3;
        if ("channelsLast" === o3) [i3, l3, d3, u3, c3] = e3;
        else {
          if ("channelsFirst" !== o3) throw new Error(`Unknown dataFormat ${o3}`);
          [i3, c3, l3, d3, u3] = e3;
        }
        let [p3, , m3, h3, f3] = t3, [_3, g3, w3] = ca2(n3), [b3, y3, M3] = ca2(r3), x3 = pa2(m3, b3), v3 = pa2(h3, y3), T3 = pa2(f3, M3), { padInfo: k3, outDepth: P3, outHeight: $3, outWidth: C3 } = fa2(s3, l3, d3, u3, _3, g3, w3, x3, v3, T3), S3 = a3 ? p3 * c3 : p3, F3 = [0, 0, 0, 0, 0];
        return "channelsFirst" === o3 ? F3 = [i3, S3, P3, $3, C3] : "channelsLast" === o3 && (F3 = [i3, P3, $3, C3, S3]), { batchSize: i3, dataFormat: o3, inDepth: l3, inHeight: d3, inWidth: u3, inChannels: c3, outDepth: P3, outHeight: $3, outWidth: C3, outChannels: S3, padInfo: k3, strideDepth: _3, strideHeight: g3, strideWidth: w3, filterDepth: m3, filterHeight: h3, filterWidth: f3, effectiveFilterDepth: x3, effectiveFilterHeight: v3, effectiveFilterWidth: T3, dilationDepth: b3, dilationHeight: y3, dilationWidth: M3, inShape: e3, outShape: F3, filterShape: t3 };
      }, ga2 = (e3, t3, n3, r3, s3, a3) => {
        let o3 = "channelsLast" === a3, i3 = (o3 ? e3[0].dims[3] : e3[0].dims[1], { x: n3.map(((e4, t4) => t4)) }), l3 = [Math.ceil(ua2(i3.x.map(((e4) => n3[e4]))) / 64), 1, 1];
        ht2("verbose", (() => `[conv3d_naive_webgpu] dispatch = ${l3}`));
        let d3 = [{ type: 12, data: gt2.size(n3) }, { type: 12, data: r3 }, { type: 12, data: s3 }, { type: 12, data: t3.strides }, { type: 12, data: t3.dilations }];
        Ws2(t3, d3), d3.push(...Jt2(e3[0].dims, e3[1].dims));
        let u3 = ["rank", "rank"], c3 = 3 === e3.length;
        c3 && (d3.push(...Jt2(e3[2].dims)), u3.push("rank")), d3.push(...Jt2(n3));
        return { name: "Conv3DNaive", shaderCache: { hint: `${t3.cacheKey};${o3};1;${c3}`, inputDependencies: u3 }, getRunData: () => ({ outputs: [{ dims: n3, dataType: e3[0].dataType }], dispatchGroup: { x: l3[0], y: l3[1], z: l3[2] }, programUniforms: d3 }), getShaderSource: (a4) => {
          let i4 = [{ name: "output_size", type: "u32" }, { name: "filter_dims", type: "u32", length: r3.length }, { name: "pads", type: "u32", length: s3.length }, { name: "strides", type: "u32", length: t3.strides.length }, { name: "dilations", type: "u32", length: t3.dilations.length }];
          Hs2(t3, i4);
          let l4 = Kt2(e3[0].dataType), d4 = sn2("x", e3[0].dataType, e3[0].dims.length, 1), u4 = sn2("W", e3[1].dataType, e3[1].dims.length, 1), p3 = [d4, u4], m3 = an2("result", e3[0].dataType, n3.length, 1), h3 = "";
          if (c3) {
            let t4 = sn2("bias", e3[2].dataType, e3[2].dims.length, 1);
            p3.push(t4), h3 += `
        fn getBiasByOutputCoords(coords : array<u32, 5>) -> ${l4} {
          return bias[${nn2("coords", o3 ? 4 : 1, 5)}];
        }`;
          }
          let f3 = Ks2(1, l4), _3 = Us2(t3, f3, l4);
          return `
            ${h3}
            fn getX(d0 : u32, d1 : u32, d2 : u32, d3 : u32, d4 : u32) -> f32 {
              let aIndices = array<u32, 5>(d0, d1, d2, d3, d4);
              return ${d4.getByIndices("aIndices")};
            }
            fn getW(d0 : u32, d1 : u32, d2 : u32, d3 : u32, d4 : u32) -> f32 {
              let aIndices = array<u32, 5>(d0, d1, d2, d3, d4);
              return ${u4.getByIndices("aIndices")};
            }
          ${a4.registerUniforms(i4).declareVariables(...p3, m3)}
          ${a4.mainStart()}
          ${a4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
              let coords = ${m3.offsetToIndices("global_idx")};
              let batch = ${nn2("coords", 0, d4.rank)};
              let d2 = ${nn2("coords", o3 ? d4.rank - 1 : 1, d4.rank)};
              let xFRCCorner = vec3<u32>(${nn2("coords", o3 ? 1 : 2, d4.rank)},
              ${nn2("coords", o3 ? 2 : 3, d4.rank)},
              ${nn2("coords", o3 ? 3 : 4, d4.rank)}) * uniforms.strides - uniforms.pads;
              let xFCorner = xFRCCorner.x;
              let xRCorner = xFRCCorner.y;
              let xCCorner = xFRCCorner.z;
              let xShapeY = ${nn2("uniforms.x_shape", o3 ? 1 : 2, d4.rank)};
              let xShapeZ = ${nn2("uniforms.x_shape", o3 ? 2 : 3, d4.rank)};
              let xShapeW = ${nn2("uniforms.x_shape", o3 ? 3 : 4, d4.rank)};
              let xShapeU = ${nn2("uniforms.x_shape", o3 ? 4 : 1, d4.rank)};
              let inputDepthNearestVec4 = (xShapeU / 4) * 4;
              let inputDepthVec4Remainder = xShapeU % 4;

              var value = 0.0;
              for (var wF = 0u; wF < uniforms.filter_dims[0]; wF++) {
                let xF = xFCorner + wF * uniforms.dilations[0];
                if (xF < 0 || xF >= xShapeY) {
                  continue;
                }

                for (var wR = 0u; wR < uniforms.filter_dims[1]; wR++) {
                  let xR = xRCorner + wR * uniforms.dilations[1];
                  if (xR < 0 || xR >= xShapeZ) {
                    continue;
                  }

                  for (var wC = 0u; wC < uniforms.filter_dims[2]; wC++) {
                    let xC = xCCorner + wC * uniforms.dilations[2];
                    if (xC < 0 || xC >= xShapeW) {
                      continue;
                    }

                    for (var d1 = 0u; d1 < inputDepthNearestVec4; d1 += 4) {
                      ${o3 ? "let xValues = vec4<f32>(\n                               getX(batch, xF, xR, xC, d1),\n                               getX(batch, xF, xR, xC, d1 + 1),\n                               getX(batch, xF, xR, xC, d1 + 2),\n                               getX(batch, xF, xR, xC, d1 + 3));\n                            " : "let xValues = vec4<f32>(\n                               getX(batch, d1, xF, xR, xC),\n                               getX(batch, d1 + 1, xF, xR, xC),\n                               getX(batch, d1 + 2, xF, xR, xC),\n                               getX(batch, d1 + 3, xF, xR, xC));\n                            "}
                            let wValues = vec4<f32>(
                              getW(d2, d1, wF, wR, wC),
                              getW(d2, d1 + 1, wF, wR, wC),
                              getW(d2, d1 + 2, wF, wR, wC),
                              getW(d2, d1 + 3, wF, wR, wC));
                      value += dot(xValues, wValues);
                    }
                    if (inputDepthVec4Remainder == 1) {
                        ${o3 ? "value += getX(batch, xF, xR, xC, inputDepthNearestVec4)\n                          * getW(d2, inputDepthNearestVec4, wF, wR, wC);" : "value += getX(batch, inputDepthNearestVec4, xF, xR, xC)\n                          * getW(d2, inputDepthNearestVec4, wF, wR, wC);"}
                    } else if (inputDepthVec4Remainder == 2) {
                      ${o3 ? "let xValues = vec2<f32>(\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4),\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1));\n                      " : "let xValues = vec2<f32>(\n                        getX(batch, inputDepthNearestVec4, xF, xR, xC),\n                        getX(batch, inputDepthNearestVec4 + 1, xF, xR, xC));\n                    "}
                    let wValues = vec2<f32>(
                      getW(d2, inputDepthNearestVec4, wF, wR, wC),
                      getW(d2, inputDepthNearestVec4 + 1, wF, wR, wC));
                      value += dot(xValues, wValues);
                    } else if (inputDepthVec4Remainder == 3) {
                      ${o3 ? "let xValues = vec3<f32>(\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4),\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1),\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4 + 2));\n                      " : "let xValues = vec3<f32>(\n                        getX(batch, inputDepthNearestVec4, xF, xR, xC),\n                        getX(batch, inputDepthNearestVec4 + 1, xF, xR, xC),\n                        getX(batch, inputDepthNearestVec4 + 2, xF, xR, xC));\n                    "}
                    let wValues = vec3<f32>(
                      getW(d2, inputDepthNearestVec4, wF, wR, wC),
                      getW(d2, inputDepthNearestVec4 + 1, wF, wR, wC),
                      getW(d2, inputDepthNearestVec4 + 2, wF, wR, wC));
                      value += dot(xValues, wValues);
                    }
                  }
                }
              }
              ${c3 ? "value = value + getBiasByOutputCoords(coords)" : ""};
              ${_3}
              result[global_idx] = f32(value);
          }`;
        } };
      };
    })), Bd2 = j2((() => {
      dd2(), pd2(), bd2(), Ed2(), wa2 = (e3, t3, n3, r3) => {
        let s3 = e3.length > 2, a3 = s3 ? "value += b[output_channel];" : "", o3 = e3[0].dims, i3 = e3[1].dims, l3 = "NHWC" === t3.format, d3 = l3 ? n3[3] : n3[1], u3 = d3 / t3.group, c3 = l3 && u3 >= 4 ? Yt2(d3) : 1, p3 = gt2.size(n3) / c3, m3 = [{ type: 12, data: p3 }, { type: 12, data: t3.dilations }, { type: 12, data: [t3.strides[0], t3.strides[1]] }, { type: 12, data: [t3.pads[0], t3.pads[1]] }, { type: 12, data: u3 }];
        Ws2(t3, m3), m3.push(...Jt2(o3, [i3[0], i3[1], i3[2], i3[3] / c3]));
        let h3 = s3 ? ["rank", "rank", "rank"] : ["rank", "rank"];
        m3.push(...Jt2([n3[0], n3[1], n3[2], n3[3] / c3]));
        return { name: "GroupedConv", shaderCache: { hint: `${t3.cacheKey}_${c3}`, inputDependencies: h3 }, getRunData: () => ({ outputs: [{ dims: r3 ? r3(n3) : n3, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(p3 / 64) }, programUniforms: m3 }), getShaderSource: (r4) => {
          let d4 = an2("output", e3[0].dataType, n3.length, c3), u4 = Kt2(d4.type.tensor), p4 = Us2(t3, d4.type.value, u4), m4 = sn2("x", e3[0].dataType, o3.length), h4 = sn2("w", e3[1].dataType, i3.length, c3), f3 = [m4, h4];
          s3 && f3.push(sn2("b", e3[2].dataType, e3[2].dims, c3));
          let _3 = [{ name: "output_size", type: "u32" }, { name: "dilations", type: "u32", length: t3.dilations.length }, { name: "strides", type: "u32", length: 2 }, { name: "pads", type: "u32", length: 2 }, { name: "output_channels_per_group", type: "u32" }];
          Hs2(t3, _3);
          let g3 = l3 ? `
      for (var wHeight: u32 = 0u; wHeight < uniforms.w_shape[0]; wHeight++) {
        let xHeight = xRCCorner.x + wHeight * uniforms.dilations[0];

        if (xHeight < 0u || xHeight >= uniforms.x_shape[1]) {
          continue;
        }

        for (var wWidth: u32 = 0u; wWidth < uniforms.w_shape[1]; wWidth++) {
          let xWidth = xRCCorner.y + wWidth * uniforms.dilations[1];
          if (xWidth < 0u || xWidth >= uniforms.x_shape[2]) {
            continue;
          }

          for (var wInChannel: u32 = 0u; wInChannel < uniforms.w_shape[2]; wInChannel++) {
            let input_channel = in_channel_offset + wInChannel;
            let xVal = ${m4.get("batch", "xHeight", "xWidth", "input_channel")};
            let wVal = ${h4.get("wHeight", "wWidth", "wInChannel", "output_channel")};
            value += xVal * wVal;
          }
        }
      }
      ` : `
      for (var wInChannel: u32 = 0u; wInChannel < uniforms.w_shape[1]; wInChannel++) {
        let input_channel = in_channel_offset + wInChannel;
        for (var wHeight: u32 = 0u; wHeight < uniforms.w_shape[2]; wHeight++) {
          let xHeight = xRCCorner.x + wHeight * uniforms.dilations[0];

          if (xHeight < 0u || xHeight >= uniforms.x_shape[2]) {
            continue;
          }

          for (var wWidth: u32 = 0u; wWidth < uniforms.w_shape[3]; wWidth++) {
            let xWidth = xRCCorner.y + wWidth * uniforms.dilations[1];
            if (xWidth < 0u || xWidth >= uniforms.x_shape[3]) {
              continue;
            }

            let xVal = ${m4.get("batch", "input_channel", "xHeight", "xWidth")};
            let wVal = ${h4.get("output_channel", "wInChannel", "wHeight", "wWidth")};
            value += xVal * wVal;
          }
        }
      }
      `;
          return `
  ${r4.registerUniforms(_3).declareVariables(...f3, d4)}

  ${r4.mainStart()}
    ${r4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}

    let outputIndices = ${d4.offsetToIndices("global_idx")};
    let batch: u32 = outputIndices[0];
    let output_channel: u32 = outputIndices[${l3 ? 3 : 1}];
    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${l3 ? 1 : 2}], outputIndices[${l3 ? 2 : 3}]) * uniforms.strides - uniforms.pads;
    let group_id: u32 = output_channel * ${c3} / uniforms.output_channels_per_group;
    var in_channel_offset = group_id * uniforms.w_shape[${l3 ? 2 : 1}];

    var value: ${d4.type.value} = ${d4.type.value}(0);
    ${g3}
    ${a3}
    ${p4}
    ${d4.setByOffset("global_idx", "value")}
  }`;
        } };
      }, ba2 = (e3, t3, n3, r3) => {
        let s3 = e3.length > 2, a3 = Yt2(n3[3]), o3 = Yt2(n3[2]), i3 = gt2.size(n3) / a3 / o3, l3 = [e3[0].dims[0], e3[0].dims[1], e3[0].dims[2], e3[0].dims[3] / a3], d3 = [e3[1].dims[0], e3[1].dims[1], e3[1].dims[2], e3[1].dims[3] / a3], u3 = [n3[0], n3[1], n3[2], n3[3] / a3], c3 = [{ type: 12, data: i3 }, { type: 6, data: [t3.strides[0], t3.strides[1]] }, { type: 6, data: [t3.pads[0], t3.pads[1]] }];
        Ws2(t3, c3), c3.push(...Jt2(l3, d3, u3));
        let p3 = (o3 - 1) * t3.strides[1] + d3[1];
        return { name: "GroupedConv-Vectorize", shaderCache: { hint: `${t3.cacheKey};${a3};${o3};${p3};${d3[0]};${d3[1]}`, inputDependencies: s3 ? ["rank", "rank", "type"] : ["rank", "rank"] }, getRunData: () => ({ outputs: [{ dims: r3 ? r3(n3) : n3, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(i3 / 64) }, programUniforms: c3 }), getShaderSource: (n4) => {
          let r4 = an2("output", e3[0].dataType, u3.length, a3), i4 = Kt2(r4.type.tensor), c4 = Us2(t3, r4.type.value, i4), m3 = sn2("x", e3[0].dataType, l3.length, a3), h3 = sn2("w", e3[1].dataType, d3.length, a3), f3 = [m3, h3];
          s3 && f3.push(sn2("b", e3[2].dataType, e3[2].dims, a3));
          let _3 = s3 ? "value += b[output_channel];" : "", g3 = [{ name: "output_size", type: "u32" }, { name: "strides", type: "i32", length: 2 }, { name: "pads", type: "i32", length: 2 }];
          return Hs2(t3, g3), `
  ${n4.registerUniforms(g3).declareVariables(...f3, r4)}
  ${n4.mainStart()}
    ${n4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
    let width0 = uniforms.output_shape[3];
    let output_channel = global_idx % width0;
    var index1 = global_idx / width0;
    let width1 = uniforms.output_shape[2] / ${o3}u;
    let col = (index1 % width1) * ${o3}u;
    index1 = index1 / width1;
    let row = index1 % uniforms.output_shape[1];
    let batch = index1 / uniforms.output_shape[1];

    let x_corner = vec2<i32>(i32(row), i32(col)) * uniforms.strides - uniforms.pads;

    var x_vals: array<${m3.type.value}, ${p3}>;
    var values: array<${r4.type.value}, ${o3}>;
    let input_channel = output_channel;
    // Use constant instead of uniform can give better performance for w's height/width.
    for (var w_height: u32 = 0u; w_height < ${d3[0]}; w_height++) {
      let x_height = x_corner.x + i32(w_height);
      if (x_height >= 0 && u32(x_height) < uniforms.x_shape[1]) {
        for (var i = 0; i < ${p3}; i++) {
          let x_width = x_corner.y + i;
          if (x_width >= 0 && u32(x_width) < uniforms.x_shape[2]) {
            x_vals[i] = ${m3.get("batch", "u32(x_height)", "u32(x_width)", "input_channel")};
          } else {
            x_vals[i] = ${m3.type.value}(0);
          }
        }
        for (var w_width: u32 = 0u; w_width < ${d3[1]}; w_width++) {
          let w_val = ${h3.get("w_height", "w_width", "0", "output_channel")};
          for (var i = 0u; i < ${o3}u; i++) {
            values[i] = fma(x_vals[i * u32(uniforms.strides[1]) + w_width], w_val, values[i]);
          }
        }
      }
    }

    for (var i = 0u; i < ${o3}u; i++) {
      var value = values[i];
      ${_3}
      ${c4}
      ${r4.set("batch", "row", "col + i", "output_channel", "value")};
    }
  }`;
        } };
      };
    })), Nd2 = j2((() => {
      pd2(), Od2(), Dd2(), Ld2(), Bd2(), Ed2(), zd2(), yd2(), ya2 = (e3, t3, n3, r3, s3, a3) => {
        let o3 = e3[0], i3 = e3.slice(a3 ? 1 : 2, a3 ? 3 : 4), l3 = i3.length, d3 = t3[0], u3 = t3.slice(2).map(((e4, t4) => e4 + (e4 - 1) * (n3[t4] - 1))), c3 = i3.map(((e4, t4) => e4 + r3[t4] + r3[t4 + l3])).map(((e4, t4) => Math.floor((e4 - u3[t4] + s3[t4]) / s3[t4])));
        return c3.splice(0, 0, o3), c3.splice(a3 ? 3 : 1, 0, d3), c3;
      }, Ma2 = [2, 3, 1, 0], xa2 = (e3, t3) => {
        if (!e3 || 2 !== e3.length && 3 !== e3.length) throw new Error("Conv requires 2 or 3 inputs");
        if (e3[0].dims.length > 5) throw new Error("greater than 5D is not supported");
        if (e3[0].dims.length !== e3[1].dims.length) throw new Error("filter does not have same dimension as input");
        if (e3[0].dims["NHWC" === t3.format ? e3[0].dims.length - 1 : 1] !== e3[1].dims[1] * t3.group) throw new Error("FILTER_IN_CHANNEL should be equal to DATA_CHANNEL");
        if (3 === e3.length && (1 !== e3[2].dims.length || e3[1].dims[0] !== e3[2].dims[0])) throw new Error("invalid bias");
        let n3 = e3[0].dims.length - 2;
        if (t3.dilations.length !== n3) throw new Error(`dilations should be ${n3}D`);
        if (t3.strides.length !== n3) throw new Error(`strides should be ${n3}D`);
        if (t3.pads.length !== 2 * n3) throw new Error(`pads should be ${2 * n3}D`);
        if (0 !== t3.kernelShape.length && t3.kernelShape.length !== e3[1].dims.length - 2) throw new Error("invalid kernel shape");
      }, va2 = (e3, t3) => {
        let n3 = e3.kernelShape.slice();
        n3.length < t3[1].dims.length - 2 && n3.push(...Array(t3[1].dims.length - 2 - n3.length).fill(0));
        for (let e4 = 2; e4 < t3[1].dims.length; ++e4) 0 === n3[e4 - 2] && (n3[e4 - 2] = t3[1].dims[e4]);
        let r3 = e3.pads.slice();
        wt2.adjustPadsBasedOnAutoPad(t3[0].dims, e3.strides, e3.dilations, n3, r3, "NHWC" === e3.format, e3.autoPad);
        let s3 = Object.assign({}, e3);
        return Object.assign(s3, { kernelShape: n3, pads: r3 }), s3;
      }, Ta2 = (e3) => {
        let t3 = Qs2(e3), n3 = e3.format;
        return { autoPad: ["NOTSET", "VALID", "SAME_UPPER", "SAME_LOWER"][e3.auto_pad], format: n3, dilations: e3.dilations, group: e3.group, kernelShape: e3.kernel_shape, pads: e3.pads, strides: e3.strides, wIsConst: e3.w_is_const(), ...t3, cacheKey: `${e3.format};${t3.activation};` };
      }, ka2 = (e3, t3, n3, r3) => {
        let s3 = "NHWC" === n3.format, a3 = ya2(t3[0].dims, t3[1].dims, n3.dilations, n3.pads, n3.strides, s3);
        if (1 !== n3.group) {
          let o4 = [t3[0]];
          if (s3) {
            let r4 = e3.kernelCustomData.wT ?? e3.compute(gn2(t3[1], Ma2), { inputs: [1], outputs: [n3.wIsConst ? -2 : -1] })[0];
            n3.wIsConst && !e3.kernelCustomData.wT && (e3.kernelCustomData.wT = r4), o4.push(r4);
          } else o4.push(t3[1]);
          return 3 === t3.length && o4.push(t3[2]), void (!e3.adapterInfo.isArchitecture("ampere") && s3 && t3[1].dims[0] === n3.group && 1 === t3[1].dims[1] && 1 === n3.dilations[0] && 1 === n3.dilations[1] ? e3.compute(ba2(o4, n3, a3, r3), { inputs: o4 }) : e3.compute(wa2(o4, n3, a3, r3), { inputs: o4 }));
        }
        let o3 = 3 === t3.length, i3 = t3[0].dims[s3 ? 1 : 2], l3 = t3[0].dims[s3 ? 2 : 3], d3 = t3[0].dims[s3 ? 3 : 1], u3 = t3[1].dims[2], c3 = t3[1].dims[3], p3 = a3[s3 ? 1 : 2], m3 = a3[s3 ? 2 : 3], h3 = a3[s3 ? 3 : 1], f3 = s3 && u3 === i3 && c3 === l3 && 0 === n3.pads[0] && 0 === n3.pads[1];
        if (f3 || 1 === u3 && 1 === c3 && 1 === n3.dilations[0] && 1 === n3.dilations[1] && 1 === n3.strides[0] && 1 === n3.strides[1] && 0 === n3.pads[0] && 0 === n3.pads[1]) {
          let u4, c4, _4, g4 = a3[0], w4 = [];
          if (s3) {
            let r4 = e3.kernelCustomData.wT ?? e3.compute(gn2(t3[1], Ma2), { inputs: [1], outputs: [n3.wIsConst ? -2 : -1] })[0];
            if (n3.wIsConst && !e3.kernelCustomData.wT && (e3.kernelCustomData.wT = r4), f3) {
              let e4 = i3 * l3 * d3;
              u4 = t3[0].reshape([1, g4, e4]), c4 = r4.reshape([1, e4, h3]), _4 = [1, g4, h3];
            } else u4 = t3[0].reshape([g4, i3 * l3, d3]), c4 = r4.reshape([1, d3, h3]), _4 = [g4, p3 * m3, h3];
            w4.push(u4), w4.push(c4);
          } else u4 = t3[0].reshape([g4, d3, i3 * l3]), c4 = t3[1].reshape([1, h3, d3]), _4 = [g4, h3, p3 * m3], w4.push(c4), w4.push(u4);
          o3 && w4.push(t3[2]);
          let b4 = _4[2], y4 = w4[0].dims[w4[0].dims.length - 1];
          return void (b4 < 8 && y4 < 8 ? e3.compute(Zs2(w4, n3, a3, _4, s3, r3), { inputs: w4 }) : e3.compute(ia2(w4, n3, a3, _4, s3, r3), { inputs: w4 }));
        }
        let _3 = e3.kernelCustomData.wT ?? e3.compute(gn2(t3[1], Ma2), { inputs: [1], outputs: [n3.wIsConst ? -2 : -1] })[0];
        n3.wIsConst && !e3.kernelCustomData.wT && (e3.kernelCustomData.wT = _3);
        let g3 = [t3[0], _3];
        o3 && g3.push(t3[2]);
        let w3 = s3 ? p3 * m3 : h3, b3 = s3 ? h3 : p3 * m3, y3 = u3 * c3 * d3;
        e3.compute(da2(g3, n3, a3, w3, b3, y3, o3, true, r3), { inputs: g3 });
      }, Pa2 = (e3, t3) => {
        let n3 = "NHWC" === t3.format, r3 = [e3.inputs[0].reshape(n3 ? [e3.inputs[0].dims[0], 1, e3.inputs[0].dims[1], e3.inputs[0].dims[2]] : [e3.inputs[0].dims[0], e3.inputs[0].dims[1], 1, e3.inputs[0].dims[2]]), e3.inputs[1].reshape([e3.inputs[1].dims[0], e3.inputs[1].dims[1], 1, e3.inputs[1].dims[2]])];
        3 === e3.inputs.length && r3.push(e3.inputs[2]);
        let s3 = [0, t3.pads[0], 0, t3.pads[1]], a3 = [1].concat(t3.strides), o3 = [1].concat(t3.dilations), i3 = [1].concat(t3.kernelShape), l3 = va2({ ...t3, pads: s3, strides: a3, dilations: o3, kernelShape: i3 }, r3);
        ka2(e3, r3, l3, ((e4) => n3 ? [e4[0], e4[2], e4[3]] : [e4[0], e4[1], e4[3]]));
      }, $a2 = (e3, t3, n3) => {
        let r3 = "NHWC" === n3.format ? "channelsLast" : "channelsFirst", s3 = va2(n3, t3), a3 = "NOTSET" === n3.autoPad ? n3.pads : n3.autoPad, o3 = _a2(t3[0].dims, t3[1].dims, n3.strides, n3.dilations, a3, false, r3);
        e3.compute(ga2(t3, s3, o3.outShape, [o3.filterDepth, o3.filterHeight, o3.filterWidth], [o3.padInfo.front, o3.padInfo.top, o3.padInfo.left], r3));
      }, Ca2 = (e3, t3) => {
        if (xa2(e3.inputs, t3), 3 === e3.inputs[0].dims.length) Pa2(e3, t3);
        else if (5 === e3.inputs[0].dims.length) $a2(e3, e3.inputs, t3);
        else {
          let n3 = va2(t3, e3.inputs);
          ka2(e3, e3.inputs, n3);
        }
      };
    })), jd2 = j2((() => {
      dd2(), cd2(), pd2(), bd2(), Sa2 = (e3, t3, n3) => {
        let r3 = e3.length > 2, s3 = t3.outputShape, a3 = "NHWC" === t3.format, o3 = t3.group, i3 = e3[1].dims, l3 = i3[2] / o3, d3 = i3[3], u3 = a3 ? Yt2(l3) : 1, c3 = a3 && 1 === d3 && l3 >= 4, p3 = c3 ? 4 * Math.floor(l3 / 4) : Math.floor(l3 / u3) * u3, m3 = l3 - p3, h3 = a3 ? Yt2(d3) : 1, f3 = a3 ? 1 === d3 ? u3 : h3 : 1, _3 = gt2.size(s3) / h3, g3 = [Math.ceil(_3 / 64), 1, 1];
        ht2("verbose", (() => `[conv2d_backprop_webgpu] dispatch = ${g3}`));
        let w3 = ["rank", "rank"], b3 = [t3.strides[0], t3.strides[1]], y3 = [t3.kernelShape[a3 ? 1 : 2], t3.kernelShape[a3 ? 2 : 3]], M3 = [t3.dilations[0], t3.dilations[1]], x3 = [y3[0] + (t3.dilations[0] <= 1 ? 0 : (t3.kernelShape[a3 ? 1 : 2] - 1) * (t3.dilations[0] - 1)), y3[1] + (t3.dilations[1] <= 1 ? 0 : (t3.kernelShape[a3 ? 2 : 3] - 1) * (t3.dilations[1] - 1))], v3 = [x3[0] - 1 - Math.floor((t3.pads[0] + t3.pads[2]) / 2), x3[1] - 1 - Math.floor((t3.pads[1] + t3.pads[3]) / 2)], T3 = [{ type: 12, data: _3 }, { type: 12, data: b3 }, { type: 12, data: y3 }, { type: 12, data: M3 }, { type: 12, data: x3 }, { type: 6, data: v3 }, { type: 12, data: p3 }, { type: 12, data: l3 }, { type: 12, data: d3 }, ...Jt2(e3[0].dims, e3[1].dims)];
        r3 && (T3.push(...Jt2(e3[2].dims)), w3.push("rank")), T3.push(...Jt2(s3));
        return { name: "ConvTranspose2D", shaderCache: { hint: `${t3.cacheKey};${u3}${f3}${h3}${c3}${m3}`, inputDependencies: w3 }, getRunData: () => ({ dispatchGroup: { x: g3[0], y: g3[1], z: g3[2] }, outputs: [{ dims: n3 ? n3(s3) : s3, dataType: e3[0].dataType }], programUniforms: T3 }), getShaderSource: (t4) => {
          let n4 = [{ name: "output_size", type: "u32" }, { name: "strides", type: "u32", length: b3.length }, { name: "filter_dims", type: "u32", length: y3.length }, { name: "dilations", type: "u32", length: y3.length }, { name: "effective_filter_dims", type: "u32", length: x3.length }, { name: "pads", type: "i32", length: v3.length }, { name: "input_channels_per_group_int", type: "u32" }, { name: "input_channels_per_group", type: "u32" }, { name: "output_channels_per_group", type: "u32" }], o4 = Kt2(e3[0].dataType), i4 = a3 ? 1 : 2, l4 = a3 ? 2 : 3, d4 = a3 ? 3 : 1, p4 = sn2("W", e3[1].dataType, e3[1].dims.length, f3), _4 = sn2("Dy", e3[0].dataType, e3[0].dims.length, u3), g4 = [_4, p4];
          r3 && g4.push(sn2("bias", e3[2].dataType, [s3[d4]].length, h3));
          let w4 = an2("result", e3[0].dataType, s3.length, h3), M4 = `
            let outputIndices = ${w4.offsetToIndices(`global_idx * ${h3}`)};
            let batch = ${w4.indicesGet("outputIndices", 0)};
            let d1 = ${w4.indicesGet("outputIndices", d4)};
            let r = ${w4.indicesGet("outputIndices", i4)};
            let c = ${w4.indicesGet("outputIndices", l4)};
            let dyCorner = vec2<i32>(i32(r), i32(c)) - uniforms.pads;
            let dyRCorner = dyCorner.x;
            let dyCCorner = dyCorner.y;
            let groupId = d1 / uniforms.output_channels_per_group;
            let wOutChannel = d1 - groupId * uniforms.output_channels_per_group;
            // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).
            // ? = to be determined. : = across all values in that axis.
            var dotProd = ${w4.type.value}(0.0);
            var wR: u32 = 0;
            if (uniforms.dilations.x == 1) {
              // Minimum wR >= 0 that satisfies (dyRCorner + wR) % (uniforms.strides.x) == 0
              wR = u32(((dyRCorner + i32(uniforms.strides.x) - 1) / i32(uniforms.strides.x)) * i32(uniforms.strides.x) - dyRCorner);
            }
            for (; wR < uniforms.effective_filter_dims.x; wR = wR + 1) {
              if (wR % uniforms.dilations.x != 0) {
                continue;
              }
              let dyR = (${o4}(dyRCorner) + ${o4}(wR)) / ${o4}(uniforms.strides[0]);
              let wRPerm = uniforms.filter_dims.x - 1 - wR / uniforms.dilations.x;
              if (dyR < 0.0 || dyR >= ${o4}(uniforms.Dy_shape[${i4}]) || fract(dyR) > 0.0 ||
                  wRPerm < 0) {
                continue;
              }
              let idyR: u32 = u32(dyR);
              var wC: u32 = 0;
              if (uniforms.dilations.y == 1) {
                // Minimum wC >= 0 that satisfies (dyCCorner + wC) % (uniforms.strides.y) == 0
                wC = u32(((dyCCorner + i32(uniforms.strides.y) - 1) / i32(uniforms.strides.y)) * i32(uniforms.strides.y) - dyCCorner);
              }
              for (; wC < uniforms.effective_filter_dims.y; wC = wC + 1) {
                if (wC % uniforms.dilations.y != 0) {
                  continue;
                }
                let dyC = (${o4}(dyCCorner) + ${o4}(wC)) / ${o4}(uniforms.strides.y);
                let wCPerm = uniforms.filter_dims.y - 1 - wC / uniforms.dilations.y;
                if (dyC < 0.0 || dyC >= ${o4}(uniforms.Dy_shape[${l4}]) ||
                    fract(dyC) > 0.0 || wCPerm < 0) {
                  continue;
                }
                let idyC: u32 = u32(dyC);
                var inputChannel = groupId * uniforms.input_channels_per_group;
                ${c3 ? `
                var x_offset = ${_4.indicesToOffset(`${_4.type.indices}(batch, idyR, idyC, inputChannel)`)} / ${u3};
                var w_offset = ${p4.indicesToOffset(`${p4.type.indices}(wRPerm, wCPerm, inputChannel, wOutChannel)`)} / ${f3};
                  ` : ""}
                for (var d2: u32 = 0; d2 < uniforms.input_channels_per_group_int; d2 = d2 + ${c3 ? 4 : u3}) {
                  ${(() => {
            let e4 = "";
            if (c3) 4 === u3 ? e4 += `
        let xValue = ${_4.getByOffset("x_offset")};
        let wValue = ${p4.getByOffset("w_offset")};
        dotProd = dotProd + dot(xValue, wValue);
        x_offset += 1u;
        w_offset += 1u;` : 2 === u3 ? e4 += `
          dotProd = dotProd + dot(vec4<${o4}>(${_4.getByOffset("x_offset")}, ${_4.getByOffset("x_offset + 1u")}), vec4<${o4}>(${p4.getByOffset("w_offset")}, ${p4.getByOffset("w_offset + 1u")}));
          x_offset += 2u;
          w_offset += 2u;` : 1 === u3 && (e4 += `
          dotProd = dotProd + dot(vec4<${o4}>(${_4.getByOffset("x_offset")}, ${_4.getByOffset("x_offset + 1u")}, ${_4.getByOffset("x_offset + 2u")}, ${_4.getByOffset("x_offset + 3u")}), vec4<${o4}>(${p4.getByOffset("w_offset")}, ${p4.getByOffset("w_offset + 1u")}, ${p4.getByOffset("w_offset + 2u")}, ${p4.getByOffset("w_offset + 3u")}));
          x_offset += 4u;
          w_offset += 4u;`);
            else if (e4 += `
                  let xValue = ${a3 ? _4.getByOffset(`${_4.indicesToOffset(`${_4.type.indices}(batch, idyR, idyC, inputChannel)`)} / ${u3}`) : _4.get("batch", "inputChannel", "idyR", "idyC")};
        `, 1 === u3) e4 += `
          let w_offset = ${p4.indicesToOffset(`${p4.type.indices}(u32(wRPerm), u32(wCPerm), inputChannel, wOutChannel)`)};
          let wValue = ${p4.getByOffset(`w_offset / ${f3}`)};
          dotProd = dotProd + xValue * wValue;`;
            else for (let t5 = 0; t5 < u3; t5++) e4 += `
            let wValue${t5} = ${p4.getByOffset(`${p4.indicesToOffset(`${p4.type.indices}(u32(wRPerm), u32(wCPerm), inputChannel + ${t5}, wOutChannel)`)} / ${f3}`)};
            dotProd = dotProd + xValue[${t5}] * wValue${t5};`;
            return e4;
          })()}
                  inputChannel = inputChannel + ${c3 ? 4 : u3};
                }
                ${(() => {
            if (0 === m3) return "";
            if (!c3) throw new Error(`packInputAs4 ${c3} is not true.`);
            let e4 = "";
            if (1 === u3) {
              e4 += "dotProd = dotProd";
              for (let t5 = 0; t5 < m3; t5++) e4 += `
            + ${_4.getByOffset(`x_offset + ${t5}`)} * ${p4.getByOffset(`w_offset + ${t5}`)}`;
              e4 += ";";
            } else if (2 === u3) {
              if (2 !== m3) throw new Error(`Invalid inputChannelsRemainder ${m3}.`);
              e4 += `
          let xValue = ${_4.getByOffset("x_offset")};
          let wValue = ${p4.getByOffset("w_offset")};
          dotProd = dotProd + dot(xValue, wValue);`;
            }
            return e4;
          })()}
                wC = wC + uniforms.strides.y - 1;
              }
              wR = wR + uniforms.strides[0] - 1;
            }
            let value = dotProd${r3 ? ` + bias[d1 / ${h3}]` : ""};
            ${w4.setByOffset("global_idx", "value")};
          `;
          return `
    ${t4.registerUniforms(n4).declareVariables(...g4, w4)}
      ${t4.mainStart()}
      ${t4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")};
    ${M4}}`;
        } };
      };
    })), Rd2 = j2((() => {
      jd2(), Ed2(), yd2(), Fa2 = (e3, t3, n3, r3, s3, a3) => (e3 - 1) * t3 + n3 + (r3 - 1) * s3 + 1 - a3, Ea2 = (e3, t3, n3, r3, s3) => {
        let a3 = Math.floor(e3 / 2);
        "SAME_UPPER" === t3 ? (n3[r3] = a3, n3[s3] = e3 - a3) : "SAME_LOWER" === t3 && (n3[r3] = e3 - a3, n3[s3] = a3);
      }, Ia2 = (e3, t3, n3, r3, s3, a3, o3, i3, l3, d3) => {
        let u3 = e3.length - 2, c3 = 0 === d3.length;
        l3.length < u3 && l3.push(...Array(u3 - l3.length).fill(0));
        let p3 = e3[0], m3 = t3[i3 ? 3 : 1] * s3;
        for (let s4 = 0, p4 = e3.length - u3 - (i3 ? 1 : 0); s4 < u3; ++s4, ++p4) {
          let i4 = e3[p4], m4 = c3 ? i4 * o3[s4] : d3[s4], h3 = Fa2(i4, o3[s4], a3[s4], t3[p4], n3[s4], m4);
          Ea2(h3, r3, a3, s4, s4 + u3), c3 && d3.push(o3[s4] * (i4 - 1) + l3[s4] + (t3[p4] - 1) * n3[s4] + 1 - a3[s4] - a3[s4 + u3]);
        }
        d3.splice(0, 0, p3), d3.splice(i3 ? 3 : 1, 0, m3);
      }, Aa2 = (e3, t3) => {
        let n3 = e3.kernelShape.slice();
        if (0 === e3.kernelShape.length || 0 === e3.kernelShape.reduce(((e4, t4) => e4 * t4), 1)) {
          n3.length = 0;
          for (let e4 = 2; e4 < t3[1].dims.length; ++e4) n3.push(t3[1].dims[e4]);
        }
        let r3 = "NHWC" === e3.format;
        n3.splice(0, 0, t3[1].dims[0]), n3.splice(r3 ? 3 : 1, 0, t3[1].dims[1]);
        let s3 = e3.pads.slice(), a3 = e3.outputShape.slice(), o3 = e3.outputPadding.slice(), i3 = t3[0].dims, l3 = e3.dilations.slice();
        if (0 === l3.reduce(((e4, t4) => e4 + t4), 0)) {
          let e4 = t3[0].dims.length - 2;
          l3 = new Array(e4).fill(1);
        }
        let d3 = e3.strides.slice();
        if (0 === d3.reduce(((e4, t4) => e4 + t4), 0)) {
          let e4 = t3[0].dims.length - 2;
          d3 = new Array(e4).fill(1);
        }
        Ia2(i3, n3, l3, e3.autoPad, e3.group, s3, d3, r3, o3, a3);
        let u3 = Object.assign({}, e3);
        return Object.assign(u3, { kernelShape: n3, pads: s3, outputPadding: o3, outputShape: a3, dilations: l3, strides: d3 }), u3;
      }, za2 = (e3) => {
        let t3 = Qs2(e3), n3 = e3.format, r3 = ["NOTSET", "VALID", "SAME_UPPER", "SAME_LOWER"][typeof e3.autoPad > "u" ? 0 : e3.autoPad], s3 = e3.dilations, a3 = e3.group, o3 = e3.kernelShape, i3 = e3.pads, l3 = e3.strides, d3 = e3.wIsConst();
        return { autoPad: r3, format: n3, dilations: s3, group: a3, kernelShape: o3, outputPadding: e3.outputPadding, outputShape: e3.outputShape, pads: i3, strides: l3, wIsConst: d3, ...t3, cacheKey: `${e3.format};${t3.activation};` };
      }, La2 = (e3, t3) => {
        if (!e3 || 2 !== e3.length && 3 !== e3.length) throw new Error("Conv requires 2 or 3 inputs");
        if (4 !== e3[0].dims.length && 3 !== e3[0].dims.length) throw new Error("currently only support 2-dimensional conv");
        if (e3[0].dims.length !== e3[1].dims.length) throw new Error("filter does not have same dimension as input");
        if (e3[0].dims["NHWC" === t3.format ? e3[0].dims.length - 1 : 1] !== e3[1].dims[0]) throw new Error("FILTER_IN_CHANNEL should be equal to DATA_CHANNEL");
        let n3 = e3[1].dims[1] * t3.group;
        if (3 === e3.length && (1 !== e3[2].dims.length || e3[2].dims[0] !== n3)) throw new Error("invalid bias");
        let r3 = e3[0].dims.length - 2;
        if (t3.dilations.reduce(((e4, t4) => e4 + t4), 0) > 0 && t3.dilations.length !== r3) throw new Error(`dilations should be ${r3}D`);
        if (t3.strides.reduce(((e4, t4) => e4 + t4), 0) > 0 && t3.strides.length !== r3) throw new Error(`strides should be ${r3}D`);
        if (t3.pads.reduce(((e4, t4) => e4 + t4), 0) > 0 && t3.pads.length !== 2 * r3) throw new Error(`pads should be ${2 * r3}D`);
        if (t3.outputPadding.length !== r3 && 0 !== t3.outputPadding.length) throw new Error(`output_padding should be ${r3}D`);
        if (t3.kernelShape.reduce(((e4, t4) => e4 + t4), 0) > 0 && 0 !== t3.kernelShape.length && t3.kernelShape.length !== e3[1].dims.length - 2) throw new Error("invalid kernel shape");
        if (0 !== t3.outputShape.length && t3.outputShape.length !== e3[0].dims.length - 2) throw new Error("invalid output shape");
      }, Oa2 = (e3, t3, n3, r3) => {
        let s3 = e3.kernelCustomData.wT ?? e3.compute(gn2(t3[1], [2, 3, 0, 1]), { inputs: [1], outputs: [n3.wIsConst ? -2 : -1] })[0];
        n3.wIsConst && !e3.kernelCustomData.wT && (e3.kernelCustomData.wT = s3);
        let a3 = [t3[0], s3];
        3 === t3.length && a3.push(t3[2]), e3.compute(Sa2(a3, n3, r3), { inputs: a3 });
      }, Da2 = (e3, t3) => {
        let n3 = "NHWC" === t3.format, r3 = [e3.inputs[0].reshape(n3 ? [e3.inputs[0].dims[0], 1, e3.inputs[0].dims[1], e3.inputs[0].dims[2]] : [e3.inputs[0].dims[0], e3.inputs[0].dims[1], 1, e3.inputs[0].dims[2]]), e3.inputs[1].reshape([e3.inputs[1].dims[0], e3.inputs[1].dims[1], 1, e3.inputs[1].dims[2]])];
        3 === e3.inputs.length && r3.push(e3.inputs[2]);
        let s3 = t3.kernelShape;
        (0 === s3.length || 0 === s3[0]) && (s3 = [e3.inputs[1].dims[2]]);
        let a3 = t3.dilations;
        (0 === a3.length || 0 === a3[0]) && (a3 = [1]);
        let o3 = t3.strides;
        (0 === o3.length || 0 === o3[0]) && (o3 = [1]);
        let i3 = t3.pads;
        0 === i3.length && (i3 = [0, 0]), i3 = [0, i3[0], 0, i3[1]], o3 = [1].concat(o3), a3 = [1].concat(a3), s3 = [1].concat(s3);
        let l3 = t3.outputPadding;
        l3 = [0].concat(l3);
        let d3 = Aa2({ ...t3, pads: i3, strides: o3, dilations: a3, kernelShape: s3, outputPadding: l3 }, r3);
        Oa2(e3, r3, d3, ((e4) => n3 ? [e4[0], e4[2], e4[3]] : [e4[0], e4[1], e4[3]]));
      }, Ba2 = (e3, t3) => {
        if (La2(e3.inputs, t3), 3 === e3.inputs[0].dims.length) Da2(e3, t3);
        else {
          let n3 = Aa2(t3, e3.inputs);
          Oa2(e3, e3.inputs, n3);
        }
      };
    })), Vd2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), Na2 = (e3, t3, n3, r3) => {
        let s3 = gt2.size(t3), a3 = t3.length, o3 = sn2("input", e3, a3), i3 = an2("output", e3, a3), l3 = 6 === n3.dataType ? n3.getInt32Array()[0] : Number(n3.getBigInt64Array()[0]), d3 = gt2.normalizeAxis(l3, a3);
        return { name: "CumSum", shaderCache: { hint: r3.cacheKey, inputDependencies: ["rank"] }, getRunData: () => ({ outputs: [{ dims: t3, dataType: e3 }], dispatchGroup: { x: Math.ceil(s3 / 64) }, programUniforms: [{ type: 12, data: s3 }, { type: 12, data: d3 }, ...Jt2(t3, t3)] }), getShaderSource: (e4) => {
          let t4 = ` i32(${o3.indicesGet("inputIndices", "uniforms.axis")}) `, n4 = nn2("uniforms.input_shape", "uniforms.axis", a3), s4 = r3.reverse ? t4 + (r3.exclusive ? " + 1" : "") : "0", l4 = r3.reverse ? n4 : t4 + (r3.exclusive ? "" : " + 1");
          return `
                ${e4.registerUniform("outputSize", "u32").registerUniform("axis", "u32").declareVariables(o3, i3)}
                ${e4.mainStart()}
                  ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
                  var inputIndices = ${i3.offsetToIndices("global_idx")};
                  var sum = ${i3.type.value}(0);
                  let first : i32 = ${s4};
                  let last : i32 = ${l4};
                  for (var i : i32 = first; i < last; i++) {
                    ${o3.indicesSet("inputIndices", "uniforms.axis", "u32(i)")};
                    sum = sum + ${o3.getByIndices("inputIndices")};
                  }
                  ${i3.setByOffset("global_idx", "sum")};
                }`;
        } };
      }, ja2 = (e3, t3) => {
        let n3 = e3.inputs[0].dims, r3 = e3.inputs[0].dataType, s3 = e3.inputs[1];
        e3.compute(Na2(r3, n3, s3, t3), { inputs: [0] });
      }, Ra2 = (e3) => {
        let t3 = 1 === e3.exclusive, n3 = 1 === e3.reverse;
        return Wt2({ exclusive: t3, reverse: n3 });
      };
    })), Gd2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), Va2 = (e3) => {
        if (!e3 || 1 !== e3.length) throw new Error("DepthToSpace requires 1 input.");
        if (4 !== e3[0].dims.length) throw new Error("DepthToSpace requires 4D input.");
      }, Ga2 = (e3, t3, n3, r3) => {
        let s3 = [];
        s3.push(`fn perm(i: ${r3.type.indices}) -> ${n3.type.indices} {
    var a: ${n3.type.indices};`);
        for (let r4 = 0; r4 < t3; ++r4) s3.push(n3.indicesSet("a", e3[r4], `i[${r4}]`));
        return s3.push("return a;}"), s3.join("\n");
      }, qa2 = (e3, t3) => {
        let n3, r3, s3, a3, o3, i3, l3 = "NHWC" === t3.format, d3 = t3.blocksize, u3 = "DCR" === t3.mode;
        l3 ? ([n3, r3, s3, a3] = e3.dims, o3 = u3 ? [n3, r3, s3, d3, d3, a3 / d3 ** 2] : [n3, r3, s3, a3 / d3 ** 2, d3, d3], i3 = u3 ? [0, 1, 3, 2, 4, 5] : [0, 1, 4, 2, 5, 3]) : ([n3, r3, s3, a3] = [e3.dims[0], e3.dims[2], e3.dims[3], e3.dims[1]], o3 = u3 ? [n3, d3, d3, a3 / d3 ** 2, r3, s3] : [n3, a3 / d3 ** 2, d3, d3, r3, s3], i3 = u3 ? [0, 3, 4, 1, 5, 2] : [0, 1, 4, 2, 5, 3]);
        let c3 = e3.reshape(o3), p3 = c3.dims.length, m3 = e3.dataType, h3 = sn2("a", m3, p3), f3 = an2("output", m3, p3);
        return { name: "DepthToSpace", shaderCache: { hint: `${e3.dims};${t3.blocksize};${t3.mode}`, inputDependencies: ["rank"] }, getRunData: (e4) => {
          let t4 = l3 ? [n3, r3 * d3, s3 * d3, a3 / d3 ** 2] : [n3, a3 / d3 ** 2, r3 * d3, s3 * d3], o4 = gt2.size(t4), u4 = c3.dims, p4 = gt2.sortBasedOnPerm(u4, i3);
          return { outputs: [{ dims: t4, dataType: e4[0].dataType }], dispatchGroup: { x: Math.ceil(o4 / 64) }, programUniforms: [{ type: 12, data: o4 }, ...Jt2(u4, p4)] };
        }, getShaderSource: (e4) => `
  ${e4.registerUniform("output_size", "u32").declareVariables(h3, f3)}

  ${Ga2(i3, p3, h3, f3)}

  ${e4.mainStart()}
    ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}

    let indices = ${f3.offsetToIndices("global_idx")};
    let aIndices = perm(indices);

    ${f3.setByOffset("global_idx", h3.getByIndices("aIndices"))}
  }` };
      }, Ua2 = (e3, t3) => {
        Va2(e3.inputs), e3.compute(qa2(e3.inputs[0], t3));
      }, Wa2 = (e3) => Wt2({ blocksize: e3.blocksize, mode: e3.mode, format: e3.format });
    })), qd2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), Ka2 = "^" + (Qa2 = "(" + (Ha2 = "[a-zA-Z]|\\.\\.\\.") + ")+") + "$", Xa2 = "^" + ("(" + Qa2 + ",)*" + Qa2) + "$", Ja2 = class {
        constructor(e3 = -1) {
          this.symbolToIndices = /* @__PURE__ */ new Map(), this.inputIndex = e3;
        }
        addSymbol(e3, t3) {
          let n3 = this.symbolToIndices.get(e3);
          void 0 === n3 ? n3 = [t3] : n3.push(t3), this.symbolToIndices.set(e3, n3);
        }
      }, Ya2 = class {
        constructor(e3, t3) {
          this.equation = t3, this.hasEllipsis = false, this.symbolToInfo = /* @__PURE__ */ new Map(), this.lhs = new Array(), this.outputDims = [];
          let [n3, r3] = t3.includes("->") ? t3.split("->", 2) : [t3, ""];
          if (!n3.match(RegExp(Xa2))) throw new Error("Invalid LHS term");
          if (n3.split(",").forEach(((t4, n4) => {
            let r4 = e3[n4].dims.slice();
            if (!t4.match(RegExp(Ka2))) throw new Error("Invalid LHS term");
            let s3 = this.processTerm(t4, true, r4, n4);
            this.lhs.push(s3);
          })), "" === r3) r3 += [...this.symbolToInfo.entries()].filter((([e4, t4]) => 1 === t4.count || "..." === e4)).map((([e4]) => e4)).join("");
          else if (!r3.match(RegExp(Qa2))) throw new Error("Invalid RHS");
          r3.match(RegExp(Ha2, "g"))?.forEach(((e4) => {
            if ("..." === e4) this.outputDims = this.outputDims.concat(this.ellipsisDims);
            else {
              let t4 = this.symbolToInfo.get(e4);
              if (void 0 === t4) throw new Error("Invalid RHS symbol");
              this.outputDims.push(t4.dimValue);
            }
          })), this.rhs = this.processTerm(r3, false, this.outputDims);
        }
        addSymbol(e3, t3, n3) {
          let r3 = this.symbolToInfo.get(e3);
          if (void 0 !== r3) {
            if (r3.dimValue !== t3 && 1 !== r3.count) throw new Error("Dimension mismatch");
            r3.count++, r3.inputIndices.push(n3);
          } else r3 = { count: 1, dimValue: t3, inputIndices: [n3] };
          this.symbolToInfo.set(e3, r3);
        }
        processTerm(e3, t3, n3, r3 = -1) {
          let s3 = n3.length, a3 = false, o3 = [], i3 = 0;
          if (!e3.match(RegExp(Ka2)) && !t3 && "" !== e3) throw new Error("Invalid LHS term");
          let l3 = e3.match(RegExp(Ha2, "g")), d3 = new Ja2(r3);
          return l3?.forEach(((e4, u3) => {
            if ("..." === e4) {
              if (a3) throw new Error("Only one ellipsis is allowed per input term");
              a3 = true;
              let e5 = s3 - l3.length + 1;
              if (e5 < 0) throw new Error("Ellipsis out of bounds");
              if (o3 = n3.slice(i3, i3 + e5), this.hasEllipsis) {
                if (this.ellipsisDims.length !== o3.length || this.ellipsisDims.toString() !== o3.toString()) throw new Error("Ellipsis dimensions mismatch");
              } else {
                if (!t3) throw new Error("Ellipsis must be specified in the LHS");
                this.hasEllipsis = true, this.ellipsisDims = o3;
              }
              for (let e6 = 0; e6 < o3.length; e6++) {
                let t4 = String.fromCharCode(48 + e6);
                d3.addSymbol(t4, u3 + e6), this.addSymbol(t4, n3[i3++], r3);
              }
            } else d3.addSymbol(e4, u3 + (this.hasEllipsis ? this.ellipsisDims.length - 1 : 0)), this.addSymbol(e4, n3[i3++], r3);
          })), d3;
        }
      }, Za2 = (e3) => e3 + "_max", eo2 = (e3, t3, n3, r3) => {
        let s3 = e3.map(((e4) => e4.length)).map(((e4, n4) => sn2(`input${n4}`, t3, e4))), a3 = gt2.size(r3), o3 = an2("output", t3, r3.length), i3 = [...n3.symbolToInfo.keys()].filter(((e4) => !n3.rhs.symbolToIndices.has(e4)));
        return { name: "Einsum", shaderCache: { hint: n3.equation, inputDependencies: e3.map((() => "rank")) }, getRunData: () => {
          let s4 = i3.filter(((e4) => n3.symbolToInfo.has(e4))).map(((e4) => ({ type: 12, data: n3.symbolToInfo.get(e4)?.dimValue || 0 })));
          s4.push({ type: 12, data: a3 });
          let o4 = e3.map(((e4, t4) => [...Jt2(e4)])).reduce(((e4, t4) => e4.concat(t4)), s4);
          return o4.push(...Jt2(r3)), { outputs: [{ dims: r3, dataType: t3 }], dispatchGroup: { x: Math.ceil(a3 / 64) }, programUniforms: o4 };
        }, getShaderSource: (e4) => {
          let t4 = [], r4 = [], a4 = [], l3 = [], d3 = [], u3 = n3.symbolToInfo.size === n3.rhs.symbolToIndices.size;
          n3.symbolToInfo.forEach(((e5, i4) => {
            if (n3.rhs.symbolToIndices.has(i4)) {
              let r5 = n3.rhs.symbolToIndices.get(i4)?.[0];
              void 0 !== r5 && n3.lhs.forEach(((n4, a5) => {
                if (e5.inputIndices.includes(a5)) {
                  let e6 = n4.symbolToIndices.get(i4);
                  if (void 0 === e6) throw new Error("Invalid symbol error");
                  e6.forEach(((e7) => {
                    t4.push(`${s3[a5].indicesSet(`input${a5}Indices`, e7, o3.indicesGet("outputIndices", r5))}`);
                  }));
                }
              }));
            } else n3.lhs.forEach(((t5, n4) => {
              if (e5.inputIndices.includes(n4)) {
                let e6 = t5.symbolToIndices.get(i4);
                if (void 0 === e6) throw new Error("Invalid symbol error");
                e6.forEach(((e7) => {
                  r4.push(`${s3[n4].indicesSet(`input${n4}Indices`, e7, `${i4}`)}`);
                })), d3.push(`prod *= ${s3[n4].getByIndices(`input${n4}Indices`)};`);
              }
            })), a4.push(`for(var ${i4}: u32 = 0; ${i4} < uniforms.${Za2(i4)}; ${i4}++) {`), l3.push("}");
          }));
          let c3 = u3 ? [...t4, `let sum = ${s3.map(((e5, t5) => e5.getByIndices(`input${t5}Indices`))).join(" * ")};`] : [...t4, "var sum = 0.0;", ...a4, ...r4, "var prod = 1.0;", ...d3, "sum += prod;", ...l3];
          return `
            ${e4.registerUniforms(i3.map(((e5) => ({ name: `${Za2(e5)}`, type: "u32" })))).registerUniform("outputSize", "u32").declareVariables(...s3, o3)}

            ${e4.mainStart()}
            ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
            var outputIndices = ${o3.offsetToIndices("global_idx")};
            ${s3.map(((e5, t5) => `var input${t5}Indices: ${s3[t5].type.indices};`)).join("\n")}
            ${c3.join("\n")};
            ${o3.setByOffset("global_idx", "sum")};
          }`;
        } };
      }, to2 = (e3, t3) => {
        let n3 = new Ya2(e3.inputs, t3.equation), r3 = n3.outputDims, s3 = e3.inputs.map(((e4, t4) => e4.dims));
        e3.compute(eo2(s3, e3.inputs[0].dataType, n3, r3));
      }, no2 = (e3) => {
        let t3 = e3.equation.replace(/\s+/g, "");
        return Wt2({ equation: t3 });
      };
    })), Ud2 = j2((() => {
      dd2(), pd2(), bd2(), ro2 = (e3) => {
        if (!e3 || 2 !== e3.length) throw new Error("Expand requires 2 input.");
        let t3 = e3[0].dims, n3 = Array.from(e3[1].getBigInt64Array(), Number), r3 = n3.length < t3.length ? 0 : n3.length - t3.length, s3 = t3.length < n3.length ? 0 : t3.length - n3.length;
        for (; r3 < n3.length && s3 < t3.length; ++r3, ++s3) if (n3[r3] !== t3[s3] && 1 !== n3[r3] && 1 !== t3[s3]) throw new Error("Expand requires shape to be broadcastable to input");
      }, so2 = (e3, t3) => {
        let n3 = e3.length - t3.length, r3 = [];
        for (let t4 = 0; t4 < n3; ++t4) r3.push(e3[t4]);
        for (let s3 = 0; s3 < t3.length; ++s3) r3.push(1 === t3[s3] ? e3[s3 + n3] : t3[s3]);
        return r3;
      }, ao2 = (e3, t3) => e3.length > t3.length ? so2(e3, t3) : so2(t3, e3), oo2 = (e3) => {
        let t3 = e3[0].dims, n3 = Array.from(e3[1].getBigInt64Array(), Number), r3 = ao2(t3, n3), s3 = e3[0].dataType, a3 = 9 === s3 || 1 === gt2.size(t3), o3 = 9 === s3 || t3.length > 0 && t3[t3.length - 1] % 4 == 0 ? 4 : 1, i3 = a3 || r3.length > 0 && r3[r3.length - 1] % 4 == 0 ? 4 : 1, l3 = Math.ceil(gt2.size(r3) / i3), d3 = [{ type: 12, data: l3 }, ...Jt2(t3, r3)];
        return { name: "Expand", shaderCache: { hint: `${r3.length};${o3}${i3}`, inputDependencies: ["rank"] }, getShaderSource: (e4) => {
          let n4, a4 = sn2("input", s3, t3.length, o3), l4 = an2("output", s3, r3.length, i3);
          if (9 === s3) {
            let e5 = (e6, t4, n5 = "") => `
          let outputIndices${t4} = ${l4.offsetToIndices(`outputOffset + ${t4}u`)};
          let offset${t4} = ${a4.broadcastedIndicesToOffset(`outputIndices${t4}`, l4)};
          let index${t4} = offset${t4} / 4u;
          let component${t4} = offset${t4} % 4u;
          ${e6}[${t4}] = ${n5}(${a4.getByOffset(`index${t4}`)}[component${t4}]);
        `;
            n4 = `
        let outputOffset = global_idx * ${i3};
        var data = vec4<u32>(0);
        ${e5("data", 0, "u32")}
        ${e5("data", 1, "u32")}
        ${e5("data", 2, "u32")}
        ${e5("data", 3, "u32")}
        ${l4.setByOffset("global_idx", "data")}
      }`;
          } else n4 = `
        let outputIndices = ${l4.offsetToIndices(`global_idx * ${i3}`)};
        let inputOffset = ${a4.broadcastedIndicesToOffset("outputIndices", l4)};
        let data = ${l4.type.value}(${a4.getByOffset(`inputOffset / ${o3}`)});
        ${l4.setByOffset("global_idx", "data")}
      }`;
          return `
    ${e4.registerUniform("vec_size", "u32").declareVariables(a4, l4)}
    ${e4.mainStart()}
    ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}
    ${n4}`;
        }, getRunData: () => ({ outputs: [{ dims: r3, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(l3 / 64) }, programUniforms: d3 }) };
      }, io2 = (e3) => {
        ro2(e3.inputs), e3.compute(oo2(e3.inputs), { inputs: [0] });
      };
    })), Wd2 = j2((() => {
      dd2(), pd2(), bd2(), $d2(), lo2 = (e3) => {
        let t3 = e3[0].dataType, n3 = gt2.size(e3[0].dims), r3 = gt2.size(e3[1].dims), s3 = r3 % 4 == 0;
        return { name: "FastGeluWithBias", shaderCache: { hint: `${s3}`, inputDependencies: ["type", "type"] }, getShaderSource: (e4) => {
          let n4 = sn2("x", t3, [1], 4), r4 = sn2("bias", t3, [1], 4), a3 = an2("y", t3, [1], 4), o3 = (e5) => `
      let bias${e5}_offset: u32 = (global_idx * 4 + ${e5}) % uniforms.bias_size;
      let bias${e5} = ${r4.getByOffset(`bias${e5}_offset / 4`)}[bias${e5}_offset % 4];`, i3 = s3 ? `
      let bias = ${r4.getByOffset("global_idx % (uniforms.bias_size / 4)")};` : `${o3(0)}${o3(1)}${o3(2)}${o3(3)}
      let bias = ${n4.type.value}(bias0, bias1, bias2, bias3);`;
          return `${e4.registerUniforms([{ name: "output_vec_size", type: "u32" }, { name: "bias_size", type: "u32" }]).declareVariables(n4, r4, a3)}

    ${fs2(Xt2(t3))}

    ${e4.mainStart(Ht2)}
      ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_vec_size")}

      let x = ${n4.getByOffset("global_idx")};
      ${i3}
      let x_in = x + bias;
      ${a3.setByOffset("global_idx", _s2("x_in"))}
    }`;
        }, getRunData: (e4) => ({ outputs: [{ dims: e4[0].dims, dataType: e4[0].dataType }], programUniforms: [{ type: 12, data: Math.ceil(n3 / 4) }, { type: 12, data: r3 }], dispatchGroup: { x: Math.ceil(n3 / Ht2 / 4) } }) };
      }, uo2 = (e3) => {
        e3.inputs.length < 2 || 0 === gt2.size(e3.inputs[1].dims) ? gs2(e3) : e3.compute(lo2(e3.inputs));
      };
    })), Hd2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), co2 = (e3) => {
        if (!e3 || 2 !== e3.length) throw new Error("Gather requires 2 inputs.");
      }, po2 = (e3, t3) => {
        let n3 = e3[0].dims, r3 = e3[1].dims, s3 = n3.length, a3 = gt2.normalizeAxis(t3.axis, s3), o3 = n3.slice(0);
        o3.splice(a3, 1, ...r3);
        let i3 = n3[a3], l3 = 9 === e3[0].dataType ? 4 : 1, d3 = Math.ceil(gt2.size(o3) / l3), u3 = [{ type: 12, data: d3 }, { type: 6, data: i3 }, { type: 12, data: a3 }, ...Jt2(e3[0].dims, e3[1].dims, o3)];
        return { name: "Gather", shaderCache: { hint: t3.cacheKey, inputDependencies: ["rank", "rank"] }, getRunData: () => ({ outputs: [{ dims: o3, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(d3 / 64) }, programUniforms: u3 }), getShaderSource: (t4) => {
          let n4, i4 = sn2("data", e3[0].dataType, e3[0].dims.length, l3), d4 = sn2("inputIndices", e3[1].dataType, e3[1].dims.length), u4 = an2("output", e3[0].dataType, o3.length, l3), c3 = (e4) => {
            let t5 = r3.length, n5 = `var indicesIndices${e4}  = ${d4.type.indices}(0);`;
            for (let r4 = 0; r4 < t5; r4++) n5 += `${t5 > 1 ? `indicesIndices${e4}[${r4}]` : `indicesIndices${e4}`} = ${o3.length > 1 ? `outputIndices${e4}[uniforms.axis + ${r4}]` : `outputIndices${e4}`};`;
            n5 += `
          var idx${e4} = ${d4.getByIndices(`indicesIndices${e4}`)};
          if (idx${e4} < 0) {
            idx${e4} = idx${e4} + uniforms.axisDimLimit;
          }
          var dataIndices${e4} : ${i4.type.indices};
        `;
            for (let r4 = 0, i5 = 0; r4 < s3; r4++) r4 === a3 ? (n5 += `${s3 > 1 ? `dataIndices${e4}[${r4}]` : `dataIndices${e4}`} = u32(idx${e4});`, i5 += t5) : (n5 += `${s3 > 1 ? `dataIndices${e4}[${r4}]` : `dataIndices${e4}`} = ${o3.length > 1 ? `outputIndices${e4}[${i5}]` : `outputIndices${e4}`};`, i5++);
            return n5;
          };
          if (9 === e3[0].dataType) {
            let e4 = (e5, t5, n5 = "") => `
          let outputIndices${t5} = ${u4.offsetToIndices(`outputOffset + ${t5}u`)};
          ${c3(t5)};
          let offset${t5} = ${i4.indicesToOffset(`dataIndices${t5}`)};
          let index${t5} = offset${t5} / 4u;
          let component${t5} = offset${t5} % 4u;
          ${e5}[${t5}] = ${n5}(${i4.getByOffset(`index${t5}`)}[component${t5}]);
        `;
            n4 = `
        let outputOffset = global_idx * ${l3};
        var value = vec4<u32>(0);
        ${e4("value", 0, "u32")}
        ${e4("value", 1, "u32")}
        ${e4("value", 2, "u32")}
        ${e4("value", 3, "u32")}
        ${u4.setByOffset("global_idx", "value")}
      `;
          } else n4 = `
      let outputIndices = ${u4.offsetToIndices("global_idx")};
      ${c3("")};
      let value = ${i4.getByIndices("dataIndices")};
      ${u4.setByOffset("global_idx", "value")};
      `;
          return `
      ${t4.registerUniform("outputSize", "u32").registerUniform("axisDimLimit", "i32").registerUniform("axis", "u32").declareVariables(i4, d4, u4)}
      ${t4.mainStart()}
        ${t4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
        ${n4}
      }`;
        } };
      }, mo2 = (e3) => Wt2({ axis: e3.axis }), ho2 = (e3, t3) => {
        let n3 = e3.inputs;
        co2(n3), e3.compute(po2(e3.inputs, t3));
      };
    })), Qd2 = j2((() => {
      dd2(), pd2(), bd2(), fo2 = (e3, t3, n3, r3, s3, a3, o3, i3, l3) => {
        let d3 = [{ type: 12, data: a3 }, { type: 12, data: r3 }, { type: 12, data: s3 }, { type: 12, data: n3 }, { type: 12, data: o3 }, { type: 12, data: i3 }, { type: 12, data: l3 }], u3 = [a3];
        d3.push(...Jt2(t3.dims, u3));
        return e3.compute({ name: "computeSliceOffsets", shaderCache: { hint: `${s3.length}_${n3.length}`, inputDependencies: ["rank"] }, getRunData: () => ({ outputs: [{ dims: u3, dataType: e3.inputs[1].dataType }], dispatchGroup: { x: Math.ceil(a3 / 64) }, programUniforms: d3 }), getShaderSource: (e4) => {
          let r4 = [sn2("indices_data", t3.dataType, t3.dims.length), an2("input_slice_offsets_data", 12, 1, 1)], a4 = [{ name: "output_size", type: "u32" }, { name: "batch_dims", type: "u32" }, { name: "input_dims", type: "u32", length: s3.length }, { name: "sizes_from_slice_dims_data", type: "u32", length: n3.length }, { name: "num_slices_per_batch", type: "u32" }, { name: "input_batch_stride", type: "u32" }, { name: "num_slice_dims", type: "u32" }];
          return `
  ${e4.registerUniforms(a4).declareVariables(...r4)}
  ${e4.mainStart()}
    ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
    let batch_idx = global_idx / uniforms.num_slices_per_batch;
    let base_offset = batch_idx * uniforms.input_batch_stride;

    let slice_indices_base_offset = global_idx * uniforms.num_slice_dims;
    var relative_slice_offset = 0;
    for (var dim_idx = 0u; dim_idx < uniforms.num_slice_dims; dim_idx ++) {
      var index = i32(indices_data[dim_idx + slice_indices_base_offset].x);
      let input_dim_idx = uniforms.batch_dims + dim_idx;
      if (index < 0) {
        ${1 === s3.length ? "index += i32(uniforms.input_dims);" : "index += i32(uniforms.input_dims[input_dim_idx]);"}
      }
      ${1 === n3.length ? "relative_slice_offset += index * i32(uniforms.sizes_from_slice_dims_data);" : "relative_slice_offset += index * i32(uniforms.sizes_from_slice_dims_data[dim_idx]);"}
    }

    input_slice_offsets_data[global_idx] =  base_offset + u32(relative_slice_offset);
  }`;
        } }, { inputs: [t3], outputs: [-1] })[0];
      }, _o2 = (e3, t3) => {
        let n3 = e3.inputs, r3 = n3[0].dims, s3 = n3[0].dataType, a3 = n3[1].dims, o3 = a3[a3.length - 1], i3 = gt2.sizeToDimension(a3, a3.length - 1), l3 = gt2.sizeFromDimension(r3, t3.batchDims + o3), d3 = gt2.sizeToDimension(r3, t3.batchDims), u3 = gt2.sizeFromDimension(r3, t3.batchDims), c3 = i3 / d3, p3 = new Array(o3), m3 = l3;
        for (let e4 = 0; e4 < o3; ++e4) p3[o3 - 1 - e4] = m3, m3 *= r3[t3.batchDims + o3 - 1 - e4];
        let h3 = fo2(e3, n3[1], p3, t3.batchDims, r3, i3, c3, u3, o3), f3 = t3.batchDims + o3;
        if (f3 > r3.length) throw new Error("last dimension of indices must not be larger than rank of input tensor");
        let _3 = a3.slice(0, -1).concat(r3.slice(f3)), g3 = gt2.size(_3), w3 = [{ type: 12, data: g3 }, { type: 12, data: l3 }, ...Jt2(n3[0].dims, h3.dims, _3)];
        e3.compute({ name: "GatherND", shaderCache: { hint: t3.cacheKey, inputDependencies: ["rank", "rank"] }, getRunData: () => ({ outputs: [{ dims: _3, dataType: s3 }], dispatchGroup: { x: Math.ceil(g3 / 64) }, programUniforms: w3 }), getShaderSource: (e4) => {
          let t4 = sn2("data", n3[0].dataType, n3[0].dims.length), r4 = sn2("slice_offsets", 12, h3.dims.length), s4 = an2("output", n3[0].dataType, _3.length);
          return `
          ${e4.registerUniform("output_size", "u32").registerUniform("slice_size", "u32").declareVariables(t4, r4, s4)}
            ${e4.mainStart()}
            ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
          let slice_offset = slice_offsets[global_idx / uniforms.slice_size];
          output[global_idx] = data[u32(slice_offset) + global_idx % uniforms.slice_size];
        }`;
        } }, { inputs: [n3[0], h3] });
      }, go2 = (e3) => ({ batchDims: e3.batch_dims, cacheKey: "" });
    })), Kd2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), wo2 = (e3, t3) => {
        if (e3.length < 3 || e3.length > 4) throw new Error("GatherBlockQuantized requires 3 or 4 inputs.");
        let n3 = gt2.normalizeAxis(t3.quantizeAxis, e3[0].dims.length), r3 = t3.blockSize, s3 = e3[0], a3 = e3[2], o3 = 4 === e3.length ? e3[3] : void 0;
        if (a3.dims.length !== s3.dims.length || !s3.dims.map(((e4, t4) => t4 === n3 ? Math.ceil(e4 / r3) === a3.dims[t4] : e4 === a3.dims[t4])).reduce(((e4, t4) => e4 && t4), true)) throw new Error("Scales must have the same rank as the input tensor and the dims should match except on gatherAxis.");
        if (o3) {
          if (o3.dataType !== s3.dataType) throw new Error("Zero point must have the same data type as the input tensor.");
          if (o3.dims.length !== a3.dims.length || !o3.dims.map(((e4, t4) => e4 === a3.dims[t4])).reduce(((e4, t4) => e4 && t4), true)) throw new Error("Zero point must have the same rank as the input tensor and the dims should match except on quantizeAxis.");
        }
      }, bo2 = (e3, t3) => {
        let n3 = e3[0].dims, r3 = e3[1].dims, s3 = n3.length, a3 = gt2.normalizeAxis(t3.gatherAxis, s3), o3 = gt2.normalizeAxis(t3.quantizeAxis, s3), i3 = n3.slice(0);
        i3.splice(a3, 1, ...r3);
        let l3 = gt2.size(i3), d3 = e3[2].dataType, u3 = 22 === e3[0].dataType, c3 = [{ type: 12, data: l3 }, { type: 12, data: o3 }, { type: 12, data: a3 }, { type: 12, data: t3.blockSize }, ...Jt2(...e3.map(((e4, t4) => e4.dims)), i3)];
        return { name: "GatherBlockQuantized", shaderCache: { hint: `${t3.cacheKey};${e3.filter(((e4, t4) => 1 !== t4)).map(((e4) => e4.dims.join("_"))).join(";")}`, inputDependencies: Array.from({ length: e3.length }, ((e4, t4) => "rank")) }, getRunData: () => ({ outputs: [{ dims: i3, dataType: d3 }], dispatchGroup: { x: Math.ceil(l3 / 64) }, programUniforms: c3 }), getShaderSource: (t4) => {
          let s4 = sn2("data", e3[0].dataType, e3[0].dims.length), o4 = sn2("inputIndices", e3[1].dataType, e3[1].dims.length), l4 = sn2("scales", e3[2].dataType, e3[2].dims.length), c4 = e3.length > 3 ? sn2("zeroPoint", e3[3].dataType, e3[3].dims.length) : void 0, p3 = an2("output", d3, i3.length), m3 = [s4, o4, l4];
          c4 && m3.push(c4);
          return `
        ${t4.registerUniforms([{ name: "output_size", type: "u32" }, { name: "quantize_axis", type: "u32" }, { name: "gather_axis", type: "u32" }, { name: "block_size", type: "u32" }]).declareVariables(...m3, p3)}
        ${t4.mainStart()}
        let output_indices = ${p3.offsetToIndices("global_idx")};
        var indices_indices = ${o4.type.indices}(0);
        ${r3.length > 1 ? `
          for (var i: u32 = 0; i < ${r3.length}; i++) {
            let index = ${p3.indicesGet("output_indices", "uniforms.gather_axis + i")};
            ${o4.indicesSet("indices_indices", "i", "index")};
          }` : `indices_indices = ${p3.indicesGet("output_indices", "uniforms.gather_axis")};`};
        var data_indices = ${s4.type.indices}(0);
        for (var i: u32 = 0; i < uniforms.gather_axis; i++) {
          let index = ${p3.indicesGet("output_indices", "i")};
          ${s4.indicesSet("data_indices", "i", "index")};
        }
        var index_from_indices = ${o4.getByIndices("indices_indices")};
        if (index_from_indices < 0) {
          index_from_indices += ${n3[a3]};
        }
        ${s4.indicesSet("data_indices", "uniforms.gather_axis", "u32(index_from_indices)")};
        for (var i = uniforms.gather_axis + 1; i < ${i3.length}; i++) {
          let index = ${p3.indicesGet("output_indices", `i + ${r3.length} - 1`)};
          ${s4.indicesSet("data_indices", "i", "index")};
        }
        let data_offset = ${s4.indicesToOffset("data_indices")};
        let data_index = data_offset % 8;
        // Convert 4-bit packed data to 8-bit packed data.
        let packed_4bit_quantized_data = ${s4.getByOffset("data_offset / 8")};
        let packed_8bit_quantized_data = (packed_4bit_quantized_data >> (4 * (data_index % 2))) & 0x0f0f0f0f;
        let quantized_data_vec = ${u3 ? "unpack4xI8" : "unpack4xU8"}(u32(packed_8bit_quantized_data));
        let quantized_data = quantized_data_vec[data_index / 2];
        var scale_indices = data_indices;
        let quantize_axis_index = ${l4.indicesGet("data_indices", "uniforms.quantize_axis")} / uniforms.block_size;
        ${l4.indicesSet("scale_indices", "uniforms.quantize_axis", "quantize_axis_index")};
        var scale = ${l4.getByIndices("scale_indices")};
        ${c4 ? `
              let zero_point_indices = scale_indices;
              let zero_point_offset = ${c4.indicesToOffset("zero_point_indices")};
              let zero_point_index = zero_point_offset % 8;
              let packed_4bit_zero_points = ${c4.getByOffset("zero_point_offset / 8")};
              let packed_8bit_zero_points = (packed_4bit_zero_points >> (4 * (zero_point_index % 2))) & 0x0f0f0f0f;
              let zero_point_vec = ${u3 ? "unpack4xI8" : "unpack4xU8"}(u32(packed_8bit_zero_points));
              let zero_point = zero_point_vec[zero_point_index / 2];` : "var zero_point = 0"};
        let dequantized_data = ${Xt2(d3)}(quantized_data - zero_point) * scale;
        ${p3.setByOffset("global_idx", "dequantized_data")};
    }`;
        } };
      }, yo2 = (e3, t3) => {
        let n3 = e3.inputs;
        wo2(n3, t3), e3.compute(bo2(e3.inputs, t3));
      }, Mo2 = (e3) => Wt2({ blockSize: e3.blockSize, gatherAxis: e3.gatherAxis, quantizeAxis: e3.quantizeAxis });
    })), Xd2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), xo2 = (e3) => {
        if (!e3 || 2 !== e3.length) throw new Error("GatherElements requires 2 inputs.");
        if (e3[0].dims.length < 1) throw new Error("GatherElements requires that the data input be rank >= 1.");
        if (e3[0].dims.length !== e3[1].dims.length) throw new Error("GatherElements requires that the data input and\n                     indices input tensors be of same rank.");
      }, vo2 = (e3, t3) => {
        let n3 = e3[0].dims, r3 = e3[0].dataType, s3 = n3.length, a3 = e3[1].dims, o3 = e3[1].dataType, i3 = gt2.normalizeAxis(t3.axis, s3), l3 = n3[i3], d3 = a3.slice(0), u3 = gt2.size(d3), c3 = sn2("input", r3, s3), p3 = sn2("indicesInput", o3, a3.length), m3 = an2("output", r3, d3.length), h3 = [{ type: 12, data: u3 }, { type: 6, data: l3 }, { type: 12, data: i3 }];
        return h3.push(...Jt2(n3, a3, d3)), { name: "GatherElements", shaderCache: { inputDependencies: ["rank", "rank"] }, getRunData: () => ({ outputs: [{ dims: d3, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(u3 / 64) }, programUniforms: h3 }), getShaderSource: (e4) => `
      ${e4.registerUniform("outputSize", "u32").registerUniform("axisDimLimit", "i32").registerUniform("axis", "u32").declareVariables(c3, p3, m3)}
      ${e4.mainStart()}
      ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}

      let outputIndices = ${m3.offsetToIndices("global_idx")};

      var idx = ${p3.getByOffset("global_idx")};
      if (idx < 0) {
        idx = idx + uniforms.axisDimLimit;
      }
      var inputIndices = ${c3.type.indices}(outputIndices);
      ${c3.indicesSet("inputIndices", "uniforms.axis", "u32(idx)")};
      let value = ${c3.getByIndices("inputIndices")};

      ${m3.setByOffset("global_idx", "value")};
  }` };
      }, To2 = (e3) => Wt2({ axis: e3.axis }), ko2 = (e3, t3) => {
        let n3 = e3.inputs;
        xo2(n3), e3.compute(vo2(e3.inputs, t3));
      };
    })), Jd2 = j2((() => {
      dd2(), pd2(), bd2(), Po2 = (e3) => {
        if (!e3) throw new Error("Input is missing");
        if (e3.length < 2 || e3.length > 3) throw new Error("Invaid input number.");
        if (3 === e3.length && e3[2].dims.length > 2) throw new Error("Invalid input shape of C");
        if (e3[0].dataType !== e3[1].dataType || 3 === e3.length && e3[0].dataType !== e3[2].dataType) throw new Error("Input types are mismatched");
      }, $o2 = (e3, t3) => {
        let n3 = e3[0].dims.slice(), r3 = e3[1].dims.slice(), [s3, a3, o3] = bt2.getShapeOfGemmResult(n3, t3.transA, r3, t3.transB, 3 === e3.length ? e3[2].dims : void 0), i3 = [s3, a3];
        if (!i3) throw new Error("Can't use gemm on the given tensors");
        let l3 = 16, d3 = Math.ceil(a3 / l3), u3 = Math.ceil(s3 / l3), c3 = (gt2.size(i3), [{ type: 12, data: d3 }, { type: 12, data: s3 }, { type: 12, data: a3 }, { type: 12, data: o3 }, { type: 1, data: t3.alpha }, { type: 1, data: t3.beta }]), p3 = ["type", "type"];
        3 === e3.length && (c3.push(...Jt2(e3[2].dims)), p3.push("rank")), c3.push(...Jt2(i3));
        return { name: "GemmShared", shaderCache: { hint: `${t3.cacheKey}`, inputDependencies: p3 }, getRunData: () => ({ outputs: [{ dims: i3, dataType: e3[0].dataType }], dispatchGroup: { x: d3 * u3 }, programUniforms: c3 }), getShaderSource: (n4) => {
          let r4 = sn2("a", e3[0].dataType, e3[0].dims), s4 = sn2("b", e3[1].dataType, e3[1].dims), a4 = null, o4 = [r4, s4];
          3 === e3.length && (a4 = sn2("c", e3[2].dataType, e3[2].dims.length), o4.push(a4));
          let d4 = an2("output", e3[0].dataType, i3.length);
          o4.push(d4);
          let u4 = "", c4 = "";
          t3.transA && t3.transB ? (c4 = `
      var col = tile_row_start + local_id.x;
      var row = k_start + local_id.y;
      if (col < uniforms.M && row < uniforms.K) {
        tile_a[local_id.y][local_id.x] = a[row * uniforms.M + col];
      } else {
        tile_a[local_id.y][local_id.x] = ${r4.type.value}(0);
      }

      col = k_start + local_id.x;
      row = tile_col_start + local_id.y;
      if (col < uniforms.K && row < uniforms.N) {
        tile_b[local_id.y][local_id.x] = b[row * uniforms.K + col];
      } else {
        tile_b[local_id.y][local_id.x] = ${s4.type.value}(0);
      }
      `, u4 = "value += tile_a[k][local_id.y] * tile_b[local_id.x][k];") : t3.transA && !t3.transB ? (c4 = `
      var col = tile_row_start + local_id.x;
      var row = k_start + local_id.y;
      if (col < uniforms.M && row < uniforms.K) {
        tile_a[local_id.y][local_id.x] = a[row * uniforms.M + col];
      } else {
        tile_a[local_id.y][local_id.x] = ${r4.type.value}(0);
      }

      col = tile_col_start + local_id.x;
      row = k_start + local_id.y;
      if (col < uniforms.N && row < uniforms.K) {
        tile_b[local_id.y][local_id.x] = b[row * uniforms.N + col];
      } else {
        tile_b[local_id.y][local_id.x] = ${s4.type.value}(0);
      }
      `, u4 = "value += tile_a[k][local_id.y] * tile_b[k][local_id.x];") : !t3.transA && t3.transB ? (c4 = `
      var col = k_start + local_id.x;
      var row = tile_row_start + local_id.y;
      if (col < uniforms.K && row < uniforms.M) {
        tile_a[local_id.y][local_id.x] = a[row * uniforms.K + col];
      } else {
        tile_a[local_id.y][local_id.x] = ${r4.type.value}(0);
      }

      col = k_start + local_id.x;
      row = tile_col_start + local_id.y;
      if (col < uniforms.K && row < uniforms.N) {
        tile_b[local_id.y][local_id.x] = b[row * uniforms.K + col];
      } else {
        tile_b[local_id.y][local_id.x] = ${s4.type.value}(0);
      }
      `, u4 = "value += tile_a[local_id.y][k] * tile_b[local_id.x][k];") : !t3.transA && !t3.transB && (c4 = `
      var col = k_start + local_id.x;
      var row = tile_row_start + local_id.y;
      if (col < uniforms.K && row < uniforms.M) {
        tile_a[local_id.y][local_id.x] = a[row * uniforms.K + col];
      } else {
        tile_a[local_id.y][local_id.x] = ${r4.type.value}(0);
      }

      col = tile_col_start + local_id.x;
      row = k_start + local_id.y;
      if (col < uniforms.N && row < uniforms.K) {
        tile_b[local_id.y][local_id.x] = b[row * uniforms.N + col];
      } else {
        tile_b[local_id.y][local_id.x] = ${s4.type.value}(0);
      }
      `, u4 = "value += tile_a[local_id.y][k] * tile_b[k][local_id.x];");
          let p4 = 1 === t3.alpha ? "" : "value *= uniforms.alpha;";
          return `
  ${n4.registerUniforms([{ name: "num_tile_n", type: "u32" }, { name: "M", type: "u32" }, { name: "N", type: "u32" }, { name: "K", type: "u32" }, { name: "alpha", type: "f32" }, { name: "beta", type: "f32" }]).declareVariables(...o4)}
  var<workgroup> tile_a: array<array<${r4.type.storage}, 16>, 16>;
  var<workgroup> tile_b: array<array<${s4.type.storage}, 16>, 16>;
  ${n4.mainStart([l3, l3, 1])}
    let tile_col_start = (workgroup_index % uniforms.num_tile_n) * 16;
    let tile_row_start = (workgroup_index / uniforms.num_tile_n) * 16;
    let num_tiles = (uniforms.K - 1) / 16 + 1;
    var k_start = 0u;
    var value = ${d4.type.value}(0);
    for (var t: u32 = 0u; t < num_tiles; t++) {
      ${c4}
      k_start = k_start + 16;
      workgroupBarrier();

      for (var k: u32 = 0u; k < 16; k++) {
        ${u4}
      }
      workgroupBarrier();
    }

    ${p4}
    let m = tile_row_start + local_id.y;
    let n = tile_col_start + local_id.x;
    ${null != a4 ? `let cOffset = ${a4.broadcastedIndicesToOffset("vec2(m, n)", d4)}; value += ${d4.type.value}(uniforms.beta) * ${a4.getByOffset("cOffset")};` : ""}
    if (m < uniforms.M && n < uniforms.N) {
      output[m * uniforms.N + n] = value;
    }
  }`;
        } };
      }, Co2 = (e3) => ({ transA: e3.transA, transB: e3.transB, alpha: e3.alpha, beta: e3.beta, cacheKey: `${e3.transA};${e3.transB};${1 === e3.alpha}` }), So2 = (e3, t3) => {
        Po2(e3.inputs), e3.compute($o2(e3.inputs, t3));
      };
    })), Yd2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), [Fo2, Eo2, Io2, Ao2] = [0, 1, 2, 3], zo2 = (e3) => {
        if (4 !== e3[0].dims.length) throw new Error("only 4-D tensor is supported.");
        if (e3[0].dims.length !== e3[1].dims.length) throw new Error("input dimensions must be equal to grid dimensions");
        if (e3[0].dims.length - 2 !== e3[1].dims[e3[1].dims.length - 1]) throw new Error("last dimension of grid must be equal to " + (e3[0].dims.length - 2));
        if (e3[0].dims[0] !== e3[1].dims[0]) throw new Error("grid batch size must match input batch size");
      }, Lo2 = (e3) => `
  fn gs_bicubic_interpolate(p: mat4x4<${e3}>, x: f32, y: f32) -> ${e3} {
    var v: vec4<f32>;
    var coeffs = gs_get_cubic_coeffs(x);
    for (var i = 0; i < 4; i++) {
      v[i] = coeffs[0] * p[i][0] + coeffs[1] * p[i][1] + coeffs[2] * p[i][2] + coeffs[3] * p[i][3];
    }
    coeffs = gs_get_cubic_coeffs(y);
    let pixel = ${e3}(coeffs[0] * v[0] + coeffs[1] * v[1] + coeffs[2] * v[2] + coeffs[3] * v[3]);
    return pixel;
  }
`, Oo2 = (e3) => `
  fn gs_denormalize(n: f32, length: i32) -> f32 {
    ${0 === e3.alignCorners ? "\n    // alignCorners: false => [-1, 1] to [-0.5, length - 0.5]\n    return ((n + 1.0) * f32(length) - 1.0) / 2.0;\n    " : "\n    // alignCorners: true => [-1, 1] to [0, length - 1]\n    return (n + 1.0) / 2.0 * (f32(length - 1));\n    "}
  }
`, Do2 = (e3) => `
  ${"reflection" === e3.paddingMode ? "\n      fn gs_reflect(x: i32, x_min: f32, x_max: f32) -> u32 {\n        var dx = 0.0;\n        var fx = f32(x);\n        let range = x_max - x_min;\n        if (fx < x_min) {\n          dx = x_min - fx;\n          let n = u32(dx / range);\n          let r = dx - f32(n) * range;\n          if (n % 2 == 0) {\n            fx = x_min + r;\n          } else {\n            fx = x_max - r;\n          }\n        } else if (fx > x_max) {\n          dx = fx - x_max;\n          let n = u32(dx / range);\n          let r = dx - f32(n) * range;\n          if (n % 2 == 0) {\n            fx = x_max - r;\n          } else {\n            fx = x_min + r;\n          }\n        }\n        return u32(fx);\n      }" : ""}
`, Bo2 = (e3, t3, n3) => `
  fn pixel_at_grid(r: i32, c: i32, H: i32, W: i32, batch: u32, channel: u32, border: vec4<f32>) -> ${t3} {
     var pixel = ${t3}(0);
     var indices = vec4<u32>(0);
     indices[${Fo2}] = batch;
     indices[${Eo2}] = channel;` + (() => {
        switch (n3.paddingMode) {
          case "zeros":
            return `
          if (r >= 0 && r < H && c >=0 && c < W) {
            indices[${Io2}] = u32(r);
            indices[${Ao2}] = u32(c);
          } else {
            return ${t3}(0);
          }
        `;
          case "border":
            return `
          indices[${Io2}] = u32(clamp(r, 0, H - 1));
          indices[${Ao2}] = u32(clamp(c, 0, W - 1));
        `;
          case "reflection":
            return `
          indices[${Io2}] = gs_reflect(r, border[1], border[3]);
          indices[${Ao2}] = gs_reflect(c, border[0], border[2]);
        `;
          default:
            throw new Error(`padding mode ${n3.paddingMode} is not supported`);
        }
      })() + `
    return ${e3.getByIndices("indices")};
  }
`, No2 = (e3, t3, n3) => (() => {
        switch (n3.mode) {
          case "nearest":
            return `
          let result = pixel_at_grid(i32(round(y)), i32(round(x)), H_in, W_in, indices[${Fo2}], indices[${Eo2}], border);
        `;
          case "bilinear":
            return `
          let x1 = i32(floor(x));
          let y1 = i32(floor(y));
          let x2 = x1 + 1;
          let y2 = y1 + 1;

          let p11 = pixel_at_grid(y1, x1, H_in, W_in, indices[${Fo2}], indices[${Eo2}], border);
          let p12 = pixel_at_grid(y1, x2, H_in, W_in, indices[${Fo2}], indices[${Eo2}], border);
          let p21 = pixel_at_grid(y2, x1, H_in, W_in, indices[${Fo2}], indices[${Eo2}], border);
          let p22 = pixel_at_grid(y2, x2, H_in, W_in, indices[${Fo2}], indices[${Eo2}], border);

          let dx2 = ${t3}(f32(x2) - x);
          let dx1 = ${t3}(x - f32(x1));
          let dy2 = ${t3}(f32(y2) - y);
          let dy1 = ${t3}(y - f32(y1));
          let result = dy2 * (dx2 * p11 + dx1 * p12) + dy1 * (dx2 * p21 + dx1 * p22);
        `;
          case "bicubic":
            return `
          let x0 = i32(floor(x)) - 1;
          let y0 = i32(floor(y)) - 1;
          var p: mat4x4<${t3}>;
          for (var h = 0; h < 4; h++) {
            for (var w = 0; w < 4; w++) {
              p[h][w] = pixel_at_grid(h + y0, w + x0, H_in, W_in, indices[${Fo2}], indices[${Eo2}], border);
            }
          }

          let dx = x - f32(x0 + 1);
          let dy = y - f32(y0 + 1);
          let result = gs_bicubic_interpolate(p, dx, dy);
        `;
          default:
            throw new Error(`mode ${n3.mode} is not supported`);
        }
      })() + `${e3.setByOffset("global_idx", "result")}`, jo2 = (e3, t3) => {
        let n3 = sn2("x", e3[0].dataType, e3[0].dims.length), r3 = [e3[1].dims[0], e3[1].dims[1], e3[1].dims[2]], s3 = sn2("grid", e3[1].dataType, r3.length, 2), a3 = [e3[0].dims[0], e3[0].dims[1], e3[1].dims[1], e3[1].dims[2]];
        "NHWC" === t3.format && (a3 = [e3[0].dims[0], e3[1].dims[1], e3[1].dims[2], e3[0].dims[3]], [Fo2, Eo2, Io2, Ao2] = [0, 3, 1, 2]);
        let o3 = an2("output", e3[0].dataType, a3.length), i3 = n3.type.value, l3 = [{ type: 12, data: gt2.size(a3) }, ...Jt2(e3[0].dims, r3, a3)];
        return { name: "GridSample", shaderCache: { hint: `${t3.cacheKey}`, inputDependencies: ["type", "type"] }, getRunData: (e4) => {
          let t4 = gt2.size(a3);
          return { outputs: [{ dims: a3, dataType: e4[0].dataType }], dispatchGroup: { x: Math.ceil(t4 / 64) }, programUniforms: l3 };
        }, getShaderSource: (e4) => `
  ${e4.registerUniform("output_size", "u32").declareVariables(n3, s3, o3)}
  
  fn gs_get_cubic_coeffs(x: f32) -> vec4<f32> {
    let cubic_alpha = -0.75f;
    let x_abs = abs(x);
    var coeffs: vec4<f32>;
    coeffs[0] = (((cubic_alpha * (x_abs + 1) - 5 * cubic_alpha) * (x_abs + 1) + 8 * cubic_alpha) * (x_abs + 1) - 4 * cubic_alpha);
    coeffs[1] = (((cubic_alpha + 2) * x_abs - (cubic_alpha + 3)) * x_abs * x_abs + 1);
    coeffs[2] = (((cubic_alpha + 2) * (1 - x_abs) - (cubic_alpha + 3)) * (1 - x_abs) * (1 - x_abs) + 1);
    coeffs[3] = (((cubic_alpha * (2 - x_abs) - 5 * cubic_alpha) * (2 - x_abs) + 8 * cubic_alpha) * (2 - x_abs) - 4 * cubic_alpha);
    return coeffs;
  }

  ${Lo2(i3)}
  ${Oo2(t3)}
  ${Do2(t3)}
  ${Bo2(n3, i3, t3)}

  ${e4.mainStart()}
    ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
      let H_in = i32(uniforms.x_shape[${Io2}]);
      let W_in = i32(uniforms.x_shape[${Ao2}]);

      ${0 === t3.alignCorners ? "\n      let x_min = -0.5;\n      let x_max = f32(W_in) - 0.5;\n      let y_min = -0.5;\n      let y_max = f32(H_in) - 0.5;\n      " : "\n      let x_min = 0.0;\n      let x_max = f32(W_in) - 1.0;\n      let y_min = 0.0;\n      let y_max = f32(H_in) - 1.0;\n      "};
      let border = vec4<f32>(x_min, y_min, x_max, y_max);

      let indices = ${o3.offsetToIndices("global_idx")};
      var grid_indices = vec3<u32>(indices[${Fo2}], indices[${Io2}], indices[${Ao2}]);
      let nxy = ${s3.getByIndices("grid_indices")};
      var x = gs_denormalize(f32(nxy[0]), W_in);
      var y = gs_denormalize(f32(nxy[1]), H_in);

      ${No2(o3, i3, t3)}
  }` };
      }, Ro2 = (e3, t3) => {
        zo2(e3.inputs), e3.compute(jo2(e3.inputs, t3));
      }, Vo2 = (e3) => Wt2({ alignCorners: e3.align_corners, mode: e3.mode, paddingMode: e3.padding_mode, format: e3.format });
    })), Zd2 = j2((() => {
      dd2(), pd2(), wd2(), _d2(), Td2(), bd2(), yd2(), Go2 = (e3, t3) => e3.length > t3 && e3[t3].dims.length > 0 ? e3[t3] : void 0, qo2 = (e3, t3) => {
        let n3 = e3[0], r3 = Go2(e3, 1), s3 = Go2(e3, 2), a3 = Go2(e3, 3), o3 = Go2(e3, 4), i3 = Go2(e3, 5), l3 = Go2(e3, 6), d3 = Go2(e3, 7);
        if (3 !== n3.dims.length && 5 !== n3.dims.length) throw new Error("Input query is expected to have 3 or 5 dimensions");
        let u3, c3 = n3.dims[0], p3 = n3.dims[1], m3 = 3 === n3.dims.length ? n3.dims[2] : t3.numHeads * n3.dims[4], h3 = p3, f3 = 0, _3 = 0, g3 = Math.floor(m3 / t3.numHeads);
        if (l3 && d3 && gt2.size(l3.dims) && gt2.size(d3.dims)) {
          if (4 !== l3.dims.length) throw new Error('Input "past_key" is expected to have 4 dimensions');
          if (l3.dims[0] !== c3 || l3.dims[1] !== t3.numHeads || l3.dims[3] !== g3) throw new Error('Input "past_key" shape (batch_size, num_heads, past_sequence_length, head_size)');
          if (d3.dims[0] !== c3 || d3.dims[1] !== t3.numHeads || d3.dims[3] !== g3) throw new Error('Input "past_value" shape (batch_size, num_heads, past_sequence_length, head_size)');
          if (l3.dims[2] !== d3.dims[2]) throw new Error('Input "past_key" and "past_value" shall have same dim 2 (past_sequence_length)');
          if (4 !== d3.dims.length) throw new Error('Input "past_value" is expected to have 4 dimensions');
          f3 = l3.dims[2], _3 = l3.dims[2];
        } else if (l3 && gt2.size(l3.dims) || d3 && gt2.size(d3.dims)) throw new Error('Input "past_key" and "past_value" shall be both present or both absent');
        if (r3 && gt2.size(r3.dims) > 0) {
          if (3 !== n3.dims.length) throw new Error('Input "query" is expected to have 3 dimensions when key is given');
          if (r3.dims.length < 3 || r3.dims.length > 5) throw new Error('Input "key" is expected to have 3, 4, or 5 dimensions');
          if (n3.dims[0] !== r3.dims[0]) throw new Error('Input "query" and "key" shall have same dim 0 (batch size)');
          if (3 === r3.dims.length) {
            if (r3.dims[2] !== n3.dims[2]) throw new Error('Input "query" and "key" shall have same dim 2 (hidden_size)');
            u3 = 2, h3 = r3.dims[1];
          } else if (5 === r3.dims.length) {
            if (r3.dims[2] !== t3.numHeads || 2 !== r3.dims[3] || r3.dims[4] !== g3) throw new Error('Expect "key" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');
            if (s3) throw new Error('Expect "value" be none when "key" has packed kv format.');
            u3 = 5, h3 = r3.dims[1];
          } else {
            if (r3.dims[1] !== t3.numHeads || r3.dims[3] !== g3) throw new Error('Expect "key" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');
            u3 = 0, h3 = r3.dims[2];
          }
        } else {
          if (5 !== n3.dims.length) throw new Error('Input "query" is expected to have 5 dimensions when key is empty');
          if (n3.dims[2] !== t3.numHeads || 3 !== n3.dims[3]) throw new Error('Expect "query" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');
          u3 = 3;
        }
        if (a3 && gt2.size(a3.dims) > 0) {
          if (1 !== a3.dims.length) throw new Error('Input "bias" is expected to have 1 dimension');
          if (r3 && 5 === r3.dims.length && 2 === r3.dims[3]) throw new Error("bias is not allowed for packed kv.");
        }
        let w3 = f3 + h3, b3 = 0;
        if (o3 && gt2.size(o3.dims) > 0) {
          b3 = 8;
          let e4 = o3.dims;
          throw 1 === e4.length ? e4[0] === c3 ? b3 = 1 : e4[0] === 3 * c3 + 2 && (b3 = 3) : 2 === e4.length && e4[0] === c3 && e4[1] === w3 && (b3 = 5), 8 === b3 ? new Error('Input "key_padding_mask" shape shall be (batch_size) or (batch_size, total_sequence_length)') : new Error("Mask not supported");
        }
        let y3 = false, M3 = m3;
        if (s3 && gt2.size(s3.dims) > 0) {
          if (3 !== s3.dims.length && 4 !== s3.dims.length) throw new Error('Input "value" is expected to have 3 or 4 dimensions');
          if (n3.dims[0] !== s3.dims[0]) throw new Error('Input "query" and "value" shall have same dim 0 (batch_size)');
          if (3 === s3.dims.length) {
            if (h3 !== s3.dims[1]) throw new Error('Input "key" and "value" shall have the same dim 1 (kv_sequence_length)');
            M3 = s3.dims[2];
          } else {
            if (h3 !== s3.dims[2]) throw new Error('Input "key" and "value" shall have the same dim 2 (kv_sequence_length)');
            M3 = s3.dims[1] * s3.dims[3], y3 = true;
          }
        }
        if (o3 && gt2.size(o3.dims) > 0) throw new Error("Key padding mask is not supported");
        if (i3 && gt2.size(i3.dims) > 0) {
          if (4 !== i3.dims.length) throw new Error('Input "attention_bias" is expected to have 4 dimensions');
          if (i3.dims[0] !== c3 || i3.dims[1] !== t3.numHeads || i3.dims[2] !== p3 || i3.dims[3] !== w3) throw new Error('Expect "attention_bias" shape (batch_size, num_heads, sequence_length, total_sequence_length)');
        }
        return { batchSize: c3, sequenceLength: p3, pastSequenceLength: f3, kvSequenceLength: h3, totalSequenceLength: w3, maxSequenceLength: _3, inputHiddenSize: 0, hiddenSize: m3, vHiddenSize: M3, headSize: g3, vHeadSize: Math.floor(M3 / t3.numHeads), numHeads: t3.numHeads, isUnidirectional: false, pastPresentShareBuffer: false, maskFilterValue: t3.maskFilterValue, maskType: b3, scale: t3.scale, broadcastResPosBias: false, passPastInKv: y3, qkvFormat: u3 };
      }, Uo2 = (e3) => Wt2({ ...e3 }), Wo2 = Wt2({ perm: [0, 2, 1, 3] }), Ho2 = (e3, t3, n3, r3, s3, a3, o3) => {
        let i3 = [r3, s3, a3], l3 = gt2.size(i3), d3 = [{ type: 12, data: l3 }, { type: 12, data: o3 }, { type: 12, data: a3 }];
        return e3.compute({ name: "MultiHeadAttentionAddBias", shaderCache: { inputDependencies: ["type", "type"] }, getRunData: () => ({ outputs: [{ dims: i3, dataType: t3.dataType, gpuDataType: 0 }], dispatchGroup: { x: Math.ceil(l3 / 64) }, programUniforms: d3 }), getShaderSource: (e4) => {
          let r4 = an2("qkv_with_bias", t3.dataType, i3), s4 = sn2("qkv", t3.dataType, i3), a4 = sn2("bias", n3.dataType, i3);
          return `
  ${e4.registerUniforms([{ name: "output_size", type: "u32" }, { name: "bias_offset", type: "u32" }, { name: "hidden_size", type: "u32" }]).declareVariables(s4, a4, r4)}
  ${e4.mainStart()}
    ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
    let bias_offset_idx = (global_idx % uniforms.hidden_size) + uniforms.bias_offset;

    qkv_with_bias[global_idx] = qkv[global_idx] + bias[bias_offset_idx];
  }`;
        } }, { inputs: [t3, n3], outputs: [-1] })[0];
      }, Qo2 = (e3, t3, n3, r3, s3, a3, o3, i3) => {
        let l3 = a3;
        if (o3 && gt2.size(o3.dims) > 0) {
          if (1 === r3) throw new Error("AddBiasReshape is not implemented. Please export your model with packed QKV or KV");
          return l3 = Ho2(e3, a3, o3, t3, r3, n3 * s3, i3), l3 = l3.reshape([t3, r3, n3, s3]), 1 === n3 || 1 === r3 ? l3 : e3.compute(gn2(l3, Wo2.perm), { inputs: [l3], outputs: [-1] })[0];
        }
        return 3 === a3.dims.length && (l3 = a3.reshape([t3, r3, n3, s3])), 1 === n3 || 1 === r3 ? l3 : e3.compute(gn2(l3, Wo2.perm), { inputs: [l3], outputs: [-1] })[0];
      }, Ko2 = (e3, t3) => {
        let n3 = qo2(e3.inputs, t3), r3 = e3.inputs[0], s3 = Go2(e3.inputs, 1), a3 = Go2(e3.inputs, 2), o3 = Go2(e3.inputs, 3), i3 = Go2(e3.inputs, 4), l3 = Go2(e3.inputs, 5), d3 = Go2(e3.inputs, 6), u3 = Go2(e3.inputs, 7);
        if (5 === r3.dims.length) throw new Error("Packed QKV is not implemented");
        if (5 === s3?.dims.length) throw new Error("Packed KV is not implemented");
        let c3 = s3 && a3 && 4 === s3.dims.length && 4 === a3.dims.length, p3 = Qo2(e3, n3.batchSize, n3.numHeads, n3.sequenceLength, n3.headSize, r3, o3, 0);
        if (c3) return xr2(e3, p3, s3, a3, i3, void 0, d3, u3, l3, n3);
        if (!s3 || !a3) throw new Error("key and value must be provided");
        let m3 = Qo2(e3, n3.batchSize, n3.numHeads, n3.kvSequenceLength, n3.headSize, s3, o3, n3.hiddenSize), h3 = Qo2(e3, n3.batchSize, n3.numHeads, n3.kvSequenceLength, n3.vHeadSize, a3, o3, 2 * n3.hiddenSize);
        xr2(e3, p3, m3, h3, i3, void 0, d3, u3, l3, n3);
      };
    })), eu2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), Xo2 = (e3) => {
        if (!e3 || e3.length < 1) throw new Error("too few inputs");
      }, Jo2 = (e3, t3) => {
        let n3 = [], r3 = t3.numOutputs;
        return e3[1].dims[0] > 0 && (e3[1].getBigInt64Array().forEach(((e4) => n3.push(Number(e4)))), r3 = n3.length), Wt2({ numOutputs: r3, axis: t3.axis, splitSizes: n3 });
      }, Yo2 = (e3) => `
fn calculateOutputIndex(index: u32) -> u32 {
    for (var i: u32 = 0u; i < ${e3}u; i += 1u ) {
    if (index < ${nn2("uniforms.size_in_split_axis", "i", e3)}) {
        return i;
    }
    }
    return ${e3}u;
}`, Zo2 = (e3) => {
        let t3 = e3.length, n3 = [];
        for (let r3 = 0; r3 < t3; ++r3) {
          let s3 = e3[r3].setByIndices("indices", "input[global_idx]");
          1 === t3 ? n3.push(s3) : 0 === r3 ? n3.push(`if (output_number == ${r3}u) { ${s3} }`) : r3 === t3 - 1 ? n3.push(`else { ${s3} }`) : n3.push(`else if (output_number == ${r3}) { ${s3} }`);
        }
        return `
      fn writeBufferData(output_number: u32, indices: ${e3[0].type.indices}, global_idx: u32) {
        ${n3.join("\n")}
      }`;
      }, ei2 = (e3, t3) => {
        let n3 = e3[0].dims, r3 = gt2.size(n3), s3 = e3[0].dataType, a3 = gt2.normalizeAxis(t3.axis, n3.length), o3 = new Array(t3.numOutputs), i3 = sn2("input", s3, n3.length), l3 = new Array(t3.numOutputs), d3 = [], u3 = [], c3 = 0, p3 = [{ type: 12, data: r3 }];
        for (let r4 = 0; r4 < t3.numOutputs; r4++) {
          c3 += t3.splitSizes[r4], l3[r4] = c3;
          let i4 = n3.slice();
          i4[a3] = t3.splitSizes[r4], u3.push(i4), o3[r4] = an2(`output${r4}`, s3, i4.length), d3.push({ dims: u3[r4], dataType: e3[0].dataType });
        }
        p3.push({ type: 12, data: l3 }, ...Jt2(n3, ...u3));
        return { name: "Split", shaderCache: { hint: t3.cacheKey, inputDependencies: ["rank"] }, getShaderSource: (e4) => `
  ${e4.registerUniform("input_size", "u32").registerUniform("size_in_split_axis", "u32", l3.length).declareVariables(i3, ...o3)}
  ${Yo2(l3.length)}
  ${Zo2(o3)}

  ${e4.mainStart()}
    ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.input_size")}

    var indices = ${i3.offsetToIndices("global_idx")};
    var index = ${i3.indicesGet("indices", a3)};
    let output_number = calculateOutputIndex(index);
    if (output_number != 0) {
      index -= ${nn2("uniforms.size_in_split_axis", "output_number - 1u", l3.length)};
      ${i3.indicesSet("indices", a3, "index")};
    }
    writeBufferData(output_number, indices, global_idx);
  }`, getRunData: () => ({ outputs: d3, dispatchGroup: { x: Math.ceil(r3 / 64) }, programUniforms: p3 }) };
      }, ti2 = (e3, t3) => {
        Xo2(e3.inputs);
        let n3 = 1 === e3.inputs.length ? t3 : Jo2(e3.inputs, t3);
        e3.compute(ei2(e3.inputs, n3), { inputs: [0] });
      }, ni2 = (e3) => {
        let t3 = e3.axis, n3 = e3.splitSizes, r3 = e3.numOutputs < 0 ? n3.length : e3.numOutputs;
        if (r3 !== n3.length) throw new Error("numOutputs and splitSizes lengh must be equal");
        return Wt2({ axis: t3, numOutputs: r3, splitSizes: n3 });
      };
    })), tu2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), ri2 = (e3, t3) => {
        let [n3, r3, s3, a3] = e3, { numHeads: o3, rotaryEmbeddingDim: i3 } = t3;
        if (3 !== n3.dims.length && 4 !== n3.dims.length) throw new Error(`Input 'x' is expected to have 3 or 4 dimensions, got ${n3.dims.length}`);
        if (!gt2.areEqual(r3.dims, []) && !gt2.areEqual(r3.dims, [1]) && 2 !== r3.dims.length) throw new Error(`Input 'position_ids' is expected to have 0, 1, or 2 dimensions, got ${r3.dims.length}`);
        if (2 !== s3.dims.length) throw new Error(`Input 'cos_cache' is expected to have 2 dimensions, got ${s3.dims.length}`);
        if (2 !== a3.dims.length) throw new Error(`Input 'sin_cache' is expected to have 2 dimensions, got ${a3.dims.length}`);
        if (!gt2.areEqual(s3.dims, a3.dims)) throw new Error("Inputs 'cos_cache' and 'sin_cache' are expected to have the same shape");
        if (i3 > 0 && 0 === o3) throw new Error("num_heads must be provided if rotary_embedding_dim is specified");
        let l3 = n3.dims[0], d3 = n3.dims[n3.dims.length - 2], u3 = s3.dims[0], c3 = gt2.sizeFromDimension(n3.dims, 1) / d3, p3 = 0 === i3 ? 2 * s3.dims[1] : c3 / o3;
        if (i3 > p3) throw new Error("rotary_embedding_dim must be less than or equal to head_size");
        if (2 === r3.dims.length) {
          if (l3 !== r3.dims[0]) throw new Error(`Input 'position_ids' dimension 0 should be of size batch_size, got ${r3.dims[0]}`);
          if (d3 !== r3.dims[1]) throw new Error(`Input 'position_ids' dimension 1 should be of size sequence_length, got ${r3.dims[1]}`);
        }
        if (p3 / 2 !== s3.dims[1] && i3 / 2 !== s3.dims[1]) throw new Error(`Input 'cos_cache' dimension 1 should be same as head_size / 2 or rotary_embedding_dim / 2, got ${s3.dims[1]}`);
        if (d3 > u3) throw new Error("Updating cos_cache and sin_cache in RotaryEmbedding is not currently supported");
      }, si2 = (e3, t3) => {
        let { interleaved: n3, numHeads: r3, rotaryEmbeddingDim: s3, scale: a3 } = t3, o3 = e3[0].dims[0], i3 = gt2.sizeFromDimension(e3[0].dims, 1), l3 = e3[0].dims[e3[0].dims.length - 2], d3 = i3 / l3, u3 = e3[2].dims[1], c3 = 0 === s3 ? 2 * u3 : d3 / r3, p3 = new Array(o3, l3, d3 / c3, c3 - u3), m3 = gt2.computeStrides(p3), h3 = [{ type: 1, data: a3 }, { type: 12, data: p3 }, { type: 12, data: m3 }, ...3 === e3[0].dims.length ? new Array({ type: 12, data: [i3, d3, c3, 1] }) : [], ...4 === e3[0].dims.length ? new Array({ type: 12, data: [i3, c3, l3 * c3, 1] }) : [], ...Jt2(e3[0].dims, e3[1].dims, e3[2].dims, e3[3].dims, e3[0].dims)];
        return { name: "RotaryEmbedding", shaderCache: { hint: Wt2({ interleaved: n3 }).cacheKey, inputDependencies: ["rank", "rank", "rank", "rank"] }, getShaderSource: (t4) => {
          let r4 = sn2("input", e3[0].dataType, e3[0].dims.length), s4 = sn2("position_ids", e3[1].dataType, e3[1].dims.length), a4 = sn2("cos_cache", e3[2].dataType, e3[2].dims.length), o4 = sn2("sin_cache", e3[3].dataType, e3[3].dims.length), i4 = an2("output", e3[0].dataType, e3[0].dims.length);
          return t4.registerUniforms([{ name: "scale", type: "f32" }, { name: "global_shape", type: "u32", length: p3.length }, { name: "global_strides", type: "u32", length: m3.length }, { name: "input_output_strides", type: "u32", length: m3.length }]), `
        ${t4.declareVariables(r4, s4, a4, o4, i4)}

        ${t4.mainStart(Ht2)}
          let half_rotary_emb_dim = uniforms.${a4.name}_shape[1];
          let bsnh = global_idx / uniforms.global_strides % uniforms.global_shape;
          let size = uniforms.global_shape[0] * uniforms.global_strides[0];
          ${t4.guardAgainstOutOfBoundsWorkgroupSizes("size")}

          if (bsnh[3] < half_rotary_emb_dim) {
            let position_ids_idx =
                ${s4.broadcastedIndicesToOffset("bsnh.xy", an2("", s4.type.tensor, 2))};
            let position_id =
                u32(${s4.getByOffset("position_ids_idx")}) + select(0, bsnh[1], position_ids_idx == 0);
            let i = dot(bsnh, uniforms.input_output_strides) + select(0, bsnh[3], ${n3});
            let j = i + select(half_rotary_emb_dim, 1, ${n3});
            let re = ${r4.getByOffset("i")} * ${a4.get("position_id", "bsnh[3]")} -
                ${r4.getByOffset("j")} * ${o4.get("position_id", "bsnh[3]")};
            ${i4.setByOffset("i", "re")}
            let im = ${r4.getByOffset("i")} * ${o4.get("position_id", "bsnh[3]")} +
                ${r4.getByOffset("j")} * ${a4.get("position_id", "bsnh[3]")};
            ${i4.setByOffset("j", "im")}
          } else {
            let k = dot(bsnh, uniforms.input_output_strides) + half_rotary_emb_dim;
            ${i4.setByOffset("k", r4.getByOffset("k"))}
          }
        }`;
        }, getRunData: () => ({ outputs: [{ dims: e3[0].dims, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(gt2.size(p3) / Ht2) }, programUniforms: h3 }) };
      }, ai2 = (e3, t3) => {
        ri2(e3.inputs, t3), e3.compute(si2(e3.inputs, t3));
      };
    })), nu2 = j2((() => {
      wd2(), dd2(), Td2(), Zd2(), eu2(), yd2(), tu2(), bd2(), oi2 = (e3, t3) => {
        if (t3.doRotary && e3.length <= 7) throw new Error("cos_cache and sin_cache inputs are required if do_rotary is specified");
        let n3 = e3[0], r3 = e3[1], s3 = e3[2], a3 = e3[3], o3 = e3[4];
        if (0 !== t3.doRotary && e3.length <= 7) throw new Error("cos_cast and sin_cache are expected if do_rotary attribute is non-zero");
        if (-1 !== t3.localWindowSize) throw new Error("Local attention is not supported");
        if (0 !== t3.softcap) throw new Error("Softcap is not supported");
        if (0 !== t3.rotaryInterleaved) throw new Error("Rotary interleaved is not supported");
        if (t3.smoothSoftmax) throw new Error("Smooth softmax is not supported");
        if (3 !== n3.dims.length && 5 !== n3.dims.length) throw new Error("Input query is expected to have 3 or 5 dimensions");
        let i3 = n3.dims[0], l3 = n3.dims[1], d3 = 3 === n3.dims.length ? n3.dims[2] : t3.numHeads * n3.dims[4], u3 = l3, c3 = 0, p3 = !r3 || 0 === r3.dims.length, m3 = Math.floor(p3 ? d3 / (t3.numHeads + 2 * t3.kvNumHeads) : d3 / t3.numHeads);
        p3 && (d3 = m3 * t3.numHeads);
        let h3 = a3 && 0 !== a3.dims.length, f3 = o3 && 0 !== o3.dims.length;
        if (h3 && 4 === a3.dims.length && a3.dims[0] === i3 && a3.dims[1] !== t3.kvNumHeads && a3.dims[2] === t3.kvNumHeads && a3.dims[3] === m3) throw new Error("BSNH pastKey/pastValue is not supported");
        if (h3 && f3) {
          if (4 !== a3.dims.length) throw new Error('Input "past_key" is expected to have 4 dimensions');
          if (4 !== o3.dims.length) throw new Error('Input "past_value" is expected to have 4 dimensions');
          c3 = a3.dims[2];
        } else if (h3 || f3) throw new Error('Input "past_key" and "past_value" shall be both present or both absent');
        let _3 = 1;
        if (r3 && r3.dims.length > 0) {
          if (3 !== n3.dims.length) throw new Error('Input "query" is expected to have 3 dimensions when key is given');
          if (r3.dims.length < 3 || r3.dims.length > 5) throw new Error('Input "key" is expected to have 3, 4, or 5 dimensions');
          if (n3.dims[0] !== r3.dims[0]) throw new Error('Input "query" and "key" shall have same dim 0 (batch size)');
          if (3 === r3.dims.length) {
            if (n3.dims[2] % r3.dims[2] != 0) throw new Error('Dimension 2 of "query" should be a multiple of "key"');
            u3 = r3.dims[1];
          } else if (5 === r3.dims.length) {
            if (r3.dims[2] !== t3.numHeads || 2 !== r3.dims[3] || r3.dims[4] !== m3) throw new Error('Expect "key" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');
            if (s3) throw new Error('Expect "value" be none when "key" has packed kv format.');
            u3 = r3.dims[1];
          } else {
            if (r3.dims[1] !== t3.numHeads || r3.dims[3] !== m3) throw new Error('Expect "key" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');
            u3 = r3.dims[2];
          }
        } else {
          if (3 !== n3.dims.length && 5 !== n3.dims.length) throw new Error('Input "query" is expected to have 3 or 5 dimensions when key is empty');
          if (5 === n3.dims.length && (n3.dims[2] !== t3.numHeads || 3 !== n3.dims[3])) throw new Error('Expect "query" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');
          _3 = 3;
        }
        let g3 = false, w3 = t3.kvNumHeads ? m3 * t3.kvNumHeads : d3;
        if (s3 && s3.dims.length > 0) {
          if (3 !== s3.dims.length && 4 !== s3.dims.length) throw new Error('Input "value" is expected to have 3 or 4 dimensions');
          if (n3.dims[0] !== s3.dims[0]) throw new Error('Input "query" and "value" shall have same dim 0 (batch_size)');
          if (3 === s3.dims.length) {
            if (u3 !== s3.dims[1]) throw new Error('Input "key" and "value" shall have the same dim 1 (kv_sequence_length)');
            w3 = s3.dims[2];
          } else {
            if (u3 !== s3.dims[2]) throw new Error('Input "past_key" and "past_value" shall have the same dim 2 (kv_sequence_length)');
            w3 = s3.dims[1] * s3.dims[3], g3 = true;
          }
        }
        let b3 = e3.length > 4 ? e3[5] : void 0;
        if (b3 && 1 !== b3.dims.length && b3.dims[0] !== i3) throw new Error('Input "seqlens" is expected to have 1 dimension and the same dim 0 as batch_size');
        return { batchSize: i3, sequenceLength: l3, pastSequenceLength: c3, kvSequenceLength: u3, totalSequenceLength: -1, maxSequenceLength: -1, inputHiddenSize: 0, hiddenSize: d3, vHiddenSize: w3, headSize: m3, vHeadSize: Math.floor(w3 / t3.kvNumHeads), numHeads: t3.numHeads, kvNumHeads: t3.kvNumHeads, nReps: t3.numHeads / t3.kvNumHeads, pastPresentShareBuffer: false, maskType: 0, scale: t3.scale, broadcastResPosBias: false, passPastInKv: g3, qkvFormat: _3 };
      }, ii2 = Wt2({ perm: [0, 2, 1, 3] }), li2 = (e3, t3, n3) => {
        let r3 = t3, s3 = n3.kvNumHeads;
        return 3 === t3.dims.length && 0 !== n3.kvSequenceLength && (r3 = t3.reshape([n3.batchSize, n3.kvSequenceLength, s3, n3.headSize]), r3 = e3.compute(gn2(r3, ii2.perm), { inputs: [r3], outputs: [-1] })[0]), r3;
      }, di2 = (e3, t3, n3, r3) => {
        let s3 = [e3 * t3], a3 = e3 * t3, o3 = [{ type: 12, data: a3 }, { type: 12, data: t3 }, { type: 12, data: e3 }];
        return { name: "GeneratePositionIds", shaderCache: { hint: `${e3};${t3}`, inputDependencies: ["type", "type"] }, getRunData: () => ({ outputs: [{ dims: s3, dataType: 7 }], dispatchGroup: { x: Math.ceil(a3 / 64) }, programUniforms: o3 }), getShaderSource: (e4) => {
          let t4 = sn2("seq_lens", n3.dataType, n3.dims), a4 = sn2("total_seq_lens", r3.dataType, r3.dims), o4 = an2("pos_ids", 7, s3);
          return `
  ${e4.registerUniforms([{ name: "output_size", type: "u32" }, { name: "sequence_length", type: "u32" }, { name: "batch_size", type: "u32" }]).declareVariables(t4, a4, o4)}
  ${e4.mainStart()}
    ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
    let total_sequence_length = u32(${a4.getByOffset("0")});
    let is_subsequent_prompt = uniforms.sequence_length > 1 && uniforms.sequence_length != total_sequence_length;
    let is_first_prompt = !is_subsequent_prompt && uniforms.sequence_length == total_sequence_length;
    let batch_idx = global_idx / uniforms.sequence_length;
    let sequence_idx = i32(global_idx % uniforms.sequence_length);
    var pos_id: i32 = 0;
    let seqlen = ${t4.getByOffset("batch_idx")};
    let total_seqlen = seqlen + 1;
    if (is_first_prompt) {
      if (sequence_idx < total_seqlen) {
        pos_id = sequence_idx;
      } else {
        pos_id = 1;
      }
      ${o4.setByOffset("global_idx", "pos_id")}
    } else if (is_subsequent_prompt) {
      let past_seqlen = total_seqlen - i32(uniforms.sequence_length);
      if (past_seqlen + sequence_idx < total_seqlen) {
        pos_id = past_seqlen + sequence_idx;
      } else {
        pos_id = 1;
      }
      ${o4.setByOffset("global_idx", "pos_id")}
    } else if (global_idx < uniforms.batch_size) {
      ${o4.setByOffset("global_idx", "seqlen")}
    };
  }
  `;
        } };
      }, ui2 = (e3, t3) => {
        let n3 = oi2(e3.inputs, t3);
        if (5 === e3.inputs[0].dims.length) throw new Error("Packed QKV is not implemented");
        if (5 === e3.inputs[1]?.dims.length) throw new Error("Packed KV is not implemented");
        let r3, s3, a3 = e3.inputs[0], o3 = e3.inputs[1] && e3.inputs[1].dims.length > 0 ? e3.inputs[1] : void 0, i3 = e3.inputs[2] && e3.inputs[2].dims.length > 0 ? e3.inputs[2] : void 0, l3 = e3.inputs[3] && 0 !== e3.inputs[3].dims.length ? e3.inputs[3] : void 0, d3 = e3.inputs[4] && 0 !== e3.inputs[4].dims.length ? e3.inputs[4] : void 0, u3 = e3.inputs.length > 4 ? e3.inputs[5] : void 0, c3 = e3.inputs.length > 5 ? e3.inputs[6] : void 0, p3 = n3.kvNumHeads ? n3.kvNumHeads : n3.numHeads, m3 = Wt2({ axis: 2, numOutputs: 3, splitSizes: [n3.numHeads * n3.headSize, p3 * n3.headSize, p3 * n3.headSize] }), [h3, f3, _3] = o3 || i3 ? [a3, o3, i3] : e3.compute(ei2([a3], m3), { inputs: [a3], outputs: [-1, -1, -1] });
        if (t3.doRotary) {
          let a4 = e3.compute(di2(n3.batchSize, n3.sequenceLength, u3, c3), { inputs: [u3, c3], outputs: [-1] })[0], o4 = e3.inputs[7], i4 = e3.inputs[8], l4 = Wt2({ interleaved: 0 !== t3.rotaryInterleaved, numHeads: n3.numHeads, rotaryEmbeddingDim: 0, scale: t3.scale }), d4 = [h3, a4, o4, i4], p4 = [-1];
          r3 = e3.compute(si2(d4, l4), { inputs: d4, outputs: p4 })[0], d4.splice(0, 1, f3);
          let m4 = Wt2({ interleaved: 0 !== t3.rotaryInterleaved, numHeads: n3.kvNumHeads, rotaryEmbeddingDim: 0, scale: t3.scale });
          s3 = e3.compute(si2(d4, m4), { inputs: d4, outputs: p4 })[0];
        }
        let g3 = Qo2(e3, n3.batchSize, n3.numHeads, n3.sequenceLength, n3.headSize, t3.doRotary ? r3 : h3, void 0, 0), w3 = li2(e3, t3.doRotary ? s3 : f3, n3), b3 = li2(e3, _3, n3);
        xr2(e3, g3, w3, b3, void 0, void 0, l3, d3, void 0, n3, u3, c3);
      };
    })), ru2 = j2((() => {
      dd2(), pd2(), yd2(), bd2(), ci2 = (e3, t3, n3, r3, s3, a3, o3, i3) => {
        let l3 = Yt2(a3), d3 = 1 === l3 ? "f32" : `vec${l3}f`, u3 = 1 === l3 ? "vec2f" : `mat2x${l3}f`, c3 = s3 * o3, p3 = 64;
        1 === c3 && (p3 = 256);
        let m3 = [s3, o3, a3 / l3], h3 = [s3, o3, 2], f3 = [];
        f3.push(...Jt2(m3, h3));
        return e3.compute({ name: "InstanceNormComputeChannelScaleShift", shaderCache: { hint: `${l3};${i3};${p3}`, inputDependencies: ["rank", "type", "type"] }, getRunData: () => ({ outputs: [{ dims: h3, dataType: 1 }], dispatchGroup: { x: c3 }, programUniforms: f3 }), getShaderSource: (e4) => {
          let s4 = sn2("x", t3.dataType, 3, l3), a4 = [s4, sn2("scale", n3.dataType, n3.dims), sn2("bias", r3.dataType, r3.dims), an2("output", 1, 3, 2)];
          return `
  var<workgroup> workgroup_shared : array<${u3}, ${p3}>;
  const workgroup_size = ${p3}u;
  ${e4.declareVariables(...a4)}
  ${e4.mainStart(p3)}
    let batch = workgroup_index / uniforms.x_shape[1];
    let channel = workgroup_index % uniforms.x_shape[1];
    let hight = uniforms.x_shape[2];
    // initialize workgroup memory
    var sum = ${d3}(0);
    var squared_sum = ${d3}(0);
    for (var h = local_idx; h < hight; h += workgroup_size) {
      let value = ${d3}(${s4.get("batch", "channel", "h")});
      sum += value;
      squared_sum += value * value;
    }
    workgroup_shared[local_idx] = ${u3}(sum, squared_sum);
    workgroupBarrier();

    for (var currSize = workgroup_size >> 1;  currSize > 0; currSize = currSize >> 1) {
      if (local_idx < currSize) {
        workgroup_shared[local_idx] = workgroup_shared[local_idx] + workgroup_shared[local_idx + currSize];
      }
      workgroupBarrier();
    }
    if (local_idx == 0) {
      let sum_final = ${tn2("workgroup_shared[0][0]", l3)} / f32(hight * ${l3});
      let squared_sum_final = ${tn2("workgroup_shared[0][1]", l3)} / f32(hight * ${l3});

      let inv_std_dev = inverseSqrt(squared_sum_final - sum_final * sum_final + f32(${i3}));
      let channel_scale = inv_std_dev * f32(scale[channel]);
      let channel_shift = f32(bias[channel]) - sum_final * channel_scale;
      output[workgroup_index] = vec2f(channel_scale, channel_shift);
    }
  }`;
        } }, { inputs: [t3, n3, r3], outputs: [-1] })[0];
      }, pi2 = (e3, t3, n3) => {
        let r3 = t3[0].dims, s3 = r3, a3 = r3[0], o3 = r3[1], i3 = gt2.sizeFromDimension(r3, 2), l3 = Yt2(i3), d3 = gt2.size(s3) / l3, u3 = ci2(e3, t3[0], t3[1], t3[2], a3, i3, o3, n3.epsilon), c3 = [a3, o3, i3 / l3], p3 = [a3, o3];
        e3.compute({ name: "InstanceNormalization", shaderCache: { hint: `${l3}`, inputDependencies: ["type", "none"] }, getRunData: () => ({ outputs: [{ dims: s3, dataType: t3[0].dataType }], dispatchGroup: { x: Math.ceil(d3 / 64) }, programUniforms: [{ type: 12, data: d3 }, ...Jt2(c3, p3, c3)] }), getShaderSource: (e4) => {
          let n4 = sn2("x", t3[0].dataType, c3.length, l3), r4 = sn2("scale_shift", 1, p3.length, 2), s4 = an2("output", t3[0].dataType, c3.length, l3), a4 = [n4, r4, s4];
          return `
  ${e4.registerUniform("output_size", "u32").declareVariables(...a4)}
  ${e4.mainStart()}
  ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
      let outputIndices = ${s4.offsetToIndices("global_idx")};
      let batch = outputIndices[0];
      let channel = outputIndices[1];
      let scale_shift = ${r4.getByIndices("vec2<u32>(batch, channel)")};
      let value = ${n4.getByOffset("global_idx")} * ${s4.type.value}(scale_shift.x) + ${s4.type.value}(scale_shift.y);
      ${s4.setByOffset("global_idx", "value")};
  }`;
        } }, { inputs: [t3[0], u3] });
      }, mi2 = (e3, t3, n3) => {
        let r3 = t3[0].dims, s3 = r3, a3 = r3[0], o3 = r3[r3.length - 1], i3 = gt2.sizeFromDimension(r3, 1) / o3, l3 = Yt2(o3), d3 = gt2.size(s3) / l3, u3 = [{ type: 12, data: i3 }, { type: 12, data: Math.floor(o3 / l3) }], c3 = false, p3 = [0, r3.length - 1];
        for (let e4 = 0; e4 < r3.length - 2; e4++) c3 = c3 || 1 !== r3[e4 + 1], p3.push(e4 + 1);
        c3 = c3 && 1 !== r3[r3.length - 1];
        let m3 = c3 ? e3.compute(gn2(e3.inputs[0], p3), { inputs: [e3.inputs[0]], outputs: [-1] })[0] : e3.inputs[0].reshape(Array.from({ length: r3.length }, ((e4, t4) => r3[p3[t4]]))), h3 = ci2(e3, m3, t3[1], t3[2], a3, i3, o3, n3.epsilon);
        e3.compute({ name: "InstanceNormalizationNHWC", shaderCache: { hint: `${l3}`, inputDependencies: ["type", "type"] }, getRunData: () => ({ outputs: [{ dims: s3, dataType: t3[0].dataType }], dispatchGroup: { x: Math.ceil(d3 / 64) }, programUniforms: u3 }), getShaderSource: (e4) => {
          let n4 = Kt2(t3[0].dataType), r4 = 1 === l3 ? "vec2f" : `mat${l3}x2f`, a4 = (e5) => {
            let t4 = 0 === e5 ? "x" : "y", r5 = 1 === l3 ? "f32" : `vec${l3}f`;
            switch (l3) {
              case 1:
                return `${n4}(${r5}(scale.${t4}))`;
              case 2:
                return `vec2<${n4}>(${r5}(scale[0].${t4}, scale[1].${t4}))`;
              case 4:
                return `vec4<${n4}>(${r5}(scale[0].${t4}, scale[1].${t4}, scale[2].${t4}, scale[3].${t4}))`;
              default:
                throw new Error(`Not supported compoents ${l3}`);
            }
          }, o4 = sn2("input", t3[0].dataType, t3[0].dims, l3), i4 = an2("output", t3[0].dataType, s3, l3);
          return `
  @group(0) @binding(0) var<storage, read> input : array<${o4.type.storage}>;
  @group(0) @binding(1) var<storage, read> scale_input : array<${r4}>;
  @group(0) @binding(2) var<storage, read_write> output : array<${i4.type.storage}>;
  struct Uniforms {H: u32, C : u32};
  @group(0) @binding(3) var<uniform> uniforms: Uniforms;

  ${e4.mainStart()}
    let current_image_number = global_idx / (uniforms.C * uniforms.H);
    let current_channel_number = global_idx % uniforms.C;

    let scale_offset = current_image_number * uniforms.C + current_channel_number;
    let scale = scale_input[scale_offset];
    output[global_idx] = fma(input[global_idx], ${a4(0)}, ${a4(1)});
  }`;
        } }, { inputs: [t3[0], h3] });
      }, hi2 = (e3, t3) => {
        "NHWC" === t3.format ? mi2(e3, e3.inputs, t3) : pi2(e3, e3.inputs, t3);
      };
    })), su2 = j2((() => {
      dd2(), pd2(), bd2(), fi2 = (e3) => {
        if (!e3 || e3.length < 2) throw new Error("layerNorm requires at least 2 inputs.");
      }, _i2 = (e3, t3, n3) => {
        let r3 = t3.simplified, s3 = e3[0].dims, a3 = e3[1], o3 = !r3 && e3[2], i3 = s3, l3 = gt2.normalizeAxis(t3.axis, s3.length), d3 = gt2.sizeToDimension(s3, l3), u3 = gt2.sizeFromDimension(s3, l3), c3 = gt2.size(a3.dims), p3 = o3 ? gt2.size(o3.dims) : 0;
        if (c3 !== u3 || o3 && p3 !== u3) throw new Error(`Size of X.shape()[axis:] == ${u3}.
       Size of scale and bias (if provided) must match this.
       Got scale size of ${c3} and bias size of ${p3}`);
        let m3 = [];
        for (let e4 = 0; e4 < s3.length; ++e4) e4 < l3 ? m3.push(s3[e4]) : m3.push(1);
        let h3 = Yt2(u3), f3 = ["type", "type"], _3 = [{ type: 12, data: d3 }, { type: 1, data: u3 }, { type: 12, data: Math.floor(u3 / h3) }, { type: 1, data: t3.epsilon }];
        o3 && f3.push("type");
        let g3 = n3 > 1, w3 = n3 > 2, b3 = [{ dims: i3, dataType: e3[0].dataType }];
        return g3 && b3.push({ dims: m3, dataType: 1 }), w3 && b3.push({ dims: m3, dataType: 1 }), { name: "LayerNormalization", shaderCache: { hint: `${h3};${n3};${r3}`, inputDependencies: f3 }, getRunData: () => ({ outputs: b3, dispatchGroup: { x: Math.ceil(d3 / 64) }, programUniforms: _3 }), getShaderSource: (t4) => {
          let n4 = Kt2(e3[0].dataType), s4 = [sn2("x", e3[0].dataType, e3[0].dims, h3), sn2("scale", a3.dataType, a3.dims, h3)];
          o3 && s4.push(sn2("bias", o3.dataType, o3.dims, h3)), s4.push(an2("output", e3[0].dataType, i3, h3)), g3 && s4.push(an2("mean_data_output", 1, m3)), w3 && s4.push(an2("inv_std_output", 1, m3));
          return `
  ${t4.registerUniforms([{ name: "norm_count", type: "u32" }, { name: "norm_size", type: "f32" }, { name: "norm_size_vectorized", type: "u32" }, { name: "epsilon", type: "f32" }]).declareVariables(...s4)}
  ${t4.mainStart()}
    ${t4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.norm_count")}
    let offset = global_idx * uniforms.norm_size_vectorized;
    var mean_vector = ${Zt2("f32", h3)};
    var mean_square_vector = ${Zt2("f32", h3)};

    for (var h: u32 = 0u; h < uniforms.norm_size_vectorized; h++) {
      let value = ${en2(n4, h3, "x[h + offset]")};
      mean_vector += value;
      mean_square_vector += value * value;
    }
    let mean = ${tn2("mean_vector", h3)} / uniforms.norm_size;
    let inv_std_dev = inverseSqrt(${tn2("mean_square_vector", h3)} / uniforms.norm_size ${r3 ? "" : "- mean * mean"} + uniforms.epsilon);

    for (var j: u32 = 0; j < uniforms.norm_size_vectorized; j++) {
      let f32input = ${en2(n4, h3, "x[j + offset]")};
      let f32scale = ${en2(n4, h3, "scale[j]")};
      output[j + offset] = ${s4[0].type.value}((f32input ${r3 ? "" : "- mean"}) * inv_std_dev * f32scale
        ${o3 ? `+ ${en2(n4, h3, "bias[j]")}` : ""}
      );
    }

    ${g3 ? "mean_data_output[global_idx] = mean" : ""};
    ${w3 ? "inv_std_output[global_idx] = inv_std_dev" : ""};
  }`;
        } };
      }, gi2 = (e3, t3) => {
        fi2(e3.inputs), e3.compute(_i2(e3.inputs, t3, e3.outputCount));
      };
    })), au2 = j2((() => {
      pd2(), zd2(), Ld2(), wi2 = (e3) => {
        if (!e3 || 2 !== e3.length) throw new Error("MatMul requires 2 inputs.");
        if (e3[0].dims[e3[0].dims.length - 1] !== e3[1].dims[e3[1].dims.length - 2]) throw new Error("shared dimension does not match.");
      }, bi2 = (e3) => {
        wi2(e3.inputs);
        let t3 = _t2.calcShape(e3.inputs[0].dims, e3.inputs[1].dims, true);
        if (!t3) throw new Error("Can't use matmul on the given tensors");
        let n3 = t3[t3.length - 1], r3 = e3.inputs[0].dims[e3.inputs[0].dims.length - 1];
        if (n3 < 8 && r3 < 8) e3.compute(Zs2(e3.inputs, { activation: "" }, t3));
        else {
          let s3 = t3[t3.length - 2], a3 = gt2.size(e3.inputs[0].dims.slice(0, -2)), o3 = gt2.size(e3.inputs[1].dims.slice(0, -2));
          if (1 !== a3 && 1 === s3 && 1 === o3) {
            let s4 = [1, a3, n3], o4 = [e3.inputs[0].reshape([1, a3, r3]), e3.inputs[1].reshape([1, r3, n3])];
            e3.compute(ia2(o4, { activation: "" }, t3, s4), { inputs: o4 });
          } else e3.compute(ia2(e3.inputs, { activation: "" }, t3));
        }
      };
    })), ou2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), yi2 = (e3, t3) => {
        if (e3.length < 3 || e3.length > 4) throw new Error("MatMulNBits requires 3 or 4 inputs");
        let n3 = e3[0], r3 = n3.dims.length;
        if (n3.dims[r3 - 1] !== t3.k) throw new Error("The last dim of input shape does not match the k value");
        let s3 = Math.floor((t3.k + t3.blockSize - 1) / t3.blockSize), a3 = t3.blockSize / 8 * t3.bits, o3 = e3[1];
        if (!gt2.areEqual(o3.dims, [t3.n, s3, a3])) throw new Error("The second inputs must be 3D tensor with shape N X nBlocksPerCol X blobSize");
        let i3 = e3[2].dims;
        if (gt2.size(i3) !== t3.n * s3) throw new Error("scales input size error.");
        if (4 === e3.length) {
          let n4 = e3[3].dims, r4 = t3.bits > 4 ? t3.n * s3 : t3.n * Math.floor((s3 + 1) / 2);
          if (gt2.size(n4) !== r4) throw new Error("zeroPoints input size error.");
        }
      }, Mi2 = (e3, t3) => {
        let n3 = e3[0].dims, r3 = n3.length, s3 = n3[r3 - 2], a3 = t3.k, o3 = t3.n, i3 = n3.slice(0, r3 - 2), l3 = gt2.size(i3), d3 = e3[1].dims[2] / 4, u3 = e3[0].dataType, c3 = Yt2(t3.k), p3 = Yt2(d3), m3 = Yt2(o3), h3 = i3.concat([s3, o3]), f3 = s3 > 1 && o3 / m3 % 2 == 0 ? 2 : 1, _3 = gt2.size(h3) / m3 / f3, g3 = 64, w3 = [], b3 = [l3, s3, a3 / c3], y3 = gt2.convertShape(e3[1].dims).slice();
        y3.splice(-1, 1, d3 / p3), w3.push(...Jt2(b3)), w3.push(...Jt2(y3)), w3.push(...Jt2(e3[2].dims)), 4 === e3.length && w3.push(...Jt2(gt2.convertShape(e3[3].dims)));
        let M3 = [l3, s3, o3 / m3];
        w3.push(...Jt2(M3));
        return { name: "MatMulNBits", shaderCache: { hint: `${t3.blockSize};${t3.bits};${c3};${p3};${m3};${f3};64`, inputDependencies: Array(e3.length).fill("rank") }, getRunData: () => ({ outputs: [{ dims: h3, dataType: u3 }], dispatchGroup: { x: _3 }, programUniforms: w3 }), getShaderSource: (n4) => {
          let r4 = b3.length, s4 = sn2("a", e3[0].dataType, r4, c3), a4 = sn2("b", 12, y3.length, p3), o4 = sn2("scales", e3[2].dataType, e3[2].dims.length), i4 = [s4, a4, o4], l4 = 4 === e3.length ? sn2("zero_points", 12, e3[3].dims.length) : void 0;
          l4 && i4.push(l4);
          let u4 = M3.length, h4 = an2("output", e3[0].dataType, u4, m3), _4 = Kt2(e3[0].dataType), w4 = (() => {
            switch (c3) {
              case 1:
                return `array<${_4}, 8>`;
              case 2:
                return `mat4x2<${_4}>`;
              case 4:
                return `mat2x4<${_4}>`;
              default:
                throw new Error(`${c3}-component is not supported.`);
            }
          })();
          return `
        var<workgroup> workgroup_shared: array<${h4.type.value}, ${f3 * g3}>;
        ${n4.declareVariables(...i4, h4)}
        ${n4.mainStart([g3, 1, 1])}
          let output_indices = ${h4.offsetToIndices(`(global_idx / 64) * ${f3}`)};
          let col = output_indices[2];
          let row = output_indices[1];
          let batch = output_indices[0];
          let nBlocksPerCol = uniforms.b_shape[1];

          for (var block = local_id.x; block < nBlocksPerCol; block += 64) {
            //process one block
            var word_offset: u32 = block * ${t3.blockSize / c3};
            ${(() => {
            let e4 = `
            var col_index = col * ${m3};
            ${l4 ? "\n            let zero_point_bytes_per_col = (nBlocksPerCol + 1) / 2;\n            var zero_point_byte_count: u32;\n            var zero_point_word_index: u32;\n            var zero_point_byte_offset: u32;\n            let zero_point_nibble_offset: u32 = block & 0x1u;\n            var zero_point_bits_offset: u32;\n            var zero_point_word: u32;" : `
            // The default zero point is 8 for unsigned 4-bit quantization.
            let zero_point = ${_4}(8);`}
            `;
            for (let t4 = 0; t4 < m3 * f3; t4++) e4 += `
            let scale${t4} = ${o4.getByOffset("col_index * nBlocksPerCol + block")};
            ${l4 ? `
            zero_point_byte_count = col_index * zero_point_bytes_per_col + (block >> 0x1u);
            zero_point_word_index = zero_point_byte_count >> 0x2u;
            zero_point_byte_offset = zero_point_byte_count & 0x3u;
            zero_point_bits_offset = (zero_point_byte_offset << 3) + (zero_point_nibble_offset << 2);
            zero_point_word = ${l4.getByOffset("zero_point_word_index")} >> zero_point_bits_offset;
            let zero_point${t4} = ${_4}((zero_point_word) & 0xFu);` : ""}
            col_index += 1;`;
            return e4;
          })()}
            for (var word: u32 = 0; word < ${d3}; word += ${p3}) {
              ${(() => {
            let e4 = `col_index = col * ${m3};`;
            for (let t4 = 0; t4 < m3 * f3; t4++) e4 += `
            let b${t4}_data = ${a4.getByIndices(`${a4.type.indices}(col_index, block, word)`)};
            col_index += 1;`;
            return e4 += `
            var b_value: u32;
            let b_mask: u32 = 0x0F0F0F0Fu;
            var b_value_lower: vec4<u32>;
            var b_value_upper: vec4<u32>;
            var b_quantized_values: ${w4};
            var b_dequantized_values: ${w4};`, e4;
          })()}
              for (var i: u32 = 0; i < ${p3}; i++) {
                ${(() => {
            let e4 = `
          // reuse a data
            var input_offset = ${s4.indicesToOffset(`${s4.type.indices}(batch, row, word_offset)`)};
            var a_data: ${w4};
            for (var j: u32 = 0; j < ${8 / c3}; j++) {
              a_data[j] = ${s4.getByOffset("input_offset")};
              input_offset++;
            }
          `;
            for (let t4 = 0; t4 < m3 * f3; t4++) e4 += `
            b_value = ${1 === p3 ? `b${t4}_data` : `b${t4}_data[i]`};
            b_value_lower = unpack4xU8(b_value & b_mask);
            b_value_upper = unpack4xU8((b_value >> 4) & b_mask);
            b_quantized_values = ${w4}(${Array.from({ length: 4 }, ((e5, t5) => `${_4}(b_value_lower[${t5}]), ${_4}(b_value_upper[${t5}])`)).join(", ")});
            b_dequantized_values = ${1 === c3 ? `${w4}(${Array.from({ length: 8 }, ((e5, n5) => `(b_quantized_values[${n5}] - ${l4 ? `zero_point${t4}` : "zero_point"}) * scale${t4}`)).join(", ")});` : `(b_quantized_values - ${w4}(${Array(8).fill(l4 ? `zero_point${t4}` : "zero_point").join(",")})) * scale${t4};`};
            workgroup_shared[local_id.x * ${f3} + ${Math.floor(t4 / m3)}]${m3 > 1 ? `[${t4 % m3}]` : ""} += ${Array.from({ length: 8 / c3 }, ((e5, t5) => 1 === c3 ? `a_data[${t5}] * b_dequantized_values[${t5}]` : `dot(a_data[${t5}], b_dequantized_values[${t5}])`)).join(" + ")};
          `;
            return e4;
          })()}
                word_offset += ${8 / c3};
              }
            }
          }
          workgroupBarrier();

          if (local_id.x < ${f3}) {
            var output_value: ${h4.type.value} = ${h4.type.value}(0);
            var workgroup_shared_offset: u32 = local_id.x;
            for (var b: u32 = 0u; b < 64u; b++) {
              output_value += workgroup_shared[workgroup_shared_offset];
              workgroup_shared_offset += ${f3};
            }
            ${h4.setByIndices(`${h4.type.indices}(batch, row, col + local_id.x)`, "output_value")};
          }
        }`;
        } };
      }, xi2 = (e3, t3) => {
        let n3 = e3[0].dims, r3 = n3.length, s3 = n3[r3 - 2], a3 = t3.k, o3 = t3.n, i3 = n3.slice(0, r3 - 2), l3 = gt2.size(i3), d3 = e3[1].dims[2] / 4, u3 = e3[0].dataType, c3 = Yt2(t3.k), p3 = Yt2(d3), m3 = i3.concat([s3, o3]), h3 = o3 % 8 == 0 ? 8 : o3 % 4 == 0 ? 4 : 1, f3 = 128 / h3, _3 = f3 * p3 * 8, g3 = _3 / c3, w3 = _3 / t3.blockSize, b3 = gt2.size(m3) / h3, y3 = [], M3 = [l3, s3, a3 / c3], x3 = gt2.convertShape(e3[1].dims).slice();
        x3.splice(-1, 1, d3 / p3), y3.push(...Jt2(M3)), y3.push(...Jt2(x3)), y3.push(...Jt2(e3[2].dims)), 4 === e3.length && y3.push(...Jt2(gt2.convertShape(e3[3].dims)));
        let v3 = [l3, s3, o3];
        y3.push(...Jt2(v3));
        return { name: "BlockwiseMatMulNBits32", shaderCache: { hint: `${t3.blockSize};${c3};${p3};${f3};${h3}`, inputDependencies: Array(e3.length).fill("rank") }, getRunData: () => ({ outputs: [{ dims: m3, dataType: u3 }], dispatchGroup: { x: b3 }, programUniforms: y3 }), getShaderSource: (n4) => {
          let r4 = M3.length, s4 = sn2("a", e3[0].dataType, r4, c3), a4 = sn2("b", 12, x3.length, p3), o4 = sn2("scales", e3[2].dataType, e3[2].dims.length), i4 = [s4, a4, o4], l4 = 4 === e3.length ? sn2("zero_points", 12, e3[3].dims.length) : void 0;
          l4 && i4.push(l4);
          let d4 = v3.length, u4 = an2("output", e3[0].dataType, d4), m4 = Kt2(e3[0].dataType);
          return `
        var<workgroup> sub_a: array<${s4.type.value}, ${g3}>;
        var<workgroup> inter_results: array<array<${u4.type.value}, ${f3}>, ${h3}>;
        ${n4.declareVariables(...i4, u4)}
        ${n4.mainStart([f3, h3, 1])}
          let output_indices = ${u4.offsetToIndices(`workgroup_index * ${h3}`)};
          let col = output_indices[2];
          let row = output_indices[1];
          let batch = output_indices[0];
          let n_blocks_per_col = uniforms.b_shape[1];
          let num_tiles =  (n_blocks_per_col - 1) / ${w3} + 1;

          // Loop over shared dimension.
          for (var tile: u32 = 0; tile < num_tiles; tile += 1) {
            let a_col_start = tile * ${g3};
            // load one tile A data into shared memory.
            for (var a_offset = local_idx; a_offset < ${g3}; a_offset += 128)
            {
              let a_col = a_col_start + a_offset;
              if (a_col < uniforms.a_shape[2])
              {
                sub_a[a_offset] = ${s4.getByIndices(`${s4.type.indices}(batch, row, a_col)`)};
              } else {
                sub_a[a_offset] = ${s4.type.value}(0);
              }
            }
            workgroupBarrier();

            // each thread process one block
            let b_row = col + local_id.y;
            let block = tile * ${w3} + local_id.x;
            ${l4 ? `
            let zero_point_bytes_per_col = (n_blocks_per_col + 1) / 2;
            let zero_point_byte_count = b_row * zero_point_bytes_per_col + (block >> 0x1u);
            let zero_point_word_index = zero_point_byte_count >> 0x2u;
            let zero_point_byte_offset = zero_point_byte_count & 0x3u;
            let zero_point_nibble_offset: u32 = block & 0x1u;
            let zero_point_bits_offset = (zero_point_byte_offset << 3) + (zero_point_nibble_offset << 2);
            let zero_point_word = ${l4.getByOffset("zero_point_word_index")} >> zero_point_bits_offset;
            let zero_point = ${m4}((zero_point_word) & 0xFu);` : `
            // The default zero point is 8 for unsigned 4-bit quantization.
            let zero_point = ${m4}(8);`}
            let scale = ${o4.getByOffset("b_row * n_blocks_per_col + block")};
            let b_data = ${a4.getByIndices(`${a4.type.indices}(b_row, block, 0)`)};
            var word_offset = local_id.x * ${t3.blockSize / c3};
            for (var i: u32 = 0; i < ${p3}; i++) {
              ${(() => {
            switch (c3) {
              case 1:
                return `
          let a_data0 = vec4<${m4}>(sub_a[word_offset], sub_a[word_offset + 1], sub_a[word_offset + 2], sub_a[word_offset + 3]);
          let a_data1 = vec4<${m4}>(sub_a[word_offset + 4], sub_a[word_offset + 5], sub_a[word_offset + 6], sub_a[word_offset + 7]);`;
              case 2:
                return `
          let a_data0 = vec4<${m4}>(sub_a[word_offset], sub_a[word_offset + 1]);
          let a_data1 = vec4<${m4}>(sub_a[word_offset + 2], sub_a[word_offset + 3]);`;
              case 4:
                return "\n          let a_data0 = sub_a[word_offset];\n          let a_data1 = sub_a[word_offset + 1];";
              default:
                throw new Error(`${c3}-component is not supported.`);
            }
          })()}
              let b_value = ${1 === p3 ? "b_data" : "b_data[i]"};
              let b_value_lower = unpack4xU8(b_value & 0x0F0F0F0Fu);
              let b_value_upper = unpack4xU8((b_value >> 4) & 0x0F0F0F0Fu);
              let b_quantized_values = mat2x4<${m4}>(${Array.from({ length: 4 }, ((e4, t4) => `${m4}(b_value_lower[${t4}]), ${m4}(b_value_upper[${t4}])`)).join(", ")});
              let b_dequantized_values = (b_quantized_values - mat2x4<${m4}>(${Array(8).fill("zero_point").join(",")})) * scale;
              inter_results[local_id.y][local_id.x] += ${Array.from({ length: 2 }, ((e4, t4) => `dot(a_data${t4}, b_dequantized_values[${t4}])`)).join(" + ")};
              word_offset += ${8 / c3};
            }
            workgroupBarrier();
          }

          if (local_idx < ${h3}) {
            var output_value: ${u4.type.value} = ${u4.type.value}(0);
            for (var b = 0u; b < ${f3}; b++) {
              output_value += inter_results[local_idx][b];
            }
            if (col + local_idx < uniforms.output_shape[2])
            {
              ${u4.setByIndices(`${u4.type.indices}(batch, row, col + local_idx)`, "output_value")}
            }
          }
        }`;
        } };
      }, vi2 = (e3, t3) => {
        yi2(e3.inputs, t3), 32 === t3.blockSize && e3.adapterInfo.isVendor("intel") && e3.adapterInfo.isArchitecture("gen-12lp") ? e3.compute(xi2(e3.inputs, t3)) : e3.compute(Mi2(e3.inputs, t3));
      }, Ti2 = (e3) => Wt2(e3);
    })), iu2 = j2((() => {
      dd2(), pd2(), bd2(), ki2 = (e3) => {
        if (!e3 || e3.length < 1) throw new Error("Too few inputs");
        if (1 !== e3[0].dataType && 10 !== e3[0].dataType) throw new Error("Input type must be float or float16.");
        if (e3.length >= 2) {
          let t3 = 2 * e3[0].dims.length === e3[1].dims[0];
          if (4 === e3.length && (t3 = 2 * e3[3].dims[0] === e3[1].dims[0]), !t3) throw new Error("The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].");
        }
      }, Pi2 = (e3, t3, n3) => {
        let r3 = "";
        for (let s3 = t3 - 1; s3 >= 0; --s3) r3 += `
            k = i32(${e3.indicesGet("indices", s3)}) - ${nn2("uniforms.pads", s3, n3)};
            if (k < 0) {
              break;
            }
            if (k >= i32(${nn2("uniforms.x_shape", s3, t3)})) {
              break;
            }
            offset += k * i32(${nn2("uniforms.x_strides", s3, t3)});
        `;
        return `
          value = ${e3.type.value}(uniforms.constant_value);
          for (var i = 0; i < 1; i++) {
            var offset = 0;
            var k = 0;
            ${r3}
            value = x[offset];
          }
      `;
      }, $i2 = (e3, t3, n3) => {
        let r3 = "";
        for (let s3 = t3 - 1; s3 >= 0; --s3) r3 += `
                k = i32(${e3.indicesGet("indices", s3)}) - ${nn2("uniforms.pads", s3, n3)};
                if (k < 0) {
                  k = -k;
                }
                {
                  let _2n_1 = 2 * (i32(${nn2("uniforms.x_shape", s3, t3)}) - 1);
                  k = k % _2n_1;
                  if(k >= i32(${nn2("uniforms.x_shape", s3, t3)})) {
                    k = _2n_1 - k;
                  }
                }
                offset += k * i32(${nn2("uniforms.x_strides", s3, t3)});
            `;
        return `
              var offset = 0;
              var k = 0;
              ${r3}
              value = x[offset];
          `;
      }, Ci2 = (e3, t3, n3) => {
        let r3 = "";
        for (let s3 = t3 - 1; s3 >= 0; --s3) r3 += `
                k = i32(${e3.indicesGet("indices", s3)}) - ${nn2("uniforms.pads", s3, n3)};
                if (k < 0) {
                  k = 0;
                }
                if (k >= i32(${nn2("uniforms.x_shape", s3, t3)})) {
                  k = i32(${nn2("uniforms.x_shape", s3, t3)}) - 1;
                }
                offset += k * i32(${nn2("uniforms.x_strides", s3, t3)});
            `;
        return `
              var offset = 0;
              var k = 0;
              ${r3}
              value = x[offset];
          `;
      }, Si2 = (e3, t3, n3) => {
        let r3 = "";
        for (let s3 = t3 - 1; s3 >= 0; --s3) r3 += `
                k = i32(${e3.indicesGet("indices", s3)}) - ${nn2("uniforms.pads", s3, n3)};
                if (k < 0)  {
                  k += i32(${nn2("uniforms.x_shape", s3, t3)}]);
                }
                if (k >= i32(${nn2("uniforms.x_shape", s3, t3)})) {
                  k -= i32(${nn2("uniforms.x_shape", s3, t3)});
                }
                offset += k * i32(${nn2("uniforms.x_strides", s3, t3)});
            `;
        return `
              var offset = 0;
              var k = 0;
              ${r3}
              value = x[offset];
          `;
      }, Fi2 = (e3, t3, n3) => {
        switch (n3.mode) {
          case 0:
            return Pi2(e3, t3, n3.pads.length);
          case 1:
            return $i2(e3, t3, n3.pads.length);
          case 2:
            return Ci2(e3, t3, n3.pads.length);
          case 3:
            return Si2(e3, t3, n3.pads.length);
          default:
            throw new Error("Invalid mode");
        }
      }, Ei2 = (e3, t3) => {
        let n3 = gt2.padShape(e3[0].dims.slice(), t3.pads), r3 = e3[0].dims, s3 = [{ type: 12, data: gt2.size(n3) }, { type: 6, data: t3.pads }], a3 = e3.length >= 3 && e3[2].data;
        0 === t3.mode && s3.push({ type: a3 ? e3[2].dataType : 1, data: t3.value }), s3.push(...Jt2(e3[0].dims, n3));
        return { name: "Pad", shaderCache: { hint: `${t3.mode}${a3}`, inputDependencies: ["rank"] }, getRunData: () => ({ outputs: [{ dims: n3, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(gt2.size(n3) / 64) }, programUniforms: s3 }), getShaderSource: (s4) => {
          let o3 = an2("output", e3[0].dataType, n3.length), i3 = sn2("x", e3[0].dataType, r3.length), l3 = i3.type.value, d3 = Fi2(o3, r3.length, t3), u3 = [{ name: "output_size", type: "u32" }, { name: "pads", type: "i32", length: t3.pads.length }];
          return 0 === t3.mode && u3.push({ name: "constant_value", type: a3 ? l3 : "f32" }), `
            ${s4.registerUniforms(u3).declareVariables(i3, o3)}
            ${s4.mainStart()}
            ${s4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}

            let indices = ${o3.offsetToIndices("global_idx")};

            var value = ${l3}(0);
            ${d3}
            output[global_idx] = value;
        }`;
        } };
      }, Ii2 = (e3, t3) => {
        if (e3.length > 1) {
          let n3 = e3[1].getBigInt64Array(), r3 = e3.length >= 3 && e3[2].data ? 10 === e3[2].dataType ? e3[2].getUint16Array()[0] : e3[2].getFloat32Array()[0] : 0, s3 = e3[0].dims.length, a3 = new Int32Array(2 * s3).fill(0);
          if (e3.length >= 4) {
            let t4 = e3[3].getBigInt64Array();
            for (let e4 = 0; e4 < t4.length; e4++) a3[Number(t4[e4])] = Number(n3[e4]), a3[Number(t4[e4]) + s3] = Number(n3[e4 + t4.length]);
          } else n3.forEach(((e4, t4) => a3[Number(t4)] = Number(e4)));
          let o3 = [];
          return a3.forEach(((e4) => o3.push(e4))), { mode: t3.mode, value: r3, pads: o3 };
        }
        return t3;
      }, Ai2 = (e3, t3) => {
        ki2(e3.inputs);
        let n3 = Ii2(e3.inputs, t3);
        e3.compute(Ei2(e3.inputs, n3), { inputs: [0] });
      };
    })), lu2 = j2((() => {
      le2(), dd2(), pd2(), bd2(), zi2 = (e3) => {
        if (p2.webgpu.validateInputContent && (!e3 || 1 !== e3.length)) throw new Error("Pool ops requires 1 input.");
      }, Li2 = (e3, t3, n3) => {
        let r3 = "NHWC" === t3.format, s3 = e3.dims.slice();
        r3 && s3.splice(1, 0, s3.pop());
        let a3 = Object.hasOwnProperty.call(t3, "dilations"), o3 = t3.kernelShape.slice(), i3 = t3.strides.slice(), l3 = a3 ? t3.dilations.slice() : [], d3 = t3.pads.slice();
        wt2.adjustPoolAttributes(n3, s3, o3, i3, l3, d3);
        let u3 = wt2.computePoolOutputShape(n3, s3, i3, l3, o3, d3, t3.autoPad), c3 = Object.assign({}, t3);
        a3 ? Object.assign(c3, { kernelShape: o3, strides: i3, pads: d3, dilations: l3, cacheKey: t3.cacheKey }) : Object.assign(c3, { kernelShape: o3, strides: i3, pads: d3, cacheKey: t3.cacheKey });
        let p3 = u3.slice();
        return p3.push(p3.splice(1, 1)[0]), [c3, r3 ? p3 : u3];
      }, Oi2 = (e3, t3) => {
        let n3 = "NHWC" === t3.format, r3 = [{ type: 12, data: gt2.size(e3) }, { type: 12, data: gt2.size(t3.kernelShape) }], s3 = [{ name: "outputSize", type: "u32" }, { name: "kernelSize", type: "u32" }];
        if (t3.kernelShape.length <= 2) {
          let e4 = t3.kernelShape[t3.kernelShape.length - 1], n4 = t3.strides[t3.strides.length - 1], a3 = t3.pads[t3.pads.length / 2 - 1], o3 = t3.pads[t3.pads.length - 1], i3 = !!(a3 + o3);
          r3.push({ type: 12, data: e4 }, { type: 12, data: n4 }, { type: 12, data: a3 }, { type: 12, data: o3 }), s3.push({ name: "kw", type: "u32" }, { name: "sw", type: "u32" }, { name: "pwStart", type: "u32" }, { name: "pwEnd", type: "u32" });
          let l3 = false;
          if (2 === t3.kernelShape.length) {
            let e5 = t3.kernelShape[t3.kernelShape.length - 2], n5 = t3.strides[t3.strides.length - 2], a4 = t3.pads[t3.pads.length / 2 - 2], o4 = t3.pads[t3.pads.length - 2];
            l3 = !!(a4 + o4), r3.push({ type: 12, data: e5 }, { type: 12, data: n5 }, { type: 12, data: a4 }, { type: 12, data: o4 }), s3.push({ name: "kh", type: "u32" }, { name: "sh", type: "u32" }, { name: "phStart", type: "u32" }, { name: "phEnd", type: "u32" });
          }
          return [r3, s3, true, i3, l3];
        }
        {
          if (n3) throw new Error("Pooling with kernelShape.length > 2 is not supported for NHWC format.");
          let e4 = gt2.computeStrides(t3.kernelShape);
          return r3.push({ type: 12, data: e4 }, { type: 12, data: t3.pads }, { type: 12, data: t3.strides }), s3.push({ name: "kernelStrides", type: "u32", length: e4.length }, { name: "pads", type: "u32", length: t3.pads.length }, { name: "strides", type: "u32", length: t3.strides.length }), [r3, s3, !!t3.pads.reduce(((e5, t4) => e5 + t4)), false, false];
        }
      }, Di2 = (e3, t3, n3, r3, s3, a3, o3, i3, l3, d3, u3, c3) => {
        let p3 = "NHWC" === s3.format, m3 = t3.type.value, h3 = an2("output", t3.type.tensor, r3);
        if (s3.kernelShape.length <= 2) {
          let r4 = "", d4 = "", f3 = "", _3 = n3 - (p3 ? 2 : 1);
          if (r4 = u3 ? `
                for (var i: u32 = 0u; i < uniforms.kw; i++) {
                  xIndices[${_3}] = indices[${_3}] * uniforms.sw - uniforms.pwStart + i;
                  if (xIndices[${_3}] < 0 || xIndices[${_3}]
                      >= uniforms.x_shape[${_3}]) {
                    pad++;
                    continue;
                  }
                  let x_val = x[${t3.indicesToOffset("xIndices")}];
                  ${a3}
                }` : `
                for (var i: u32 = 0u; i < uniforms.kw; i++) {
                  xIndices[${_3}] = indices[${_3}] * uniforms.sw - uniforms.pwStart + i;
                  let x_val = x[${t3.indicesToOffset("xIndices")}];
                  ${a3}
                }`, 2 === s3.kernelShape.length) {
            let e4 = n3 - (p3 ? 3 : 2);
            d4 = c3 ? `
                for (var j: u32 = 0u; j < uniforms.kh; j++) {
                  xIndices[${e4}] = indices[${e4}] * uniforms.sh - uniforms.phStart + j;
                  if (xIndices[${e4}] < 0 || xIndices[${e4}] >= uniforms.x_shape[${e4}]) {
                    pad += i32(uniforms.kw);
                    continue;
                  }
              ` : `
                for (var j: u32 = 0u; j < uniforms.kh; j++) {
                  xIndices[${e4}] = indices[${e4}] * uniforms.sh - uniforms.phStart + j;
                `, f3 = "\n              }\n            ";
          }
          return `
            ${e3.registerUniforms(l3).declareVariables(t3, h3)}

            ${e3.mainStart()}
              ${e3.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}

              let indices = ${h3.offsetToIndices("global_idx")};
              var xIndices = ${h3.offsetToIndices("global_idx")};

              var value = ${m3}(${i3});
              var pad = 0;
              ${d4}
              ${r4}
              ${f3}
              ${o3}

              output[global_idx] = value;
            }`;
        }
        {
          if (p3) throw new Error("Pooling with kernelShape.length > 2 is not supported for NHWC format.");
          let r4 = s3.kernelShape.length, u4 = s3.pads.length, c4 = "";
          return c4 = d3 ? `
                if (xIndices[j] >= uniforms.x_shape[j]) {
                  pad++;
                  isPad = true;
                  break;
                }
              }
              if (!isPad) {
                let x_val = x[${t3.indicesToOffset("xIndices")}];
                ${a3}
              }` : `
              }
              let x_val = x[${t3.indicesToOffset("xIndices")}];
              ${a3}
            `, `
            ${e3.registerUniforms(l3).declareVariables(t3, h3)}

            ${e3.mainStart()}
              ${e3.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
              let indices = ${h3.offsetToIndices("global_idx")};
              var xIndices = ${h3.offsetToIndices("global_idx")};

              var offsets: array<u32, ${r4}>;

              var value = ${m3}(${i3});
              var pad = 0;
              var isPad = false;

              for (var i: u32 = 0u; i < uniforms.kernelSize; i++) {
                var offset = i;
                for (var j = 0u; j < ${r4 - 1}u; j++) {
                  offsets[j] = offset / ${nn2("uniforms.kernelStrides", "j", r4)};
                  offset -= offsets[j] * ${nn2("uniforms.kernelStrides", "j", r4)};
                }
                offsets[${r4 - 1}] = offset;

                isPad = false;
                for (var j = ${n3 - r4}u; j < ${n3}u; j++) {
                  xIndices[j] = indices[j] * ${nn2("uniforms.strides", `j - ${n3 - r4}u`, r4)}
                    + offsets[j - ${n3 - r4}u] - ${nn2("uniforms.pads", "j - 2u", u4)};
                  ${c4}
              }
              ${o3}

              output[global_idx] = value;
            }`;
        }
      }, Bi2 = (e3) => `${e3.format};${e3.ceilMode};${e3.autoPad};${e3.kernelShape.length}`, Ni2 = (e3) => `${Bi2(e3)};${e3.countIncludePad}`, ji2 = (e3) => `${Bi2(e3)};${e3.storageOrder};${e3.dilations}`, Ri2 = (e3) => ({ format: e3.format, autoPad: ["NOTSET", "VALID", "SAME_UPPER", "SAME_LOWER"][e3.auto_pad], ceilMode: e3.ceil_mode, kernelShape: e3.kernel_shape, strides: e3.strides, pads: e3.pads }), Vi2 = (e3, t3, n3, r3) => {
        let [s3, a3] = Li2(t3, r3, n3), o3 = sn2("x", t3.dataType, t3.dims.length), i3 = o3.type.value, l3 = "";
        s3.countIncludePad ? l3 += `value /= ${i3}(uniforms.kernelSize);` : l3 += `value /= ${i3}(i32(uniforms.kernelSize) - pad);`;
        let [d3, u3, c3, p3, m3] = Oi2(a3, s3);
        d3.push(...Jt2(t3.dims, a3));
        return { name: e3, shaderCache: { hint: `${r3.cacheKey};${c3};${p3};${m3}`, inputDependencies: ["rank"] }, getRunData: () => ({ outputs: [{ dims: a3, dataType: t3.dataType }], dispatchGroup: { x: Math.ceil(gt2.size(a3) / 64) }, programUniforms: d3 }), getShaderSource: (e4) => Di2(e4, o3, t3.dims.length, a3.length, s3, "value += x_val;", l3, 0, u3, c3, p3, m3) };
      }, Gi2 = (e3) => {
        let t3 = 0 !== e3.count_include_pad, n3 = Ri2(e3);
        if (0 !== n3.ceilMode) throw new Error("using ceil() in shape computation is not yet supported for AveragePool");
        let r3 = { countIncludePad: t3, ...n3, cacheKey: "" };
        return { ...r3, cacheKey: Ni2(r3) };
      }, qi2 = (e3, t3) => {
        zi2(e3.inputs), e3.compute(Vi2("AveragePool", e3.inputs[0], false, t3));
      }, Ui2 = { autoPad: "", ceilMode: 0, countIncludePad: false, kernelShape: [], strides: [], pads: [], storageOrder: 0, dilations: [] }, Wi2 = (e3) => {
        let t3 = e3.format;
        return { format: t3, ...Ui2, cacheKey: t3 };
      }, Hi2 = (e3, t3) => {
        zi2(e3.inputs), e3.compute(Vi2("GlobalAveragePool", e3.inputs[0], true, t3));
      }, Qi2 = (e3, t3, n3, r3) => {
        let [s3, a3] = Li2(t3, r3, n3), o3 = sn2("x", t3.dataType, t3.dims.length), [i3, l3, d3, u3, c3] = Oi2(a3, s3);
        return i3.push(...Jt2(t3.dims, a3)), { name: e3, shaderCache: { hint: `${r3.cacheKey};${d3};${u3};${c3}`, inputDependencies: ["rank"] }, getRunData: () => ({ outputs: [{ dims: a3, dataType: t3.dataType }], dispatchGroup: { x: Math.ceil(gt2.size(a3) / 64) }, programUniforms: i3 }), getShaderSource: (e4) => Di2(e4, o3, t3.dims.length, a3.length, s3, "\n      value = max(x_val, value);\n    ", "", 10 === t3.dataType ? -65504 : -1e5, l3, d3, u3, c3) };
      }, Ki2 = (e3, t3) => {
        zi2(e3.inputs), e3.compute(Qi2("MaxPool", e3.inputs[0], false, t3));
      }, Xi2 = (e3) => {
        let t3 = e3.storage_order, n3 = e3.dilations, r3 = Ri2(e3);
        if (0 !== t3) throw new Error("column major storage order is not yet supported for MaxPool");
        if (0 !== r3.ceilMode) throw new Error("using ceil() in shape computation is not yet supported for MaxPool");
        let s3 = { storageOrder: t3, dilations: n3, ...r3, cacheKey: "" };
        return { ...s3, cacheKey: ji2(s3) };
      }, Ji2 = (e3) => {
        let t3 = e3.format;
        return { format: t3, ...Ui2, cacheKey: t3 };
      }, Yi2 = (e3, t3) => {
        zi2(e3.inputs), e3.compute(Qi2("GlobalMaxPool", e3.inputs[0], true, t3));
      };
    })), du2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), Zi2 = (e3, t3) => {
        if (e3.length < 2 || e3.length > 3) throw new Error("DequantizeLinear requires 2 or 3 inputs.");
        if (3 === e3.length && e3[1].dims === e3[2].dims) throw new Error("x-scale and x-zero-point must have the same shape.");
        if (3 === e3.length && e3[0].dataType !== e3[2].dataType) throw new Error("x and x-zero-point must have the same data type.");
        if (6 === e3[0].dataType && e3.length > 2) throw new Error("In the case of dequantizing int32 there is no zero point.");
        if (0 !== e3[1].dims.length && 1 !== e3[1].dims.length && e3[1].dims.length !== e3[0].dims.length) throw new Error("scale input must be a scalar, a 1D tensor, or have the same rank as the input tensor.");
        if (e3.length > 2) {
          if (e3[0].dataType !== e3[2].dataType) throw new Error("x and x-zero-point must have the same data type.");
          if (e3[1].dims.length !== e3[2].dims.length) throw new Error("scale and zero-point inputs must have the same rank.");
          if (!e3[1].dims.map(((t4, n3) => t4 === e3[2].dims[n3])).reduce(((e4, t4) => e4 && t4), true)) throw new Error("scale and zero-point inputs must have the same shape.");
        }
        if (t3.blockSize > 0) {
          if (0 === e3[1].dims.length || 1 === e3[1].dims.length && 1 === e3[1].dims[0]) throw new Error("blockSize must be set only for block quantization.");
          if (!e3[1].dims.map(((n4, r4) => r4 === t3.axis || n4 === e3[0].dims[r4])).reduce(((e4, t4) => e4 && t4), true)) throw new Error("For block qunatization, scale input shape to match the input shape except for the axis");
          if (e3[1].dims.length !== e3[0].dims.length) throw new Error("For block qunatization the scale input rank must be the same as the x rank.");
          let n3 = e3[0].dims[t3.axis], r3 = e3[1].dims[t3.axis];
          if (t3.blockSize < Math.ceil(n3 / r3) || t3.blockSize > Math.ceil(n3 / (r3 - 1) - 1)) throw new Error("blockSize must be with in the range [ceil(dI / Si), ceil(dI / (Si - 1) - 1)].");
        }
      }, el2 = (e3, t3) => {
        let n3 = gt2.normalizeAxis(t3.axis, e3[0].dims.length), r3 = e3[0].dataType, s3 = 3 === r3, a3 = e3[0].dims, o3 = e3[1].dataType, i3 = gt2.size(a3), l3 = 3 === r3 || 2 === r3, d3 = l3 ? [Math.ceil(gt2.size(e3[0].dims) / 4)] : e3[0].dims, u3 = e3[1].dims, c3 = e3.length > 2 ? e3[2] : void 0, p3 = c3 ? l3 ? [Math.ceil(gt2.size(c3.dims) / 4)] : c3.dims : void 0, m3 = 0 === u3.length || 1 === u3.length && 1 === u3[0], h3 = false === m3 && 1 === u3.length, f3 = Yt2(i3), _3 = m3 && (!l3 || 4 === f3), g3 = _3 ? f3 : 1, w3 = _3 && !l3 ? f3 : 1, b3 = sn2("input", l3 ? 12 : r3, d3.length, w3), y3 = sn2("scale", o3, u3.length), M3 = c3 ? sn2("zero_point", l3 ? 12 : r3, p3.length) : void 0, x3 = an2("output", o3, a3.length, g3), v3 = [b3, y3];
        M3 && v3.push(M3);
        let T3 = [d3, u3];
        c3 && T3.push(p3);
        let k3 = [{ type: 12, data: i3 / g3 }, { type: 12, data: n3 }, { type: 12, data: t3.blockSize }, ...Jt2(...T3, a3)];
        return { name: "DequantizeLinear", shaderCache: { hint: t3.cacheKey, inputDependencies: M3 ? ["rank", "rank", "rank"] : ["rank", "rank"] }, getShaderSource: (e4) => `
      ${e4.registerUniforms([{ name: "output_size", type: "u32" }, { name: "axis", type: "u32" }, { name: "block_size", type: "u32" }]).declareVariables(...v3, x3)}
      ${e4.mainStart()}
          ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
          let output_indices = ${x3.offsetToIndices("global_idx")};

          // Set input x
          ${l3 ? `
            let input = ${b3.getByOffset("global_idx / 4")};
            let x_vec = ${s3 ? "unpack4xI8(input)" : "unpack4xU8(input)"};
            let x_value = ${1 === g3 ? "x_vec[global_idx % 4]" : "x_vec"};` : `let x_value = ${b3.getByOffset("global_idx")};`};

          // Set scale input
          ${m3 ? `let scale_value= ${y3.getByOffset("0")}` : h3 ? `
            let scale_index = ${x3.indicesGet("output_indices", "uniforms.axis")};
            let scale_value= ${y3.getByOffset("scale_index")};` : `
            var scale_indices: ${y3.type.indices} = output_indices;
            let index = ${y3.indicesGet("scale_indices", "uniforms.axis")} / uniforms.block_size;
            ${y3.indicesSet("scale_indices", "uniforms.axis", "index")};
            let scale_value= ${y3.getByIndices("scale_indices")};`};

          // Set zero-point input
          ${M3 ? m3 ? l3 ? `
                let zero_point_input = ${M3.getByOffset("0")};
                let zero_point_vec =  ${s3 ? "unpack4xI8(zero_point_input)" : "unpack4xU8(zero_point_input)"};
                let zero_point_value= zero_point_vec[0]` : `let zero_point_value = ${M3.getByOffset("0")}` : h3 ? l3 ? `
                let zero_point_index = ${x3.indicesGet("output_indices", "uniforms.axis")};
                let zero_point_input = ${M3.getByOffset("zero_point_index / 4")};
                let zero_point_vec =  ${s3 ? "unpack4xI8(zero_point_input)" : "unpack4xU8(zero_point_input)"};
                let zero_point_value = zero_point_vec[zero_point_index % 4]` : `
                let zero_point_index = ${x3.indicesGet("output_indices", "uniforms.axis")};
                let zero_point_value = ${M3.getByOffset("zero_point_index")};` : l3 ? `
                let zero_point_offset = ${y3.indicesToOffset("scale_indices")};
                let zero_point_input = ${M3.getByOffset("zero_point_offset / 4")};
                let zero_point_vec = ${s3 ? "unpack4xI8(zero_point_input)" : "unpack4xU8(zero_point_input)"};
                let zero_point_value = zero_point_vec[zero_point_offset % 4];` : `let zero_point_value = ${M3.getByIndices("scale_indices")};` : `let zero_point_value = ${l3 ? s3 ? "i32" : "u32" : b3.type.value}(0);`};
      // Compute and write output
      ${x3.setByOffset("global_idx", `${x3.type.value}(x_value - zero_point_value) * scale_value`)};
      }`, getRunData: () => ({ outputs: [{ dims: a3, dataType: o3 }], dispatchGroup: { x: Math.ceil(i3 / g3 / 64), y: 1, z: 1 }, programUniforms: k3 }) };
      }, tl2 = (e3, t3) => {
        Zi2(e3.inputs, t3), e3.compute(el2(e3.inputs, t3));
      }, nl2 = (e3) => Wt2({ axis: e3.axis, blockSize: e3.blockSize });
    })), uu2 = j2((() => {
      le2(), dd2(), bd2(), rl2 = (e3, t3, n3) => {
        if (e3 === t3 || e3 < t3 && n3 < 0 || e3 > t3 && n3 > 0) throw new Error("Range these inputs' contents are invalid.");
      }, sl2 = (e3, t3, n3, r3) => {
        let s3 = Math.abs(Math.ceil((t3 - e3) / n3)), a3 = [s3], o3 = s3, i3 = [{ type: 12, data: o3 }, { type: r3, data: e3 }, { type: r3, data: n3 }, ...Jt2(a3)];
        return { name: "Range", shaderCache: { hint: `${r3}` }, getShaderSource: (e4) => {
          let t4 = an2("output", r3, a3.length), n4 = t4.type.value, s4 = [{ name: "outputSize", type: "u32" }, { name: "start", type: n4 }, { name: "delta", type: n4 }];
          return `
        ${e4.registerUniforms(s4).declareVariables(t4)}
        ${e4.mainStart()}
        ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
        output[global_idx] = uniforms.start + ${n4}(global_idx) * uniforms.delta;
      }`;
        }, getRunData: () => ({ outputs: [{ dims: a3, dataType: r3 }], dispatchGroup: { x: Math.ceil(o3 / 64) }, programUniforms: i3 }) };
      }, al2 = (e3) => {
        let t3 = 0, n3 = 0, r3 = 0;
        6 === e3.inputs[0].dataType ? (t3 = e3.inputs[0].getInt32Array()[0], n3 = e3.inputs[1].getInt32Array()[0], r3 = e3.inputs[2].getInt32Array()[0]) : 1 === e3.inputs[0].dataType && (t3 = e3.inputs[0].getFloat32Array()[0], n3 = e3.inputs[1].getFloat32Array()[0], r3 = e3.inputs[2].getFloat32Array()[0]), p2.webgpu.validateInputContent && rl2(t3, n3, r3), e3.compute(sl2(t3, n3, r3, e3.inputs[0].dataType), { inputs: [] });
      };
    })), cu2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), ol2 = (e3, t3, n3, r3) => {
        if ("none" !== e3 && "i32" !== r3 && "u32" !== r3 && "f32" !== r3) throw new Error(`Input ${r3} is not supported with reduction ${e3}.`);
        let s3 = "{\n                var oldValue = 0;\n                loop {\n                  let newValueF32 =", a3 = `;
                  let newValue = bitcast<i32>(newValueF32);
                  let res = atomicCompareExchangeWeak(&${t3}, oldValue, newValue);
                  if res.exchanged {
                    break;
                  }
                  oldValue = res.old_value;
                }
              }`;
        switch (e3) {
          case "none":
            return `${t3}=${n3};`;
          case "add":
            return "i32" === r3 || "u32" === r3 ? `atomicAdd(&${t3}, bitcast<${r3}>(${n3}));` : `
              ${s3}bitcast<${r3}>(oldValue) + (${n3})${a3}`;
          case "max":
            return "i32" === r3 || "u32" === r3 ? `atomicMax(&${t3}, bitcast<${r3}>(${n3}));` : `
                ${s3}max(bitcast<f32>(oldValue), (${n3}))${a3}`;
          case "min":
            return "i32" === r3 || "u32" === r3 ? `atomicMin(&${t3}, bitcast<${r3}>(${n3}));` : `${s3}min(bitcast<${r3}>(oldValue), (${n3}))${a3}`;
          case "mul":
            return `${s3}(bitcast<${r3}>(oldValue) * (${n3}))${a3}`;
          default:
            throw new Error(`Reduction ${e3} is not supported.`);
        }
      }, il2 = (e3, t3) => (1 === e3 ? "\n    let element_count_dim = uniforms.output_strides;\n    let dim_value = uniforms.output_shape;" : `
    let element_count_dim = uniforms.output_strides[${t3 ? "i - indices_start" : "i"}];
    let dim_value = uniforms.output_shape[${t3 ? "i - indices_start" : "i"} + uniforms.last_index_dimension];`) + "\n    \n    if (index >= 0) {\n      if (index >= i32(dim_value)) {\n        index = i32(dim_value - 1);\n      }\n    } else {\n      if (index < -i32(dim_value)) {\n        index = 0;\n      } else {\n        index += i32(dim_value);\n      }\n    }\n    data_offset += u32((u32(index) * element_count_dim));", ll2 = (e3, t3, n3) => `for (var i = 0u; i < uniforms.num_updates_elements; i++) {
        let value = updates[uniforms.num_updates_elements * ${n3 ? "global_idx" : "idx"} + i];
        ${ol2(e3.reduction, "output[data_offset + i]", "value", t3)}
      }`, dl2 = (e3, t3) => {
        let n3 = e3[0].dims, r3 = e3[1].dims, s3 = n3, a3 = Math.ceil(gt2.size(r3) / 1), o3 = r3[r3.length - 1], i3 = gt2.sizeFromDimension(n3, o3), l3 = gt2.sizeFromDimension(r3, 0) / o3, d3 = [{ type: 12, data: a3 }, { type: 12, data: o3 }, { type: 12, data: i3 }, ...Jt2(e3[1].dims, e3[2].dims, s3)];
        return { name: "ScatterND", shaderCache: { hint: `${t3.cacheKey}_${t3.reduction}`, inputDependencies: ["rank", "rank"] }, getRunData: () => ({ outputs: [{ dims: s3, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(a3 / 64) }, programUniforms: d3 }), getShaderSource: (r4) => {
          let a4 = sn2("indices", e3[1].dataType, e3[1].dims.length), o4 = sn2("updates", e3[2].dataType, e3[2].dims.length, 1), i4 = "none" !== t3.reduction && "" !== t3.reduction ? on2("output", e3[0].dataType, s3.length) : an2("output", e3[0].dataType, s3.length, 1);
          return `
      ${r4.registerUniform("output_size", "u32").registerUniform("last_index_dimension", "u32").registerUniform("num_updates_elements", "u32").declareVariables(a4, o4, i4)}
      ${r4.mainStart()}
        ${r4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
  var hasDuplicates = false;
  if (${"none" === t3.reduction}) {
    for (var i = 0; i < ${l3}; i = i + 1) {
      for (var j = i + 1; j < ${l3}; j = j + 1) {
        var index_i = i32(indices[i].x);
        var index_j = i32(indices[j].x);
        if (index_i == index_j) {
          hasDuplicates = true;
          break;
        }
      }
      if (hasDuplicates) {
        break;
      }
    }
  }

  if (${"none" === t3.reduction} && hasDuplicates) {
    if (global_idx != 0u) {
      return;
    }
    // Process each index-update pair individually when duplicates exist
    for (var idx = 0u; idx < ${l3}u; idx++) {
      var data_offset = 0u;
      for (var i = 0u; i < uniforms.last_index_dimension; i++) {
        var index = i32(indices[idx * uniforms.last_index_dimension + i].x);
        ${il2(n3.length, false)}
      }
      ${ll2(t3, i4.type.value, false)}
    }
    return;
  }

  var data_offset = 0u;
  var indices_start = uniforms.last_index_dimension * global_idx;
  var indices_end = indices_start + uniforms.last_index_dimension;
  for (var i = indices_start; i < indices_end; i++) {
    var index = i32(indices[i].x);
    ${il2(n3.length, true)}
  }
  ${ll2(t3, i4.type.value, true)}
  }`;
        } };
      }, ul2 = (e3) => Wt2({ reduction: e3.reduction }), cl2 = (e3, t3) => {
        e3.compute(dl2(e3.inputs, t3), { inputs: [e3.inputs[1], e3.inputs[2]], outputs: [] });
      };
    })), pu2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), pl2 = (e3, t3) => {
        if (e3.every(((e4) => e4 > 0 || (() => {
          throw new Error("Resize requires scales input values to be positive");
        }))), e3.length > 0) {
          if ("linear" === t3.mode) {
            if (!(2 === e3.length || 3 === e3.length || 4 === e3.length && 1 === e3[0] && 1 === e3[1] || 4 === e3.length && 1 === e3[0] && 1 === e3[3] || 5 === e3.length && 1 === e3[0] && 1 === e3[1])) throw new Error("For linear mode, Resize requires scales to be 2D, 3D, 4D with either two outermost or one innermost and\n            one outermost scale values equal to 1, or 5D with two outermost scale values equal to 1");
          } else if ("cubic" === t3.mode && !(2 === e3.length || 4 === e3.length && 1 === e3[0] && 1 === e3[1] || 4 === e3.length && 1 === e3[0] && 1 === e3[3])) throw new Error("Resize requires scales input size to be 2 or 4 for cubic mode");
        }
      }, ml2 = (e3, t3, n3) => {
        t3.every(((e4) => e4 >= 0 && e4 < n3 || (() => {
          throw new Error("Resize requires axes input values to be positive and less than rank");
        })));
        let r3 = new Array(n3).fill(1);
        return t3.forEach(((t4, n4) => r3[t4] = e3[n4])), r3;
      }, hl2 = (e3, t3, n3, r3, s3, a3) => {
        let [o3, i3, l3] = n3 > 10 ? [1, 2, 3] : [-1, e3.length > 1 ? 1 : -1, -1], d3 = e3[0].dims.length;
        if (o3 > 0 && e3.length > o3 && e3[o3].dims.length > 0) e3[o3].getFloat32Array().forEach(((e4) => a3.push(e4)));
        else if ("tf_crop_and_resize" === t3.coordinateTransformMode) throw new Error("Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize");
        if (i3 > 0 && e3.length > i3 && 1 === e3[i3].dims.length && e3[i3].dims[0] > 0) {
          if (e3[i3].getFloat32Array().forEach(((e4) => r3.push(e4))), 0 !== r3.length && r3.length !== d3 && n3 >= 18 && r3.length !== t3.axes.length) throw new Error("Resize requires scales input size to be same as input rank or axes size for opset 18 and up");
          pl2(r3, t3), t3.axes.length > 0 && ml2(r3, t3.axes, d3).forEach(((e4, t4) => r3[t4] = e4));
        }
        if (l3 > 0 && e3.length > l3 && 1 === e3[l3].dims.length && e3[l3].dims[0] > 0 && (e3[l3].getBigInt64Array().forEach(((e4) => s3.push(Number(e4)))), 0 !== s3.length && s3.length !== d3 && n3 >= 18 && s3.length !== t3.axes.length)) throw new Error("Resize requires sizes input size to be same as input rank or axes size for opset 18 and up");
        if (t3.axes.length > 0) {
          if (0 !== r3.length && r3.length !== t3.axes.length) throw new Error('Resize requires "scales" input size to be of axes rank when axes attributes is specified');
          if (0 !== s3.length && s3.length !== t3.axes.length) throw new Error('Resize requires "sizes" input size to be of rank axes rank when axes attributes is specified');
        }
        if (typeof r3 < "u" && typeof s3 < "u" && r3.length > 0 && s3.length > d3) throw new Error("Resize requires only of scales or sizes to be specified");
      }, fl2 = (e3, t3, n3, r3) => `
  // The whole part and the fractional part are calculated separately due to inaccuracy of floating
  // point division. As an example, f32(21) / f32(7) may evaluate to 2.99... instead of 3, causing an
  // offset-by-one error later in floor().
  let big = (${e3}) * (${t3});
  let whole = ${r3}(big / (${n3}));
  let fract = ${r3}(big % (${n3})) / ${r3}(${n3});
  return whole + fract;
`, _l2 = (e3, t3) => `fn getOriginalCoordinateFromResizedCoordinate(xResized: u32, xScale: f32, lengthResized: u32,
     lengthOriginal: u32, roiStart: f32, roiEnd: f32) -> ${t3} { ` + (() => {
        switch (e3) {
          case "asymmetric":
            return `
          if (xScale < 1.0 || floor(xScale) != xScale) {
            return ${t3}(xResized) / ${t3}(xScale);
          } else {
            ${fl2("xResized", "lengthOriginal", "lengthResized", t3)}
          }
        `;
          case "pytorch_half_pixel":
            return `if (lengthResized > 1) {
                    return (${t3}(xResized) + 0.5) / ${t3}(xScale) - 0.5;
                  } else {
                    return 0.0;
                  }`;
          case "tf_half_pixel_for_nn":
            return `return (${t3}(xResized) + 0.5) / ${t3}(xScale);`;
          case "align_corners":
            return `if (lengthResized == 1) {
                    return 0.0;
                  } else {
                    ${fl2("xResized", "lengthOriginal - 1", "lengthResized - 1", t3)}
                  }`;
          case "tf_crop_and_resize":
            return `if (lengthResized > 1) {
                    return ${t3}(roiStart) * ${t3}(lengthOriginal - 1) +
                        (${t3}(xResized) * ${t3}(roiEnd - roiStart) * ${t3}(lengthOriginal - 1)) /
                        ${t3}(lengthResized - 1);
                  } else {
                    return 0.5 * ${t3}(roiStart + roiEnd) * ${t3}(lengthOriginal - 1);
                  }`;
          case "half_pixel_symmetric":
            return `const outputWidth = ${t3}xScale * ${t3}(lengthResized);
                  const adjustment = ${t3}(lengthResized) / outputWidth;
                  const center = ${t3}(lengthOriginal) / 2;
                  const offset = center * (1 - adjustment);
                  return offset + ((${t3}(xResized) + 0.5) / ${t3}(xScale)) - 0.5;`;
          case "half_pixel":
            return `return ((${t3}(xResized) + 0.5) / ${t3}(xScale)) - 0.5;`;
          default:
            throw new Error(`Coordinate transform mode ${e3} is not supported`);
        }
      })() + "}", gl2 = (e3, t3, n3) => `fn getNearestPixelFromOriginal(xOriginal: ${n3}, isDownSample: bool) -> ${n3} {` + (() => {
        switch (e3) {
          case "round_prefer_ceil":
            return "if (fract(xOriginal) == 0.5) {             return ceil(xOriginal);           } else {             return round(xOriginal);           }";
          case "floor":
            return "return floor(xOriginal);";
          case "ceil":
            return "return ceil(xOriginal);";
          case "round_prefer_floor":
            return "if (fract(xOriginal) == 0.5) {                     return floor(xOriginal);                   } else {                     return round(xOriginal);                   }";
          default:
            if (t3 < 11) return "if (isDownSample)                     {                       return ceil(xOriginal);                     } else {                       return xOriginal;                     }";
            throw new Error(`Nearest mode ${e3} is not supported`);
        }
      })() + "}", wl2 = (e3, t3, n3) => {
        let r3 = new Array(n3).fill(0).concat(new Array(n3).fill(1)), s3 = 0 === e3.length ? r3 : e3.slice();
        return t3.length > 0 ? (t3.forEach(((e4, a3) => {
          r3[e4] = s3[a3], r3[a3 + n3] = s3[t3.length + a3];
        })), r3) : s3;
      }, bl2 = (e3, t3, n3, r3) => {
        let s3 = [];
        if (n3.length > 0) if (r3.length > 0) {
          if (e3.forEach(((e4) => s3.push(e4))), Math.max(...r3) > e3.length) throw new Error("axes is out of bound");
          r3.forEach(((e4, t4) => s3[e4] = n3[t4]));
        } else n3.forEach(((e4) => s3.push(e4)));
        else {
          if (0 === t3.length) throw new Error("Resize requires either scales or sizes.");
          s3 = e3.map(((e4, n4) => Math.round(e4 * t3[n4])));
        }
        return s3;
      }, yl2 = (e3, t3, n3) => {
        let r3 = (() => {
          switch (n3.keepAspectRatioPolicy) {
            case "not_larger":
              return n3.axes.length > 0 ? Math.min(...n3.axes.map(((e4) => t3[e4])), Number.MAX_VALUE) : Math.min(...t3, Number.MAX_VALUE);
            case "not_smaller":
              return n3.axes.length > 0 ? Math.max(...n3.axes.map(((e4) => t3[e4])), Number.MIN_VALUE) : Math.max(...t3, Number.MIN_VALUE);
            default:
              throw new Error(`Keep aspect ratio policy ${n3.keepAspectRatioPolicy} is not supported`);
          }
        })();
        t3.fill(1, 0, t3.length);
        let s3 = e3.slice();
        return n3.axes.length > 0 ? (n3.axes.forEach(((e4) => t3[e4] = r3)), n3.axes.forEach(((n4) => s3[n4] = Math.round(e3[n4] * t3[n4])))) : (t3.fill(r3, 0, t3.length), s3.forEach(((e4, n4) => s3[n4] = Math.round(e4 * t3[n4])))), s3;
      }, Ml2 = (e3, t3, n3, r3, s3) => `
    fn calculateOriginalIndicesFromOutputIndices(output_indices: ${e3.type.indices}) -> array<${e3.type.value}, ${n3.length}> {
      var original_indices: array<${e3.type.value}, ${n3.length}>;
      for (var i:u32 = 0; i < ${n3.length}; i++) {
        var output_index = ${e3.indicesGet("output_indices", "i")};
        var scale = ${nn2("uniforms.scales", "i", r3)};
        var roi_low = ${nn2("uniforms.roi", "i", s3)};
        var roi_hi = ${nn2("uniforms.roi", `i + ${t3.length}`, s3)};
        if (scale == 1.0) {
          original_indices[i] = ${e3.type.value}(output_index);
        } else {
          var input_shape_i = ${nn2("uniforms.input_shape", "i", t3.length)};
          var output_shape_i = ${nn2("uniforms.output_shape", "i", n3.length)};
          original_indices[i] = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,
                                                                           input_shape_i, roi_low, roi_hi);
        }
      }
      return original_indices;
    }`, xl2 = (e3, t3, n3, r3, s3, a3, o3) => `
    fn calculateInputIndicesFromOutputIndices(output_indices: ${t3.type.indices}) -> ${e3.type.indices} {
      var input_indices: ${e3.type.indices};
      for (var i:u32 = 0; i < ${r3.length}; i++) {
        var output_index = ${t3.indicesGet("output_indices", "i")};
        var input_index: u32;
        var scale = ${nn2("uniforms.scales", "i", s3)};
        if (scale == 1.0) {
          input_index = output_index;
        } else {
          var roi_low = ${nn2("uniforms.roi", "i", a3)};
          var roi_hi = ${nn2("uniforms.roi", `i + ${n3.length}`, a3)};
          var input_shape_i = ${nn2("uniforms.input_shape", "i", n3.length)};
          var output_shape_i = ${nn2("uniforms.output_shape", "i", r3.length)};
          var original_idx = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,
                                                                        input_shape_i, roi_low, roi_hi);
          if (!${o3} || (original_idx >= 0 && original_idx < ${t3.type.value}(input_shape_i))) {
            if (original_idx < 0) {
              input_index = 0;
            } else if (original_idx > ${t3.type.value}(input_shape_i - 1)) {
              input_index = input_shape_i - 1;
            } else {
              input_index = u32(getNearestPixelFromOriginal(original_idx, scale < 1));
            }
          } else {
            input_index = u32(original_idx);
          }
        }
        ${e3.indicesSet("input_indices", "i", "input_index")}
      }
      return input_indices;
    }`, vl2 = (e3, t3) => `
    fn checkInputIndices(input_indices: ${e3.type.indices}) -> bool {
      for (var i:u32 = 0; i < ${t3.length}; i++) {
        var input_index = ${e3.indicesGet("input_indices", "i")};
        if (input_index < 0 || input_index >= ${nn2("uniforms.input_shape", "i", t3.length)}) {
          return false;
        }
      }
      return true;
    }`, Tl2 = (e3, t3, n3, r3) => e3.rank > r3 ? `
    ${e3.indicesSet("input_indices", t3, "channel")};
    ${e3.indicesSet("input_indices", n3, "batch")};
` : "", kl2 = (e3, t3, n3, r3, s3) => {
        let [a3, o3, i3, l3] = 2 === n3.length ? [-1, 0, 1, -1] : [0, 2, 3, 1], d3 = e3.type.value;
        return `
    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> ${d3} {
      var input_indices: ${e3.type.indices};
      ${e3.indicesSet("input_indices", o3, `max(0, min(row, ${n3[o3]} - 1))`)};
      ${e3.indicesSet("input_indices", i3, `max(0, min(col, ${n3[i3]} - 1))`)};
      ${Tl2(e3, l3, a3, 2)}
      return ${e3.getByIndices("input_indices")};
    }

    fn bilinearInterpolation(output_indices: ${t3.type.indices}) -> ${d3} {
      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);
      var row:${d3} = originalIndices[${o3}];
      var col:${d3} = originalIndices[${i3}];
      ${r3 ? `if (row < 0 || row > (${n3[o3]} - 1) || col < 0 || col > (${n3[i3]} - 1)) {
        return ${s3};
      }` : ""};
      row = max(0, min(row, ${n3[o3]} - 1));
      col = max(0, min(col, ${n3[i3]} - 1));
      var row1: u32 = u32(row);
      var col1: u32 = u32(col);
      var row2: u32 = u32(row + 1);
      var col2: u32 = u32(col + 1);
      var channel: u32 = ${n3.length > 2 ? `u32(originalIndices[${l3}])` : "0"};
      var batch: u32 =  ${n3.length > 2 ? `u32(originalIndices[${a3}])` : "0"};
      var x11: ${d3} = getInputValue(batch, channel, row1, col1);
      var x12: ${d3} = getInputValue(batch, channel, row1, col2);
      var x21: ${d3} = getInputValue(batch, channel, row2, col1);
      var x22: ${d3} = getInputValue(batch, channel, row2, col2);
      var dx1: ${d3} = abs(row - ${d3}(row1));
      var dx2: ${d3} = abs(${d3}(row2) - row);
      var dy1: ${d3} = abs(col - ${d3}(col1));
      var dy2: ${d3} = abs(${d3}(col2) - col);
      if (row1 == row2) {
        dx1 = 0.5;
        dx2 = 0.5;
      }
      if (col1 == col2) {
        dy1 = 0.5;
        dy2 = 0.5;
      }
      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);
    }`;
      }, Pl2 = (e3, t3, n3, r3, s3, a3, o3, i3, l3, d3) => {
        let u3 = 2 === n3.length, [c3, p3] = u3 ? [0, 1] : [2, 3], m3 = e3.type.value, h3 = (o4) => {
          let u4 = o4 === c3 ? "row" : "col";
          return `
      fn ${u4}CubicInterpolation(input_indices: ${e3.type.indices}, output_indices: ${t3.type.indices}) -> ${m3} {
        var output_index = ${t3.indicesGet("output_indices", o4)};
        var originalIdx: ${m3} = getOriginalCoordinateFromResizedCoordinate(output_index, ${s3[o4]},
        ${r3[o4]}, ${n3[o4]}, ${a3[o4]}, ${a3[o4]} + ${n3.length});
        var fractOriginalIdx: ${m3} = originalIdx - floor(originalIdx);
        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);

        if (${i3} && (originalIdx < 0 || originalIdx > (${n3[o4]} - 1))) {
          return ${l3};
        }
        var data: array<${m3}, 4> = array<${m3}, 4>(0.0, 0.0, 0.0, 0.0);
        for (var i: i32 = -1; i < 3; i++) {
          var ${u4}: ${m3} = originalIdx + ${m3}(i);
          if (${u4} < 0 || ${u4} >= ${n3[o4]}) {
            ${d3 ? "coefs[i + 1] = 0.0;\n                        continue;" : i3 ? `return ${l3};` : `${u4} = max(0, min(${u4}, ${n3[o4]} - 1));`};
          }
        var input_indices_copy: ${e3.type.indices} = input_indices;
          ${e3.indicesSet("input_indices_copy", o4, `u32(${u4})`)};
          data[i + 1] = ${o4 === c3 ? e3.getByIndices("input_indices_copy") : "rowCubicInterpolation(input_indices_copy, output_indices)"};
        }
        return cubicInterpolation1D(data, coefs);
      }`;
        };
        return `
    ${h3(c3)};
    ${h3(p3)};
  fn getCubicInterpolationCoefs(s: ${m3}) -> array<${m3}, 4> {
    var absS = abs(s);
    var coeffs: array<${m3}, 4> = array<${m3}, 4>(0.0, 0.0, 0.0, 0.0);
    var oneMinusAbsS: ${m3} = 1.0 - absS;
    var twoMinusAbsS: ${m3} = 2.0 - absS;
    var onePlusAbsS: ${m3} = 1.0 + absS;
    coeffs[0] = ((${o3} * onePlusAbsS - 5 * ${o3}) * onePlusAbsS + 8 * ${o3}) * onePlusAbsS - 4 * ${o3};
    coeffs[1] = ((${o3} + 2) * absS - (${o3} + 3)) * absS * absS + 1;
    coeffs[2] = ((${o3} + 2) * oneMinusAbsS - (${o3} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;
    coeffs[3] = ((${o3} * twoMinusAbsS - 5 * ${o3}) * twoMinusAbsS + 8 * ${o3}) * twoMinusAbsS - 4 * ${o3};
    return coeffs;
  }

  fn cubicInterpolation1D(x: array<${m3}, 4>, coefs: array<${m3}, 4>) -> ${m3} {
    var coefsSum: ${m3} = coefs[0] + coefs[1] + coefs[2] + coefs[3];
    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;
  }

  fn bicubicInterpolation(output_indices: ${t3.type.indices}) -> ${m3} {
    var input_indices: ${e3.type.indices} = output_indices;
    return colCubicInterpolation(input_indices, output_indices);
  }
    `;
      }, $l2 = (e3, t3, n3, r3, s3) => {
        let [a3, o3, i3, l3, d3] = 3 === n3.length ? [-1, 0, 1, 2, -1] : [0, 2, 3, 4, 1], u3 = e3.type.value;
        return `
    fn getInputValue(batch: u32, channel: u32, depth:u32, height: u32, width: u32) -> ${u3} {
      var input_indices: ${e3.type.indices};
      ${e3.indicesSet("input_indices", o3, `max(0, min(depth, ${n3[o3]} - 1))`)};
      ${e3.indicesSet("input_indices", i3, `max(0, min(height, ${n3[i3]} - 1))`)};
      ${e3.indicesSet("input_indices", l3, `max(0, min(width, ${n3[l3]} - 1))`)};
      ${Tl2(e3, d3, a3, 3)}
      return ${e3.getByIndices("input_indices")};
    }

    fn trilinearInterpolation(output_indices: ${t3.type.indices}) -> ${u3} {
      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);
      var depth:${u3} = originalIndices[${o3}];
      var height:${u3} = originalIndices[${i3}];
      var width:${u3} = originalIndices[${l3}];
      ${r3 ? `if (depth < 0 || depth > (${n3[o3]} - 1) || height < 0 || height > (${n3[i3]} - 1) || width < 0 || (width > ${n3[l3]} - 1)) {
      return ${s3};
        }` : ""};

    depth = max(0, min(depth, ${n3[o3]} - 1));
      height = max(0, min(height, ${n3[i3]} - 1));
      width = max(0, min(width, ${n3[l3]} - 1));
      var depth1: u32 = u32(depth);
      var height1: u32 = u32(height);
      var width1: u32 = u32(width);
      var depth2: u32 = u32(depth + 1);
      var height2: u32 = u32(height + 1);
      var width2: u32 = u32(width + 1);
      var channel: u32 = ${n3.length > 3 ? `u32(originalIndices[${d3}])` : "0"};
      var batch: u32 =  ${n3.length > 3 ? `u32(originalIndices[${a3}])` : "0"};

      var x111: ${u3} = getInputValue(batch, channel, depth1, height1, width1);
      var x112: ${u3} = getInputValue(batch, channel, depth1, height1, width2);
      var x121: ${u3} = getInputValue(batch, channel, depth1, height2, width1);
      var x122: ${u3} = getInputValue(batch, channel, depth1, height2, width2);
      var x211: ${u3} = getInputValue(batch, channel, depth2, height1, width1);
      var x212: ${u3} = getInputValue(batch, channel, depth2, height1, width2);
      var x221: ${u3} = getInputValue(batch, channel, depth2, height2, width1);
      var x222: ${u3} = getInputValue(batch, channel, depth2, height2, width2);
      var dx1: ${u3} = abs(depth - ${u3}(depth1));
      var dx2: ${u3} = abs(${u3}(depth2) - depth);
      var dy1: ${u3} = abs(height - ${u3}(height1));
      var dy2: ${u3} = abs(${u3}(height2) - height);
      var dz1: ${u3} = abs(width - ${u3}(width1));
      var dz2: ${u3} = abs(${u3}(width2) - width);
      if (depth1 == depth2) {
        dx1 = 0.5;
        dx2 = 0.5;
      }
      if (height1 == height2) {
        dy1 = 0.5;
        dy2 = 0.5;
      }
      if (width1 == width2) {
        dz1 = 0.5;
        dz2 = 0.5;
      }
      return (x111 * dx2 * dy2 * dz2 + x112 * dx2 * dy2 * dz1 + x121 * dx2 * dy1 *dz2 + x122 * dx2 * dy1 * dz1 +
              x211 * dx1 * dy2 * dz2 + x212 * dx1 * dy2 * dz1 + x221 * dx1 * dy1 *dz2 + x222 * dx1 * dy1 * dz1);
    }`;
      }, Cl2 = (e3, t3, n3, r3, s3, a3) => {
        let o3 = e3.dims, i3 = wl2(a3, t3.axes, o3.length), l3 = bl2(o3, r3, s3, t3.axes), d3 = r3.slice();
        0 === r3.length && (d3 = o3.map(((e4, t4) => 0 === e4 ? 1 : l3[t4] / e4)), "stretch" !== t3.keepAspectRatioPolicy && (l3 = yl2(o3, d3, t3)));
        let u3 = an2("output", e3.dataType, l3.length), c3 = sn2("input", e3.dataType, o3.length), p3 = gt2.size(l3), m3 = o3.length === l3.length && o3.every(((e4, t4) => e4 === l3[t4])), h3 = "tf_crop_and_resize" === t3.coordinateTransformMode, f3 = t3.extrapolationValue, _3 = c3.type.value;
        return { name: "Resize", shaderCache: { hint: `${t3.cacheKey}|${n3}|${d3.length > 0 ? "cubic" === t3.mode ? d3 : d3.length : ""}|${s3.length > 0 ? s3 : ""}|${i3.length > 0 ? i3 : ""}|${m3}|${"nearest" === t3.mode ? o3.length : o3}`, inputDependencies: ["rank"] }, getShaderSource: (e4) => `
      ${m3 ? "" : `
      ${_l2(t3.coordinateTransformMode, _3)};
      ${(() => {
          switch (t3.mode) {
            case "nearest":
              return `
              ${vl2(c3, o3)};
              ${gl2(t3.nearestMode, n3, _3)};
              ${xl2(c3, u3, o3, l3, d3.length, i3.length, h3)};
              `;
            case "linear":
              return `
              ${Ml2(u3, o3, l3, d3.length, i3.length)};
              ${(() => {
                if (2 === o3.length || 4 === o3.length) return `${kl2(c3, u3, o3, h3, f3)}`;
                if (3 === o3.length || 5 === o3.length) return `${$l2(c3, u3, o3, h3, f3)}`;
                throw Error("Linear mode only supports input dims 2, 3, 4 and 5 are supported in linear mode.");
              })()};
            `;
            case "cubic":
              return `
            ${(() => {
                if (2 === o3.length || 4 === o3.length) return `${Pl2(c3, u3, o3, l3, d3, i3, t3.cubicCoeffA, h3, t3.extrapolationValue, t3.excludeOutside)}`;
                throw Error("Cubic mode only supports input dims 2 and 4 are supported in linear mode.");
              })()};
            `;
            default:
              throw Error("Invalid resize mode");
          }
        })()};
      `}
      ${e4.registerUniform("output_size", "u32").registerUniform("scales", "f32", d3.length).registerUniform("roi", "f32", i3.length).declareVariables(c3, u3)}
      ${e4.mainStart()}
        ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
        ${m3 ? "output[global_idx] = input[global_idx];" : `
        let output_indices = ${u3.offsetToIndices("global_idx")};
        var input_indices: ${c3.type.indices};
        ${(() => {
          switch (t3.mode) {
            case "nearest":
              return `input_indices = calculateInputIndicesFromOutputIndices(output_indices);
                if (checkInputIndices(input_indices)) {
                  output[global_idx] = ${c3.getByIndices("input_indices")};
                } else {
                  output[global_idx] = ${t3.extrapolationValue};
                }`;
            case "linear":
              return `output[global_idx] = ${2 === o3.length || 4 === o3.length ? "bilinearInterpolation" : "trilinearInterpolation"}(output_indices);`;
            case "cubic":
              return "output[global_idx] = bicubicInterpolation(output_indices);";
            default:
              throw Error(`Unsupported resize mode: ${t3.mode}`);
          }
        })()};
`}
      }`, getRunData: () => ({ outputs: [{ dims: l3, dataType: e3.dataType }], dispatchGroup: { x: Math.ceil(p3 / 64) }, programUniforms: [{ type: 12, data: p3 }, { type: 1, data: d3 }, { type: 1, data: i3 }, ...Jt2(o3, l3)] }) };
      }, Sl2 = (e3) => {
        let t3 = e3.customDataBuffer;
        return new Uint32Array(t3, t3.byteOffset, 1)[0];
      }, Fl2 = (e3, t3) => {
        let n3 = [], r3 = [], s3 = [], a3 = Sl2(e3);
        if (0 !== t3.antialias) throw Error("Only default value (0) for Antialias attribute is supported");
        hl2(e3.inputs, t3, a3, n3, r3, s3), e3.compute(Cl2(e3.inputs[0], t3, a3, n3, r3, s3), { inputs: [0] });
      }, El2 = (e3) => {
        let t3 = e3.antialias, n3 = e3.axes, r3 = e3.coordinateTransformMode, s3 = e3.cubicCoeffA, a3 = 0 !== e3.excludeOutside, o3 = e3.extrapolationValue, i3 = e3.keepAspectRatioPolicy, l3 = e3.mode, d3 = "" === e3.nearestMode ? "simple" : e3.nearestMode;
        return Wt2({ antialias: t3, axes: n3, coordinateTransformMode: r3, cubicCoeffA: s3, excludeOutside: a3, extrapolationValue: o3, keepAspectRatioPolicy: i3, mode: l3, nearestMode: d3 });
      };
    })), mu2 = j2((() => {
      dd2(), pd2(), bd2(), Il2 = (e3) => {
        if (!e3 || e3.length < 3) throw new Error("layerNorm requires at least 3 inputs.");
        let t3 = e3[0], n3 = e3[1], r3 = e3[2];
        if (t3.dataType !== n3.dataType || t3.dataType !== r3.dataType) throw new Error("All inputs must have the same data type");
        if (3 !== t3.dims.length && 2 !== t3.dims.length) throw new Error("Input must be 2D or 3D");
        if (3 !== n3.dims.length && 2 !== n3.dims.length) throw new Error("Skip must be 2D or 3D");
        let s3 = t3.dims[t3.dims.length - 1], a3 = t3.dims[t3.dims.length - 2];
        if (n3.dims[n3.dims.length - 1] !== s3) throw new Error("Skip must have the same hidden size as input");
        if (n3.dims[n3.dims.length - 2] !== a3) throw new Error("Skip must have the same sequence length as input");
        if (1 !== r3.dims.length) throw new Error("Gamma must be 1D");
        if (r3.dims[r3.dims.length - 1] !== s3) throw new Error("Gamma must have the same hidden size as input");
        if (e3.length > 3) {
          let t4 = e3[3];
          if (1 !== t4.dims.length) throw new Error("Beta must be 1D");
          if (t4.dims[t4.dims.length - 1] !== s3) throw new Error("Beta must have the same hidden size as input");
        }
        if (e3.length > 4) {
          let t4 = e3[4];
          if (1 !== t4.dims.length) throw new Error("Bias must be 1D");
          if (t4.dims[t4.dims.length - 1] !== s3) throw new Error("Bias must have the same hidden size as input");
        }
      }, Al2 = (e3, t3, n3, r3) => {
        let s3 = t3.simplified, a3 = e3[0].dims, o3 = gt2.size(a3), i3 = a3, l3 = o3, d3 = a3.slice(-1)[0], u3 = r3 ? a3.slice(0, -1).concat(1) : [], c3 = !s3 && e3.length > 3, p3 = e3.length > 4, m3 = r3 && n3 > 1, h3 = r3 && n3 > 2, f3 = n3 > 3, _3 = 64, g3 = Yt2(d3), w3 = [{ type: 12, data: l3 }, { type: 12, data: g3 }, { type: 12, data: d3 }, { type: 1, data: t3.epsilon }], b3 = [{ dims: i3, dataType: e3[0].dataType }];
        return n3 > 1 && b3.push({ dims: u3, dataType: 1 }), n3 > 2 && b3.push({ dims: u3, dataType: 1 }), n3 > 3 && b3.push({ dims: a3, dataType: e3[0].dataType }), { name: "SkipLayerNormalization", shaderCache: { hint: `${g3};${m3};${h3};${f3}`, inputDependencies: e3.map(((e4, t4) => "type")) }, getShaderSource: (t4) => {
          let n4 = [sn2("x", e3[0].dataType, e3[0].dims, g3), sn2("skip", e3[1].dataType, e3[1].dims, g3), sn2("gamma", e3[2].dataType, e3[2].dims, g3)];
          c3 && n4.push(sn2("beta", e3[3].dataType, e3[3].dims, g3)), p3 && n4.push(sn2("bias", e3[4].dataType, e3[4].dims, g3)), n4.push(an2("output", e3[0].dataType, i3, g3)), m3 && n4.push(an2("mean_output", 1, u3)), h3 && n4.push(an2("inv_std_output", 1, u3)), f3 && n4.push(an2("input_skip_bias_sum", e3[0].dataType, i3, g3));
          let r4 = Kt2(e3[0].dataType), a4 = Kt2(1, g3);
          return `

      ${t4.registerUniforms([{ name: "output_size", type: "u32" }, { name: "components", type: "u32" }, { name: "hidden_size", type: "u32" }, { name: "epsilon", type: "f32" }]).declareVariables(...n4)}
      var<workgroup> sum_shared : array<${a4}, 64>;
      var<workgroup> sum_squared_shared : array<${a4}, 64>;

      ${t4.mainStart([_3, 1, 1])}
        let ix = local_id.x;
        let iy = global_id.x / 64;

        let hidden_size_vectorized: u32 = uniforms.hidden_size / uniforms.components;
        var stride = hidden_size_vectorized / 64;
        let offset = ix * stride + iy * hidden_size_vectorized;
        let offset1d = stride * ix;
        if (ix == 63) {
          stride = hidden_size_vectorized - stride * ix;
        }
        for (var i: u32 = 0; i < stride; i++) {
          let skip_value = skip[offset + i];
          let bias_value = ${p3 ? "bias[offset1d + i]" : r4 + "(0.0)"};
          let input_value = x[offset + i];
          let value = input_value + skip_value + bias_value;
          ${f3 ? "input_skip_bias_sum[offset + i] = value;" : ""}
          output[offset + i] = value;
          let f32_value = ${en2(r4, g3, "value")};
          sum_shared[ix] += f32_value;
          sum_squared_shared[ix] += f32_value * f32_value;
        }
        workgroupBarrier();

        var reduce_size : u32 = 64;
        for (var curr_size = reduce_size >> 1;  curr_size > 0; curr_size = reduce_size >> 1) {
          reduce_size = curr_size + (reduce_size & 1);
          if (ix < curr_size) {
            sum_shared[ix] += sum_shared[ix + reduce_size];
            sum_squared_shared[ix] += sum_squared_shared[ix + reduce_size];
          }
          workgroupBarrier();
        }

        let sum = sum_shared[0];
        let square_sum = sum_squared_shared[0];
        let mean = ${tn2("sum", g3)} / f32(uniforms.hidden_size);
        let inv_std_dev = inverseSqrt(${tn2("square_sum", g3)} / f32(uniforms.hidden_size) ${s3 ? "" : "- mean * mean"} + uniforms.epsilon);
        ${m3 ? "mean_output[global_idx] = mean;" : ""}
        ${h3 ? "inv_std_output[global_idx] = inv_std_dev;" : ""}

        for (var i: u32 = 0; i < stride; i++) {
          output[offset + i] = (output[offset + i] ${s3 ? "" : `- ${r4}(mean)`}) *
            ${r4}(inv_std_dev) * gamma[offset1d + i]
            ${c3 ? "+ beta[offset1d + i]" : ""};
        }
      }`;
        }, getRunData: () => ({ outputs: b3, dispatchGroup: { x: Math.ceil(l3 / d3) }, programUniforms: w3 }) };
      }, zl2 = (e3, t3) => {
        Il2(e3.inputs);
        let n3 = [0];
        e3.outputCount > 1 && n3.push(-3), e3.outputCount > 2 && n3.push(-3), e3.outputCount > 3 && n3.push(3), e3.compute(Al2(e3.inputs, t3, e3.outputCount, false), { outputs: n3 });
      };
    })), hu2 = j2((() => {
      dd2(), pd2(), wd2(), bd2(), Ll2 = (e3, t3) => {
        if (!e3 || e3.length < 1) throw new Error("too few inputs");
        if (0 !== t3.axes.length) {
          if (t3.axes.length !== t3.starts.length || t3.axes.length !== t3.ends.length) throw new Error("axes, starts and ends must have the same length");
        } else if (t3.starts.length !== t3.ends.length) throw new Error("starts and ends must have the same length");
        e3.slice(1).forEach(((t4, n3) => {
          if (6 !== e3[n3 + 1].dataType && 7 !== e3[n3 + 1].dataType) throw new Error(`Input ${n3} must be an array of int32 or int64`);
        }));
      }, Ol2 = (e3, t3) => {
        let n3 = [];
        if (e3.length > t3) if (7 === e3[t3].dataType) e3[t3].getBigInt64Array().forEach(((e4) => n3.push(Number(e4))));
        else {
          if (6 !== e3[t3].dataType) throw new Error(`Input ${t3} must be an array of int32 or int64`);
          e3[t3].getInt32Array().forEach(((e4) => n3.push(Number(e4))));
        }
        return n3;
      }, Dl2 = (e3, t3) => {
        if (e3.length > 1) {
          let t4 = Ol2(e3, 1), n3 = Ol2(e3, 2), r3 = Ol2(e3, 3);
          return 0 === r3.length && (r3 = [...Array(e3[0].dims.length).keys()]), Wt2({ starts: t4, ends: n3, axes: r3 });
        }
        return t3;
      }, Bl2 = (e3, t3, n3, r3, s3) => {
        let a3 = e3;
        return e3 < 0 && (a3 += n3[r3[t3]]), s3[t3] < 0 ? Math.max(0, Math.min(a3, n3[r3[t3]] - 1)) : Math.max(0, Math.min(a3, n3[r3[t3]]));
      }, Nl2 = (e3, t3, n3) => `fn calculateInputIndices(output_indices: ${t3.type.indices}) -> ${e3.type.indices} {
          var input_indices: ${e3.type.indices};
          var carry = 0u;
          for (var i = ${n3.length}; i >= 0; i--) {
            let input_shape_i = ${nn2("uniforms.input_shape", "i", n3.length)};
            let steps_i = ${nn2("uniforms.steps", "i", n3.length)};
            let signs_i = ${nn2("uniforms.signs", "i", n3.length)};
            let starts_i = ${nn2("uniforms.starts", "i", n3.length)};
            var output_index = ${t3.indicesGet("output_indices", "i")};
            var input_index = output_index * steps_i + starts_i + carry;
            carry = input_index / input_shape_i;
            input_index = input_index % input_shape_i;
            if (signs_i < 0) {
              input_index = input_shape_i - input_index - 1u + starts_i;
            }
            ${e3.indicesSet("input_indices", "i", "input_index")};
          }
          return input_indices;
      }`, jl2 = (e3, t3) => {
        let n3 = e3[0].dims, r3 = gt2.size(n3), s3 = t3.axes.length > 0 ? gt2.normalizeAxes(t3.axes, n3.length) : [...Array(n3.length).keys()], a3 = Ol2(e3, 4);
        a3.forEach(((e4) => 0 !== e4 || (() => {
          throw new Error("step cannot be 0");
        }))), 0 === a3.length && (a3 = Array(s3.length).fill(1));
        let o3 = t3.starts.map(((e4, t4) => Bl2(e4, t4, n3, s3, a3))), i3 = t3.ends.map(((e4, t4) => Bl2(e4, t4, n3, s3, a3)));
        if (s3.length !== o3.length || s3.length !== i3.length) throw new Error("start, ends and axes should have the same number of elements");
        if (s3.length !== n3.length) for (let e4 = 0; e4 < n3.length; ++e4) s3.includes(e4) || (o3.splice(e4, 0, 0), i3.splice(e4, 0, n3[e4]), a3.splice(e4, 0, 1));
        let l3 = a3.map(((e4) => Math.sign(e4)));
        a3.forEach(((e4, t4, n4) => {
          if (e4 < 0) {
            let r4 = (i3[t4] - o3[t4]) / e4, s4 = o3[t4], l4 = s4 + r4 * a3[t4];
            o3[t4] = l4, i3[t4] = s4, n4[t4] = -e4;
          }
        }));
        let d3 = n3.slice(0);
        s3.forEach(((e4, t4) => {
          d3[e4] = Math.ceil((i3[e4] - o3[e4]) / a3[e4]);
        }));
        let u3 = { dims: d3, dataType: e3[0].dataType }, c3 = an2("output", e3[0].dataType, d3.length), p3 = sn2("input", e3[0].dataType, e3[0].dims.length), m3 = gt2.size(d3), h3 = [{ name: "outputSize", type: "u32" }, { name: "starts", type: "u32", length: o3.length }, { name: "signs", type: "i32", length: l3.length }, { name: "steps", type: "u32", length: a3.length }], f3 = [{ type: 12, data: m3 }, { type: 12, data: o3 }, { type: 6, data: l3 }, { type: 12, data: a3 }, ...Jt2(e3[0].dims, d3)];
        return { name: "Slice", shaderCache: { hint: `${l3.length}_${o3.length}_${a3.length}`, inputDependencies: ["rank"] }, getShaderSource: (e4) => `
      ${e4.registerUniforms(h3).declareVariables(p3, c3)}
        ${Nl2(p3, c3, n3)}
        ${e4.mainStart()}
          ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
          let output_indices = ${c3.offsetToIndices("global_idx")};
          let input_indices = calculateInputIndices(output_indices);
          ${c3.setByOffset("global_idx", p3.getByIndices("input_indices"))}
      }`, getRunData: () => ({ outputs: [u3], dispatchGroup: { x: Math.ceil(r3 / 64) }, programUniforms: f3 }) };
      }, Rl2 = (e3, t3) => {
        Ll2(e3.inputs, t3);
        let n3 = Dl2(e3.inputs, t3);
        e3.compute(jl2(e3.inputs, n3), { inputs: [0] });
      }, Vl2 = (e3) => {
        let t3 = e3.starts, n3 = e3.ends, r3 = e3.axes;
        return Wt2({ starts: t3, ends: n3, axes: r3 });
      };
    })), fu2 = j2((() => {
      dd2(), pd2(), wd2(), yd2(), bd2(), Gl2 = (e3) => {
        if (!e3 || 1 !== e3.length) throw new Error("Softmax op requires 1 input.");
      }, ql2 = (e3, t3) => {
        let n3, r3 = e3.inputs[0], s3 = r3.dims, a3 = gt2.size(s3), o3 = s3.length, i3 = gt2.normalizeAxis(t3.axis, o3), l3 = i3 < s3.length - 1, d3 = [];
        l3 ? (d3 = Array.from({ length: o3 }, ((e4, t4) => t4)), d3[i3] = o3 - 1, d3[o3 - 1] = i3, n3 = e3.compute(gn2(r3, d3), { inputs: [r3], outputs: [-1] })[0]) : n3 = r3;
        let u3 = n3.dims, c3 = u3[o3 - 1], p3 = a3 / c3, m3 = Yt2(c3), h3 = c3 / m3, f3 = 64;
        1 === p3 && (f3 = 256);
        let _3 = sn2("x", n3.dataType, n3.dims, m3), g3 = an2("result", n3.dataType, n3.dims, m3), w3 = _3.type.value, b3 = "f32" === Kt2(n3.dataType) ? `var threadMax = ${w3}(-3.402823e+38f);` : `var threadMax = ${w3}(-65504.0h);`, y3 = e3.compute({ name: "Softmax", shaderCache: { hint: `${m3};${f3}`, inputDependencies: ["type"] }, getRunData: () => ({ outputs: [{ dims: u3, dataType: n3.dataType }], dispatchGroup: { x: p3 }, programUniforms: [{ type: 6, data: h3 }] }), getShaderSource: (e4) => `
      var<workgroup> rowMaxShared : ${w3};
      var<workgroup> rowSumShared : ${w3};
      var<workgroup> threadShared : array<${w3}, ${f3}>;

      fn getValue(row: i32, col: i32, row_stride: i32) -> ${w3} {
        let index = row * row_stride + col;
        return x[index];
      }

      fn setValue(row: i32, col: i32, row_stride: i32, value: ${w3}) {
        let index = row * row_stride + col;
        result[index] = value;
      }
      ${e4.registerUniform("packedCols", "i32").declareVariables(_3, g3)}
      ${e4.mainStart(f3)}
        let gindex = i32(global_idx);
        let lindex = i32(local_idx);
        const wg = ${f3};
        let row = gindex / wg;
        let cols = uniforms.packedCols;
        let row_stride : i32 = uniforms.packedCols;

        // find the rows max
        ${b3}
        for (var col = lindex; col < cols; col += wg) {
          let value = getValue(row, col, row_stride);
          threadMax = max(threadMax, value);
        }
        if (lindex < cols) {
          threadShared[lindex] = threadMax;
        }
        workgroupBarrier();

        var reduceSize = min(cols, wg);
        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {
          reduceSize = currSize + (reduceSize & 1);
          if (lindex < currSize) {
            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);
          }
          workgroupBarrier();
        }
        if (lindex == 0) {
          rowMaxShared = ${w3}(${((e5, t4) => 4 === t4 ? `max(max(${e5}.x, ${e5}.y), max(${e5}.z, ${e5}.w))` : 2 === t4 ? `max(${e5}.x, ${e5}.y)` : 3 === t4 ? `max(max(${e5}.x, ${e5}.y), ${e5}.z)` : e5)("threadShared[0]", m3)});
        }
        workgroupBarrier();

        // find the rows sum
        var threadSum = ${w3}(0.0);
        for (var col = lindex; col < cols; col += wg) {
          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);
          threadSum += subExp;
        }
        threadShared[lindex] = threadSum;
        workgroupBarrier();

        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {
          if (lindex < currSize) {
            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];
          }
          workgroupBarrier();
        }
        if (lindex == 0) {
          rowSumShared = ${w3}(${tn2("threadShared[0]", m3)});
        }
        workgroupBarrier();

        // calculate final value for each element in the row
        for (var col = lindex; col < cols; col += wg) {
          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;
          setValue(row, col, row_stride, value);
        }
      }` }, { inputs: [n3], outputs: [l3 ? -1 : 0] })[0];
        l3 && e3.compute(gn2(y3, d3), { inputs: [y3] });
      }, Ul2 = (e3, t3) => {
        Gl2(e3.inputs), ql2(e3, t3);
      }, Wl2 = (e3) => Wt2({ axis: e3.axis });
    })), _u2 = j2((() => {
      dd2(), pd2(), bd2(), Hl2 = (e3) => Array.from(e3.getBigInt64Array(), Number), Ql2 = (e3) => {
        if (!e3 || 2 !== e3.length) throw new Error("Tile requires 2 inputs.");
        if (1 !== e3[0].dataType && 10 !== e3[0].dataType && 6 !== e3[0].dataType && 12 !== e3[0].dataType) throw new Error("Tile only support float, float16, int32, and uint32 data types");
        if (7 !== e3[1].dataType) throw new Error("Tile `repeats` input should be of int64 data type");
        if (1 !== e3[1].dims.length) throw new Error("Tile `repeats` input should be 1-D");
        if (Hl2(e3[1]).length !== e3[0].dims.length) throw new Error("Tile `repeats` input should have same number of elements as rank of input data tensor");
      }, Kl2 = (e3, t3) => {
        let n3 = [];
        for (let r3 = 0; r3 < e3.length; ++r3) n3.push(e3[r3] * t3[r3]);
        return n3;
      }, Xl2 = (e3, t3) => {
        let n3 = e3[0].dims, r3 = t3 ?? Hl2(e3[1]), s3 = Kl2(n3, r3), a3 = gt2.size(s3), o3 = e3[0].dataType, i3 = sn2("input", o3, n3.length), l3 = an2("output", o3, s3.length);
        return { name: "Tile", shaderCache: { hint: `${r3}`, inputDependencies: ["rank"] }, getRunData: () => ({ outputs: [{ dims: s3, dataType: e3[0].dataType }], dispatchGroup: { x: Math.ceil(a3 / 64) }, programUniforms: [{ type: 12, data: a3 }, ...Jt2(e3[0].dims, s3)] }), getShaderSource: (e4) => `
      const inputShape = ${i3.indices(...n3)};
      ${e4.registerUniform("output_size", "u32").declareVariables(i3, l3)}
      ${e4.mainStart()}
      ${e4.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
      let output_indices = ${l3.offsetToIndices("global_idx")};
      var input_indices: ${i3.type.indices};
      for (var i = 0; i < ${n3.length}; i++) {
        let input_dim_i = ${i3.indicesGet("uniforms.input_shape", "i")};
        let input_dim_value = ${l3.indicesGet("output_indices", "i")}  % input_dim_i;

        ${i3.indicesSet("input_indices", "i", "input_dim_value")}
      }
      ${l3.setByOffset("global_idx", i3.getByIndices("input_indices"))}
    }` };
      }, Jl2 = (e3) => {
        Ql2(e3.inputs), e3.compute(Xl2(e3.inputs), { inputs: [0] });
      };
    })), gu2 = j2((() => {
      dd2(), pd2(), bd2(), Yl2 = (e3, t3, n3, r3, s3) => {
        let a3, o3 = an2("output_data", s3, n3.length, 4), i3 = sn2("a_data", t3[1].dataType, t3[1].dims.length, 4), l3 = sn2("b_data", t3[2].dataType, t3[2].dims.length, 4), d3 = sn2("c_data", t3[0].dataType, t3[0].dims.length, 4), u3 = (e4, t4, n4) => `select(${t4}, ${e4}, ${n4})`;
        if (r3) {
          let e4 = (e5, t4, n4 = "") => {
            let r4 = `a_data[index_a${t4}][component_a${t4}]`, s4 = `b_data[index_b${t4}][component_b${t4}]`, a4 = `bool(c_data[index_c${t4}] & (0xffu << (component_c${t4} * 8)))`;
            return `
            let output_indices${t4} = ${o3.offsetToIndices(`global_idx * 4u + ${t4}u`)};
            let offset_a${t4} = ${i3.broadcastedIndicesToOffset(`output_indices${t4}`, o3)};
            let offset_b${t4} = ${l3.broadcastedIndicesToOffset(`output_indices${t4}`, o3)};
            let offset_c${t4} = ${d3.broadcastedIndicesToOffset(`output_indices${t4}`, o3)};
            let index_a${t4} = offset_a${t4} / 4u;
            let index_b${t4} = offset_b${t4} / 4u;
            let index_c${t4} = offset_c${t4} / 4u;
            let component_a${t4} = offset_a${t4} % 4u;
            let component_b${t4} = offset_b${t4} % 4u;
            let component_c${t4} = offset_c${t4} % 4u;
            ${e5}[${t4}] = ${n4}(${u3(r4, s4, a4)});
          `;
          };
          a3 = 9 === s3 ? `
            var data = vec4<u32>(0);
            ${e4("data", 0, "u32")}
            ${e4("data", 1, "u32")}
            ${e4("data", 2, "u32")}
            ${e4("data", 3, "u32")}
            output_data[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));` : `
            ${e4("output_data[global_idx]", 0)}
            ${e4("output_data[global_idx]", 1)}
            ${e4("output_data[global_idx]", 2)}
            ${e4("output_data[global_idx]", 3)}
          `;
        } else a3 = o3.setByOffset("global_idx", u3(i3.getByOffset("global_idx"), l3.getByOffset("global_idx"), d3.getByOffset("global_idx")));
        return `
        ${e3.registerUniform("vec_size", "u32").declareVariables(d3, i3, l3, o3)}
        ${e3.mainStart()}
        ${e3.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}
        ${a3}
      }`;
      }, Zl2 = (e3) => {
        let t3 = e3[1].dims, n3 = e3[2].dims, r3 = e3[0].dims, s3 = e3[1].dataType, a3 = !(gt2.areEqual(t3, n3) && gt2.areEqual(n3, r3)), o3 = t3, i3 = gt2.size(t3);
        if (a3) {
          let e4 = _t2.calcShape(_t2.calcShape(t3, n3, false), r3, false);
          if (!e4) throw new Error("Can't perform where op on the given tensors");
          o3 = e4, i3 = gt2.size(o3);
        }
        let l3 = Math.ceil(i3 / 4);
        return { name: "Where", shaderCache: { inputDependencies: ["rank", "rank", "rank"] }, getShaderSource: (t4) => Yl2(t4, e3, o3, a3, s3), getRunData: () => ({ outputs: [{ dims: o3, dataType: s3 }], dispatchGroup: { x: Math.ceil(i3 / 64 / 4) }, programUniforms: [{ type: 12, data: l3 }, ...Jt2(r3, t3, n3, o3)] }) };
      }, ed2 = (e3) => {
        e3.compute(Zl2(e3.inputs));
      };
    })), wu2 = j2((() => {
      vd2(), Td2(), kd2(), Pd2(), Cd2(), Sd2(), Fd2(), Nd2(), Rd2(), Vd2(), Gd2(), qd2(), Ud2(), Wd2(), Hd2(), Qd2(), Kd2(), Xd2(), Jd2(), Yd2(), nu2(), ru2(), su2(), au2(), ou2(), Zd2(), iu2(), lu2(), du2(), uu2(), cu2(), xd2(), pu2(), tu2(), mu2(), hu2(), fu2(), eu2(), _u2(), yd2(), $d2(), gu2(), td2 = /* @__PURE__ */ new Map([["Abs", [zr2]], ["Acos", [Lr2]], ["Acosh", [Or2]], ["Add", [Ss2]], ["ArgMax", [fr2, _r2]], ["ArgMin", [hr2, _r2]], ["Asin", [Dr2]], ["Asinh", [Br2]], ["Atan", [Nr2]], ["Atanh", [jr2]], ["Attention", [Tr2]], ["AveragePool", [qi2, Gi2]], ["BatchNormalization", [Cr2]], ["BiasAdd", [Er2]], ["BiasSplitGelu", [ks2]], ["Cast", [Vr2, Rr2]], ["Ceil", [Ur2]], ["Clip", [qr2]], ["Concat", [Gs2, qs2]], ["Conv", [Ca2, Ta2]], ["ConvTranspose", [Ba2, za2]], ["Cos", [Wr2]], ["Cosh", [Hr2]], ["CumSum", [ja2, Ra2]], ["DepthToSpace", [Ua2, Wa2]], ["DequantizeLinear", [tl2, nl2]], ["Div", [Fs2]], ["Einsum", [to2, no2]], ["Elu", [Kr2, Qr2]], ["Equal", [Es2]], ["Erf", [Jr2]], ["Exp", [Yr2]], ["Expand", [io2]], ["FastGelu", [uo2]], ["Floor", [Zr2]], ["FusedConv", [Ca2, Ta2]], ["Gather", [ho2, mo2]], ["GatherElements", [ko2, To2]], ["GatherBlockQuantized", [yo2, Mo2]], ["GatherND", [_o2, go2]], ["Gelu", [es2]], ["Gemm", [So2, Co2]], ["GlobalAveragePool", [Hi2, Wi2]], ["GlobalMaxPool", [Yi2, Ji2]], ["Greater", [Ls2]], ["GreaterOrEqual", [Ds2]], ["GridSample", [Ro2, Vo2]], ["GroupQueryAttention", [ui2]], ["HardSigmoid", [ls2, is2]], ["InstanceNormalization", [hi2]], ["LayerNormalization", [gi2]], ["LeakyRelu", [ts2, Qr2]], ["Less", [Os2]], ["LessOrEqual", [Bs2]], ["Log", [bs2]], ["MatMul", [bi2]], ["MatMulNBits", [vi2, Ti2]], ["MaxPool", [Ki2, Xi2]], ["Mul", [Is2]], ["MultiHeadAttention", [Ko2, Uo2]], ["Neg", [rs2]], ["Not", [ns2]], ["Pad", [Ai2]], ["Pow", [As2]], ["QuickGelu", [xs2, Qr2]], ["Range", [al2]], ["Reciprocal", [ss2]], ["ReduceMin", [lr2]], ["ReduceMean", [rr2]], ["ReduceMax", [ir2]], ["ReduceSum", [ur2]], ["ReduceProd", [dr2]], ["ReduceL1", [sr2]], ["ReduceL2", [ar2]], ["ReduceLogSum", [pr2]], ["ReduceLogSumExp", [or2]], ["ReduceSumSquare", [cr2]], ["Relu", [as2]], ["Resize", [Fl2, El2]], ["RotaryEmbedding", [ai2]], ["ScatterND", [cl2, ul2]], ["Sigmoid", [os2]], ["Sin", [ds2]], ["Sinh", [us2]], ["Slice", [Rl2, Vl2]], ["SkipLayerNormalization", [zl2]], ["Split", [ti2, ni2]], ["Sqrt", [cs2]], ["Softmax", [Ul2, Wl2]], ["Sub", [zs2]], ["Tan", [ps2]], ["Tanh", [hs2]], ["ThresholdedRelu", [ws2, Qr2]], ["Tile", [Jl2]], ["Transpose", [wn2, bn2]], ["Where", [ed2]]]);
    })), bu2 = j2((() => {
      le2(), cd2(), bd2(), nd2 = class {
        constructor(e3) {
          this.backend = e3, this.repo = /* @__PURE__ */ new Map(), this.attributesBound = false;
        }
        getArtifact(e3) {
          return this.repo.get(e3);
        }
        setArtifact(e3, t3) {
          this.repo.set(e3, t3);
        }
        run(e3, t3, n3, r3, s3) {
          E2(e3.programInfo.name);
          let a3 = this.backend.device, o3 = this.backend.getComputePassEncoder();
          this.backend.writeTimestamp(2 * this.backend.pendingDispatchNumber);
          let i3 = [];
          for (let e4 of t3) i3.push({ binding: i3.length, resource: { buffer: e4.buffer } });
          for (let e4 of n3) i3.push({ binding: i3.length, resource: { buffer: e4.buffer } });
          s3 && i3.push({ binding: i3.length, resource: s3 });
          let l3 = a3.createBindGroup({ layout: e3.computePipeline.getBindGroupLayout(0), entries: i3, label: e3.programInfo.name });
          if ("capturing" === this.backend.sessionStatus) {
            let t4 = { kernelId: this.backend.currentKernelId, computePipeline: e3.computePipeline, bindGroup: l3, dispatchGroup: r3 };
            this.backend.capturedCommandList.get(this.backend.currentSessionId).push(t4);
          }
          o3.setPipeline(e3.computePipeline), o3.setBindGroup(0, l3), o3.dispatchWorkgroups(...r3), this.backend.writeTimestamp(2 * this.backend.pendingDispatchNumber + 1), this.backend.pendingDispatchNumber++, (this.backend.pendingDispatchNumber >= this.backend.maxDispatchNumber || "at-passes" === this.backend.queryType) && this.backend.endComputePass(), this.backend.pendingDispatchNumber >= this.backend.maxDispatchNumber && this.backend.flush(), I2(e3.programInfo.name);
        }
        dispose() {
        }
        build(e3, t3) {
          E2(e3.name);
          let n3 = this.backend.device, r3 = [];
          [{ feature: "shader-f16", extension: "f16" }, { feature: "subgroups", extension: "subgroups" }].forEach(((e4) => {
            n3.features.has(e4.feature) && r3.push(`enable ${e4.extension};`);
          }));
          let s3 = un2(t3, this.backend.device.limits), a3 = e3.getShaderSource(s3), o3 = `${r3.join("\n")}
${s3.additionalImplementations}
${a3}`, i3 = n3.createShaderModule({ code: o3, label: e3.name });
          ht2("verbose", (() => `[WebGPU] ${e3.name} shader code: ${o3}`));
          let l3 = n3.createComputePipeline({ compute: { module: i3, entryPoint: "main" }, layout: "auto", label: e3.name });
          return I2(e3.name), { programInfo: e3, computePipeline: l3, uniformVariablesInfo: s3.variablesInfo };
        }
        normalizeDispatchGroupSize(e3) {
          let t3 = "number" == typeof e3 ? e3 : e3.x, n3 = "number" == typeof e3 ? 1 : e3.y || 1, r3 = "number" == typeof e3 ? 1 : e3.z || 1, s3 = this.backend.device.limits.maxComputeWorkgroupsPerDimension;
          if (t3 <= s3 && n3 <= s3 && r3 <= s3) return [t3, n3, r3];
          let a3 = t3 * n3 * r3, o3 = Math.ceil(Math.sqrt(a3));
          if (o3 > s3) {
            if (o3 = Math.ceil(Math.cbrt(a3)), o3 > s3) throw new Error("Total dispatch size exceeds WebGPU maximum.");
            return [o3, o3, o3];
          }
          return [o3, o3, 1];
        }
      };
    })), yu2 = {};
    R2(yu2, { WebGpuBackend: () => Tu2 });
    var Mu2, xu2, vu2, Tu2, ku2 = j2((() => {
      le2(), dd2(), cd2(), md2(), gd2(), wu2(), bu2(), Mu2 = (e3, t3) => {
        if (t3.length !== e3.length) throw new Error(`inputDependencies length ${t3.length} is not equal to inputTensors length ${e3.length}.`);
        let n3 = [];
        for (let r3 = 0; r3 < e3.length; ++r3) {
          let s3 = e3[r3].dataType;
          switch (t3[r3]) {
            case "none":
              n3.push("");
              break;
            case "type":
              n3.push(`${s3}`);
              break;
            case "rank": {
              let t4 = e3[r3].dims.length;
              n3.push(`${s3};${t4}`);
              break;
            }
            case "dims": {
              let t4 = e3[r3].dims.join(",");
              n3.push(`${s3};${t4}`);
              break;
            }
            default:
              throw new Error(`unsupported input dependency: ${t3[r3]}`);
          }
        }
        return n3.join("|");
      }, xu2 = (e3, t3, n3) => {
        let r3 = e3.name;
        return e3.shaderCache?.hint && (r3 += "[" + e3.shaderCache.hint + "]"), r3 += ":" + n3 + `:${Mu2(t3, e3.shaderCache?.inputDependencies ?? new Array(t3.length).fill("dims"))}`, r3;
      }, vu2 = class {
        constructor(e3) {
          e3 && (this.architecture = e3.architecture, this.vendor = e3.vendor);
        }
        isArchitecture(e3) {
          return this.architecture === e3;
        }
        isVendor(e3) {
          return this.vendor === e3;
        }
      }, Tu2 = class {
        constructor() {
          this.currentSessionId = null, this.currentKernelId = null, this.commandEncoder = null, this.computePassEncoder = null, this.maxDispatchNumber = 16, this.pendingDispatchNumber = 0, this.pendingKernels = [], this.pendingQueries = /* @__PURE__ */ new Map(), this.sessionStatus = "default", this.capturedCommandList = /* @__PURE__ */ new Map(), this.capturedPendingKernels = /* @__PURE__ */ new Map(), this.sessionExternalDataMapping = /* @__PURE__ */ new Map();
        }
        get currentKernelCustomData() {
          if (null === this.currentKernelId) throw new Error("currentKernelCustomData(): currentKernelId is null. (should not happen)");
          let e3 = this.kernelCustomData.get(this.currentKernelId);
          return e3 || (e3 = {}, this.kernelCustomData.set(this.currentKernelId, e3)), e3;
        }
        async initialize(e3, t3) {
          this.env = e3;
          let n3 = [], r3 = { requiredLimits: { maxComputeWorkgroupStorageSize: t3.limits.maxComputeWorkgroupStorageSize, maxComputeWorkgroupsPerDimension: t3.limits.maxComputeWorkgroupsPerDimension, maxStorageBufferBindingSize: t3.limits.maxStorageBufferBindingSize, maxBufferSize: t3.limits.maxBufferSize, maxComputeInvocationsPerWorkgroup: t3.limits.maxComputeInvocationsPerWorkgroup, maxComputeWorkgroupSizeX: t3.limits.maxComputeWorkgroupSizeX, maxComputeWorkgroupSizeY: t3.limits.maxComputeWorkgroupSizeY, maxComputeWorkgroupSizeZ: t3.limits.maxComputeWorkgroupSizeZ }, requiredFeatures: n3 }, s3 = (e4) => t3.features.has(e4) && n3.push(e4) && true;
          s3("chromium-experimental-timestamp-query-inside-passes") || s3("timestamp-query"), s3("shader-f16"), s3("subgroups"), this.device = await t3.requestDevice(r3), this.adapterInfo = new vu2(t3.info || await t3.requestAdapterInfo()), this.gpuDataManager = qt2(this), this.programManager = new nd2(this), this.kernels = /* @__PURE__ */ new Map(), this.kernelPersistentData = /* @__PURE__ */ new Map(), this.kernelCustomData = /* @__PURE__ */ new Map(), pt2(e3.logLevel, !!e3.debug), this.device.onuncapturederror = (e4) => {
            e4.error instanceof GPUValidationError && console.error(`An uncaught WebGPU validation error was raised: ${e4.error.message}`);
          }, Object.defineProperty(this.env.webgpu, "device", { value: this.device, writable: false, enumerable: true, configurable: false }), Object.defineProperty(this.env.webgpu, "adapter", { value: t3, writable: false, enumerable: true, configurable: false }), this.setQueryType();
        }
        dispose() {
          typeof this.querySet < "u" && this.querySet.destroy(), this.gpuDataManager.dispose();
        }
        getCommandEncoder() {
          return this.commandEncoder || (this.commandEncoder = this.device.createCommandEncoder()), this.commandEncoder;
        }
        getComputePassEncoder() {
          if (!this.computePassEncoder) {
            let e3 = this.getCommandEncoder(), t3 = {};
            "at-passes" === this.queryType && (t3.timestampWrites = { querySet: this.querySet, beginningOfPassWriteIndex: 2 * this.pendingDispatchNumber, endOfPassWriteIndex: 2 * this.pendingDispatchNumber + 1 }), this.computePassEncoder = e3.beginComputePass(t3);
          }
          return this.computePassEncoder;
        }
        endComputePass() {
          this.computePassEncoder && (this.computePassEncoder.end(), this.computePassEncoder = null);
        }
        flush() {
          if (!this.commandEncoder) return;
          let e3;
          E2(), this.endComputePass(), "none" !== this.queryType && (this.commandEncoder.resolveQuerySet(this.querySet, 0, 2 * this.pendingDispatchNumber, this.queryResolveBuffer, 0), e3 = this.device.createBuffer({ size: 2 * this.pendingDispatchNumber * 8, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST }), this.pendingQueries.set(e3, this.pendingKernels), this.pendingKernels = [], this.commandEncoder.copyBufferToBuffer(this.queryResolveBuffer, 0, e3, 0, 2 * this.pendingDispatchNumber * 8)), this.device.queue.submit([this.commandEncoder.finish()]), this.gpuDataManager.refreshPendingBuffers(), this.commandEncoder = null, this.pendingDispatchNumber = 0, "none" !== this.queryType && e3.mapAsync(GPUMapMode.READ).then((() => {
            let t3 = new BigUint64Array(e3.getMappedRange()), n3 = this.pendingQueries.get(e3);
            for (let e4 = 0; e4 < t3.length / 2; e4++) {
              let r3 = n3[e4], s3 = r3.kernelId, a3 = this.kernels.get(s3), o3 = a3.kernelType, i3 = a3.kernelName, l3 = r3.programName, d3 = r3.inputTensorViews, u3 = r3.outputTensorViews, c3 = t3[2 * e4], p3 = t3[2 * e4 + 1];
              typeof this.queryTimeBase > "u" && (this.queryTimeBase = c3);
              let m3 = Number(c3 - this.queryTimeBase), h3 = Number(p3 - this.queryTimeBase);
              if (!Number.isSafeInteger(m3) || !Number.isSafeInteger(h3)) throw new RangeError("incorrect timestamp range");
              if (this.env.webgpu.profiling?.ondata) this.env.webgpu.profiling.ondata({ version: 1, inputsMetadata: d3.map(((e5) => ({ dims: e5.dims, dataType: et2(e5.dataType) }))), outputsMetadata: u3.map(((e5) => ({ dims: e5.dims, dataType: et2(e5.dataType) }))), kernelId: s3, kernelType: o3, kernelName: i3, programName: l3, startTime: m3, endTime: h3 });
              else {
                let e5 = "";
                d3.forEach(((t5, n4) => {
                  e5 += `input[${n4}]: [${t5.dims}] | ${et2(t5.dataType)}, `;
                }));
                let t4 = "";
                u3.forEach(((e6, n4) => {
                  t4 += `output[${n4}]: [${e6.dims}] | ${et2(e6.dataType)}, `;
                })), console.log(`[profiling] kernel "${s3}|${o3}|${i3}|${l3}" ${e5}${t4}execution time: ${h3 - m3} ns`);
              }
              S2("GPU", `${l3}::${c3}::${p3}`);
            }
            e3.unmap(), this.pendingQueries.delete(e3);
          })), I2();
        }
        run(e3, t3, n3, r3, s3, a3) {
          E2(e3.name);
          let o3 = [];
          for (let e4 = 0; e4 < t3.length; ++e4) {
            let n4 = t3[e4].data;
            if (0 === n4) continue;
            let r4 = this.gpuDataManager.get(n4);
            if (!r4) throw new Error(`no GPU data for input: ${n4}`);
            o3.push(r4);
          }
          let { outputs: i3, dispatchGroup: l3, programUniforms: d3 } = e3.getRunData(t3), u3 = 0 === n3.length ? i3.map(((e4, t4) => t4)) : n3;
          if (u3.length !== i3.length) throw new Error(`Output size ${u3.length} must be equal to ${i3.length}.`);
          let c3, p3 = [], m3 = [];
          for (let e4 = 0; e4 < i3.length; ++e4) {
            if (!Number.isInteger(u3[e4]) || u3[e4] < -3 || u3[e4] >= a3) throw new Error(`Invalid output index: ${u3[e4]}`);
            if (-3 === u3[e4]) continue;
            let t4 = -1 === u3[e4], n4 = -2 === u3[e4], o4 = t4 || n4 ? s3(i3[e4].dataType, i3[e4].dims) : r3(u3[e4], i3[e4].dataType, i3[e4].dims);
            if (p3.push(o4), 0 === o4.data) continue;
            let l4 = this.gpuDataManager.get(o4.data);
            if (!l4) throw new Error(`no GPU data for output: ${o4.data}`);
            if (t4 && this.temporaryData.push(l4), n4) {
              let e5 = this.kernelPersistentData.get(this.currentKernelId);
              e5 || (e5 = [], this.kernelPersistentData.set(this.currentKernelId, e5)), e5.push(l4);
            }
            m3.push(l4);
          }
          if (o3.length !== t3.length || m3.length !== p3.length) {
            if (0 === m3.length) return I2(e3.name), p3;
            throw new Error(`Program ${e3.name} has zero-sized tensor(s) in inputs or outputs. This is not supported now.`);
          }
          if (d3) {
            let e4 = 0, t4 = [];
            d3.forEach(((n5) => {
              let r5 = "number" == typeof n5.data ? [n5.data] : n5.data;
              if (0 === r5.length) return;
              let s5, a4, o4 = 10 === n5.type ? 2 : 4;
              10 === n5.type ? (a4 = r5.length > 4 ? 16 : r5.length > 2 ? 8 : r5.length * o4, s5 = r5.length > 4 ? 16 : o4 * r5.length) : (a4 = r5.length <= 2 ? r5.length * o4 : 16, s5 = 16), e4 = Math.ceil(e4 / a4) * a4, t4.push(e4);
              let i4 = 10 === n5.type ? 8 : 4;
              e4 += r5.length > 4 ? Math.ceil(r5.length / i4) * s5 : r5.length * o4;
            }));
            let n4 = 16;
            e4 = Math.ceil(e4 / n4) * n4;
            let r4 = new ArrayBuffer(e4);
            d3.forEach(((e5, n5) => {
              let s5 = t4[n5], a4 = "number" == typeof e5.data ? [e5.data] : e5.data;
              if (6 === e5.type) new Int32Array(r4, s5, a4.length).set(a4);
              else if (12 === e5.type) new Uint32Array(r4, s5, a4.length).set(a4);
              else if (10 === e5.type) new Uint16Array(r4, s5, a4.length).set(a4);
              else {
                if (1 !== e5.type) throw new Error(`Unsupported uniform type: ${et2(e5.type)}`);
                new Float32Array(r4, s5, a4.length).set(a4);
              }
            }));
            let s4 = this.gpuDataManager.create(e4, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);
            this.device.queue.writeBuffer(s4.buffer, 0, r4, 0, e4), this.gpuDataManager.release(s4.id), c3 = { offset: 0, size: e4, buffer: s4.buffer };
          }
          let h3 = this.programManager.normalizeDispatchGroupSize(l3), f3 = 1 === h3[1] && 1 === h3[2], _3 = xu2(e3, t3, f3), g3 = this.programManager.getArtifact(_3);
          if (g3 || (g3 = this.programManager.build(e3, h3), this.programManager.setArtifact(_3, g3), ht2("info", (() => `[artifact] key: ${_3}, programName: ${e3.name}`))), d3 && g3.uniformVariablesInfo) {
            if (d3.length !== g3.uniformVariablesInfo.length) throw new Error(`Uniform variables count mismatch: expect ${g3.uniformVariablesInfo.length}, got ${d3.length} in program "${g3.programInfo.name}".`);
            for (let e4 = 0; e4 < d3.length; e4++) {
              let t4 = d3[e4], n4 = t4.type, r4 = "number" == typeof t4.data ? 1 : t4.data.length, [s4, a4] = g3.uniformVariablesInfo[e4];
              if (n4 !== s4 || r4 !== a4) throw new Error(`Uniform variable ${e4} mismatch: expect type ${s4} with size ${a4}, got type ${n4} with size ${r4} in program "${g3.programInfo.name}".`);
            }
          }
          if (ht2("info", (() => `[ProgramManager] run "${e3.name}" (key=${_3}) with ${h3[0]}x${h3[1]}x${h3[2]}`)), "none" !== this.queryType || "capturing" === this.sessionStatus) {
            let e4 = { kernelId: this.currentKernelId, programName: g3.programInfo.name, inputTensorViews: t3, outputTensorViews: p3 };
            this.pendingKernels.push(e4), "capturing" === this.sessionStatus && this.capturedPendingKernels.get(this.currentSessionId).push(e4);
          }
          return this.programManager.run(g3, o3, m3, h3, c3), I2(e3.name), p3;
        }
        upload(e3, t3) {
          this.gpuDataManager.upload(e3, t3);
        }
        memcpy(e3, t3) {
          this.gpuDataManager.memcpy(e3, t3);
        }
        async download(e3, t3) {
          await this.gpuDataManager.download(e3, t3);
        }
        alloc(e3) {
          return this.gpuDataManager.create(e3).id;
        }
        free(e3) {
          return this.gpuDataManager.release(e3);
        }
        createKernel(e3, t3, n3, r3) {
          let s3 = td2.get(e3);
          if (!s3) throw new Error(`kernel not implemented: ${e3}`);
          let a3 = { kernelType: e3, kernelName: r3, kernelEntry: s3[0], attributes: [s3[1], n3] };
          this.kernels.set(t3, a3);
        }
        releaseKernel(e3) {
          let t3 = this.kernelPersistentData.get(e3);
          if (t3) {
            for (let e4 of t3) this.gpuDataManager.release(e4.id);
            this.kernelPersistentData.delete(e3);
          }
          this.kernelCustomData.delete(e3), this.kernels.delete(e3);
        }
        computeKernel(e3, t3, n3) {
          let r3 = this.kernels.get(e3);
          if (!r3) throw new Error(`kernel not created: ${e3}`);
          let s3 = r3.kernelType, a3 = r3.kernelName, o3 = r3.kernelEntry, i3 = r3.attributes;
          if (null !== this.currentKernelId) throw new Error(`kernel "[${s3}] ${a3}" is not allowed to be called recursively`);
          this.currentKernelId = e3, i3[0] && (i3[1] = i3[0](i3[1]), i3[0] = void 0), ht2("info", (() => `[WebGPU] Start to run kernel "[${s3}] ${a3}"...`));
          let l3 = this.env.debug;
          this.temporaryData = [];
          try {
            return l3 && this.device.pushErrorScope("validation"), o3(t3, i3[1]), 0;
          } catch (e4) {
            return n3.push(Promise.resolve(`[WebGPU] Kernel "[${s3}] ${a3}" failed. ${e4}`)), 1;
          } finally {
            l3 && n3.push(this.device.popErrorScope().then(((e4) => e4 ? `GPU validation error for kernel "[${s3}] ${a3}": ${e4.message}` : null)));
            for (let e4 of this.temporaryData) this.gpuDataManager.release(e4.id);
            this.temporaryData = [], this.currentKernelId = null;
          }
        }
        registerBuffer(e3, t3, n3, r3) {
          let s3 = this.sessionExternalDataMapping.get(e3);
          s3 || (s3 = /* @__PURE__ */ new Map(), this.sessionExternalDataMapping.set(e3, s3));
          let a3 = s3.get(t3), o3 = this.gpuDataManager.registerExternalBuffer(n3, r3, a3);
          return s3.set(t3, [o3, n3]), o3;
        }
        unregisterBuffers(e3) {
          let t3 = this.sessionExternalDataMapping.get(e3);
          t3 && (t3.forEach(((e4) => this.gpuDataManager.unregisterExternalBuffer(e4[0]))), this.sessionExternalDataMapping.delete(e3));
        }
        getBuffer(e3) {
          let t3 = this.gpuDataManager.get(e3);
          if (!t3) throw new Error(`no GPU data for buffer: ${e3}`);
          return t3.buffer;
        }
        createDownloader(e3, t3, n3) {
          return async () => {
            let r3 = await Vt2(this, e3, t3);
            return xt2(r3.buffer, n3);
          };
        }
        writeTimestamp(e3) {
          "inside-passes" === this.queryType && this.computePassEncoder.writeTimestamp(this.querySet, e3);
        }
        setQueryType() {
          this.queryType = "none", ("default" === this.env.webgpu.profiling?.mode || (typeof this.env.trace > "u" ? this.env.wasm.trace : this.env.trace)) && (this.device.features.has("chromium-experimental-timestamp-query-inside-passes") ? this.queryType = "inside-passes" : this.device.features.has("timestamp-query") && (this.queryType = "at-passes"), "none" !== this.queryType && typeof this.querySet > "u" && (this.querySet = this.device.createQuerySet({ type: "timestamp", count: 2 * this.maxDispatchNumber }), this.queryResolveBuffer = this.device.createBuffer({ size: 2 * this.maxDispatchNumber * 8, usage: GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE })));
        }
        captureBegin() {
          ht2("info", "captureBegin"), this.capturedCommandList.get(this.currentSessionId) || this.capturedCommandList.set(this.currentSessionId, []), this.capturedPendingKernels.get(this.currentSessionId) || this.capturedPendingKernels.set(this.currentSessionId, []), this.flush(), this.sessionStatus = "capturing";
        }
        captureEnd() {
          ht2("info", "captureEnd"), this.flush(), this.sessionStatus = "default";
        }
        replay() {
          ht2("info", "replay"), this.sessionStatus = "replaying";
          let e3 = this.capturedCommandList.get(this.currentSessionId), t3 = this.capturedPendingKernels.get(this.currentSessionId), n3 = e3.length;
          this.pendingKernels = [];
          for (let r3 = 0; r3 < n3; r3++) {
            let n4 = this.getComputePassEncoder(), s3 = e3[r3];
            this.writeTimestamp(2 * this.pendingDispatchNumber), n4.setPipeline(s3.computePipeline), n4.setBindGroup(0, s3.bindGroup), n4.dispatchWorkgroups(...s3.dispatchGroup), this.writeTimestamp(2 * this.pendingDispatchNumber + 1), this.pendingDispatchNumber++, "none" !== this.queryType && this.pendingKernels.push(t3[r3]), (this.pendingDispatchNumber >= this.maxDispatchNumber || "at-passes" === this.queryType) && this.endComputePass(), this.pendingDispatchNumber >= this.maxDispatchNumber && this.flush();
          }
          this.flush(), this.sessionStatus = "default";
        }
        onCreateSession() {
          this.gpuDataManager.onCreateSession();
        }
        onReleaseSession(e3) {
          this.unregisterBuffers(e3), this.capturedCommandList.has(e3) && this.capturedCommandList.delete(e3), this.capturedPendingKernels.has(e3) && this.capturedPendingKernels.delete(e3), this.gpuDataManager.onReleaseSession(e3);
        }
        onRunStart(e3) {
          this.currentSessionId = e3, this.setQueryType();
        }
      };
    })), Pu2 = {};
    R2(Pu2, { init: () => Su2 });
    var $u2, Cu2, Su2, Fu2, Eu2, Iu2, Au2, zu2, Lu2, Ou2, Du2, Bu2, Nu2, ju2, Ru2, Vu2, Gu2, qu2, Uu2, Wu2, Hu2, Qu2, Ku2, Xu2, Ju2, Yu2, Zu2, ec2, tc2, nc2, rc2, sc2, ac2, oc2, ic2, lc2, dc2, uc2 = j2((() => {
      dd2(), cd2(), pd2(), fd2(), $u2 = class e3 {
        constructor(e4, t3, n3, r3) {
          this.module = e4, this.dataType = t3, this.data = n3, this.dims = r3;
        }
        getFloat32Array() {
          if (1 !== this.dataType) throw new Error("Invalid data type");
          let e4 = gt2.size(this.dims);
          return 0 === e4 ? new Float32Array() : new Float32Array(this.module.HEAP8.buffer, this.data, e4);
        }
        getBigInt64Array() {
          if (7 !== this.dataType) throw new Error("Invalid data type");
          let e4 = gt2.size(this.dims);
          return 0 === e4 ? new BigInt64Array() : new BigInt64Array(this.module.HEAP8.buffer, this.data, e4);
        }
        getInt32Array() {
          if (6 !== this.dataType) throw new Error("Invalid data type");
          let e4 = gt2.size(this.dims);
          return 0 === e4 ? new Int32Array() : new Int32Array(this.module.HEAP8.buffer, this.data, e4);
        }
        getUint16Array() {
          if (10 !== this.dataType && 4 !== this.dataType) throw new Error("Invalid data type");
          let e4 = gt2.size(this.dims);
          return 0 === e4 ? new Uint16Array() : new Uint16Array(this.module.HEAP8.buffer, this.data, e4);
        }
        reshape(t3) {
          if (gt2.size(t3) !== gt2.size(this.dims)) throw new Error("Invalid new shape");
          return new e3(this.module, this.dataType, this.data, t3);
        }
      }, Cu2 = class {
        constructor(e3, t3, n3) {
          this.module = e3, this.backend = t3, this.customDataOffset = 0, this.customDataSize = 0, this.adapterInfo = t3.adapterInfo;
          let r3 = e3.PTR_SIZE, s3 = n3 / e3.PTR_SIZE, a3 = 4 === r3 ? "i32" : "i64";
          this.opKernelContext = Number(e3.getValue(r3 * s3++, a3));
          let o3 = Number(e3.getValue(r3 * s3++, a3));
          this.outputCount = Number(e3.getValue(r3 * s3++, a3)), this.customDataOffset = Number(e3.getValue(r3 * s3++, "*")), this.customDataSize = Number(e3.getValue(r3 * s3++, a3));
          let i3 = [];
          for (let t4 = 0; t4 < o3; t4++) {
            let t5 = Number(e3.getValue(r3 * s3++, a3)), n4 = Number(e3.getValue(r3 * s3++, "*")), o4 = Number(e3.getValue(r3 * s3++, a3)), l3 = [];
            for (let t6 = 0; t6 < o4; t6++) l3.push(Number(e3.getValue(r3 * s3++, a3)));
            i3.push(new $u2(e3, t5, n4, l3));
          }
          this.inputs = i3;
        }
        get kernelCustomData() {
          return this.backend.currentKernelCustomData;
        }
        get customDataBuffer() {
          return this.module.HEAPU8.subarray(this.customDataOffset, this.customDataOffset + this.customDataSize);
        }
        compute(e3, t3) {
          let n3 = t3?.inputs?.map(((e4) => "number" == typeof e4 ? this.inputs[e4] : e4)) ?? this.inputs, r3 = t3?.outputs ?? [];
          return this.backend.run(e3, n3, r3, ((e4, t4, n4) => new $u2(this.module, t4, this.output(e4, n4), n4)), ((e4, t4) => {
            let n4 = tt2(e4, t4);
            if (!n4) throw new Error(`Unsupported data type: ${e4}`);
            let r4 = n4 > 0 ? this.backend.gpuDataManager.create(n4).id : 0;
            return new $u2(this.module, e4, r4, t4);
          }), this.outputCount);
        }
        output(e3, t3) {
          let n3 = this.module.stackSave();
          try {
            let n4 = this.module.PTR_SIZE, r3 = 4 === n4 ? "i32" : "i64", s3 = this.module.stackAlloc((1 + t3.length) * n4);
            this.module.setValue(s3, t3.length, r3);
            for (let e4 = 0; e4 < t3.length; e4++) this.module.setValue(s3 + n4 * (e4 + 1), t3[e4], r3);
            return this.module._JsepOutput(this.opKernelContext, e3, s3);
          } catch (n4) {
            throw new Error(`Failed to generate kernel's output[${e3}] with dims [${t3}]. If you are running with pre-allocated output, please make sure the output type/dims are correct. Error: ${n4}`);
          } finally {
            this.module.stackRestore(n3);
          }
        }
      }, Su2 = async (e3, t3, n3, r3) => {
        let s3 = t3.jsepInit;
        if (!s3) throw new Error("Failed to initialize JSEP. The WebAssembly module is not built with JSEP support.");
        if ("webgpu" === e3) {
          let e4 = new (0, (ku2(), V2(yu2)).WebGpuBackend)();
          await e4.initialize(n3, r3), s3("webgpu", [e4, (t4) => e4.alloc(Number(t4)), (t4) => e4.free(t4), (n4, r4, s4, a3 = false) => {
            if (a3) ht2("verbose", (() => `[WebGPU] jsepCopyGpuToGpu: src=${Number(n4)}, dst=${Number(r4)}, size=${Number(s4)}`)), e4.memcpy(Number(n4), Number(r4));
            else {
              ht2("verbose", (() => `[WebGPU] jsepCopyCpuToGpu: dataOffset=${Number(n4)}, gpuDataId=${Number(r4)}, size=${Number(s4)}`));
              let a4 = t3.HEAPU8.subarray(Number(n4 >>> 0), Number(n4 >>> 0) + Number(s4));
              e4.upload(Number(r4), a4);
            }
          }, async (n4, r4, s4) => {
            ht2("verbose", (() => `[WebGPU] jsepCopyGpuToCpu: gpuDataId=${n4}, dataOffset=${r4}, size=${s4}`)), await e4.download(Number(n4), (() => t3.HEAPU8.subarray(Number(r4) >>> 0, Number(r4 + s4) >>> 0)));
          }, (n4, r4, s4) => e4.createKernel(n4, Number(r4), s4, t3.UTF8ToString(t3._JsepGetNodeName(Number(r4)))), (t4) => e4.releaseKernel(t4), (n4, r4, s4, a3) => {
            ht2("verbose", (() => `[WebGPU] jsepRun: sessionHandle=${s4}, kernel=${n4}, contextDataOffset=${r4}`));
            let o3 = new Cu2(t3, e4, Number(r4));
            return e4.computeKernel(Number(n4), o3, a3);
          }, () => e4.captureBegin(), () => e4.captureEnd(), () => e4.replay()]);
        } else {
          let e4 = new Lt2(n3);
          s3("webnn", [e4, () => e4.reserveTensorId(), (t4) => e4.releaseTensorId(t4), async (t4, n4, r4, s4, a3) => e4.ensureTensor(t4, n4, r4, s4, a3), (t4, n4) => {
            e4.uploadTensor(t4, n4);
          }, async (t4, n4) => e4.downloadTensor(t4, n4)]);
        }
      };
    })), cc2 = j2((() => {
      id2(), ld2(), dd2(), ad2(), od2(), ud2(), Fu2 = (e3, t3) => {
        0 !== Ve2()._OrtInit(e3, t3) && Ue2("Can't initialize onnxruntime.");
      }, Eu2 = async (e3) => {
        Fu2(e3.wasm.numThreads, rt2(e3.logLevel));
      }, Iu2 = async (e3, t3) => {
        Ve2().asyncInit?.();
        {
          let n3 = (uc2(), V2(Pu2)).init;
          if ("webgpu" === t3) {
            if (typeof navigator > "u" || !navigator.gpu) throw new Error("WebGPU is not supported in current environment");
            let t4 = e3.webgpu.adapter;
            if (t4) {
              if ("object" != typeof t4.limits || "object" != typeof t4.features || "function" != typeof t4.requestDevice) throw new Error("Invalid GPU adapter set in `env.webgpu.adapter`. It must be a GPUAdapter object.");
            } else {
              let n4 = e3.webgpu.powerPreference;
              if (void 0 !== n4 && "low-power" !== n4 && "high-performance" !== n4) throw new Error(`Invalid powerPreference setting: "${n4}"`);
              let r3 = e3.webgpu.forceFallbackAdapter;
              if (void 0 !== r3 && "boolean" != typeof r3) throw new Error(`Invalid forceFallbackAdapter setting: "${r3}"`);
              if (t4 = await navigator.gpu.requestAdapter({ powerPreference: n4, forceFallbackAdapter: r3 }), !t4) throw new Error('Failed to get GPU adapter. You may need to enable flag "--enable-unsafe-webgpu" if you are using Chrome.');
            }
            await n3("webgpu", Ve2(), e3, t4);
          }
          if ("webnn" === t3) {
            if (typeof navigator > "u" || !navigator.ml) throw new Error("WebNN is not supported in current environment");
            await n3("webnn", Ve2(), e3);
          }
        }
      }, Au2 = /* @__PURE__ */ new Map(), zu2 = (e3) => {
        let t3 = Ve2(), n3 = t3.stackSave();
        try {
          let n4 = t3.PTR_SIZE, r3 = t3.stackAlloc(2 * n4);
          0 !== t3._OrtGetInputOutputCount(e3, r3, r3 + n4) && Ue2("Can't get session input/output count.");
          let s3 = 4 === n4 ? "i32" : "i64";
          return [Number(t3.getValue(r3, s3)), Number(t3.getValue(r3 + n4, s3))];
        } finally {
          t3.stackRestore(n3);
        }
      }, Lu2 = (e3, t3) => {
        let n3 = Ve2(), r3 = n3.stackSave(), s3 = 0;
        try {
          let r4 = n3.PTR_SIZE, a3 = n3.stackAlloc(2 * r4);
          0 !== n3._OrtGetInputOutputMetadata(e3, t3, a3, a3 + r4) && Ue2("Can't get session input/output metadata.");
          let o3 = Number(n3.getValue(a3, "*"));
          s3 = Number(n3.getValue(a3 + r4, "*"));
          let i3 = n3.HEAP32[s3 / 4];
          if (0 === i3) return [o3, 0];
          let l3 = n3.HEAPU32[s3 / 4 + 1], d3 = [];
          for (let e4 = 0; e4 < l3; e4++) {
            let t4 = Number(n3.getValue(s3 + 8 + e4 * r4, "*"));
            d3.push(0 !== t4 ? n3.UTF8ToString(t4) : Number(n3.getValue(s3 + 8 + (e4 + l3) * r4, "*")));
          }
          return [o3, i3, d3];
        } finally {
          n3.stackRestore(r3), 0 !== s3 && n3._OrtFree(s3);
        }
      }, Ou2 = (e3) => {
        let t3 = Ve2(), n3 = t3._malloc(e3.byteLength);
        if (0 === n3) throw new Error(`Can't create a session. failed to allocate a buffer of size ${e3.byteLength}.`);
        return t3.HEAPU8.set(e3, n3), [n3, e3.byteLength];
      }, Du2 = async (e3, t3) => {
        let n3, r3, s3 = Ve2();
        Array.isArray(e3) ? [n3, r3] = e3 : e3.buffer === s3.HEAPU8.buffer ? [n3, r3] = [e3.byteOffset, e3.byteLength] : [n3, r3] = Ou2(e3);
        let a3 = 0, o3 = 0, i3 = 0, l3 = [], d3 = [], u3 = [];
        try {
          if ([o3, l3] = await Ye2(t3), t3?.externalData && s3.mountExternalData) {
            let e5 = [];
            for (let n4 of t3.externalData) {
              let t4 = "string" == typeof n4 ? n4 : n4.path;
              e5.push(it2("string" == typeof n4 ? n4 : n4.data).then(((e6) => {
                s3.mountExternalData(t4, e6);
              })));
            }
            await Promise.all(e5);
          }
          for (let e5 of t3?.executionProviders ?? []) if ("webnn" === ("string" == typeof e5 ? e5 : e5.name)) {
            if (s3.shouldTransferToMLTensor = false, "string" != typeof e5) {
              let t4 = e5, n4 = t4?.context, r4 = t4?.gpuDevice, a4 = t4?.deviceType, o4 = t4?.powerPreference;
              s3.currentContext = n4 || (r4 ? await s3.webnnCreateMLContext(r4) : await s3.webnnCreateMLContext({ deviceType: a4, powerPreference: o4 }));
            } else s3.currentContext = await s3.webnnCreateMLContext();
            break;
          }
          a3 = await s3._OrtCreateSession(n3, r3, o3), s3.webgpuOnCreateSession?.(a3), 0 === a3 && Ue2("Can't create a session."), s3.jsepOnCreateSession?.(), s3.currentContext && (s3.webnnRegisterMLContext(a3, s3.currentContext), s3.currentContext = void 0, s3.shouldTransferToMLTensor = true);
          let [e4, c3] = zu2(a3), p3 = !!t3?.enableGraphCapture, m3 = [], h3 = [], f3 = [], _3 = [], g3 = [];
          for (let t4 = 0; t4 < e4; t4++) {
            let [e5, n4, r4] = Lu2(a3, t4);
            0 === e5 && Ue2("Can't get an input name."), d3.push(e5);
            let o4 = s3.UTF8ToString(e5);
            m3.push(o4), f3.push(0 === n4 ? { name: o4, isTensor: false } : { name: o4, isTensor: true, type: et2(n4), shape: r4 });
          }
          for (let n4 = 0; n4 < c3; n4++) {
            let [r4, o4, i4] = Lu2(a3, n4 + e4);
            0 === r4 && Ue2("Can't get an output name."), u3.push(r4);
            let l4 = s3.UTF8ToString(r4);
            h3.push(l4), _3.push(0 === o4 ? { name: l4, isTensor: false } : { name: l4, isTensor: true, type: et2(o4), shape: i4 });
            {
              if (p3 && void 0 === t3?.preferredOutputLocation) {
                g3.push("gpu-buffer");
                continue;
              }
              let e5 = "string" == typeof t3?.preferredOutputLocation ? t3.preferredOutputLocation : t3?.preferredOutputLocation?.[l4] ?? "cpu";
              if ("cpu" !== e5 && "cpu-pinned" !== e5 && "gpu-buffer" !== e5 && "ml-tensor" !== e5) throw new Error(`Not supported preferred output location: ${e5}.`);
              if (p3 && "gpu-buffer" !== e5) throw new Error(`Not supported preferred output location: ${e5}. Only 'gpu-buffer' location is supported when enableGraphCapture is true.`);
              g3.push(e5);
            }
          }
          let w3 = null;
          return g3.some(((e5) => "gpu-buffer" === e5 || "ml-tensor" === e5)) && (i3 = s3._OrtCreateBinding(a3), 0 === i3 && Ue2("Can't create IO binding."), w3 = { handle: i3, outputPreferredLocations: g3, outputPreferredLocationsEncoded: g3.map(((e5) => ot2(e5))) }), Au2.set(a3, [a3, d3, u3, w3, p3, false]), [a3, m3, h3, f3, _3];
        } catch (e4) {
          throw d3.forEach(((e5) => s3._OrtFree(e5))), u3.forEach(((e5) => s3._OrtFree(e5))), 0 !== i3 && 0 !== s3._OrtReleaseBinding(i3) && Ue2("Can't release IO binding."), 0 !== a3 && 0 !== s3._OrtReleaseSession(a3) && Ue2("Can't release session."), e4;
        } finally {
          s3._free(n3), 0 !== o3 && 0 !== s3._OrtReleaseSessionOptions(o3) && Ue2("Can't release session options."), l3.forEach(((e4) => s3._free(e4))), s3.unmountExternalData?.();
        }
      }, Bu2 = (e3) => {
        let t3 = Ve2(), n3 = Au2.get(e3);
        if (!n3) throw new Error(`cannot release session. invalid session id: ${e3}`);
        let [r3, s3, a3, o3, i3] = n3;
        o3 && (i3 && 0 !== t3._OrtClearBoundOutputs(o3.handle) && Ue2("Can't clear bound outputs."), 0 !== t3._OrtReleaseBinding(o3.handle) && Ue2("Can't release IO binding.")), t3.jsepOnReleaseSession?.(e3), t3.webnnOnReleaseSession?.(e3), t3.webgpuOnReleaseSession?.(e3), s3.forEach(((e4) => t3._OrtFree(e4))), a3.forEach(((e4) => t3._OrtFree(e4))), 0 !== t3._OrtReleaseSession(r3) && Ue2("Can't release session."), Au2.delete(e3);
      }, Nu2 = async (e3, t3, n3, r3, s3, a3, o3 = false) => {
        if (!e3) return void t3.push(0);
        let i3, l3, d3 = Ve2(), u3 = d3.PTR_SIZE, c3 = e3[0], p3 = e3[1], m3 = e3[3], h3 = m3;
        if ("string" === c3 && ("gpu-buffer" === m3 || "ml-tensor" === m3)) throw new Error("String tensor is not supported on GPU.");
        if (o3 && "gpu-buffer" !== m3) throw new Error(`External buffer must be provided for input/output index ${a3} when enableGraphCapture is true.`);
        if ("gpu-buffer" === m3) {
          let t4 = e3[2].gpuBuffer;
          l3 = tt2(Ze2(c3), p3);
          {
            let e4 = d3.jsepRegisterBuffer;
            if (!e4) throw new Error('Tensor location "gpu-buffer" is not supported without using WebGPU.');
            i3 = e4(r3, a3, t4, l3);
          }
        } else if ("ml-tensor" === m3) {
          let t4 = e3[2].mlTensor;
          l3 = tt2(Ze2(c3), p3);
          let n4 = d3.webnnRegisterMLTensor;
          if (!n4) throw new Error('Tensor location "ml-tensor" is not supported without using WebNN.');
          i3 = n4(r3, t4, Ze2(c3), p3);
        } else {
          let t4 = e3[2];
          if (Array.isArray(t4)) {
            l3 = u3 * t4.length, i3 = d3._malloc(l3), n3.push(i3);
            for (let e4 = 0; e4 < t4.length; e4++) {
              if ("string" != typeof t4[e4]) throw new TypeError(`tensor data at index ${e4} is not a string`);
              d3.setValue(i3 + e4 * u3, Ge2(t4[e4], n3), "*");
            }
          } else {
            let e4 = d3.webnnIsGraphInput;
            if ("string" !== c3 && e4) {
              if (e4(r3, d3.UTF8ToString(s3))) {
                let e5 = Ze2(c3);
                l3 = tt2(e5, p3), h3 = "ml-tensor";
                let n4 = d3.webnnCreateTemporaryTensor, s4 = d3.webnnUploadTensor;
                if (!n4 || !s4) throw new Error('Tensor location "ml-tensor" is not supported without using WebNN.');
                let a4 = await n4(r3, e5, p3);
                s4(a4, new Uint8Array(t4.buffer, t4.byteOffset, t4.byteLength)), i3 = a4;
              } else l3 = t4.byteLength, i3 = d3._malloc(l3), n3.push(i3), d3.HEAPU8.set(new Uint8Array(t4.buffer, t4.byteOffset, l3), i3);
            } else l3 = t4.byteLength, i3 = d3._malloc(l3), n3.push(i3), d3.HEAPU8.set(new Uint8Array(t4.buffer, t4.byteOffset, l3), i3);
          }
        }
        let f3 = d3.stackSave(), _3 = d3.stackAlloc(4 * p3.length);
        try {
          p3.forEach(((e5, t4) => d3.setValue(_3 + t4 * u3, e5, 4 === u3 ? "i32" : "i64")));
          let e4 = d3._OrtCreateTensor(Ze2(c3), i3, l3, _3, p3.length, ot2(h3));
          0 === e4 && Ue2(`Can't create tensor for input/output. session=${r3}, index=${a3}.`), t3.push(e4);
        } finally {
          d3.stackRestore(f3);
        }
      }, ju2 = async (e3, t3, n3, r3, s3, a3) => {
        let o3 = Ve2(), i3 = o3.PTR_SIZE, l3 = Au2.get(e3);
        if (!l3) throw new Error(`cannot run inference. invalid session id: ${e3}`);
        let d3 = l3[0], u3 = l3[1], c3 = l3[2], p3 = l3[3], m3 = l3[4], h3 = l3[5], f3 = t3.length, _3 = r3.length, g3 = 0, w3 = [], b3 = [], y3 = [], M3 = [], x3 = o3.stackSave(), v3 = o3.stackAlloc(f3 * i3), T3 = o3.stackAlloc(f3 * i3), k3 = o3.stackAlloc(_3 * i3), P3 = o3.stackAlloc(_3 * i3);
        try {
          [g3, w3] = We2(a3);
          for (let r4 = 0; r4 < f3; r4++) await Nu2(n3[r4], b3, M3, e3, u3[t3[r4]], t3[r4], m3);
          for (let t4 = 0; t4 < _3; t4++) await Nu2(s3[t4], y3, M3, e3, c3[r3[t4]], f3 + r3[t4], m3);
          for (let e4 = 0; e4 < f3; e4++) o3.setValue(v3 + e4 * i3, b3[e4], "*"), o3.setValue(T3 + e4 * i3, u3[t3[e4]], "*");
          for (let e4 = 0; e4 < _3; e4++) o3.setValue(k3 + e4 * i3, y3[e4], "*"), o3.setValue(P3 + e4 * i3, c3[r3[e4]], "*");
          if (p3 && !h3) {
            let { handle: n4, outputPreferredLocations: a4, outputPreferredLocationsEncoded: i4 } = p3;
            if (u3.length !== f3) throw new Error(`input count from feeds (${f3}) is expected to be always equal to model's input count (${u3.length}).`);
            for (let r4 = 0; r4 < f3; r4++) {
              let s4 = t3[r4];
              0 !== await o3._OrtBindInput(n4, u3[s4], b3[r4]) && Ue2(`Can't bind input[${r4}] for session=${e3}.`);
            }
            for (let t4 = 0; t4 < _3; t4++) {
              let l5 = r3[t4];
              s3[t4]?.[3] ? 0 !== o3._OrtBindOutput(n4, c3[l5], y3[t4], 0) && Ue2(`Can't bind pre-allocated output[${t4}] for session=${e3}.`) : 0 !== o3._OrtBindOutput(n4, c3[l5], 0, i4[l5]) && Ue2(`Can't bind output[${t4}] to ${a4[t4]} for session=${e3}.`);
            }
            Au2.set(e3, [d3, u3, c3, p3, m3, true]);
          }
          let l4;
          o3.jsepOnRunStart?.(d3), o3.webnnOnRunStart?.(d3), l4 = p3 ? await o3._OrtRunWithBinding(d3, p3.handle, _3, k3, g3) : await o3._OrtRun(d3, T3, v3, f3, P3, _3, k3, g3), 0 !== l4 && Ue2("failed to call OrtRun().");
          let x4 = [];
          for (let t4 = 0; t4 < _3; t4++) {
            let n4 = Number(o3.getValue(k3 + t4 * i3, "*"));
            if (n4 === y3[t4]) {
              x4.push(s3[t4]);
              continue;
            }
            let a4, l5 = o3.stackSave(), u4 = o3.stackAlloc(4 * i3), c4 = false, m4 = 0;
            try {
              0 !== o3._OrtGetTensorData(n4, u4, u4 + i3, u4 + 2 * i3, u4 + 3 * i3) && Ue2(`Can't access output tensor data on index ${t4}.`);
              let s4 = 4 === i3 ? "i32" : "i64", l6 = Number(o3.getValue(u4, s4));
              m4 = o3.getValue(u4 + i3, "*");
              let d4 = o3.getValue(u4 + 2 * i3, "*"), h4 = Number(o3.getValue(u4 + 3 * i3, s4)), f4 = [];
              for (let e4 = 0; e4 < h4; e4++) f4.push(Number(o3.getValue(d4 + e4 * i3, s4)));
              0 !== o3._OrtFree(d4) && Ue2("Can't free memory for tensor dims.");
              let _4 = f4.reduce(((e4, t5) => e4 * t5), 1);
              a4 = et2(l6);
              let g4 = p3?.outputPreferredLocations[r3[t4]];
              if ("string" === a4) {
                if ("gpu-buffer" === g4 || "ml-tensor" === g4) throw new Error("String tensor is not supported on GPU.");
                let e4 = [];
                for (let t5 = 0; t5 < _4; t5++) {
                  let n5 = o3.getValue(m4 + t5 * i3, "*"), r4 = o3.getValue(m4 + (t5 + 1) * i3, "*"), s5 = t5 === _4 - 1 ? void 0 : r4 - n5;
                  e4.push(o3.UTF8ToString(n5, s5));
                }
                x4.push([a4, f4, e4, "cpu"]);
              } else if ("gpu-buffer" === g4 && _4 > 0) {
                let e4 = o3.jsepGetBuffer;
                if (!e4) throw new Error('preferredLocation "gpu-buffer" is not supported without using WebGPU.');
                let t5 = e4(m4), r4 = tt2(l6, _4);
                if (void 0 === r4 || !st2(a4)) throw new Error(`Unsupported data type: ${a4}`);
                c4 = true, x4.push([a4, f4, { gpuBuffer: t5, download: o3.jsepCreateDownloader(t5, r4, a4), dispose: () => {
                  0 !== o3._OrtReleaseTensor(n4) && Ue2("Can't release tensor.");
                } }, "gpu-buffer"]);
              } else if ("ml-tensor" === g4 && _4 > 0) {
                let t5 = o3.webnnEnsureTensor, r4 = o3.webnnIsInt64Supported;
                if (!t5 || !r4) throw new Error('preferredLocation "ml-tensor" is not supported without using WebNN.');
                if (void 0 === tt2(l6, _4) || !at2(a4)) throw new Error(`Unsupported data type: ${a4}`);
                if ("int64" === a4 && !r4(e3)) throw new Error('preferredLocation "ml-tensor" for int64 output is not supported by current WebNN Context.');
                let s5 = await t5(e3, m4, l6, f4, false);
                c4 = true, x4.push([a4, f4, { mlTensor: s5, download: o3.webnnCreateMLTensorDownloader(m4, a4), dispose: () => {
                  o3.webnnReleaseTensorId(m4), o3._OrtReleaseTensor(n4);
                } }, "ml-tensor"]);
              } else {
                let e4 = new (nt2(a4))(_4);
                new Uint8Array(e4.buffer, e4.byteOffset, e4.byteLength).set(o3.HEAPU8.subarray(m4, m4 + e4.byteLength)), x4.push([a4, f4, e4, "cpu"]);
              }
            } finally {
              o3.stackRestore(l5), "string" === a4 && m4 && o3._free(m4), c4 || o3._OrtReleaseTensor(n4), o3.webnnOnRunEnd?.(d3);
            }
          }
          return p3 && !m3 && (0 !== o3._OrtClearBoundOutputs(p3.handle) && Ue2("Can't clear bound outputs."), Au2.set(e3, [d3, u3, c3, p3, m3, false])), x4;
        } finally {
          o3.stackRestore(x3), b3.forEach(((e4) => o3._OrtReleaseTensor(e4))), y3.forEach(((e4) => o3._OrtReleaseTensor(e4))), M3.forEach(((e4) => o3._free(e4))), 0 !== g3 && o3._OrtReleaseRunOptions(g3), w3.forEach(((e4) => o3._free(e4)));
        }
      }, Ru2 = (e3) => {
        let t3 = Ve2(), n3 = Au2.get(e3);
        if (!n3) throw new Error("invalid session id");
        let r3 = n3[0], s3 = t3._OrtEndProfiling(r3);
        0 === s3 && Ue2("Can't get an profile file name."), t3._OrtFree(s3);
      }, Vu2 = (e3) => {
        let t3 = [];
        for (let n3 of e3) {
          let e4 = n3[2];
          !Array.isArray(e4) && "buffer" in e4 && t3.push(e4.buffer);
        }
        return t3;
      };
    })), pc2 = j2((() => {
      le2(), cc2(), ad2(), sd2(), Gu2 = () => !!p2.wasm.proxy && typeof document < "u", Uu2 = false, Wu2 = false, Hu2 = false, Xu2 = /* @__PURE__ */ new Map(), Ju2 = (e3, t3) => {
        let n3 = Xu2.get(e3);
        n3 ? n3.push(t3) : Xu2.set(e3, [t3]);
      }, Yu2 = () => {
        if (Uu2 || !Wu2 || Hu2 || !qu2) throw new Error("worker not ready");
      }, Zu2 = (e3) => {
        switch (e3.data.type) {
          case "init-wasm":
            Uu2 = false, e3.data.err ? (Hu2 = true, Ku2[1](e3.data.err)) : (Wu2 = true, Ku2[0]()), Qu2 && (URL.revokeObjectURL(Qu2), Qu2 = void 0);
            break;
          case "init-ep":
          case "copy-from":
          case "create":
          case "release":
          case "run":
          case "end-profiling": {
            let t3 = Xu2.get(e3.data.type);
            e3.data.err ? t3.shift()[1](e3.data.err) : t3.shift()[0](e3.data.out);
            break;
          }
        }
      }, ec2 = async () => {
        if (!Wu2) {
          if (Uu2) throw new Error("multiple calls to 'initWasm()' detected.");
          if (Hu2) throw new Error("previous call to 'initWasm()' failed.");
          if (Uu2 = true, Gu2()) return new Promise(((e3, t3) => {
            qu2?.terminate(), Ee2().then((([r3, s3]) => {
              try {
                (qu2 = s3).onerror = (e4) => t3(e4), qu2.onmessage = Zu2, Ku2 = [e3, t3];
                let a3 = { type: "init-wasm", in: p2 };
                !a3.in.wasm.wasmPaths && (r3 || Me2) && (a3.in.wasm.wasmPaths = { wasm: new URL(n2("./node_modules/onnxruntime-web/dist/ort-wasm-simd-threaded.jsep.wasm"), n2.b).href }), qu2.postMessage(a3), Qu2 = r3;
              } catch (e4) {
                t3(e4);
              }
            }), t3);
          }));
          try {
            await Re2(p2.wasm), await Eu2(p2), Wu2 = true;
          } catch (e3) {
            throw Hu2 = true, e3;
          } finally {
            Uu2 = false;
          }
        }
      }, tc2 = async (e3) => {
        if (Gu2()) return Yu2(), new Promise(((t3, n3) => {
          Ju2("init-ep", [t3, n3]);
          let r3 = { type: "init-ep", in: { epName: e3, env: p2 } };
          qu2.postMessage(r3);
        }));
        await Iu2(p2, e3);
      }, nc2 = async (e3) => Gu2() ? (Yu2(), new Promise(((t3, n3) => {
        Ju2("copy-from", [t3, n3]);
        let r3 = { type: "copy-from", in: { buffer: e3 } };
        qu2.postMessage(r3, [e3.buffer]);
      }))) : Ou2(e3), rc2 = async (e3, t3) => {
        if (Gu2()) {
          if (t3?.preferredOutputLocation) throw new Error('session option "preferredOutputLocation" is not supported for proxy.');
          return Yu2(), new Promise(((n3, r3) => {
            Ju2("create", [n3, r3]);
            let s3 = { type: "create", in: { model: e3, options: { ...t3 } } }, a3 = [];
            e3 instanceof Uint8Array && a3.push(e3.buffer), qu2.postMessage(s3, a3);
          }));
        }
        return Du2(e3, t3);
      }, sc2 = async (e3) => {
        if (Gu2()) return Yu2(), new Promise(((t3, n3) => {
          Ju2("release", [t3, n3]);
          let r3 = { type: "release", in: e3 };
          qu2.postMessage(r3);
        }));
        Bu2(e3);
      }, ac2 = async (e3, t3, n3, r3, s3, a3) => {
        if (Gu2()) {
          if (n3.some(((e4) => "cpu" !== e4[3]))) throw new Error("input tensor on GPU is not supported for proxy.");
          if (s3.some(((e4) => e4))) throw new Error("pre-allocated output tensor is not supported for proxy.");
          return Yu2(), new Promise(((s4, o3) => {
            Ju2("run", [s4, o3]);
            let i3 = n3, l3 = { type: "run", in: { sessionId: e3, inputIndices: t3, inputs: i3, outputIndices: r3, options: a3 } };
            qu2.postMessage(l3, Vu2(i3));
          }));
        }
        return ju2(e3, t3, n3, r3, s3, a3);
      }, oc2 = async (e3) => {
        if (Gu2()) return Yu2(), new Promise(((t3, n3) => {
          Ju2("end-profiling", [t3, n3]);
          let r3 = { type: "end-profiling", in: e3 };
          qu2.postMessage(r3);
        }));
        Ru2(e3);
      };
    })), mc2 = j2((() => {
      le2(), pc2(), dd2(), de2(), ud2(), ic2 = (e3, t3) => {
        switch (e3.location) {
          case "cpu":
            return [e3.type, e3.dims, e3.data, "cpu"];
          case "gpu-buffer":
            return [e3.type, e3.dims, { gpuBuffer: e3.gpuBuffer }, "gpu-buffer"];
          case "ml-tensor":
            return [e3.type, e3.dims, { mlTensor: e3.mlTensor }, "ml-tensor"];
          default:
            throw new Error(`invalid data location: ${e3.location} for ${t3()}`);
        }
      }, lc2 = (e3) => {
        switch (e3[3]) {
          case "cpu":
            return new C2(e3[0], e3[2], e3[1]);
          case "gpu-buffer": {
            let t3 = e3[0];
            if (!st2(t3)) throw new Error(`not supported data type: ${t3} for deserializing GPU tensor`);
            let { gpuBuffer: n3, download: r3, dispose: s3 } = e3[2];
            return C2.fromGpuBuffer(n3, { dataType: t3, dims: e3[1], download: r3, dispose: s3 });
          }
          case "ml-tensor": {
            let t3 = e3[0];
            if (!at2(t3)) throw new Error(`not supported data type: ${t3} for deserializing MLTensor tensor`);
            let { mlTensor: n3, download: r3, dispose: s3 } = e3[2];
            return C2.fromMLTensor(n3, { dataType: t3, dims: e3[1], download: r3, dispose: s3 });
          }
          default:
            throw new Error(`invalid data location: ${e3[3]}`);
        }
      }, dc2 = class {
        async fetchModelAndCopyToWasmMemory(e3) {
          return nc2(await it2(e3));
        }
        async loadModel(e3, t3) {
          let n3;
          E2(), n3 = "string" == typeof e3 ? await this.fetchModelAndCopyToWasmMemory(e3) : e3, [this.sessionId, this.inputNames, this.outputNames, this.inputMetadata, this.outputMetadata] = await rc2(n3, t3), I2();
        }
        async dispose() {
          return sc2(this.sessionId);
        }
        async run(e3, t3, n3) {
          E2();
          let r3 = [], s3 = [];
          Object.entries(e3).forEach(((e4) => {
            let t4 = e4[0], n4 = e4[1], a4 = this.inputNames.indexOf(t4);
            if (-1 === a4) throw new Error(`invalid input '${t4}'`);
            r3.push(n4), s3.push(a4);
          }));
          let a3 = [], o3 = [];
          Object.entries(t3).forEach(((e4) => {
            let t4 = e4[0], n4 = e4[1], r4 = this.outputNames.indexOf(t4);
            if (-1 === r4) throw new Error(`invalid output '${t4}'`);
            a3.push(n4), o3.push(r4);
          }));
          let i3 = r3.map(((e4, t4) => ic2(e4, (() => `input "${this.inputNames[s3[t4]]}"`)))), l3 = a3.map(((e4, t4) => e4 ? ic2(e4, (() => `output "${this.outputNames[o3[t4]]}"`)) : null)), d3 = await ac2(this.sessionId, s3, i3, o3, l3, n3), u3 = {};
          for (let e4 = 0; e4 < d3.length; e4++) u3[this.outputNames[o3[e4]]] = a3[e4] ?? lc2(d3[e4]);
          return I2(), u3;
        }
        startProfiling() {
        }
        endProfiling() {
          oc2(this.sessionId);
        }
      };
    })), hc2 = {};
    R2(hc2, { OnnxruntimeWebAssemblyBackend: () => _c2, initializeFlags: () => fc2, wasmBackend: () => gc2 });
    var fc2, _c2, gc2, wc2 = j2((() => {
      le2(), pc2(), mc2(), fc2 = () => {
        ("number" != typeof p2.wasm.initTimeout || p2.wasm.initTimeout < 0) && (p2.wasm.initTimeout = 0);
        let e3 = p2.wasm.simd;
        if ("boolean" != typeof e3 && void 0 !== e3 && "fixed" !== e3 && "relaxed" !== e3 && (console.warn(`Property "env.wasm.simd" is set to unknown value "${e3}". Reset it to \`false\` and ignore SIMD feature checking.`), p2.wasm.simd = false), "boolean" != typeof p2.wasm.proxy && (p2.wasm.proxy = false), "boolean" != typeof p2.wasm.trace && (p2.wasm.trace = false), "number" != typeof p2.wasm.numThreads || !Number.isInteger(p2.wasm.numThreads) || p2.wasm.numThreads <= 0) if (typeof self < "u" && !self.crossOriginIsolated) p2.wasm.numThreads = 1;
        else {
          let e4 = typeof navigator > "u" ? N2("node:os").cpus().length : navigator.hardwareConcurrency;
          p2.wasm.numThreads = Math.min(4, Math.ceil((e4 || 1) / 2));
        }
      }, gc2 = new (_c2 = class {
        async init(e3) {
          fc2(), await ec2(), await tc2(e3);
        }
        async createInferenceSessionHandler(e3, t3) {
          let n3 = new dc2();
          return await n3.loadModel(e3, t3), n3;
        }
      })();
    }));
    le2(), le2(), le2();
    var bc2 = ie2;
    {
      let e3 = (wc2(), V2(hc2)).wasmBackend;
      o2("webgpu", e3, 5), o2("webnn", e3, 5), o2("cpu", e3, 10), o2("wasm", e3, 10);
    }
    Object.defineProperty(p2.versions, "web", { value: "1.22.0-dev.20250409-89f8206ba4", enumerable: true });
  }, "./src/backends/onnx.js": (e2, t2, n2) => {
    var r2;
    n2.r(t2), n2.d(t2, { Tensor: () => i2.Tensor, createInferenceSession: () => _2, deviceToExecutionProviders: () => h2, isONNXProxy: () => x2, isONNXTensor: () => y2, runInferenceSession: () => b2 });
    var s2 = n2("./src/env.js"), a2 = n2("?2ce3"), o2 = n2("./node_modules/onnxruntime-web/dist/ort.bundle.min.mjs?3a96"), i2 = n2("./node_modules/onnxruntime-common/dist/esm/index.js");
    const l2 = Object.freeze({ auto: null, gpu: null, cpu: "cpu", wasm: "wasm", webgpu: "webgpu", cuda: "cuda", dml: "dml", webnn: { name: "webnn", deviceType: "cpu" }, "webnn-npu": { name: "webnn", deviceType: "npu" }, "webnn-gpu": { name: "webnn", deviceType: "gpu" }, "webnn-cpu": { name: "webnn", deviceType: "cpu" } }), d2 = [];
    let u2, c2;
    const p2 = Symbol.for("onnxruntime");
    if (p2 in globalThis) c2 = globalThis[p2];
    else if (s2.apis.IS_NODE_ENV) {
      switch (c2 = a2 ?? (r2 || (r2 = n2.t(a2, 2))), process.platform) {
        case "win32":
          d2.push("dml");
          break;
        case "linux":
          "x64" === process.arch && d2.push("cuda");
      }
      d2.push("cpu"), u2 = ["cpu"];
    } else c2 = o2, s2.apis.IS_WEBNN_AVAILABLE && d2.push("webnn-npu", "webnn-gpu", "webnn-cpu", "webnn"), s2.apis.IS_WEBGPU_AVAILABLE && d2.push("webgpu"), d2.push("wasm"), u2 = ["wasm"];
    const m2 = c2.InferenceSession;
    function h2(e3 = null) {
      if (!e3) return u2;
      switch (e3) {
        case "auto":
          return d2;
        case "gpu":
          return d2.filter(((e4) => ["webgpu", "cuda", "dml", "webnn-gpu"].includes(e4)));
      }
      if (d2.includes(e3)) return [l2[e3] ?? e3];
      throw new Error(`Unsupported device: "${e3}". Should be one of: ${d2.join(", ")}.`);
    }
    let f2 = null;
    async function _2(e3, t3, n3) {
      f2 && await f2;
      const r3 = m2.create(e3, t3);
      f2 ??= r3;
      const s3 = await r3;
      return s3.config = n3, s3;
    }
    let g2 = Promise.resolve();
    const w2 = s2.apis.IS_BROWSER_ENV || s2.apis.IS_WEBWORKER_ENV;
    async function b2(e3, t3) {
      const n3 = () => e3.run(t3);
      return await (w2 ? g2 = g2.then(n3) : n3());
    }
    function y2(e3) {
      return e3 instanceof c2.Tensor;
    }
    const M2 = c2?.env;
    function x2() {
      return M2?.wasm?.proxy;
    }
    M2?.wasm && ("undefined" != typeof ServiceWorkerGlobalScope && self instanceof ServiceWorkerGlobalScope || M2.wasm.wasmPaths || (M2.wasm.wasmPaths = `https://cdn.jsdelivr.net/npm/@huggingface/transformers@${s2.env.version}/dist/`), M2.wasm.proxy = false), M2?.webgpu && (M2.webgpu.powerPreference = "high-performance"), s2.env.backends.onnx = M2;
  }, "./src/base/feature_extraction_utils.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { FeatureExtractor: () => o2, validate_audio_inputs: () => i2 });
    var r2 = n2("./src/utils/constants.js"), s2 = n2("./src/utils/generic.js"), a2 = n2("./src/utils/hub.js");
    class o2 extends s2.Callable {
      constructor(e3) {
        super(), this.config = e3;
      }
      static async from_pretrained(e3, t3 = {}) {
        return new this(await (0, a2.getModelJSON)(e3, r2.FEATURE_EXTRACTOR_NAME, true, t3));
      }
    }
    function i2(e3, t3) {
      if (!(e3 instanceof Float32Array || e3 instanceof Float64Array)) throw new Error(`${t3} expects input to be a Float32Array or a Float64Array, but got ${e3?.constructor?.name ?? typeof e3} instead. If using the feature extractor directly, remember to use \`read_audio(url, sampling_rate)\` to obtain the raw audio data of the file/url.`);
    }
  }, "./src/base/image_processors_utils.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { ImageProcessor: () => b2, center_to_corners_format: () => c2, post_process_instance_segmentation: () => w2, post_process_object_detection: () => p2, post_process_panoptic_segmentation: () => g2, post_process_semantic_segmentation: () => m2 });
    var r2 = n2("./src/utils/generic.js"), s2 = n2("./src/utils/tensor.js"), a2 = n2("./src/utils/maths.js"), o2 = (n2("./src/utils/image.js"), n2("./src/utils/core.js")), i2 = n2("./src/utils/hub.js"), l2 = n2("./src/utils/constants.js");
    function d2(e3, t3, n3 = 0, r3 = null) {
      const s3 = e3 / t3;
      let o3 = (0, a2.bankers_round)(s3) * t3;
      return null !== r3 && o3 > r3 && (o3 = Math.floor(s3) * t3), o3 < n3 && (o3 = Math.ceil(s3) * t3), o3;
    }
    function u2([e3, t3], n3) {
      return [Math.max(Math.floor(e3 / n3), 1) * n3, Math.max(Math.floor(t3 / n3), 1) * n3];
    }
    function c2([e3, t3, n3, r3]) {
      return [e3 - n3 / 2, t3 - r3 / 2, e3 + n3 / 2, t3 + r3 / 2];
    }
    function p2(e3, t3 = 0.5, n3 = null, r3 = false) {
      const s3 = e3.logits, o3 = e3.pred_boxes, [i3, l3, d3] = s3.dims;
      if (null !== n3 && n3.length !== i3) throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");
      let u3 = [];
      for (let e4 = 0; e4 < i3; ++e4) {
        let i4 = null !== n3 ? n3[e4] : null, p3 = { boxes: [], classes: [], scores: [] }, m3 = s3[e4], h3 = o3[e4];
        for (let e5 = 0; e5 < l3; ++e5) {
          let n4, s4 = m3[e5], o4 = [];
          if (r3) {
            n4 = s4.sigmoid().data;
            for (let e6 = 0; e6 < n4.length; ++e6) n4[e6] > t3 && o4.push(e6);
          } else {
            let e6 = (0, a2.max)(s4.data)[1];
            if (e6 === d3 - 1) continue;
            if (n4 = (0, a2.softmax)(s4.data), n4[e6] < t3) continue;
            o4.push(e6);
          }
          for (const t4 of o4) {
            let r4 = h3[e5].data;
            r4 = c2(r4), null !== i4 && (r4 = r4.map(((e6, t5) => e6 * i4[(t5 + 1) % 2]))), p3.boxes.push(r4), p3.classes.push(t4), p3.scores.push(n4[t4]);
          }
        }
        u3.push(p3);
      }
      return u3;
    }
    function m2(e3, t3 = null) {
      const n3 = e3.logits, r3 = n3.dims[0];
      if (null !== t3 && t3.length !== r3) throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");
      const a3 = [];
      for (let e4 = 0; e4 < r3; ++e4) {
        const r4 = null !== t3 ? t3[e4] : null;
        let o3 = n3[e4];
        null !== r4 && (o3 = (0, s2.interpolate)(o3, r4, "bilinear", false));
        const [i3, l3] = r4 ?? o3.dims.slice(-2), d3 = new s2.Tensor("int32", new Int32Array(i3 * l3), [i3, l3]), u3 = o3[0].data, c3 = d3.data;
        for (let e5 = 1; e5 < o3.dims[0]; ++e5) {
          const t4 = o3[e5].data;
          for (let n4 = 0; n4 < t4.length; ++n4) t4[n4] > u3[n4] && (u3[n4] = t4[n4], c3[n4] = e5);
        }
        const p3 = new Array(o3.dims[0]);
        for (let e5 = 0; e5 < c3.length; ++e5) {
          const t4 = c3[e5];
          p3[t4] = t4;
        }
        const m3 = p3.filter(((e5) => void 0 !== e5));
        a3.push({ segmentation: d3, labels: m3 });
      }
      return a3;
    }
    function h2(e3, t3, n3, r3) {
      const s3 = [], o3 = [], i3 = [];
      for (let l3 = 0; l3 < e3.dims[0]; ++l3) {
        const d3 = e3[l3], u3 = t3[l3], c3 = (0, a2.max)(d3.data)[1];
        if (c3 === r3) continue;
        const p3 = (0, a2.softmax)(d3.data)[c3];
        p3 > n3 && (s3.push(u3), o3.push(p3), i3.push(c3));
      }
      return [s3, o3, i3];
    }
    function f2(e3, t3, n3, r3 = 0.5, s3 = 0.8) {
      const a3 = [];
      let o3 = 0, i3 = 0;
      const l3 = t3[n3].data;
      for (let t4 = 0; t4 < e3.length; ++t4) e3[t4] === n3 && (a3.push(t4), ++o3), l3[t4] >= r3 && ++i3;
      let d3 = o3 > 0 && i3 > 0;
      if (d3) {
        d3 = o3 / i3 > s3;
      }
      return [d3, a3];
    }
    function _2(e3, t3, n3, r3, a3, o3 = null, i3 = null) {
      const [l3, d3] = i3 ?? e3[0].dims, u3 = new s2.Tensor("int32", new Int32Array(l3 * d3), [l3, d3]), c3 = [];
      if (null !== i3) for (let t4 = 0; t4 < e3.length; ++t4) e3[t4] = (0, s2.interpolate)(e3[t4], i3, "bilinear", false);
      const p3 = new Int32Array(e3[0].data.length), m3 = new Float32Array(e3[0].data.length);
      for (let n4 = 0; n4 < e3.length; ++n4) {
        let r4 = t3[n4];
        const s3 = e3[n4].data;
        for (let e4 = 0; e4 < s3.length; ++e4) s3[e4] *= r4, s3[e4] > m3[e4] && (p3[e4] = n4, m3[e4] = s3[e4]);
      }
      let h3 = 0;
      const _3 = u3.data;
      for (let s3 = 0; s3 < n3.length; ++s3) {
        const o4 = n3[s3], [i4, l4] = f2(p3, e3, s3, r3, a3);
        if (i4) {
          ++h3;
          for (const e4 of l4) _3[e4] = h3;
          c3.push({ id: h3, label_id: o4, score: t3[s3] });
        }
      }
      return [u3, c3];
    }
    function g2(e3, t3 = 0.5, n3 = 0.5, r3 = 0.8, a3 = null, o3 = null) {
      null === a3 && (console.warn("`label_ids_to_fuse` unset. No instance will be fused."), a3 = /* @__PURE__ */ new Set());
      const i3 = e3.class_queries_logits ?? e3.logits, l3 = (e3.masks_queries_logits ?? e3.pred_masks).sigmoid();
      let [d3, u3, c3] = i3.dims;
      if (c3 -= 1, null !== o3 && o3.length !== d3) throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");
      let p3 = [];
      for (let e4 = 0; e4 < d3; ++e4) {
        let d4 = null !== o3 ? o3[e4] : null, u4 = i3[e4], m3 = l3[e4], [f3, g3, w3] = h2(u4, m3, t3, c3);
        if (0 === w3.length) {
          let [e5, t4] = d4 ?? m3.dims.slice(-2), n4 = new s2.Tensor("int32", new Int32Array(e5 * t4).fill(-1), [e5, t4]);
          p3.push({ segmentation: n4, segments_info: [] });
          continue;
        }
        let [b3, y2] = _2(f3, g3, w3, n3, r3, a3, d4);
        p3.push({ segmentation: b3, segments_info: y2 });
      }
      return p3;
    }
    function w2(e3, t3 = 0.5, n3 = null) {
      throw new Error("`post_process_instance_segmentation` is not yet implemented.");
    }
    class b2 extends r2.Callable {
      constructor(e3) {
        super(), this.image_mean = e3.image_mean ?? e3.mean, this.image_std = e3.image_std ?? e3.std, this.resample = e3.resample ?? 2, this.do_rescale = e3.do_rescale ?? true, this.rescale_factor = e3.rescale_factor ?? 1 / 255, this.do_normalize = e3.do_normalize, this.do_thumbnail = e3.do_thumbnail, this.size = e3.size ?? e3.image_size, this.do_resize = e3.do_resize ?? void 0 !== this.size, this.size_divisibility = e3.size_divisibility ?? e3.size_divisor, this.do_center_crop = e3.do_center_crop, this.crop_size = e3.crop_size, this.do_convert_rgb = e3.do_convert_rgb ?? true, this.do_crop_margin = e3.do_crop_margin, this.pad_size = e3.pad_size, this.do_pad = e3.do_pad, this.min_pixels = e3.min_pixels, this.max_pixels = e3.max_pixels, this.do_pad && !this.pad_size && this.size && void 0 !== this.size.width && void 0 !== this.size.height && (this.pad_size = this.size), this.do_flip_channel_order = e3.do_flip_channel_order ?? false, this.config = e3;
      }
      async thumbnail(e3, t3, n3 = 2) {
        const r3 = e3.height, s3 = e3.width, a3 = t3.height, o3 = t3.width;
        let i3 = Math.min(r3, a3), l3 = Math.min(s3, o3);
        return i3 === r3 && l3 === s3 ? e3 : (r3 > s3 ? l3 = Math.floor(s3 * i3 / r3) : s3 > r3 && (i3 = Math.floor(r3 * l3 / s3)), await e3.resize(l3, i3, { resample: n3 }));
      }
      async crop_margin(e3, t3 = 200) {
        const n3 = e3.clone().grayscale(), r3 = (0, a2.min)(n3.data)[0], s3 = (0, a2.max)(n3.data)[0] - r3;
        if (0 === s3) return e3;
        const o3 = t3 / 255;
        let i3 = n3.width, l3 = n3.height, d3 = 0, u3 = 0;
        const c3 = n3.data;
        for (let e4 = 0; e4 < n3.height; ++e4) {
          const t4 = e4 * n3.width;
          for (let a3 = 0; a3 < n3.width; ++a3) (c3[t4 + a3] - r3) / s3 < o3 && (i3 = Math.min(i3, a3), l3 = Math.min(l3, e4), d3 = Math.max(d3, a3), u3 = Math.max(u3, e4));
        }
        return e3 = await e3.crop([i3, l3, d3, u3]);
      }
      pad_image(e3, t3, n3, { mode: r3 = "constant", center: s3 = false, constant_values: a3 = 0 } = {}) {
        const [i3, l3, d3] = t3;
        let u3, c3;
        if ("number" == typeof n3 ? (u3 = n3, c3 = n3) : "square" === n3 ? u3 = c3 = Math.max(i3, l3) : (u3 = n3.width, c3 = n3.height), u3 !== l3 || c3 !== i3) {
          const n4 = new Float32Array(u3 * c3 * d3);
          if (Array.isArray(a3)) for (let e4 = 0; e4 < n4.length; ++e4) n4[e4] = a3[e4 % d3];
          else 0 !== a3 && n4.fill(a3);
          const [p3, m3] = s3 ? [Math.floor((u3 - l3) / 2), Math.floor((c3 - i3) / 2)] : [0, 0];
          for (let t4 = 0; t4 < i3; ++t4) {
            const r4 = (t4 + m3) * u3, s4 = t4 * l3;
            for (let t5 = 0; t5 < l3; ++t5) {
              const a4 = (r4 + t5 + p3) * d3, o3 = (s4 + t5) * d3;
              for (let t6 = 0; t6 < d3; ++t6) n4[a4 + t6] = e3[o3 + t6];
            }
          }
          if ("symmetric" === r3) {
            if (s3) throw new Error("`center` padding is not supported when `mode` is set to `symmetric`.");
            const t4 = i3 - 1, r4 = l3 - 1;
            for (let s4 = 0; s4 < c3; ++s4) {
              const a4 = s4 * u3, c4 = (0, o2.calculateReflectOffset)(s4, t4) * l3;
              for (let t5 = 0; t5 < u3; ++t5) {
                if (s4 < i3 && t5 < l3) continue;
                const u4 = (a4 + t5) * d3, p4 = (c4 + (0, o2.calculateReflectOffset)(t5, r4)) * d3;
                for (let t6 = 0; t6 < d3; ++t6) n4[u4 + t6] = e3[p4 + t6];
              }
            }
          }
          e3 = n4, t3 = [c3, u3, d3];
        }
        return [e3, t3];
      }
      rescale(e3) {
        for (let t3 = 0; t3 < e3.length; ++t3) e3[t3] = this.rescale_factor * e3[t3];
      }
      get_resize_output_image_size(e3, t3) {
        const [n3, r3] = e3.size;
        let s3, a3;
        if (this.do_thumbnail) {
          const { height: e4, width: n4 } = t3;
          s3 = Math.min(e4, n4);
        } else Number.isInteger(t3) ? (s3 = t3, a3 = this.config.max_size ?? s3) : void 0 !== t3 && (s3 = t3.shortest_edge, a3 = t3.longest_edge);
        if (void 0 !== s3 || void 0 !== a3) {
          const e4 = void 0 === s3 ? 1 : Math.max(s3 / n3, s3 / r3), t4 = n3 * e4, o3 = r3 * e4, i3 = void 0 === a3 ? 1 : Math.min(a3 / t4, a3 / o3);
          let l3 = Math.floor(Number((t4 * i3).toFixed(2))), d3 = Math.floor(Number((o3 * i3).toFixed(2)));
          return void 0 !== this.size_divisibility && ([l3, d3] = u2([l3, d3], this.size_divisibility)), [l3, d3];
        }
        if (void 0 !== t3 && void 0 !== t3.width && void 0 !== t3.height) {
          let e4 = t3.width, s4 = t3.height;
          if (this.config.keep_aspect_ratio && this.config.ensure_multiple_of) {
            let t4 = s4 / r3, a4 = e4 / n3;
            Math.abs(1 - a4) < Math.abs(1 - t4) ? t4 = a4 : a4 = t4, s4 = d2(t4 * r3, this.config.ensure_multiple_of), e4 = d2(a4 * n3, this.config.ensure_multiple_of);
          }
          return [e4, s4];
        }
        if (void 0 !== this.size_divisibility) return u2([n3, r3], this.size_divisibility);
        if (void 0 !== this.min_pixels && void 0 !== this.max_pixels) {
          return (function(e4, t4, n4 = 28, r4 = 3136, s4 = 1003520) {
            if (e4 < n4 || t4 < n4) throw new Error(`height:${e4} or width:${t4} must be larger than factor:${n4}`);
            if (Math.max(e4, t4) / Math.min(e4, t4) > 200) throw new Error("absolute aspect ratio must be smaller than 200, got " + Math.max(e4, t4) / Math.min(e4, t4));
            let a4 = Math.round(e4 / n4) * n4, o3 = Math.round(t4 / n4) * n4;
            if (a4 * o3 > s4) {
              const r5 = Math.sqrt(e4 * t4 / s4);
              a4 = Math.floor(e4 / r5 / n4) * n4, o3 = Math.floor(t4 / r5 / n4) * n4;
            } else if (a4 * o3 < r4) {
              const s5 = Math.sqrt(r4 / (e4 * t4));
              a4 = Math.ceil(e4 * s5 / n4) * n4, o3 = Math.ceil(t4 * s5 / n4) * n4;
            }
            return [a4, o3];
          })(r3, n3, this.config.patch_size * this.config.merge_size, this.min_pixels, this.max_pixels);
        }
        throw new Error(`Could not resize image due to unsupported \`this.size\` option in config: ${JSON.stringify(t3)}`);
      }
      async resize(e3) {
        const [t3, n3] = this.get_resize_output_image_size(e3, this.size);
        return await e3.resize(t3, n3, { resample: this.resample });
      }
      async preprocess(e3, { do_normalize: t3 = null, do_pad: n3 = null, do_convert_rgb: r3 = null, do_convert_grayscale: a3 = null, do_flip_channel_order: o3 = null } = {}) {
        this.do_crop_margin && (e3 = await this.crop_margin(e3));
        const [i3, l3] = e3.size;
        if (r3 ?? this.do_convert_rgb ? e3 = e3.rgb() : a3 && (e3 = e3.grayscale()), this.do_resize && (e3 = await this.resize(e3)), this.do_thumbnail && (e3 = await this.thumbnail(e3, this.size, this.resample)), this.do_center_crop) {
          let t4, n4;
          Number.isInteger(this.crop_size) ? (t4 = this.crop_size, n4 = this.crop_size) : (t4 = this.crop_size.width, n4 = this.crop_size.height), e3 = await e3.center_crop(t4, n4);
        }
        const d3 = [e3.height, e3.width];
        let c3 = Float32Array.from(e3.data), p3 = [e3.height, e3.width, e3.channels];
        if (this.do_rescale && this.rescale(c3), t3 ?? this.do_normalize) {
          let t4 = this.image_mean;
          Array.isArray(this.image_mean) || (t4 = new Array(e3.channels).fill(t4));
          let n4 = this.image_std;
          if (Array.isArray(this.image_std) || (n4 = new Array(e3.channels).fill(n4)), t4.length !== e3.channels || n4.length !== e3.channels) throw new Error(`When set to arrays, the length of \`image_mean\` (${t4.length}) and \`image_std\` (${n4.length}) must match the number of channels in the image (${e3.channels}).`);
          for (let r4 = 0; r4 < c3.length; r4 += e3.channels) for (let s3 = 0; s3 < e3.channels; ++s3) c3[r4 + s3] = (c3[r4 + s3] - t4[s3]) / n4[s3];
        }
        if (n3 ?? this.do_pad) {
          if (this.pad_size) {
            const t4 = this.pad_image(c3, [e3.height, e3.width, e3.channels], this.pad_size);
            [c3, p3] = t4;
          } else if (this.size_divisibility) {
            const [e4, t4] = u2([p3[1], p3[0]], this.size_divisibility);
            [c3, p3] = this.pad_image(c3, p3, { width: e4, height: t4 });
          }
        }
        if (o3 ?? this.do_flip_channel_order) {
          if (3 !== p3[2]) throw new Error("Flipping channel order is only supported for RGB images.");
          for (let e4 = 0; e4 < c3.length; e4 += 3) {
            const t4 = c3[e4];
            c3[e4] = c3[e4 + 2], c3[e4 + 2] = t4;
          }
        }
        return { original_size: [l3, i3], reshaped_input_size: d3, pixel_values: new s2.Tensor("float32", c3, p3).permute(2, 0, 1) };
      }
      async _call(e3, ...t3) {
        Array.isArray(e3) || (e3 = [e3]);
        const n3 = await Promise.all(e3.map(((e4) => this.preprocess(e4))));
        return { pixel_values: (0, s2.stack)(n3.map(((e4) => e4.pixel_values)), 0), original_sizes: n3.map(((e4) => e4.original_size)), reshaped_input_sizes: n3.map(((e4) => e4.reshaped_input_size)) };
      }
      static async from_pretrained(e3, t3 = {}) {
        return new this(await (0, i2.getModelJSON)(e3, l2.IMAGE_PROCESSOR_NAME, true, t3));
      }
    }
  }, "./src/base/processing_utils.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Processor: () => o2 });
    var r2 = n2("./src/utils/constants.js"), s2 = n2("./src/utils/generic.js"), a2 = n2("./src/utils/hub.js");
    class o2 extends s2.Callable {
      static classes = ["image_processor_class", "tokenizer_class", "feature_extractor_class"];
      static uses_processor_config = false;
      static uses_chat_template_file = false;
      constructor(e3, t3, n3) {
        super(), this.config = e3, this.components = t3, this.chat_template = n3;
      }
      get image_processor() {
        return this.components.image_processor;
      }
      get tokenizer() {
        return this.components.tokenizer;
      }
      get feature_extractor() {
        return this.components.feature_extractor;
      }
      apply_chat_template(e3, t3 = {}) {
        if (!this.tokenizer) throw new Error("Unable to apply chat template without a tokenizer.");
        return this.tokenizer.apply_chat_template(e3, { tokenize: false, chat_template: this.chat_template ?? void 0, ...t3 });
      }
      batch_decode(...e3) {
        if (!this.tokenizer) throw new Error("Unable to decode without a tokenizer.");
        return this.tokenizer.batch_decode(...e3);
      }
      decode(...e3) {
        if (!this.tokenizer) throw new Error("Unable to decode without a tokenizer.");
        return this.tokenizer.decode(...e3);
      }
      async _call(e3, ...t3) {
        for (const n3 of [this.image_processor, this.feature_extractor, this.tokenizer]) if (n3) return n3(e3, ...t3);
        throw new Error("No image processor, feature extractor, or tokenizer found.");
      }
      static async from_pretrained(e3, t3 = {}) {
        const [n3, s3, o3] = await Promise.all([this.uses_processor_config ? (0, a2.getModelJSON)(e3, r2.PROCESSOR_NAME, true, t3) : {}, Promise.all(this.classes.filter(((e4) => e4 in this)).map((async (n4) => {
          const r3 = await this[n4].from_pretrained(e3, t3);
          return [n4.replace(/_class$/, ""), r3];
        }))).then(Object.fromEntries), this.uses_chat_template_file ? (0, a2.getModelText)(e3, r2.CHAT_TEMPLATE_NAME, true, t3) : null]);
        return new this(n3, s3, o3);
      }
    }
  }, "./src/configs.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { AutoConfig: () => l2, PretrainedConfig: () => i2, getCacheShapes: () => o2 });
    var r2 = n2("./src/utils/core.js"), s2 = n2("./src/utils/hub.js");
    function a2(e3) {
      const t3 = {};
      let n3 = {};
      switch (e3.model_type) {
        case "llava":
        case "paligemma":
        case "gemma3":
        case "florence2":
        case "llava_onevision":
        case "idefics3":
        case "ultravox":
        case "voxtral":
        case "smolvlm":
        case "gemma3n":
          n3 = a2(e3.text_config);
          break;
        case "moondream1":
          n3 = a2(e3.phi_config);
          break;
        case "musicgen":
          n3 = a2(e3.decoder);
          break;
        case "multi_modality":
          n3 = a2(e3.language_config);
          break;
        case "gpt2":
        case "gptj":
        case "jais":
        case "codegen":
        case "gpt_bigcode":
          t3.num_heads = "n_head", t3.num_layers = "n_layer", t3.hidden_size = "n_embd";
          break;
        case "gpt_neox":
        case "stablelm":
        case "opt":
        case "falcon":
        case "modernbert-decoder":
          t3.num_heads = "num_attention_heads", t3.num_layers = "num_hidden_layers", t3.hidden_size = "hidden_size";
          break;
        case "llama":
        case "llama4_text":
        case "nanochat":
        case "arcee":
        case "lfm2":
        case "smollm3":
        case "olmo":
        case "olmo2":
        case "mobilellm":
        case "granite":
        case "granitemoehybrid":
        case "cohere":
        case "mistral":
        case "starcoder2":
        case "qwen2":
        case "qwen2_vl":
        case "phi":
        case "phi3":
        case "phi3_v":
        case "llava_qwen2":
          t3.num_heads = "num_key_value_heads", t3.num_layers = "num_hidden_layers", t3.hidden_size = "hidden_size", t3.num_attention_heads = "num_attention_heads", t3.dim_kv = "head_dim";
          break;
        case "qwen3":
        case "gemma":
        case "gemma2":
        case "vaultgemma":
        case "gemma3_text":
        case "gemma3n_text":
        case "glm":
        case "helium":
        case "ernie4_5":
          t3.num_heads = "num_key_value_heads", t3.num_layers = "num_hidden_layers", t3.dim_kv = "head_dim";
          break;
        case "openelm":
          t3.num_heads = "num_kv_heads", t3.num_layers = "num_transformer_layers", t3.dim_kv = "head_dim";
          break;
        case "gpt_neo":
        case "donut-swin":
          t3.num_heads = "num_heads", t3.num_layers = "num_layers", t3.hidden_size = "hidden_size";
          break;
        case "bloom":
          t3.num_heads = "n_head", t3.num_layers = "n_layer", t3.hidden_size = "hidden_size";
          break;
        case "mpt":
          t3.num_heads = "n_heads", t3.num_layers = "n_layers", t3.hidden_size = "d_model";
          break;
        case "exaone":
          t3.num_heads = "num_key_value_heads", t3.num_layers = "num_layers", t3.dim_kv = "head_dim", t3.num_attention_heads = "num_attention_heads";
          break;
        case "t5":
        case "mt5":
        case "longt5":
          t3.num_decoder_layers = "num_decoder_layers", t3.num_decoder_heads = "num_heads", t3.decoder_dim_kv = "d_kv", t3.num_encoder_layers = "num_layers", t3.num_encoder_heads = "num_heads", t3.encoder_dim_kv = "d_kv";
          break;
        case "bart":
        case "mbart":
        case "marian":
        case "whisper":
        case "lite-whisper":
        case "m2m_100":
        case "blenderbot":
        case "blenderbot-small":
        case "florence2_language":
          t3.num_decoder_layers = "decoder_layers", t3.num_decoder_heads = "decoder_attention_heads", t3.decoder_hidden_size = "d_model", t3.num_encoder_layers = "encoder_layers", t3.num_encoder_heads = "encoder_attention_heads", t3.encoder_hidden_size = "d_model";
          break;
        case "speecht5":
          t3.num_decoder_layers = "decoder_layers", t3.num_decoder_heads = "decoder_attention_heads", t3.decoder_hidden_size = "hidden_size", t3.num_encoder_layers = "encoder_layers", t3.num_encoder_heads = "encoder_attention_heads", t3.encoder_hidden_size = "hidden_size";
          break;
        case "trocr":
          t3.num_encoder_layers = t3.num_decoder_layers = "decoder_layers", t3.num_encoder_heads = t3.num_decoder_heads = "decoder_attention_heads", t3.encoder_hidden_size = t3.decoder_hidden_size = "d_model";
          break;
        case "musicgen_decoder":
          t3.num_encoder_layers = t3.num_decoder_layers = "num_hidden_layers", t3.num_encoder_heads = t3.num_decoder_heads = "num_attention_heads", t3.encoder_hidden_size = t3.decoder_hidden_size = "hidden_size";
          break;
        case "moonshine":
          t3.num_decoder_layers = "decoder_num_hidden_layers", t3.num_decoder_heads = "decoder_num_key_value_heads", t3.num_encoder_layers = "encoder_num_hidden_layers", t3.num_encoder_heads = "encoder_num_key_value_heads", t3.encoder_hidden_size = t3.decoder_hidden_size = "hidden_size";
          break;
        case "vision-encoder-decoder":
          const s4 = a2(e3.decoder), o3 = "num_decoder_layers" in s4, i3 = (0, r2.pick)(e3, ["model_type", "is_encoder_decoder"]);
          return o3 ? (i3.num_decoder_layers = s4.num_decoder_layers, i3.num_decoder_heads = s4.num_decoder_heads, i3.decoder_hidden_size = s4.decoder_hidden_size, i3.num_encoder_layers = s4.num_encoder_layers, i3.num_encoder_heads = s4.num_encoder_heads, i3.encoder_hidden_size = s4.encoder_hidden_size) : (i3.num_layers = s4.num_layers, i3.num_heads = s4.num_heads, i3.hidden_size = s4.hidden_size), i3;
      }
      const s3 = { ...n3, ...(0, r2.pick)(e3, ["model_type", "multi_query", "is_encoder_decoder"]) };
      for (const n4 in t3) s3[n4] = e3[t3[n4]];
      return s3;
    }
    function o2(e3, t3) {
      if ("lfm2" === e3.model_type) {
        const n3 = t3?.prefix ?? "past_key_values", r3 = "present" === n3 ? "present" : "past", s3 = {}, { layer_types: a3, num_attention_heads: o3, num_key_value_heads: i3, hidden_size: l3, conv_L_cache: d2 } = e3, u2 = l3 / o3, c2 = t3?.batch_size ?? 1;
        for (let e4 = 0; e4 < a3.length; ++e4) if ("full_attention" === a3[e4]) for (const t4 of ["key", "value"]) s3[`${n3}.${e4}.${t4}`] = [c2, i3, 0, u2];
        else {
          if ("conv" !== a3[e4]) throw new Error(`Unsupported layer type: ${a3[e4]}`);
          s3[`${r3}_conv.${e4}`] = [c2, l3, d2];
        }
        return s3;
      }
      return (function(e4, { prefix: t4 = "past_key_values", batch_size: n3 = 1 } = {}) {
        const r3 = {}, s3 = e4.normalized_config;
        if (s3.is_encoder_decoder && "num_encoder_heads" in s3 && "num_decoder_heads" in s3) {
          const e5 = s3.encoder_dim_kv ?? s3.encoder_hidden_size / s3.num_encoder_heads, a3 = s3.decoder_dim_kv ?? s3.decoder_hidden_size / s3.num_decoder_heads, o3 = [n3, s3.num_encoder_heads, 0, e5], i3 = [n3, s3.num_decoder_heads, 0, a3];
          for (let e6 = 0; e6 < s3.num_decoder_layers; ++e6) r3[`${t4}.${e6}.encoder.key`] = o3, r3[`${t4}.${e6}.encoder.value`] = o3, r3[`${t4}.${e6}.decoder.key`] = i3, r3[`${t4}.${e6}.decoder.value`] = i3;
        } else {
          const e5 = s3.num_heads, a3 = s3.num_layers, o3 = s3.dim_kv ?? s3.hidden_size / (s3.num_attention_heads ?? e5);
          if ("falcon" === s3.model_type) {
            const s4 = [n3 * e5, 0, o3];
            for (let e6 = 0; e6 < a3; ++e6) r3[`${t4}.${e6}.key`] = s4, r3[`${t4}.${e6}.value`] = s4;
          } else if (s3.multi_query) {
            const s4 = [n3 * e5, 0, 2 * o3];
            for (let e6 = 0; e6 < a3; ++e6) r3[`${t4}.${e6}.key_value`] = s4;
          } else if ("bloom" === s3.model_type) {
            const s4 = [n3 * e5, o3, 0], i3 = [n3 * e5, 0, o3];
            for (let e6 = 0; e6 < a3; ++e6) r3[`${t4}.${e6}.key`] = s4, r3[`${t4}.${e6}.value`] = i3;
          } else if ("openelm" === s3.model_type) for (let s4 = 0; s4 < a3; ++s4) {
            const a4 = [n3, e5[s4], 0, o3];
            r3[`${t4}.${s4}.key`] = a4, r3[`${t4}.${s4}.value`] = a4;
          }
          else {
            const s4 = [n3, e5, 0, o3];
            for (let e6 = 0; e6 < a3; ++e6) r3[`${t4}.${e6}.key`] = s4, r3[`${t4}.${e6}.value`] = s4;
          }
        }
        return r3;
      })(e3, t3);
    }
    class i2 {
      model_type = null;
      is_encoder_decoder = false;
      max_position_embeddings;
      "transformers.js_config";
      constructor(e3) {
        Object.assign(this, e3), this.normalized_config = a2(this);
      }
      static async from_pretrained(e3, { progress_callback: t3 = null, config: n3 = null, cache_dir: r3 = null, local_files_only: a3 = false, revision: o3 = "main" } = {}) {
        !n3 || n3 instanceof i2 || (n3 = new i2(n3));
        const l3 = n3 ?? await (async function(e4, t4) {
          return await (0, s2.getModelJSON)(e4, "config.json", true, t4);
        })(e3, { progress_callback: t3, config: n3, cache_dir: r3, local_files_only: a3, revision: o3 });
        return new this(l3);
      }
    }
    class l2 {
      static async from_pretrained(...e3) {
        return i2.from_pretrained(...e3);
      }
    }
  }, "./src/env.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { apis: () => _2, env: () => M2 });
    var r2 = n2("?db59"), s2 = n2("?383f"), a2 = n2("?fa4b");
    const o2 = "undefined" != typeof window && void 0 !== window.document, i2 = "undefined" != typeof self && ["DedicatedWorkerGlobalScope", "ServiceWorkerGlobalScope", "SharedWorkerGlobalScope"].includes(self.constructor?.name), l2 = "undefined" != typeof self && "caches" in self, d2 = "undefined" != typeof navigator && "gpu" in navigator, u2 = "undefined" != typeof navigator && "ml" in navigator, c2 = "undefined" != typeof process, p2 = c2 && "node" === process?.release?.name, m2 = !x2(r2), h2 = !x2(s2), f2 = void 0 !== globalThis.Deno, _2 = (globalThis.Bun, Object.freeze({ IS_BROWSER_ENV: o2, IS_WEBWORKER_ENV: i2, IS_WEB_CACHE_AVAILABLE: l2, IS_WEBGPU_AVAILABLE: d2, IS_WEBNN_AVAILABLE: u2, IS_PROCESS_AVAILABLE: c2, IS_NODE_ENV: p2, IS_FS_AVAILABLE: m2, IS_PATH_AVAILABLE: h2 })), g2 = m2 && h2;
    let w2 = "./";
    if (g2) {
      const e3 = Object(import_meta).url;
      e3 ? w2 = s2.dirname(s2.dirname(a2.fileURLToPath(e3))) : "undefined" != typeof __dirname && (w2 = s2.dirname(__dirname));
    }
    const b2 = g2 ? s2.join(w2, "/.cache/") : null, y2 = "/models/", M2 = { version: "3.8.0", backends: { onnx: {} }, allowRemoteModels: true, remoteHost: "https://huggingface.co/", remotePathTemplate: "{model}/resolve/{revision}/", allowLocalModels: !(o2 || i2), localModelPath: g2 ? s2.join(w2, y2) : y2, useFS: m2, useBrowserCache: l2 && !f2, useFSCache: m2, cacheDir: b2, useCustomCache: false, customCache: null };
    function x2(e3) {
      return 0 === Object.keys(e3).length;
    }
  }, "./src/generation/configuration_utils.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { GenerationConfig: () => s2 });
    var r2 = n2("./src/utils/core.js");
    class s2 {
      max_length = 20;
      max_new_tokens = null;
      min_length = 0;
      min_new_tokens = null;
      early_stopping = false;
      max_time = null;
      do_sample = false;
      num_beams = 1;
      num_beam_groups = 1;
      penalty_alpha = null;
      use_cache = true;
      temperature = 1;
      top_k = 50;
      top_p = 1;
      typical_p = 1;
      epsilon_cutoff = 0;
      eta_cutoff = 0;
      diversity_penalty = 0;
      repetition_penalty = 1;
      encoder_repetition_penalty = 1;
      length_penalty = 1;
      no_repeat_ngram_size = 0;
      bad_words_ids = null;
      force_words_ids = null;
      renormalize_logits = false;
      constraints = null;
      forced_bos_token_id = null;
      forced_eos_token_id = null;
      remove_invalid_values = false;
      exponential_decay_length_penalty = null;
      suppress_tokens = null;
      streamer = null;
      begin_suppress_tokens = null;
      forced_decoder_ids = null;
      guidance_scale = null;
      num_return_sequences = 1;
      output_attentions = false;
      output_hidden_states = false;
      output_scores = false;
      return_dict_in_generate = false;
      pad_token_id = null;
      bos_token_id = null;
      eos_token_id = null;
      encoder_no_repeat_ngram_size = 0;
      decoder_start_token_id = null;
      generation_kwargs = {};
      constructor(e3) {
        Object.assign(this, (0, r2.pick)(e3, Object.getOwnPropertyNames(this)));
      }
    }
  }, "./src/generation/logits_process.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { ClassifierFreeGuidanceLogitsProcessor: () => g2, ForcedBOSTokenLogitsProcessor: () => l2, ForcedEOSTokenLogitsProcessor: () => d2, LogitsProcessor: () => a2, LogitsProcessorList: () => i2, LogitsWarper: () => o2, MinLengthLogitsProcessor: () => h2, MinNewTokensLengthLogitsProcessor: () => f2, NoBadWordsLogitsProcessor: () => _2, NoRepeatNGramLogitsProcessor: () => p2, RepetitionPenaltyLogitsProcessor: () => m2, SuppressTokensAtBeginLogitsProcessor: () => u2, TemperatureLogitsWarper: () => w2, TopKLogitsWarper: () => y2, TopPLogitsWarper: () => b2, WhisperTimeStampLogitsProcessor: () => c2 });
    var r2 = n2("./src/utils/generic.js"), s2 = (n2("./src/utils/tensor.js"), n2("./src/utils/maths.js"));
    class a2 extends r2.Callable {
      _call(e3, t3) {
        throw Error("`_call` should be implemented in a subclass");
      }
    }
    class o2 extends r2.Callable {
      _call(e3, t3) {
        throw Error("`_call` should be implemented in a subclass");
      }
    }
    class i2 extends r2.Callable {
      constructor() {
        super(), this.processors = [];
      }
      push(e3) {
        this.processors.push(e3);
      }
      extend(e3) {
        this.processors.push(...e3);
      }
      _call(e3, t3) {
        let n3 = t3;
        for (const t4 of this.processors) n3 = t4(e3, n3);
        return n3;
      }
      [Symbol.iterator]() {
        return this.processors.values();
      }
    }
    class l2 extends a2 {
      constructor(e3) {
        super(), this.bos_token_id = e3;
      }
      _call(e3, t3) {
        for (let n3 = 0; n3 < e3.length; ++n3) if (1 === e3[n3].length) {
          const e4 = t3[n3].data;
          e4.fill(-1 / 0), e4[this.bos_token_id] = 0;
        }
        return t3;
      }
    }
    class d2 extends a2 {
      constructor(e3, t3) {
        super(), this.max_length = e3, this.eos_token_id = Array.isArray(t3) ? t3 : [t3];
      }
      _call(e3, t3) {
        for (let n3 = 0; n3 < e3.length; ++n3) if (e3[n3].length === this.max_length - 1) {
          const e4 = t3[n3].data;
          e4.fill(-1 / 0);
          for (const t4 of this.eos_token_id) e4[t4] = 0;
        }
        return t3;
      }
    }
    class u2 extends a2 {
      constructor(e3, t3) {
        super(), this.begin_suppress_tokens = e3, this.begin_index = t3;
      }
      _call(e3, t3) {
        for (let n3 = 0; n3 < e3.length; ++n3) if (e3[n3].length === this.begin_index) {
          const e4 = t3[n3].data;
          for (const t4 of this.begin_suppress_tokens) e4[t4] = -1 / 0;
        }
        return t3;
      }
    }
    class c2 extends a2 {
      constructor(e3, t3) {
        super(), this.eos_token_id = Array.isArray(e3.eos_token_id) ? e3.eos_token_id[0] : e3.eos_token_id, this.no_timestamps_token_id = e3.no_timestamps_token_id, this.timestamp_begin = this.no_timestamps_token_id + 1, this.begin_index = t3.length, t3.at(-1) === this.no_timestamps_token_id && (this.begin_index -= 1), this.max_initial_timestamp_index = e3.max_initial_timestamp_index;
      }
      _call(e3, t3) {
        for (let n3 = 0; n3 < e3.length; ++n3) {
          const r3 = t3[n3].data;
          if (r3[this.no_timestamps_token_id] = -1 / 0, e3[n3].length === this.begin_index - 1) {
            r3.fill(-1 / 0), r3[this.timestamp_begin] = 0;
            continue;
          }
          const a3 = e3[n3].slice(this.begin_index), o3 = a3.length >= 1 && a3[a3.length - 1] >= this.timestamp_begin, i3 = a3.length < 2 || a3[a3.length - 2] >= this.timestamp_begin;
          if (o3 && (i3 ? r3.subarray(this.timestamp_begin).fill(-1 / 0) : r3.subarray(0, this.eos_token_id).fill(-1 / 0)), e3[n3].length === this.begin_index && null !== this.max_initial_timestamp_index) {
            const e4 = this.timestamp_begin + this.max_initial_timestamp_index;
            r3.subarray(e4 + 1).fill(-1 / 0);
          }
          const l3 = (0, s2.log_softmax)(r3);
          Math.log(l3.subarray(this.timestamp_begin).map(Math.exp).reduce(((e4, t4) => e4 + t4))) > (0, s2.max)(l3.subarray(0, this.timestamp_begin))[0] && r3.subarray(0, this.timestamp_begin).fill(-1 / 0);
        }
        return t3;
      }
    }
    class p2 extends a2 {
      constructor(e3) {
        super(), this.no_repeat_ngram_size = e3;
      }
      getNgrams(e3) {
        const t3 = e3.length, n3 = [];
        for (let r4 = 0; r4 < t3 + 1 - this.no_repeat_ngram_size; ++r4) {
          const t4 = [];
          for (let n4 = 0; n4 < this.no_repeat_ngram_size; ++n4) t4.push(e3[r4 + n4]);
          n3.push(t4.map(Number));
        }
        const r3 = /* @__PURE__ */ new Map();
        for (const e4 of n3) {
          const t4 = e4.slice(0, e4.length - 1), n4 = JSON.stringify(t4), s3 = r3.get(n4) ?? [];
          s3.push(e4[e4.length - 1]), r3.set(n4, s3);
        }
        return r3;
      }
      getGeneratedNgrams(e3, t3) {
        const n3 = t3.slice(t3.length + 1 - this.no_repeat_ngram_size, t3.length);
        return e3.get(JSON.stringify(n3.map(Number))) ?? [];
      }
      calcBannedNgramTokens(e3) {
        const t3 = [];
        if (e3.length + 1 < this.no_repeat_ngram_size) return t3;
        {
          const t4 = this.getNgrams(e3);
          return this.getGeneratedNgrams(t4, e3);
        }
      }
      _call(e3, t3) {
        for (let n3 = 0; n3 < e3.length; ++n3) {
          const r3 = t3[n3].data, s3 = this.calcBannedNgramTokens(e3[n3]);
          for (const e4 of s3) r3[e4] = -1 / 0;
        }
        return t3;
      }
    }
    class m2 extends a2 {
      constructor(e3) {
        super(), this.penalty = e3;
      }
      _call(e3, t3) {
        for (let n3 = 0; n3 < e3.length; ++n3) {
          const r3 = t3[n3].data;
          for (const t4 of new Set(e3[n3])) {
            const e4 = Number(t4);
            r3[e4] < 0 ? r3[e4] *= this.penalty : r3[e4] /= this.penalty;
          }
        }
        return t3;
      }
    }
    class h2 extends a2 {
      constructor(e3, t3) {
        super(), this.min_length = e3, this.eos_token_id = Array.isArray(t3) ? t3 : [t3];
      }
      _call(e3, t3) {
        for (let n3 = 0; n3 < e3.length; ++n3) if (e3[n3].length < this.min_length) {
          const e4 = t3[n3].data;
          for (const t4 of this.eos_token_id) e4[t4] = -1 / 0;
        }
        return t3;
      }
    }
    class f2 extends a2 {
      constructor(e3, t3, n3) {
        super(), this.prompt_length_to_skip = e3, this.min_new_tokens = t3, this.eos_token_id = Array.isArray(n3) ? n3 : [n3];
      }
      _call(e3, t3) {
        for (let n3 = 0; n3 < e3.length; ++n3) {
          if (e3[n3].length - this.prompt_length_to_skip < this.min_new_tokens) {
            const e4 = t3[n3].data;
            for (const t4 of this.eos_token_id) e4[t4] = -1 / 0;
          }
        }
        return t3;
      }
    }
    class _2 extends a2 {
      constructor(e3, t3) {
        super(), this.bad_words_ids = e3, this.eos_token_id = Array.isArray(t3) ? t3 : [t3];
      }
      _call(e3, t3) {
        for (let n3 = 0; n3 < e3.length; ++n3) {
          const r3 = t3[n3].data, s3 = e3[n3];
          for (const e4 of this.bad_words_ids) {
            if (s3.length < e4.length - 1) continue;
            let t4 = true;
            for (let n4 = 1; n4 <= e4.length - 1; ++n4) if (e4.at(-n4 - 1) != s3.at(-n4)) {
              t4 = false;
              break;
            }
            t4 && (r3[e4.at(-1)] = -1 / 0);
          }
        }
        return t3;
      }
    }
    class g2 extends a2 {
      constructor(e3) {
        if (super(), e3 <= 1) throw new Error(`Require guidance scale >1 to use the classifier free guidance processor, got guidance scale ${e3}.`);
        this.guidance_scale = e3;
      }
      _call(e3, t3) {
        if (t3.dims[0] !== 2 * e3.length) throw new Error(`Logits should have twice the batch size of the input ids, the first half of batches corresponding to the conditional inputs, and the second half of batches corresponding to the unconditional inputs. Got batch size ${t3.dims[0]} for the logits and ${e3.length} for the input ids.`);
        const n3 = e3.length, r3 = t3.slice([0, n3], null), s3 = t3.slice([n3, t3.dims[0]], null);
        for (let e4 = 0; e4 < s3.data.length; ++e4) s3.data[e4] += (r3.data[e4] - s3.data[e4]) * this.guidance_scale;
        return s3;
      }
    }
    class w2 extends o2 {
      constructor(e3) {
        if (super(), "number" != typeof e3 || e3 <= 0) {
          let t3 = `\`temperature\` (=${e3}) must be a strictly positive float, otherwise your next token scores will be invalid.`;
          0 === e3 && (t3 += " If you're looking for greedy decoding strategies, set `do_sample=false`.");
        }
        this.temperature = e3;
      }
      _call(e3, t3) {
        const n3 = t3.data;
        for (let e4 = 0; e4 < n3.length; ++e4) n3[e4] /= this.temperature;
        return t3;
      }
    }
    class b2 extends o2 {
      constructor(e3, { filter_value: t3 = -1 / 0, min_tokens_to_keep: n3 = 1 } = {}) {
        if (super(), e3 < 0 || e3 > 1) throw new Error(`\`top_p\` must be a float > 0 and < 1, but is ${e3}`);
        if (!Number.isInteger(n3) || n3 < 1) throw new Error(`\`min_tokens_to_keep\` must be a positive integer, but is ${n3}`);
        this.top_p = e3, this.filter_value = t3, this.min_tokens_to_keep = n3;
      }
    }
    class y2 extends o2 {
      constructor(e3, { filter_value: t3 = -1 / 0, min_tokens_to_keep: n3 = 1 } = {}) {
        if (super(), !Number.isInteger(e3) || e3 < 0) throw new Error(`\`top_k\` must be a positive integer, but is ${e3}`);
        this.top_k = Math.max(e3, n3), this.filter_value = t3;
      }
    }
  }, "./src/generation/logits_sampler.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { LogitsSampler: () => o2 });
    var r2 = n2("./src/utils/generic.js"), s2 = n2("./src/utils/tensor.js"), a2 = n2("./src/utils/maths.js");
    n2("./src/generation/configuration_utils.js");
    class o2 extends r2.Callable {
      constructor(e3) {
        super(), this.generation_config = e3;
      }
      async _call(e3) {
        return this.sample(e3);
      }
      async sample(e3) {
        throw Error("sample should be implemented in subclasses.");
      }
      getLogits(e3, t3) {
        let n3 = e3.dims.at(-1), r3 = e3.data;
        if (-1 === t3) r3 = r3.slice(-n3);
        else {
          let e4 = t3 * n3;
          r3 = r3.slice(e4, e4 + n3);
        }
        return r3;
      }
      randomSelect(e3) {
        let t3 = 0;
        for (let n4 = 0; n4 < e3.length; ++n4) t3 += e3[n4];
        let n3 = Math.random() * t3;
        for (let t4 = 0; t4 < e3.length; ++t4) if (n3 -= e3[t4], n3 <= 0) return t4;
        return 0;
      }
      static getSampler(e3) {
        if (e3.do_sample) return new l2(e3);
        if (e3.num_beams > 1) return new d2(e3);
        if (e3.num_return_sequences > 1) throw Error(`num_return_sequences has to be 1 when doing greedy search, but is ${e3.num_return_sequences}.`);
        return new i2(e3);
      }
    }
    class i2 extends o2 {
      async sample(e3) {
        const t3 = (0, a2.max)(e3.data)[1];
        return [[BigInt(t3), 0]];
      }
    }
    class l2 extends o2 {
      async sample(e3) {
        let t3 = e3.dims.at(-1);
        this.generation_config.top_k > 0 && (t3 = Math.min(this.generation_config.top_k, t3));
        const [n3, r3] = await (0, s2.topk)(e3, t3), o3 = (0, a2.softmax)(n3.data);
        return Array.from({ length: this.generation_config.num_beams }, (() => {
          const e4 = this.randomSelect(o3);
          return [r3.data[e4], Math.log(o3[e4])];
        }));
      }
    }
    class d2 extends o2 {
      async sample(e3) {
        let t3 = e3.dims.at(-1);
        this.generation_config.top_k > 0 && (t3 = Math.min(this.generation_config.top_k, t3));
        const [n3, r3] = await (0, s2.topk)(e3, t3), o3 = (0, a2.softmax)(n3.data);
        return Array.from({ length: this.generation_config.num_beams }, ((e4, t4) => [r3.data[t4], Math.log(o3[t4])]));
      }
    }
  }, "./src/generation/stopping_criteria.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { EosTokenCriteria: () => i2, InterruptableStoppingCriteria: () => l2, MaxLengthCriteria: () => o2, StoppingCriteria: () => s2, StoppingCriteriaList: () => a2 });
    var r2 = n2("./src/utils/generic.js");
    class s2 extends r2.Callable {
      _call(e3, t3) {
        throw Error("StoppingCriteria needs to be subclassed");
      }
    }
    class a2 extends r2.Callable {
      constructor() {
        super(), this.criteria = [];
      }
      push(e3) {
        this.criteria.push(e3);
      }
      extend(e3) {
        e3 instanceof a2 ? e3 = e3.criteria : e3 instanceof s2 && (e3 = [e3]), this.criteria.push(...e3);
      }
      _call(e3, t3) {
        const n3 = new Array(e3.length).fill(false);
        for (const r3 of this.criteria) {
          const s3 = r3(e3, t3);
          for (let e4 = 0; e4 < n3.length; ++e4) n3[e4] ||= s3[e4];
        }
        return n3;
      }
      [Symbol.iterator]() {
        return this.criteria.values();
      }
    }
    class o2 extends s2 {
      constructor(e3, t3 = null) {
        super(), this.max_length = e3, this.max_position_embeddings = t3;
      }
      _call(e3) {
        return e3.map(((e4) => e4.length >= this.max_length));
      }
    }
    class i2 extends s2 {
      constructor(e3) {
        super(), Array.isArray(e3) || (e3 = [e3]), this.eos_token_id = e3;
      }
      _call(e3, t3) {
        return e3.map(((e4) => {
          const t4 = e4.at(-1);
          return this.eos_token_id.some(((e5) => t4 == e5));
        }));
      }
    }
    class l2 extends s2 {
      constructor() {
        super(), this.interrupted = false;
      }
      interrupt() {
        this.interrupted = true;
      }
      reset() {
        this.interrupted = false;
      }
      _call(e3, t3) {
        return new Array(e3.length).fill(this.interrupted);
      }
    }
  }, "./src/generation/streamers.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { BaseStreamer: () => o2, TextStreamer: () => l2, WhisperTextStreamer: () => d2 });
    var r2 = n2("./src/utils/core.js"), s2 = n2("./src/tokenizers.js"), a2 = n2("./src/env.js");
    class o2 {
      put(e3) {
        throw Error("Not implemented");
      }
      end() {
        throw Error("Not implemented");
      }
    }
    const i2 = a2.apis.IS_PROCESS_AVAILABLE ? (e3) => process.stdout.write(e3) : (e3) => console.log(e3);
    class l2 extends o2 {
      constructor(e3, { skip_prompt: t3 = false, callback_function: n3 = null, token_callback_function: r3 = null, skip_special_tokens: s3 = true, decode_kwargs: a3 = {}, ...o3 } = {}) {
        super(), this.tokenizer = e3, this.skip_prompt = t3, this.callback_function = n3 ?? i2, this.token_callback_function = r3, this.decode_kwargs = { skip_special_tokens: s3, ...a3, ...o3 }, this.token_cache = [], this.print_len = 0, this.next_tokens_are_prompt = true;
      }
      put(e3) {
        if (e3.length > 1) throw Error("TextStreamer only supports batch size of 1");
        const t3 = this.next_tokens_are_prompt;
        if (t3 && (this.next_tokens_are_prompt = false, this.skip_prompt)) return;
        const n3 = e3[0];
        this.token_callback_function?.(n3), this.token_cache = (0, r2.mergeArrays)(this.token_cache, n3);
        const a3 = this.tokenizer.decode(this.token_cache, this.decode_kwargs);
        let o3;
        t3 || a3.endsWith("\n") ? (o3 = a3.slice(this.print_len), this.token_cache = [], this.print_len = 0) : a3.length > 0 && (0, s2.is_chinese_char)(a3.charCodeAt(a3.length - 1)) ? (o3 = a3.slice(this.print_len), this.print_len += o3.length) : (o3 = a3.slice(this.print_len, a3.lastIndexOf(" ") + 1), this.print_len += o3.length), this.on_finalized_text(o3, false);
      }
      end() {
        let e3;
        if (this.token_cache.length > 0) {
          e3 = this.tokenizer.decode(this.token_cache, this.decode_kwargs).slice(this.print_len), this.token_cache = [], this.print_len = 0;
        } else e3 = "";
        this.next_tokens_are_prompt = true, this.on_finalized_text(e3, true);
      }
      on_finalized_text(e3, t3) {
        e3.length > 0 && this.callback_function?.(e3), t3 && this.callback_function === i2 && a2.apis.IS_PROCESS_AVAILABLE && this.callback_function?.("\n");
      }
    }
    class d2 extends l2 {
      constructor(e3, { skip_prompt: t3 = false, callback_function: n3 = null, token_callback_function: r3 = null, on_chunk_start: s3 = null, on_chunk_end: a3 = null, on_finalize: o3 = null, time_precision: i3 = 0.02, skip_special_tokens: l3 = true, decode_kwargs: d3 = {} } = {}) {
        super(e3, { skip_prompt: t3, skip_special_tokens: l3, callback_function: n3, token_callback_function: r3, decode_kwargs: d3 }), this.timestamp_begin = e3.timestamp_begin, this.on_chunk_start = s3, this.on_chunk_end = a3, this.on_finalize = o3, this.time_precision = i3, this.waiting_for_timestamp = false;
      }
      put(e3) {
        if (e3.length > 1) throw Error("WhisperTextStreamer only supports batch size of 1");
        const t3 = e3[0];
        if (1 === t3.length) {
          const e4 = Number(t3[0]) - this.timestamp_begin;
          if (e4 >= 0) {
            const n3 = e4 * this.time_precision;
            return this.waiting_for_timestamp ? this.on_chunk_end?.(n3) : this.on_chunk_start?.(n3), this.waiting_for_timestamp = !this.waiting_for_timestamp, void this.token_callback_function?.(t3);
          }
        }
        return super.put(e3);
      }
      end() {
        super.end(), this.on_finalize?.();
      }
    }
  }, "./src/models.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { ASTForAudioClassification: () => zn2, ASTModel: () => An2, ASTPreTrainedModel: () => In2, AlbertForMaskedLM: () => Vt2, AlbertForQuestionAnswering: () => Rt2, AlbertForSequenceClassification: () => jt2, AlbertModel: () => Nt2, AlbertPreTrainedModel: () => Bt2, ArceeForCausalLM: () => ts2, ArceeModel: () => es2, ArceePreTrainedModel: () => Zr2, AutoModel: () => ec2, AutoModelForAudioClassification: () => bc2, AutoModelForAudioFrameClassification: () => Mc2, AutoModelForAudioTextToText: () => Fc2, AutoModelForCTC: () => wc2, AutoModelForCausalLM: () => ic2, AutoModelForDepthEstimation: () => kc2, AutoModelForDocumentQuestionAnswering: () => xc2, AutoModelForImageClassification: () => cc2, AutoModelForImageFeatureExtraction: () => Cc2, AutoModelForImageMatting: () => vc2, AutoModelForImageSegmentation: () => pc2, AutoModelForImageTextToText: () => Sc2, AutoModelForImageToImage: () => Tc2, AutoModelForMaskGeneration: () => gc2, AutoModelForMaskedLM: () => lc2, AutoModelForNormalEstimation: () => Pc2, AutoModelForObjectDetection: () => fc2, AutoModelForPoseEstimation: () => $c2, AutoModelForQuestionAnswering: () => dc2, AutoModelForSemanticSegmentation: () => mc2, AutoModelForSeq2SeqLM: () => rc2, AutoModelForSequenceClassification: () => tc2, AutoModelForSpeechSeq2Seq: () => sc2, AutoModelForTextToSpectrogram: () => ac2, AutoModelForTextToWaveform: () => oc2, AutoModelForTokenClassification: () => nc2, AutoModelForUniversalSegmentation: () => hc2, AutoModelForVision2Seq: () => uc2, AutoModelForXVector: () => yc2, AutoModelForZeroShotObjectDetection: () => _c2, BartForConditionalGeneration: () => en2, BartForSequenceClassification: () => tn2, BartModel: () => Zt2, BartPretrainedModel: () => Yt2, BaseModelOutput: () => oe2, BeitForImageClassification: () => no2, BeitModel: () => to2, BeitPreTrainedModel: () => eo2, BertForMaskedLM: () => de2, BertForQuestionAnswering: () => pe2, BertForSequenceClassification: () => ue2, BertForTokenClassification: () => ce2, BertModel: () => le2, BertPreTrainedModel: () => ie2, BlenderbotForConditionalGeneration: () => un2, BlenderbotModel: () => dn2, BlenderbotPreTrainedModel: () => ln2, BlenderbotSmallForConditionalGeneration: () => mn2, BlenderbotSmallModel: () => pn2, BlenderbotSmallPreTrainedModel: () => cn2, BloomForCausalLM: () => pa2, BloomModel: () => ca2, BloomPreTrainedModel: () => ua2, CLIPModel: () => or2, CLIPPreTrainedModel: () => ar2, CLIPSegForImageSegmentation: () => vr2, CLIPSegModel: () => xr2, CLIPSegPreTrainedModel: () => Mr2, CLIPTextModel: () => ir2, CLIPTextModelWithProjection: () => lr2, CLIPVisionModel: () => dr2, CLIPVisionModelWithProjection: () => ur2, CamembertForMaskedLM: () => Ke2, CamembertForQuestionAnswering: () => Ye2, CamembertForSequenceClassification: () => Xe2, CamembertForTokenClassification: () => Je2, CamembertModel: () => Qe2, CamembertPreTrainedModel: () => He2, CausalLMOutput: () => Dc2, CausalLMOutputWithPast: () => Bc2, ChineseCLIPModel: () => _r2, ChineseCLIPPreTrainedModel: () => fr2, ClapAudioModelWithProjection: () => rd2, ClapModel: () => td2, ClapPreTrainedModel: () => ed2, ClapTextModelWithProjection: () => nd2, CodeGenForCausalLM: () => qr2, CodeGenModel: () => Gr2, CodeGenPreTrainedModel: () => Vr2, CohereForCausalLM: () => zs2, CohereModel: () => As2, CoherePreTrainedModel: () => Is2, ConvBertForMaskedLM: () => De2, ConvBertForQuestionAnswering: () => je2, ConvBertForSequenceClassification: () => Be2, ConvBertForTokenClassification: () => Ne2, ConvBertModel: () => Oe2, ConvBertPreTrainedModel: () => Le2, ConvNextForImageClassification: () => _i2, ConvNextModel: () => fi2, ConvNextPreTrainedModel: () => hi2, ConvNextV2ForImageClassification: () => bi2, ConvNextV2Model: () => wi2, ConvNextV2PreTrainedModel: () => gi2, DFineForObjectDetection: () => To2, DFineModel: () => vo2, DFinePreTrainedModel: () => xo2, DINOv3ConvNextModel: () => Si2, DINOv3ConvNextPreTrainedModel: () => Ci2, DINOv3ViTModel: () => $i2, DINOv3ViTPreTrainedModel: () => Pi2, DPTForDepthEstimation: () => Ho2, DPTModel: () => Wo2, DPTPreTrainedModel: () => Uo2, DacDecoderModel: () => du2, DacDecoderOutput: () => ou2, DacEncoderModel: () => lu2, DacEncoderOutput: () => au2, DacModel: () => iu2, DacPreTrainedModel: () => su2, DebertaForMaskedLM: () => tt2, DebertaForQuestionAnswering: () => st2, DebertaForSequenceClassification: () => nt2, DebertaForTokenClassification: () => rt2, DebertaModel: () => et2, DebertaPreTrainedModel: () => Ze2, DebertaV2ForMaskedLM: () => it2, DebertaV2ForQuestionAnswering: () => ut2, DebertaV2ForSequenceClassification: () => lt2, DebertaV2ForTokenClassification: () => dt2, DebertaV2Model: () => ot2, DebertaV2PreTrainedModel: () => at2, DecisionTransformerModel: () => Dd2, DecisionTransformerPreTrainedModel: () => Od2, DeiTForImageClassification: () => Eo2, DeiTModel: () => Fo2, DeiTPreTrainedModel: () => So2, DepthAnythingForDepthEstimation: () => Ko2, DepthAnythingPreTrainedModel: () => Qo2, DepthProForDepthEstimation: () => ti2, DepthProPreTrainedModel: () => ei2, DetrForObjectDetection: () => ao2, DetrForSegmentation: () => oo2, DetrModel: () => so2, DetrObjectDetectionOutput: () => io2, DetrPreTrainedModel: () => ro2, DetrSegmentationOutput: () => lo2, Dinov2ForImageClassification: () => xi2, Dinov2Model: () => Mi2, Dinov2PreTrainedModel: () => yi2, Dinov2WithRegistersForImageClassification: () => ki2, Dinov2WithRegistersModel: () => Ti2, Dinov2WithRegistersPreTrainedModel: () => vi2, DistilBertForMaskedLM: () => _t2, DistilBertForQuestionAnswering: () => ft2, DistilBertForSequenceClassification: () => mt2, DistilBertForTokenClassification: () => ht2, DistilBertModel: () => pt2, DistilBertPreTrainedModel: () => ct2, DonutSwinModel: () => mi2, DonutSwinPreTrainedModel: () => pi2, EdgeTamModel: () => Vi2, EfficientNetForImageClassification: () => fd2, EfficientNetModel: () => hd2, EfficientNetPreTrainedModel: () => md2, ElectraForMaskedLM: () => Ge2, ElectraForQuestionAnswering: () => We2, ElectraForSequenceClassification: () => qe2, ElectraForTokenClassification: () => Ue2, ElectraModel: () => Ve2, ElectraPreTrainedModel: () => Re2, Ernie4_5_ForCausalLM: () => Hl2, Ernie4_5_Model: () => Wl2, Ernie4_5_PretrainedModel: () => Ul2, EsmForMaskedLM: () => bt2, EsmForSequenceClassification: () => yt2, EsmForTokenClassification: () => Mt2, EsmModel: () => wt2, EsmPreTrainedModel: () => gt2, ExaoneForCausalLM: () => _s2, ExaoneModel: () => fs2, ExaonePreTrainedModel: () => hs2, FalconForCausalLM: () => Zl2, FalconModel: () => Yl2, FalconPreTrainedModel: () => Jl2, FastViTForImageClassification: () => Na2, FastViTModel: () => Ba2, FastViTPreTrainedModel: () => Da2, Florence2ForConditionalGeneration: () => Qn2, Florence2PreTrainedModel: () => Hn2, GLPNForDepthEstimation: () => ci2, GLPNModel: () => ui2, GLPNPreTrainedModel: () => di2, GPT2LMHeadModel: () => Pr2, GPT2Model: () => kr2, GPT2PreTrainedModel: () => Tr2, GPTBigCodeForCausalLM: () => Rr2, GPTBigCodeModel: () => jr2, GPTBigCodePreTrainedModel: () => Nr2, GPTJForCausalLM: () => Br2, GPTJModel: () => Dr2, GPTJPreTrainedModel: () => Or2, GPTNeoForCausalLM: () => Ir2, GPTNeoModel: () => Er2, GPTNeoPreTrainedModel: () => Fr2, GPTNeoXForCausalLM: () => Lr2, GPTNeoXModel: () => zr2, GPTNeoXPreTrainedModel: () => Ar2, Gemma2ForCausalLM: () => js2, Gemma2Model: () => Ns2, Gemma2PreTrainedModel: () => Bs2, Gemma3ForCausalLM: () => Ws2, Gemma3Model: () => Us2, Gemma3PreTrainedModel: () => qs2, Gemma3nForConditionalGeneration: () => Zn2, Gemma3nPreTrainedModel: () => Yn2, GemmaForCausalLM: () => Ds2, GemmaModel: () => Os2, GemmaPreTrainedModel: () => Ls2, GlmForCausalLM: () => ms2, GlmModel: () => ps2, GlmPreTrainedModel: () => cs2, GraniteForCausalLM: () => Cs2, GraniteModel: () => $s2, GraniteMoeHybridForCausalLM: () => Es2, GraniteMoeHybridModel: () => Fs2, GraniteMoeHybridPreTrainedModel: () => Ss2, GranitePreTrainedModel: () => Ps2, GroundingDinoForObjectDetection: () => Ei2, GroundingDinoPreTrainedModel: () => Fi2, GroupViTModel: () => Oa2, GroupViTPreTrainedModel: () => La2, HeliumForCausalLM: () => us2, HeliumModel: () => ds2, HeliumPreTrainedModel: () => ls2, HieraForImageClassification: () => zo2, HieraModel: () => Ao2, HieraPreTrainedModel: () => Io2, HubertForCTC: () => vl2, HubertForSequenceClassification: () => Tl2, HubertModel: () => xl2, HubertPreTrainedModel: () => Ml2, IJepaForImageClassification: () => Ta2, IJepaModel: () => va2, IJepaPreTrainedModel: () => xa2, Idefics3ForConditionalGeneration: () => tr2, Idefics3PreTrainedModel: () => er2, ImageMattingOutput: () => Nc2, JAISLMHeadModel: () => Sr2, JAISModel: () => Cr2, JAISPreTrainedModel: () => $r2, JinaCLIPModel: () => wr2, JinaCLIPPreTrainedModel: () => gr2, JinaCLIPTextModel: () => br2, JinaCLIPVisionModel: () => yr2, Lfm2ForCausalLM: () => ss2, Lfm2Model: () => rs2, Lfm2PreTrainedModel: () => ns2, LiteWhisperForConditionalGeneration: () => Bn2, Llama4ForCausalLM: () => Kr2, Llama4PreTrainedModel: () => Qr2, LlamaForCausalLM: () => Hr2, LlamaModel: () => Wr2, LlamaPreTrainedModel: () => Ur2, LlavaForConditionalGeneration: () => qn2, LlavaOnevisionForConditionalGeneration: () => Un2, LlavaPreTrainedModel: () => Gn2, LlavaQwen2ForCausalLM: () => Jn2, LongT5ForConditionalGeneration: () => Qt2, LongT5Model: () => Ht2, LongT5PreTrainedModel: () => Wt2, M2M100ForConditionalGeneration: () => Ki2, M2M100Model: () => Qi2, M2M100PreTrainedModel: () => Hi2, MBartForCausalLM: () => on2, MBartForConditionalGeneration: () => sn2, MBartForSequenceClassification: () => an2, MBartModel: () => rn2, MBartPreTrainedModel: () => nn2, MPNetForMaskedLM: () => St2, MPNetForQuestionAnswering: () => It2, MPNetForSequenceClassification: () => Ft2, MPNetForTokenClassification: () => Et2, MPNetModel: () => Ct2, MPNetPreTrainedModel: () => $t2, MT5ForConditionalGeneration: () => Jt2, MT5Model: () => Xt2, MT5PreTrainedModel: () => Kt2, MarianMTModel: () => Wi2, MarianModel: () => Ui2, MarianPreTrainedModel: () => qi2, MaskFormerForInstanceSegmentation: () => li2, MaskFormerModel: () => ii2, MaskFormerPreTrainedModel: () => oi2, MaskedLMOutput: () => Lc2, Metric3DForDepthEstimation: () => ri2, Metric3DPreTrainedModel: () => ni2, Metric3Dv2ForDepthEstimation: () => ai2, Metric3Dv2PreTrainedModel: () => si2, MgpstrForSceneTextRecognition: () => Vd2, MgpstrModelOutput: () => jd2, MgpstrPreTrainedModel: () => Rd2, MimiDecoderModel: () => ru2, MimiDecoderOutput: () => eu2, MimiEncoderModel: () => nu2, MimiEncoderOutput: () => Zd2, MimiModel: () => tu2, MimiPreTrainedModel: () => Yd2, MistralForCausalLM: () => ql2, MistralModel: () => Gl2, MistralPreTrainedModel: () => Vl2, MobileBertForMaskedLM: () => Tt2, MobileBertForQuestionAnswering: () => Pt2, MobileBertForSequenceClassification: () => kt2, MobileBertModel: () => vt2, MobileBertPreTrainedModel: () => xt2, MobileLLMForCausalLM: () => bs2, MobileLLMModel: () => ws2, MobileLLMPreTrainedModel: () => gs2, MobileNetV1ForImageClassification: () => xd2, MobileNetV1ForSemanticSegmentation: () => vd2, MobileNetV1Model: () => Md2, MobileNetV1PreTrainedModel: () => yd2, MobileNetV2ForImageClassification: () => Pd2, MobileNetV2ForSemanticSegmentation: () => $d2, MobileNetV2Model: () => kd2, MobileNetV2PreTrainedModel: () => Td2, MobileNetV3ForImageClassification: () => Fd2, MobileNetV3ForSemanticSegmentation: () => Ed2, MobileNetV3Model: () => Sd2, MobileNetV3PreTrainedModel: () => Cd2, MobileNetV4ForImageClassification: () => zd2, MobileNetV4ForSemanticSegmentation: () => Ld2, MobileNetV4Model: () => Ad2, MobileNetV4PreTrainedModel: () => Id2, MobileViTForImageClassification: () => qa2, MobileViTModel: () => Ga2, MobileViTPreTrainedModel: () => Va2, MobileViTV2ForImageClassification: () => Ha2, MobileViTV2Model: () => Wa2, MobileViTV2PreTrainedModel: () => Ua2, ModelOutput: () => ae2, ModernBertDecoderForCausalLM: () => Pe2, ModernBertDecoderModel: () => ke2, ModernBertDecoderPreTrainedModel: () => Te2, ModernBertForMaskedLM: () => Me2, ModernBertForSequenceClassification: () => xe2, ModernBertForTokenClassification: () => ve2, ModernBertModel: () => ye2, ModernBertPreTrainedModel: () => be2, Moondream1ForConditionalGeneration: () => Wn2, MoonshineForConditionalGeneration: () => Rn2, MoonshineModel: () => jn2, MoonshinePreTrainedModel: () => Nn2, MptForCausalLM: () => fa2, MptModel: () => ha2, MptPreTrainedModel: () => ma2, MultiModalityCausalLM: () => Nd2, MultiModalityPreTrainedModel: () => Bd2, MusicgenForCausalLM: () => wd2, MusicgenForConditionalGeneration: () => bd2, MusicgenModel: () => gd2, MusicgenPreTrainedModel: () => _d2, NanoChatForCausalLM: () => Yr2, NanoChatModel: () => Jr2, NanoChatPreTrainedModel: () => Xr2, NeoBertForMaskedLM: () => fe2, NeoBertForQuestionAnswering: () => we2, NeoBertForSequenceClassification: () => _e2, NeoBertForTokenClassification: () => ge2, NeoBertModel: () => he2, NeoBertPreTrainedModel: () => me2, NomicBertModel: () => Ce2, NomicBertPreTrainedModel: () => $e2, OPTForCausalLM: () => wa2, OPTModel: () => ga2, OPTPreTrainedModel: () => _a2, Olmo2ForCausalLM: () => ks2, Olmo2Model: () => Ts2, Olmo2PreTrainedModel: () => vs2, OlmoForCausalLM: () => xs2, OlmoModel: () => Ms2, OlmoPreTrainedModel: () => ys2, OpenELMForCausalLM: () => Ks2, OpenELMModel: () => Qs2, OpenELMPreTrainedModel: () => Hs2, OwlViTForObjectDetection: () => Xa2, OwlViTModel: () => Ka2, OwlViTPreTrainedModel: () => Qa2, Owlv2ForObjectDetection: () => Za2, Owlv2Model: () => Ya2, Owlv2PreTrainedModel: () => Ja2, PaliGemmaForConditionalGeneration: () => Xn2, PaliGemmaPreTrainedModel: () => Kn2, ParakeetForCTC: () => nl2, ParakeetPreTrainedModel: () => tl2, PatchTSMixerForPrediction: () => Qd2, PatchTSMixerModel: () => Hd2, PatchTSMixerPreTrainedModel: () => Wd2, PatchTSTForPrediction: () => Ud2, PatchTSTModel: () => qd2, PatchTSTPreTrainedModel: () => Gd2, Phi3ForCausalLM: () => da2, Phi3Model: () => la2, Phi3PreTrainedModel: () => ia2, Phi3VForCausalLM: () => sr2, Phi3VPreTrainedModel: () => rr2, PhiForCausalLM: () => oa2, PhiModel: () => aa2, PhiPreTrainedModel: () => sa2, PreTrainedModel: () => se2, PretrainedMixin: () => hu2, PvtForImageClassification: () => Sa2, PvtModel: () => Ca2, PvtPreTrainedModel: () => $a2, PyAnnoteForAudioFrameClassification: () => al2, PyAnnoteModel: () => sl2, PyAnnotePreTrainedModel: () => rl2, QuestionAnsweringModelOutput: () => Oc2, Qwen2ForCausalLM: () => Ys2, Qwen2Model: () => Js2, Qwen2PreTrainedModel: () => Xs2, Qwen2VLForConditionalGeneration: () => ra2, Qwen2VLPreTrainedModel: () => na2, Qwen3ForCausalLM: () => ta2, Qwen3Model: () => ea2, Qwen3PreTrainedModel: () => Zs2, RFDetrForObjectDetection: () => yo2, RFDetrModel: () => bo2, RFDetrObjectDetectionOutput: () => Mo2, RFDetrPreTrainedModel: () => wo2, RTDetrForObjectDetection: () => po2, RTDetrModel: () => co2, RTDetrObjectDetectionOutput: () => mo2, RTDetrPreTrainedModel: () => uo2, RTDetrV2ForObjectDetection: () => _o2, RTDetrV2Model: () => fo2, RTDetrV2ObjectDetectionOutput: () => go2, RTDetrV2PreTrainedModel: () => ho2, ResNetForImageClassification: () => Do2, ResNetModel: () => Oo2, ResNetPreTrainedModel: () => Lo2, RoFormerForMaskedLM: () => Ee2, RoFormerForQuestionAnswering: () => ze2, RoFormerForSequenceClassification: () => Ie2, RoFormerForTokenClassification: () => Ae2, RoFormerModel: () => Fe2, RoFormerPreTrainedModel: () => Se2, RobertaForMaskedLM: () => _n2, RobertaForQuestionAnswering: () => bn2, RobertaForSequenceClassification: () => gn2, RobertaForTokenClassification: () => wn2, RobertaModel: () => fn2, RobertaPreTrainedModel: () => hn2, Sam2ImageSegmentationOutput: () => Ni2, Sam2Model: () => Ri2, Sam2PreTrainedModel: () => ji2, Sam3TrackerModel: () => Gi2, SamImageSegmentationOutput: () => Bi2, SamModel: () => Di2, SamPreTrainedModel: () => Oi2, SapiensForDepthEstimation: () => Yo2, SapiensForNormalEstimation: () => Zo2, SapiensForSemanticSegmentation: () => Jo2, SapiensPreTrainedModel: () => Xo2, SegformerForImageClassification: () => ld2, SegformerForSemanticSegmentation: () => dd2, SegformerModel: () => id2, SegformerPreTrainedModel: () => od2, Seq2SeqLMOutput: () => Ec2, SequenceClassifierOutput: () => Ic2, SiglipModel: () => pr2, SiglipPreTrainedModel: () => cr2, SiglipTextModel: () => mr2, SiglipVisionModel: () => hr2, SmolLM3ForCausalLM: () => is2, SmolLM3Model: () => os2, SmolLM3PreTrainedModel: () => as2, SmolVLMForConditionalGeneration: () => nr2, SnacDecoderModel: () => mu2, SnacEncoderModel: () => pu2, SnacModel: () => cu2, SnacPreTrainedModel: () => uu2, SpeechT5ForSpeechToText: () => Ll2, SpeechT5ForTextToSpeech: () => Ol2, SpeechT5HifiGan: () => Dl2, SpeechT5Model: () => zl2, SpeechT5PreTrainedModel: () => Al2, SqueezeBertForMaskedLM: () => Lt2, SqueezeBertForQuestionAnswering: () => Dt2, SqueezeBertForSequenceClassification: () => Ot2, SqueezeBertModel: () => zt2, SqueezeBertPreTrainedModel: () => At2, StableLmForCausalLM: () => pd2, StableLmModel: () => cd2, StableLmPreTrainedModel: () => ud2, Starcoder2ForCausalLM: () => Xl2, Starcoder2Model: () => Kl2, Starcoder2PreTrainedModel: () => Ql2, StyleTextToSpeech2Model: () => Il2, StyleTextToSpeech2PreTrainedModel: () => El2, SupertonicForConditionalGeneration: () => Nl2, SupertonicPreTrainedModel: () => Bl2, Swin2SRForImageSuperResolution: () => qo2, Swin2SRModel: () => Go2, Swin2SRPreTrainedModel: () => Vo2, SwinForImageClassification: () => jo2, SwinForSemanticSegmentation: () => Ro2, SwinModel: () => No2, SwinPreTrainedModel: () => Bo2, T5ForConditionalGeneration: () => Ut2, T5Model: () => qt2, T5PreTrainedModel: () => Gt2, TableTransformerForObjectDetection: () => $o2, TableTransformerModel: () => Po2, TableTransformerObjectDetectionOutput: () => Co2, TableTransformerPreTrainedModel: () => ko2, TokenClassifierOutput: () => zc2, TrOCRForCausalLM: () => Rl2, TrOCRPreTrainedModel: () => jl2, UltravoxModel: () => Xd2, UltravoxPreTrainedModel: () => Kd2, UniSpeechForCTC: () => ul2, UniSpeechForSequenceClassification: () => cl2, UniSpeechModel: () => dl2, UniSpeechPreTrainedModel: () => ll2, UniSpeechSatForAudioFrameClassification: () => _l2, UniSpeechSatForCTC: () => hl2, UniSpeechSatForSequenceClassification: () => fl2, UniSpeechSatModel: () => ml2, UniSpeechSatPreTrainedModel: () => pl2, VaultGemmaForCausalLM: () => Gs2, VaultGemmaModel: () => Vs2, VaultGemmaPreTrainedModel: () => Rs2, ViTForImageClassification: () => Ma2, ViTMAEModel: () => Ea2, ViTMAEPreTrainedModel: () => Fa2, ViTMSNForImageClassification: () => za2, ViTMSNModel: () => Aa2, ViTMSNPreTrainedModel: () => Ia2, ViTModel: () => ya2, ViTPreTrainedModel: () => ba2, VisionEncoderDecoderModel: () => Vn2, VitMatteForImageMatting: () => Ra2, VitMattePreTrainedModel: () => ja2, VitPoseForPoseEstimation: () => Pa2, VitPosePreTrainedModel: () => ka2, VitsModel: () => ad2, VitsModelOutput: () => jc2, VitsPreTrainedModel: () => sd2, VoxtralForConditionalGeneration: () => Jd2, Wav2Vec2BertForCTC: () => bl2, Wav2Vec2BertForSequenceClassification: () => yl2, Wav2Vec2BertModel: () => wl2, Wav2Vec2BertPreTrainedModel: () => gl2, Wav2Vec2ForAudioFrameClassification: () => el2, Wav2Vec2ForCTC: () => Yi2, Wav2Vec2ForSequenceClassification: () => Zi2, Wav2Vec2Model: () => Ji2, Wav2Vec2PreTrainedModel: () => Xi2, WavLMForAudioFrameClassification: () => Fl2, WavLMForCTC: () => $l2, WavLMForSequenceClassification: () => Cl2, WavLMForXVector: () => Sl2, WavLMModel: () => Pl2, WavLMPreTrainedModel: () => kl2, WeSpeakerResNetModel: () => il2, WeSpeakerResNetPreTrainedModel: () => ol2, WhisperForConditionalGeneration: () => Dn2, WhisperModel: () => On2, WhisperPreTrainedModel: () => Ln2, XLMForQuestionAnswering: () => kn2, XLMForSequenceClassification: () => vn2, XLMForTokenClassification: () => Tn2, XLMModel: () => Mn2, XLMPreTrainedModel: () => yn2, XLMRobertaForMaskedLM: () => Cn2, XLMRobertaForQuestionAnswering: () => En2, XLMRobertaForSequenceClassification: () => Sn2, XLMRobertaForTokenClassification: () => Fn2, XLMRobertaModel: () => $n2, XLMRobertaPreTrainedModel: () => Pn2, XLMWithLMHeadModel: () => xn2, XVectorOutput: () => Ac2, YolosForObjectDetection: () => zi2, YolosModel: () => Ai2, YolosObjectDetectionOutput: () => Li2, YolosPreTrainedModel: () => Ii2 });
    var r2 = n2("./src/configs.js"), s2 = n2("./src/backends/onnx.js"), a2 = n2("./src/utils/dtypes.js"), o2 = n2("./src/utils/generic.js"), i2 = n2("./src/utils/core.js"), l2 = n2("./src/utils/hub.js"), d2 = n2("./src/utils/constants.js"), u2 = n2("./src/generation/logits_process.js"), c2 = n2("./src/generation/configuration_utils.js"), p2 = n2("./src/utils/tensor.js"), m2 = n2("./src/utils/image.js"), h2 = n2("./src/utils/maths.js"), f2 = n2("./src/generation/stopping_criteria.js"), _2 = n2("./src/generation/logits_sampler.js"), g2 = n2("./src/env.js"), w2 = n2("./src/models/whisper/generation_whisper.js"), b2 = n2("./src/models/whisper/common_whisper.js");
    const y2 = 0, M2 = 1, x2 = 2, v2 = 3, T2 = 4, k2 = 5, P2 = 6, $2 = 7, C2 = 8, S2 = 9, F2 = 10, E2 = 11, I2 = 12, A2 = 13, z2 = /* @__PURE__ */ new Map(), L2 = /* @__PURE__ */ new Map(), O2 = /* @__PURE__ */ new Map();
    async function D2(e3, t3, n3) {
      return Object.fromEntries(await Promise.all(Object.keys(t3).map((async (o3) => {
        const { buffer_or_path: i3, session_options: d3, session_config: u3 } = await (async function(e4, t4, n4) {
          let o4 = n4.config?.["transformers.js_config"] ?? {}, i4 = n4.device ?? o4.device;
          i4 && "string" != typeof i4 && (i4.hasOwnProperty(t4) ? i4 = i4[t4] : (console.warn(`device not specified for "${t4}". Using the default device.`), i4 = null));
          const d4 = i4 ?? (g2.apis.IS_NODE_ENV ? "cpu" : "wasm"), u4 = (0, s2.deviceToExecutionProviders)(d4), c3 = o4.device_config ?? {};
          c3.hasOwnProperty(d4) && (o4 = { ...o4, ...c3[d4] });
          let p3 = n4.dtype ?? o4.dtype;
          if ("string" != typeof p3 && (p3 && p3.hasOwnProperty(t4) ? p3 = p3[t4] : (p3 = a2.DEFAULT_DEVICE_DTYPE_MAPPING[d4] ?? a2.DATA_TYPES.fp32, console.warn(`dtype not specified for "${t4}". Using the default dtype (${p3}) for this device (${d4}).`))), p3 === a2.DATA_TYPES.auto) {
            let e5 = o4.dtype;
            "string" != typeof e5 && (e5 = e5?.[t4]), p3 = e5 && e5 !== a2.DATA_TYPES.auto && a2.DATA_TYPES.hasOwnProperty(e5) ? e5 : a2.DEFAULT_DEVICE_DTYPE_MAPPING[d4] ?? a2.DATA_TYPES.fp32;
          }
          const m3 = p3;
          if (!a2.DEFAULT_DTYPE_SUFFIX_MAPPING.hasOwnProperty(m3)) throw new Error(`Invalid dtype: ${m3}. Should be one of: ${Object.keys(a2.DATA_TYPES).join(", ")}`);
          if (m3 === a2.DATA_TYPES.fp16 && "webgpu" === d4 && !await (0, a2.isWebGpuFp16Supported)()) throw new Error(`The device (${d4}) does not support fp16.`);
          const h3 = o4.kv_cache_dtype, f3 = h3 ? "string" == typeof h3 ? h3 : h3[m3] ?? "float32" : void 0;
          if (f3 && !["float32", "float16"].includes(f3)) throw new Error(`Invalid kv_cache_dtype: ${f3}. Should be one of: float32, float16`);
          const _3 = { dtype: m3, kv_cache_dtype: f3, device: d4 }, w3 = `${t4}${a2.DEFAULT_DTYPE_SUFFIX_MAPPING[m3]}.onnx`, b3 = `${n4.subfolder ?? ""}/${w3}`, y3 = { ...n4.session_options };
          y3.executionProviders ??= u4;
          const M3 = o4.free_dimension_overrides;
          M3 ? y3.freeDimensionOverrides ??= M3 : d4.startsWith("webnn") && !y3.freeDimensionOverrides && console.warn(`WebNN does not currently support dynamic shapes and requires 'free_dimension_overrides' to be set in config.json, preferably as a field within config["transformers.js_config"]["device_config"]["${d4}"]. When 'free_dimension_overrides' is not set, you may experience significant performance degradation.`);
          const x3 = g2.apis.IS_NODE_ENV && g2.env.useFSCache, v3 = (0, l2.getModelFile)(e4, b3, true, n4, x3), T3 = n4.use_external_data_format ?? o4.use_external_data_format;
          let k3 = [];
          if (T3) {
            let r3;
            r3 = "object" == typeof T3 ? T3.hasOwnProperty(w3) ? T3[w3] : !!T3.hasOwnProperty(t4) && T3[t4] : T3;
            const s3 = +r3;
            if (s3 > l2.MAX_EXTERNAL_DATA_CHUNKS) throw new Error(`The number of external data chunks (${s3}) exceeds the maximum allowed value (${l2.MAX_EXTERNAL_DATA_CHUNKS}).`);
            for (let t5 = 0; t5 < s3; ++t5) {
              const r4 = `${w3}_data${0 === t5 ? "" : "_" + t5}`, s4 = `${n4.subfolder ?? ""}/${r4}`;
              k3.push(new Promise((async (t6, a3) => {
                const o5 = await (0, l2.getModelFile)(e4, s4, true, n4, x3);
                t6(o5 instanceof Uint8Array ? { path: r4, data: o5 } : r4);
              })));
            }
          } else void 0 !== y3.externalData && (k3 = y3.externalData.map((async (t5) => {
            if ("string" == typeof t5.data) {
              const r3 = await (0, l2.getModelFile)(e4, t5.data, true, n4);
              return { ...t5, data: r3 };
            }
            return t5;
          })));
          if (k3.length > 0) {
            const e5 = await Promise.all(k3);
            g2.apis.IS_NODE_ENV || (y3.externalData = e5);
          }
          if ("webgpu" === d4) {
            const e5 = (0, r2.getCacheShapes)(n4.config, { prefix: "present" });
            if (Object.keys(e5).length > 0 && !(0, s2.isONNXProxy)()) {
              const t5 = {};
              for (const n5 in e5) t5[n5] = "gpu-buffer";
              y3.preferredOutputLocation = t5;
            }
          }
          return { buffer_or_path: await v3, session_options: y3, session_config: _3 };
        })(e3, t3[o3], n3);
        return [o3, await (0, s2.createInferenceSession)(i3, d3, u3)];
      }))));
    }
    async function B2(e3, t3, n3) {
      return Object.fromEntries(await Promise.all(Object.keys(t3).map((async (r3) => [r3, await (0, l2.getModelJSON)(e3, t3[r3], false, n3)]))));
    }
    async function N2(e3, t3) {
      const n3 = (function(e4, t4) {
        const n4 = /* @__PURE__ */ Object.create(null), r3 = [];
        for (const a4 of e4.inputNames) {
          const e5 = t4[a4];
          e5 instanceof p2.Tensor ? n4[a4] = (0, s2.isONNXProxy)() ? e5.clone() : e5 : r3.push(a4);
        }
        if (r3.length > 0) throw new Error(`An error occurred during model execution: "Missing the following inputs: ${r3.join(", ")}.`);
        const a3 = Object.keys(t4).length, o3 = e4.inputNames.length;
        if (a3 > o3) {
          let n5 = Object.keys(t4).filter(((t5) => !e4.inputNames.includes(t5)));
          console.warn(`WARNING: Too many inputs were provided (${a3} > ${o3}). The following inputs will be ignored: "${n5.join(", ")}".`);
        }
        return n4;
      })(e3, t3);
      try {
        const t4 = Object.fromEntries(Object.entries(n3).map((([e4, t5]) => [e4, t5.ort_tensor])));
        return j2(await (0, s2.runInferenceSession)(e3, t4));
      } catch (e4) {
        const t4 = Object.fromEntries(Object.entries(n3).map((([e5, t5]) => {
          const n4 = { type: t5.type, dims: t5.dims, location: t5.location };
          return "gpu-buffer" !== n4.location && (n4.data = t5.data), [e5, n4];
        })));
        throw console.error(`An error occurred during model execution: "${e4}".`), console.error("Inputs given to model:", t4), e4;
      }
    }
    function j2(e3) {
      for (let t3 in e3) (0, s2.isONNXTensor)(e3[t3]) ? e3[t3] = new p2.Tensor(e3[t3]) : "object" == typeof e3[t3] && j2(e3[t3]);
      return e3;
    }
    function R2(e3) {
      if (e3 instanceof p2.Tensor) return e3;
      if (0 === e3.length) throw Error("items must be non-empty");
      if (Array.isArray(e3[0])) {
        if (e3.some(((t3) => t3.length !== e3[0].length))) throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.");
        return new p2.Tensor("int64", BigInt64Array.from(e3.flat().map(((e4) => BigInt(e4)))), [e3.length, e3[0].length]);
      }
      return new p2.Tensor("int64", BigInt64Array.from(e3.map(((e4) => BigInt(e4)))), [1, e3.length]);
    }
    function V2(e3) {
      return new p2.Tensor("bool", [e3], [1]);
    }
    async function G2(e3, t3) {
      let { encoder_outputs: n3, input_ids: r3, decoder_input_ids: s3, ...a3 } = t3;
      if (!n3) {
        const r4 = (0, i2.pick)(t3, e3.sessions.model.inputNames);
        n3 = (await q2(e3, r4)).last_hidden_state;
      }
      a3.input_ids = s3, a3.encoder_hidden_states = n3, e3.sessions.decoder_model_merged.inputNames.includes("encoder_attention_mask") && (a3.encoder_attention_mask = t3.attention_mask);
      return await W2(e3, a3, true);
    }
    async function q2(e3, t3) {
      const n3 = e3.sessions.model, r3 = (0, i2.pick)(t3, n3.inputNames);
      if (n3.inputNames.includes("inputs_embeds") && !r3.inputs_embeds) {
        if (!t3.input_ids) throw new Error("Both `input_ids` and `inputs_embeds` are missing in the model inputs.");
        r3.inputs_embeds = await e3.encode_text({ input_ids: t3.input_ids });
      }
      if (n3.inputNames.includes("token_type_ids") && !r3.token_type_ids) {
        if (!r3.input_ids) throw new Error("Both `input_ids` and `token_type_ids` are missing in the model inputs.");
        r3.token_type_ids = (0, p2.zeros_like)(r3.input_ids);
      }
      if (n3.inputNames.includes("pixel_mask") && !r3.pixel_mask) {
        if (!r3.pixel_values) throw new Error("Both `pixel_values` and `pixel_mask` are missing in the model inputs.");
        const e4 = r3.pixel_values.dims;
        r3.pixel_mask = (0, p2.ones)([e4[0], e4[2], e4[3]]);
      }
      return await N2(n3, r3);
    }
    async function U2(e3, t3) {
      const n3 = await e3.encode(t3);
      return await e3.decode(n3);
    }
    async function W2(e3, t3, n3 = false) {
      const r3 = e3.sessions[n3 ? "decoder_model_merged" : "model"], { past_key_values: s3, ...a3 } = t3;
      if (r3.inputNames.includes("use_cache_branch") && (a3.use_cache_branch = V2(!!s3)), r3.inputNames.includes("position_ids") && a3.attention_mask && !a3.position_ids) {
        const t4 = ["paligemma", "gemma3_text", "gemma3"].includes(e3.config.model_type) ? 1 : 0;
        a3.position_ids = (function(e4, t5 = null, n4 = 0) {
          const { input_ids: r4, inputs_embeds: s4, attention_mask: a4 } = e4, { data: o4, dims: i3 } = Z2(a4, n4);
          let l3 = new p2.Tensor("int64", o4, i3);
          if (t5) {
            const e5 = -(r4 ?? s4).dims.at(1);
            l3 = l3.slice(null, [e5, null]);
          }
          return l3;
        })(a3, s3, t4);
      }
      e3.addPastKeyValues(a3, s3);
      const o3 = (0, i2.pick)(a3, r3.inputNames);
      return await N2(r3, o3);
    }
    function H2({ modality_token_id: e3, inputs_embeds: t3, modality_features: n3, input_ids: r3, attention_mask: s3 }) {
      const a3 = r3.tolist().map(((t4) => t4.reduce(((t5, n4, r4) => (n4 == e3 && t5.push(r4), t5)), []))), o3 = a3.reduce(((e4, t4) => e4 + t4.length), 0), i3 = n3.dims[0];
      if (o3 !== i3) throw new Error(`Number of tokens and features do not match: tokens: ${o3}, features ${i3}`);
      let l3 = 0;
      for (let e4 = 0; e4 < a3.length; ++e4) {
        const r4 = a3[e4], s4 = t3[e4];
        for (let e5 = 0; e5 < r4.length; ++e5) s4[r4[e5]].data.set(n3[l3++].data);
      }
      return { inputs_embeds: t3, attention_mask: s3 };
    }
    function Q2({ image_token_id: e3, inputs_embeds: t3, image_features: n3, input_ids: r3, attention_mask: s3 }) {
      return H2({ modality_token_id: e3, inputs_embeds: t3, modality_features: n3, input_ids: r3, attention_mask: s3 });
    }
    function K2({ audio_token_id: e3, inputs_embeds: t3, audio_features: n3, input_ids: r3, attention_mask: s3 }) {
      return H2({ modality_token_id: e3, inputs_embeds: t3, modality_features: n3, input_ids: r3, attention_mask: s3 });
    }
    async function X2(e3, { encode_function: t3, merge_function: n3, modality_input_name: r3, modality_output_name: s3, input_ids: a3 = null, attention_mask: o3 = null, position_ids: i3 = null, inputs_embeds: l3 = null, past_key_values: d3 = null, generation_config: u3 = null, logits_processor: c3 = null, ...m3 }) {
      const h3 = m3[r3];
      if (!l3) {
        if (l3 = await e3.encode_text({ input_ids: a3, ...m3 }), h3 && 1 !== a3.dims[1]) {
          const e4 = await t3({ [r3]: h3, ...m3 });
          ({ inputs_embeds: l3, attention_mask: o3 } = n3({ [s3]: e4, inputs_embeds: l3, input_ids: a3, attention_mask: o3 }));
        } else if (d3 && h3 && 1 === a3.dims[1]) {
          const e4 = a3.dims[1], t4 = Object.values(d3)[0].dims.at(-2);
          o3 = (0, p2.cat)([(0, p2.ones)([a3.dims[0], t4]), o3.slice(null, [o3.dims[1] - e4, o3.dims[1]])], 1);
        }
      }
      if (!i3 && "qwen2_vl" === e3.config.model_type) {
        const { image_grid_thw: t4, video_grid_thw: n4 } = m3;
        [i3] = e3.get_rope_index(a3, t4, n4, o3);
      }
      return await W2(e3, { inputs_embeds: l3, past_key_values: d3, attention_mask: o3, position_ids: i3, generation_config: u3, logits_processor: c3 }, true);
    }
    async function J2(e3, t3) {
      return await X2(e3, { ...t3, modality_input_name: "audio_values", modality_output_name: "audio_features", encode_function: e3.encode_audio.bind(e3), merge_function: e3._merge_input_ids_with_audio_features.bind(e3) });
    }
    async function Y2(e3, t3) {
      return await X2(e3, { ...t3, modality_input_name: "pixel_values", modality_output_name: "image_features", encode_function: e3.encode_image.bind(e3), merge_function: e3._merge_input_ids_with_image_features.bind(e3) });
    }
    function Z2(e3, t3 = 0) {
      const [n3, r3] = e3.dims, s3 = e3.data, a3 = new BigInt64Array(s3.length);
      for (let e4 = 0; e4 < n3; ++e4) {
        const n4 = e4 * r3;
        let o3 = BigInt(t3);
        for (let e5 = 0; e5 < r3; ++e5) {
          const t4 = n4 + e5;
          0n === s3[t4] ? a3[t4] = BigInt(1) : (a3[t4] = o3, o3 += s3[t4]);
        }
      }
      return { data: a3, dims: e3.dims };
    }
    function ee2(e3, t3, n3, r3) {
      const s3 = n3.past_key_values ? Object.values(n3.past_key_values)[0].dims.at(-2) : 0;
      if (!n3.attention_mask) {
        let e4;
        for (const t4 of ["input_ids", "inputs_embeds", "position_ids"]) if (n3[t4]) {
          e4 = n3[t4].dims;
          break;
        }
        if (!e4) throw new Error("attention_mask is not provided, and unable to infer its shape from model inputs.");
        n3.attention_mask = (0, p2.ones)([e4[0], s3 + e4[1]]);
      }
      if (n3.past_key_values) {
        const { input_ids: e4, attention_mask: t4 } = n3;
        t4 && t4.dims[1] > e4.dims[1] || s3 < e4.dims[1] && (n3.input_ids = e4.slice(null, [s3, null]));
      }
      return n3;
    }
    function te2(e3, t3, n3, r3) {
      return n3.past_key_values && (t3 = t3.map(((e4) => [e4.at(-1)]))), { ...n3, decoder_input_ids: R2(t3) };
    }
    function ne2(e3, ...t3) {
      return e3.config.is_encoder_decoder ? te2(e3, ...t3) : ee2(e3, ...t3);
    }
    function re2(e3, t3, n3, r3) {
      const s3 = !!n3.past_key_values;
      if (null !== r3.guidance_scale && r3.guidance_scale > 1 && (s3 ? n3.input_ids = (0, p2.cat)([n3.input_ids, n3.input_ids], 0) : (n3.input_ids = (0, p2.cat)([n3.input_ids, (0, p2.full_like)(n3.input_ids, BigInt(r3.pad_token_id))], 0), n3.attention_mask = (0, p2.cat)([n3.attention_mask, (0, p2.full_like)(n3.attention_mask, 0n)], 0))), !s3 && n3.pixel_values || (n3.pixel_values = (0, p2.full)([0, 0, 3, 384, 384], 1)), s3) {
        const e4 = 0, t4 = 1, r4 = e4 > 0 ? 1 : 0, s4 = 1;
        n3.images_seq_mask = new p2.Tensor("bool", new Array(e4 + t4).fill(true).fill(false, 0, t4), [s4, e4 + t4]), n3.images_emb_mask = new p2.Tensor("bool", new Array(e4).fill(!!r4), [s4, 1, e4]);
      }
      return n3;
    }
    class se2 extends o2.Callable {
      main_input_name = "input_ids";
      forward_params = ["input_ids", "attention_mask"];
      constructor(e3, t3, n3) {
        super(), this.config = e3, this.sessions = t3, this.configs = n3;
        const r3 = O2.get(this.constructor), s3 = z2.get(r3);
        switch (this.can_generate = false, this._forward = null, this._prepare_inputs_for_generation = null, s3) {
          case T2:
            this.can_generate = true, this._forward = W2, this._prepare_inputs_for_generation = ee2;
            break;
          case x2:
          case v2:
          case $2:
            this.can_generate = true, this._forward = G2, this._prepare_inputs_for_generation = te2;
            break;
          case M2:
            this._forward = G2;
            break;
          case P2:
            this.can_generate = true, this._forward = Y2, this._prepare_inputs_for_generation = ne2;
            break;
          case F2:
            this.can_generate = true, this._forward = J2, this._prepare_inputs_for_generation = ne2;
            break;
          case S2:
          case I2:
            this.can_generate = true, this._prepare_inputs_for_generation = ne2;
            break;
          case C2:
            this.can_generate = true, this._prepare_inputs_for_generation = re2;
            break;
          case E2:
            this._forward = U2;
            break;
          default:
            this._forward = q2;
        }
        this.can_generate && this.forward_params.push("past_key_values"), this.custom_config = this.config["transformers.js_config"] ?? {};
      }
      async dispose() {
        const e3 = [];
        for (const t3 of Object.values(this.sessions)) t3?.handler?.dispose && e3.push(t3.handler.dispose());
        return await Promise.all(e3);
      }
      static async from_pretrained(e3, { progress_callback: t3 = null, config: n3 = null, cache_dir: s3 = null, local_files_only: a3 = false, revision: o3 = "main", model_file_name: i3 = null, subfolder: l3 = "onnx", device: u3 = null, dtype: c3 = null, use_external_data_format: p3 = null, session_options: m3 = {} } = {}) {
        let h3 = { progress_callback: t3, config: n3, cache_dir: s3, local_files_only: a3, revision: o3, model_file_name: i3, subfolder: l3, device: u3, dtype: c3, use_external_data_format: p3, session_options: m3 };
        const f3 = O2.get(this), _3 = z2.get(f3);
        let g3;
        if (n3 = h3.config = await r2.AutoConfig.from_pretrained(e3, h3), _3 === T2) g3 = await Promise.all([D2(e3, { model: h3.model_file_name ?? "model" }, h3), B2(e3, { generation_config: "generation_config.json" }, h3)]);
        else if (_3 === x2 || _3 === v2) g3 = await Promise.all([D2(e3, { model: "encoder_model", decoder_model_merged: "decoder_model_merged" }, h3), B2(e3, { generation_config: "generation_config.json" }, h3)]);
        else if (_3 === k2) g3 = await Promise.all([D2(e3, { model: "vision_encoder", prompt_encoder_mask_decoder: "prompt_encoder_mask_decoder" }, h3)]);
        else if (_3 === M2) g3 = await Promise.all([D2(e3, { model: "encoder_model", decoder_model_merged: "decoder_model_merged" }, h3)]);
        else if (_3 === P2) {
          const t4 = { embed_tokens: "embed_tokens", vision_encoder: "vision_encoder", decoder_model_merged: "decoder_model_merged" };
          n3.is_encoder_decoder && (t4.model = "encoder_model"), g3 = await Promise.all([D2(e3, t4, h3), B2(e3, { generation_config: "generation_config.json" }, h3)]);
        } else if (_3 === F2) {
          const t4 = { embed_tokens: "embed_tokens", audio_encoder: "audio_encoder", decoder_model_merged: "decoder_model_merged" };
          g3 = await Promise.all([D2(e3, t4, h3), B2(e3, { generation_config: "generation_config.json" }, h3)]);
        } else if (_3 === I2) {
          const t4 = { embed_tokens: "embed_tokens", audio_encoder: "audio_encoder", vision_encoder: "vision_encoder", decoder_model_merged: "decoder_model_merged" };
          g3 = await Promise.all([D2(e3, t4, h3), B2(e3, { generation_config: "generation_config.json" }, h3)]);
        } else if (_3 === $2) g3 = await Promise.all([D2(e3, { model: "text_encoder", decoder_model_merged: "decoder_model_merged", encodec_decode: "encodec_decode" }, h3), B2(e3, { generation_config: "generation_config.json" }, h3)]);
        else if (_3 === C2) g3 = await Promise.all([D2(e3, { prepare_inputs_embeds: "prepare_inputs_embeds", model: "language_model", lm_head: "lm_head", gen_head: "gen_head", gen_img_embeds: "gen_img_embeds", image_decode: "image_decode" }, h3), B2(e3, { generation_config: "generation_config.json" }, h3)]);
        else if (_3 === S2) g3 = await Promise.all([D2(e3, { prepare_inputs_embeds: "prepare_inputs_embeds", model: "model", vision_encoder: "vision_encoder" }, h3), B2(e3, { generation_config: "generation_config.json" }, h3)]);
        else if (_3 === E2) g3 = await Promise.all([D2(e3, { encoder_model: "encoder_model", decoder_model: "decoder_model" }, h3)]);
        else if (_3 === A2) g3 = await Promise.all([D2(e3, { text_encoder: "text_encoder", latent_denoiser: "latent_denoiser", voice_decoder: "voice_decoder" }, h3)]);
        else {
          if (_3 !== y2) {
            const e4 = f3 ?? n3?.model_type;
            "custom" !== e4 && console.warn(`Model type for '${e4}' not found, assuming encoder-only architecture. Please report this at ${d2.GITHUB_ISSUE_URL}.`);
          }
          g3 = await Promise.all([D2(e3, { model: h3.model_file_name ?? "model" }, h3)]);
        }
        return new this(n3, ...g3);
      }
      async _call(e3) {
        return await this.forward(e3);
      }
      async forward(e3) {
        return await this._forward(this, e3);
      }
      get generation_config() {
        return this.configs?.generation_config ?? null;
      }
      _get_logits_processor(e3, t3, n3 = null) {
        const r3 = new u2.LogitsProcessorList();
        if (null !== e3.repetition_penalty && 1 !== e3.repetition_penalty && r3.push(new u2.RepetitionPenaltyLogitsProcessor(e3.repetition_penalty)), null !== e3.no_repeat_ngram_size && e3.no_repeat_ngram_size > 0 && r3.push(new u2.NoRepeatNGramLogitsProcessor(e3.no_repeat_ngram_size)), null !== e3.bad_words_ids && r3.push(new u2.NoBadWordsLogitsProcessor(e3.bad_words_ids, e3.eos_token_id)), null !== e3.min_length && null !== e3.eos_token_id && e3.min_length > 0 && r3.push(new u2.MinLengthLogitsProcessor(e3.min_length, e3.eos_token_id)), null !== e3.min_new_tokens && null !== e3.eos_token_id && e3.min_new_tokens > 0 && r3.push(new u2.MinNewTokensLengthLogitsProcessor(t3, e3.min_new_tokens, e3.eos_token_id)), null !== e3.forced_bos_token_id && r3.push(new u2.ForcedBOSTokenLogitsProcessor(e3.forced_bos_token_id)), null !== e3.forced_eos_token_id && r3.push(new u2.ForcedEOSTokenLogitsProcessor(e3.max_length, e3.forced_eos_token_id)), null !== e3.begin_suppress_tokens) {
          const n4 = t3 > 1 || null === e3.forced_bos_token_id ? t3 : t3 + 1;
          r3.push(new u2.SuppressTokensAtBeginLogitsProcessor(e3.begin_suppress_tokens, n4));
        }
        return null !== e3.guidance_scale && e3.guidance_scale > 1 && r3.push(new u2.ClassifierFreeGuidanceLogitsProcessor(e3.guidance_scale)), 0 === e3.temperature && e3.do_sample && (console.warn("`do_sample` changed to false because `temperature: 0` implies greedy sampling (always selecting the most likely token), which is incompatible with `do_sample: true`."), e3.do_sample = false), e3.do_sample && null !== e3.temperature && 1 !== e3.temperature && r3.push(new u2.TemperatureLogitsWarper(e3.temperature)), null !== n3 && r3.extend(n3), r3;
      }
      _prepare_generation_config(e3, t3, n3 = c2.GenerationConfig) {
        const r3 = { ...this.config };
        for (const e4 of ["decoder", "generator", "text_config"]) e4 in r3 && Object.assign(r3, r3[e4]);
        const s3 = new n3(r3);
        return Object.assign(s3, this.generation_config ?? {}), e3 && Object.assign(s3, e3), t3 && Object.assign(s3, (0, i2.pick)(t3, Object.getOwnPropertyNames(s3))), s3;
      }
      _get_stopping_criteria(e3, t3 = null) {
        const n3 = new f2.StoppingCriteriaList();
        return null !== e3.max_length && n3.push(new f2.MaxLengthCriteria(e3.max_length, this.config.max_position_embeddings ?? null)), null !== e3.eos_token_id && n3.push(new f2.EosTokenCriteria(e3.eos_token_id)), t3 && n3.extend(t3), n3;
      }
      _validate_model_class() {
        if (!this.can_generate) {
          const e3 = [ku2, Su2, Tu2, bu2], t3 = O2.get(this.constructor), n3 = /* @__PURE__ */ new Set(), r3 = this.config.model_type;
          for (const t4 of e3) {
            const e4 = t4.get(r3);
            e4 && n3.add(e4[0]);
          }
          let s3 = `The current model class (${t3}) is not compatible with \`.generate()\`, as it doesn't have a language model head.`;
          throw n3.size > 0 && (s3 += ` Please use the following class instead: ${[...n3].join(", ")}`), Error(s3);
        }
      }
      prepare_inputs_for_generation(...e3) {
        return this._prepare_inputs_for_generation(this, ...e3);
      }
      _update_model_kwargs_for_generation({ generated_input_ids: e3, outputs: t3, model_inputs: n3, is_encoder_decoder: r3 }) {
        return n3.past_key_values = this.getPastKeyValues(t3, n3.past_key_values), n3.input_ids = new p2.Tensor("int64", e3.flat(), [e3.length, 1]), r3 || (n3.attention_mask = (0, p2.cat)([n3.attention_mask, (0, p2.ones)([n3.attention_mask.dims[0], 1])], 1)), n3.position_ids = null, n3;
      }
      _prepare_model_inputs({ inputs: e3, bos_token_id: t3, model_kwargs: n3 }) {
        const r3 = (0, i2.pick)(n3, this.forward_params), s3 = this.main_input_name;
        if (s3 in r3) {
          if (e3) throw new Error("`inputs`: {inputs}` were passed alongside {input_name} which is not allowed. Make sure to either pass {inputs} or {input_name}=...");
        } else r3[s3] = e3;
        return { inputs_tensor: r3[s3], model_inputs: r3, model_input_name: s3 };
      }
      async _prepare_encoder_decoder_kwargs_for_generation({ inputs_tensor: e3, model_inputs: t3, model_input_name: n3, generation_config: r3 }) {
        if (this.sessions.model.inputNames.includes("inputs_embeds") && !t3.inputs_embeds && "_prepare_inputs_embeds" in this) {
          const { input_ids: e4, pixel_values: n4, attention_mask: r4, ...s4 } = t3, a3 = await this._prepare_inputs_embeds(t3);
          t3 = { ...s4, ...(0, i2.pick)(a3, ["inputs_embeds", "attention_mask"]) };
        }
        let { last_hidden_state: s3 } = await q2(this, t3);
        if (null !== r3.guidance_scale && r3.guidance_scale > 1) s3 = (0, p2.cat)([s3, (0, p2.full_like)(s3, 0)], 0), "attention_mask" in t3 && (t3.attention_mask = (0, p2.cat)([t3.attention_mask, (0, p2.zeros_like)(t3.attention_mask)], 0));
        else if (t3.decoder_input_ids) {
          const e4 = R2(t3.decoder_input_ids).dims[0];
          if (e4 !== s3.dims[0]) {
            if (1 !== s3.dims[0]) throw new Error(`The encoder outputs have a different batch size (${s3.dims[0]}) than the decoder inputs (${e4}).`);
            s3 = (0, p2.cat)(Array.from({ length: e4 }, (() => s3)), 0);
          }
        }
        return t3.encoder_outputs = s3, t3;
      }
      _prepare_decoder_input_ids_for_generation({ batch_size: e3, model_input_name: t3, model_kwargs: n3, decoder_start_token_id: r3, bos_token_id: s3, generation_config: a3 }) {
        let { decoder_input_ids: o3, ...i3 } = n3;
        if (!(o3 instanceof p2.Tensor)) {
          if (o3) Array.isArray(o3[0]) || (o3 = Array.from({ length: e3 }, (() => o3)));
          else if (r3 ??= s3, "musicgen" === this.config.model_type) o3 = Array.from({ length: e3 * this.config.decoder.num_codebooks }, (() => [r3]));
          else if (Array.isArray(r3)) {
            if (r3.length !== e3) throw new Error(`\`decoder_start_token_id\` expcted to have length ${e3} but got ${r3.length}`);
            o3 = r3;
          } else o3 = Array.from({ length: e3 }, (() => [r3]));
          o3 = R2(o3);
        }
        return n3.decoder_attention_mask = (0, p2.ones_like)(o3), { input_ids: o3, model_inputs: i3 };
      }
      async generate({ inputs: e3 = null, generation_config: t3 = null, logits_processor: n3 = null, stopping_criteria: r3 = null, streamer: s3 = null, ...a3 }) {
        this._validate_model_class(), t3 = this._prepare_generation_config(t3, a3);
        let { inputs_tensor: o3, model_inputs: i3, model_input_name: l3 } = this._prepare_model_inputs({ inputs: e3, model_kwargs: a3 });
        const d3 = this.config.is_encoder_decoder;
        let u3;
        d3 && ("encoder_outputs" in i3 || (i3 = await this._prepare_encoder_decoder_kwargs_for_generation({ inputs_tensor: o3, model_inputs: i3, model_input_name: l3, generation_config: t3 }))), d3 ? { input_ids: u3, model_inputs: i3 } = this._prepare_decoder_input_ids_for_generation({ batch_size: i3[l3].dims.at(0), model_input_name: l3, model_kwargs: i3, decoder_start_token_id: t3.decoder_start_token_id, bos_token_id: t3.bos_token_id, generation_config: t3 }) : u3 = i3[l3];
        let c3 = u3.dims.at(-1);
        null !== t3.max_new_tokens && (t3.max_length = c3 + t3.max_new_tokens);
        const m3 = this._get_logits_processor(t3, c3, n3), h3 = this._get_stopping_criteria(t3, r3), f3 = i3[l3].dims.at(0), g3 = _2.LogitsSampler.getSampler(t3), w3 = new Array(f3).fill(0), b3 = u3.tolist();
        let y3;
        s3 && s3.put(b3);
        let M3 = {};
        for (; ; ) {
          if (i3 = this.prepare_inputs_for_generation(b3, i3, t3), y3 = await this.forward(i3), t3.output_attentions && t3.return_dict_in_generate) {
            const e5 = this.getAttentions(y3);
            for (const t4 in e5) t4 in M3 || (M3[t4] = []), M3[t4].push(e5[t4]);
          }
          const e4 = m3(b3, y3.logits.slice(null, -1, null)), n4 = [];
          for (let t4 = 0; t4 < e4.dims.at(0); ++t4) {
            const r4 = e4[t4], s4 = await g3(r4);
            for (const [e5, r5] of s4) {
              const s5 = BigInt(e5);
              w3[t4] += r5, b3[t4].push(s5), n4.push([s5]);
              break;
            }
          }
          s3 && s3.put(n4);
          if (h3(b3).every(((e5) => e5))) break;
          i3 = this._update_model_kwargs_for_generation({ generated_input_ids: n4, outputs: y3, model_inputs: i3, is_encoder_decoder: d3 });
        }
        s3 && s3.end();
        const x3 = this.getPastKeyValues(y3, i3.past_key_values, true), v3 = new p2.Tensor("int64", b3.flat(), [b3.length, b3[0].length]);
        if (t3.return_dict_in_generate) return { sequences: v3, past_key_values: x3, ...M3 };
        for (const e4 of Object.values(y3)) "gpu-buffer" === e4.location && e4.dispose();
        return v3;
      }
      getPastKeyValues(e3, t3, n3 = false) {
        const r3 = /* @__PURE__ */ Object.create(null);
        for (const s3 in e3) if (s3.startsWith("present")) {
          const a3 = s3.replace("present_conv", "past_conv").replace("present", "past_key_values"), o3 = s3.includes("encoder");
          if (r3[a3] = o3 && t3 ? t3[a3] : e3[s3], t3 && (!o3 || n3)) {
            const e4 = t3[a3];
            "gpu-buffer" === e4.location && e4.dispose();
          }
        }
        return r3;
      }
      getAttentions(e3) {
        const t3 = {};
        for (const n3 of ["cross_attentions", "encoder_attentions", "decoder_attentions"]) for (const r3 in e3) r3.startsWith(n3) && (n3 in t3 || (t3[n3] = []), t3[n3].push(e3[r3]));
        return t3;
      }
      addPastKeyValues(e3, t3) {
        if (t3) Object.assign(e3, t3);
        else {
          const t4 = this.sessions.decoder_model_merged ?? this.sessions.model, n3 = (e3[this.main_input_name] ?? e3.attention_mask)?.dims?.[0] ?? 1, s3 = t4?.config?.kv_cache_dtype ?? "float32", a3 = "float16" === s3 ? p2.DataTypeMap.float16 : p2.DataTypeMap.float32, o3 = (0, r2.getCacheShapes)(this.config, { batch_size: n3 });
          for (const t5 in o3) {
            const n4 = o3[t5].reduce(((e4, t6) => e4 * t6), 1);
            e3[t5] = new p2.Tensor(s3, new a3(n4), o3[t5]);
          }
        }
      }
      async encode_image({ pixel_values: e3 }) {
        return (await N2(this.sessions.vision_encoder, { pixel_values: e3 })).image_features;
      }
      async encode_text({ input_ids: e3 }) {
        return (await N2(this.sessions.embed_tokens, { input_ids: e3 })).inputs_embeds;
      }
      async encode_audio({ audio_values: e3 }) {
        return (await N2(this.sessions.audio_encoder, { audio_values: e3 })).audio_features;
      }
    }
    class ae2 {
    }
    class oe2 extends ae2 {
      constructor({ last_hidden_state: e3, hidden_states: t3 = null, attentions: n3 = null }) {
        super(), this.last_hidden_state = e3, this.hidden_states = t3, this.attentions = n3;
      }
    }
    class ie2 extends se2 {
    }
    class le2 extends ie2 {
    }
    class de2 extends ie2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class ue2 extends ie2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class ce2 extends ie2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class pe2 extends ie2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class me2 extends se2 {
    }
    class he2 extends me2 {
    }
    class fe2 extends me2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class _e2 extends me2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class ge2 extends me2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class we2 extends me2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class be2 extends se2 {
    }
    class ye2 extends be2 {
    }
    class Me2 extends be2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class xe2 extends be2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class ve2 extends be2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class Te2 extends se2 {
    }
    class ke2 extends Te2 {
    }
    class Pe2 extends Te2 {
    }
    class $e2 extends se2 {
    }
    class Ce2 extends $e2 {
    }
    class Se2 extends se2 {
    }
    class Fe2 extends Se2 {
    }
    class Ee2 extends Se2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class Ie2 extends Se2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Ae2 extends Se2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class ze2 extends Se2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class Le2 extends se2 {
    }
    class Oe2 extends Le2 {
    }
    class De2 extends Le2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class Be2 extends Le2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Ne2 extends Le2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class je2 extends Le2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class Re2 extends se2 {
    }
    class Ve2 extends Re2 {
    }
    class Ge2 extends Re2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class qe2 extends Re2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Ue2 extends Re2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class We2 extends Re2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class He2 extends se2 {
    }
    class Qe2 extends He2 {
    }
    class Ke2 extends He2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class Xe2 extends He2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Je2 extends He2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class Ye2 extends He2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class Ze2 extends se2 {
    }
    class et2 extends Ze2 {
    }
    class tt2 extends Ze2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class nt2 extends Ze2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class rt2 extends Ze2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class st2 extends Ze2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class at2 extends se2 {
    }
    class ot2 extends at2 {
    }
    class it2 extends at2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class lt2 extends at2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class dt2 extends at2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class ut2 extends at2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class ct2 extends se2 {
    }
    class pt2 extends ct2 {
    }
    class mt2 extends ct2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class ht2 extends ct2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class ft2 extends ct2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class _t2 extends ct2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class gt2 extends se2 {
    }
    class wt2 extends gt2 {
    }
    class bt2 extends gt2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class yt2 extends gt2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Mt2 extends gt2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class xt2 extends se2 {
    }
    class vt2 extends xt2 {
    }
    class Tt2 extends xt2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class kt2 extends xt2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Pt2 extends xt2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class $t2 extends se2 {
    }
    class Ct2 extends $t2 {
    }
    class St2 extends $t2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class Ft2 extends $t2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Et2 extends $t2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class It2 extends $t2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class At2 extends se2 {
    }
    class zt2 extends At2 {
    }
    class Lt2 extends At2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class Ot2 extends At2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Dt2 extends At2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class Bt2 extends se2 {
    }
    class Nt2 extends Bt2 {
    }
    class jt2 extends Bt2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Rt2 extends Bt2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class Vt2 extends Bt2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class Gt2 extends se2 {
      forward_params = ["input_ids", "attention_mask", "encoder_outputs", "decoder_input_ids", "decoder_attention_mask", "past_key_values"];
    }
    class qt2 extends Gt2 {
    }
    class Ut2 extends Gt2 {
    }
    class Wt2 extends se2 {
    }
    class Ht2 extends Wt2 {
    }
    class Qt2 extends Wt2 {
    }
    class Kt2 extends se2 {
    }
    class Xt2 extends Kt2 {
    }
    class Jt2 extends Kt2 {
    }
    class Yt2 extends se2 {
    }
    class Zt2 extends Yt2 {
    }
    class en2 extends Yt2 {
    }
    class tn2 extends Yt2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class nn2 extends se2 {
    }
    class rn2 extends nn2 {
    }
    class sn2 extends nn2 {
    }
    class an2 extends nn2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class on2 extends nn2 {
    }
    class ln2 extends se2 {
    }
    class dn2 extends ln2 {
    }
    class un2 extends ln2 {
    }
    class cn2 extends se2 {
    }
    class pn2 extends cn2 {
    }
    class mn2 extends cn2 {
    }
    class hn2 extends se2 {
    }
    class fn2 extends hn2 {
    }
    class _n2 extends hn2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class gn2 extends hn2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class wn2 extends hn2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class bn2 extends hn2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class yn2 extends se2 {
    }
    class Mn2 extends yn2 {
    }
    class xn2 extends yn2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class vn2 extends yn2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Tn2 extends yn2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class kn2 extends yn2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class Pn2 extends se2 {
    }
    class $n2 extends Pn2 {
    }
    class Cn2 extends Pn2 {
      async _call(e3) {
        return new Lc2(await super._call(e3));
      }
    }
    class Sn2 extends Pn2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Fn2 extends Pn2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class En2 extends Pn2 {
      async _call(e3) {
        return new Oc2(await super._call(e3));
      }
    }
    class In2 extends se2 {
    }
    class An2 extends In2 {
    }
    class zn2 extends In2 {
    }
    class Ln2 extends se2 {
      requires_attention_mask = false;
      main_input_name = "input_features";
      forward_params = ["input_features", "attention_mask", "decoder_input_ids", "decoder_attention_mask", "past_key_values"];
    }
    class On2 extends Ln2 {
    }
    class Dn2 extends Ln2 {
      _prepare_generation_config(e3, t3) {
        return super._prepare_generation_config(e3, t3, w2.WhisperGenerationConfig);
      }
      _retrieve_init_tokens(e3) {
        const t3 = [e3.decoder_start_token_id];
        let n3 = e3.language;
        const r3 = e3.task;
        if (e3.is_multilingual) {
          n3 || (console.warn("No language specified - defaulting to English (en)."), n3 = "en");
          const s3 = `<|${(0, b2.whisper_language_to_code)(n3)}|>`;
          t3.push(e3.lang_to_id[s3]), t3.push(e3.task_to_id[r3 ?? "transcribe"]);
        } else if (n3 || r3) throw new Error("Cannot specify `task` or `language` for an English-only model. If the model is intended to be multilingual, pass `is_multilingual=true` to generate, or update the generation config.");
        return !e3.return_timestamps && e3.no_timestamps_token_id && t3.at(-1) !== e3.no_timestamps_token_id ? t3.push(e3.no_timestamps_token_id) : e3.return_timestamps && t3.at(-1) === e3.no_timestamps_token_id && (console.warn("<|notimestamps|> prompt token is removed from generation_config since `return_timestamps` is set to `true`."), t3.pop()), t3.filter(((e4) => null != e4));
      }
      async generate({ inputs: e3 = null, generation_config: t3 = null, logits_processor: n3 = null, stopping_criteria: r3 = null, ...s3 }) {
        t3 = this._prepare_generation_config(t3, s3);
        const a3 = s3.decoder_input_ids ?? this._retrieve_init_tokens(t3);
        if (t3.return_timestamps && (n3 ??= new u2.LogitsProcessorList(), n3.push(new u2.WhisperTimeStampLogitsProcessor(t3, a3))), t3.begin_suppress_tokens && (n3 ??= new u2.LogitsProcessorList(), n3.push(new u2.SuppressTokensAtBeginLogitsProcessor(t3.begin_suppress_tokens, a3.length))), t3.return_token_timestamps) {
          if (!t3.alignment_heads) throw new Error("Model generation config has no `alignment_heads`, token-level timestamps not available. See https://gist.github.com/hollance/42e32852f24243b748ae6bc1f985b13a on how to add this property to the generation config.");
          "translate" === t3.task && console.warn("Token-level timestamps may not be reliable for task 'translate'."), t3.output_attentions = true, t3.return_dict_in_generate = true;
        }
        const o3 = await super.generate({ inputs: e3, generation_config: t3, logits_processor: n3, decoder_input_ids: a3, ...s3 });
        return t3.return_token_timestamps && (o3.token_timestamps = this._extract_token_timestamps(o3, t3.alignment_heads, t3.num_frames)), o3;
      }
      _extract_token_timestamps(e3, t3, n3 = null, r3 = 0.02) {
        if (!e3.cross_attentions) throw new Error("Model outputs must contain cross attentions to extract timestamps. This is most likely because the model was not exported with `output_attentions=True`.");
        null == n3 && console.warn("`num_frames` has not been set, meaning the entire audio will be analyzed. This may lead to inaccurate token-level timestamps for short audios (< 30 seconds).");
        let s3 = this.config.median_filter_width;
        void 0 === s3 && (console.warn("Model config has no `median_filter_width`, using default value of 7."), s3 = 7);
        const a3 = e3.cross_attentions, o3 = Array.from({ length: this.config.decoder_layers }, ((e4, t4) => (0, p2.cat)(a3.map(((e5) => e5[t4])), 2))), l3 = (0, p2.stack)(t3.map((([e4, t4]) => {
          if (e4 >= o3.length) throw new Error(`Layer index ${e4} is out of bounds for cross attentions (length ${o3.length}).`);
          return n3 ? o3[e4].slice(null, t4, null, [0, n3]) : o3[e4].slice(null, t4);
        }))).transpose(1, 0, 2, 3), [d3, u3] = (0, p2.std_mean)(l3, -2, 0, true), c3 = l3.clone();
        for (let e4 = 0; e4 < c3.dims[0]; ++e4) {
          const t4 = c3[e4];
          for (let n4 = 0; n4 < t4.dims[0]; ++n4) {
            const r4 = t4[n4], a4 = d3[e4][n4][0].data, o4 = u3[e4][n4][0].data;
            for (let e5 = 0; e5 < r4.dims[0]; ++e5) {
              let t5 = r4[e5].data;
              for (let e6 = 0; e6 < t5.length; ++e6) t5[e6] = (t5[e6] - o4[e6]) / a4[e6];
              t5.set((0, h2.medianFilter)(t5, s3));
            }
          }
        }
        const m3 = [(0, p2.mean)(c3, 1)], f3 = e3.sequences.dims, _3 = new p2.Tensor("float32", new Float32Array(f3[0] * f3[1]), f3);
        for (let e4 = 0; e4 < f3[0]; ++e4) {
          const t4 = m3[e4].neg().squeeze_(0), [n4, s4] = (0, h2.dynamic_time_warping)(t4.tolist()), a4 = Array.from({ length: n4.length - 1 }, ((e5, t5) => n4[t5 + 1] - n4[t5])), o4 = (0, i2.mergeArrays)([1], a4).map(((e5) => !!e5)), l4 = [];
          for (let e5 = 0; e5 < o4.length; ++e5) o4[e5] && l4.push(s4[e5] * r3);
          _3[e4].data.set(l4, 1);
        }
        return _3;
      }
    }
    class Bn2 extends Dn2 {
    }
    class Nn2 extends se2 {
      requires_attention_mask = false;
      main_input_name = "input_values";
      forward_params = ["input_values", "decoder_input_ids", "past_key_values"];
    }
    class jn2 extends Nn2 {
    }
    class Rn2 extends Nn2 {
    }
    class Vn2 extends se2 {
      main_input_name = "pixel_values";
      forward_params = ["pixel_values", "decoder_input_ids", "encoder_hidden_states", "past_key_values"];
    }
    class Gn2 extends se2 {
      forward_params = ["input_ids", "attention_mask", "pixel_values", "position_ids", "past_key_values"];
    }
    class qn2 extends Gn2 {
      _merge_input_ids_with_image_features(e3) {
        const t3 = e3.image_features.dims.at(-1), n3 = e3.image_features.view(-1, t3);
        return Q2({ image_token_id: this.config.image_token_index, ...e3, image_features: n3 });
      }
    }
    class Un2 extends qn2 {
    }
    class Wn2 extends qn2 {
    }
    class Hn2 extends se2 {
      forward_params = ["input_ids", "inputs_embeds", "attention_mask", "pixel_values", "encoder_outputs", "decoder_input_ids", "decoder_inputs_embeds", "decoder_attention_mask", "past_key_values"];
      main_input_name = "inputs_embeds";
    }
    class Qn2 extends Hn2 {
      _merge_input_ids_with_image_features({ inputs_embeds: e3, image_features: t3, input_ids: n3, attention_mask: r3 }) {
        return { inputs_embeds: (0, p2.cat)([t3, e3], 1), attention_mask: (0, p2.cat)([(0, p2.ones)(t3.dims.slice(0, 2)), r3], 1) };
      }
      async _prepare_inputs_embeds({ input_ids: e3, pixel_values: t3, inputs_embeds: n3, attention_mask: r3 }) {
        if (!e3 && !t3) throw new Error("Either `input_ids` or `pixel_values` should be provided.");
        let s3, a3;
        return e3 && (s3 = await this.encode_text({ input_ids: e3 })), t3 && (a3 = await this.encode_image({ pixel_values: t3 })), s3 && a3 ? { inputs_embeds: n3, attention_mask: r3 } = this._merge_input_ids_with_image_features({ inputs_embeds: s3, image_features: a3, input_ids: e3, attention_mask: r3 }) : n3 = s3 || a3, { inputs_embeds: n3, attention_mask: r3 };
      }
      async forward({ input_ids: e3, pixel_values: t3, attention_mask: n3, decoder_input_ids: r3, decoder_attention_mask: s3, encoder_outputs: a3, past_key_values: o3, inputs_embeds: i3, decoder_inputs_embeds: l3 }) {
        if (i3 || ({ inputs_embeds: i3, attention_mask: n3 } = await this._prepare_inputs_embeds({ input_ids: e3, pixel_values: t3, inputs_embeds: i3, attention_mask: n3 })), !a3) {
          let { last_hidden_state: e4 } = await q2(this, { inputs_embeds: i3, attention_mask: n3 });
          a3 = e4;
        }
        if (!l3) {
          if (!r3) throw new Error("Either `decoder_input_ids` or `decoder_inputs_embeds` should be provided.");
          l3 = await this.encode_text({ input_ids: r3 });
        }
        const d3 = { inputs_embeds: l3, attention_mask: s3, encoder_attention_mask: n3, encoder_hidden_states: a3, past_key_values: o3 };
        return await W2(this, d3, true);
      }
    }
    class Kn2 extends se2 {
      forward_params = ["input_ids", "attention_mask", "pixel_values", "position_ids", "past_key_values"];
    }
    class Xn2 extends Kn2 {
      _merge_input_ids_with_image_features(e3) {
        const t3 = e3.image_features.dims.at(-1), n3 = e3.image_features.view(-1, t3);
        return Q2({ image_token_id: this.config.image_token_index, ...e3, image_features: n3 });
      }
    }
    class Jn2 extends Gn2 {
      _merge_input_ids_with_image_features(e3) {
        const t3 = e3.image_features.dims.at(-1), n3 = e3.image_features.view(-1, t3);
        return Q2({ image_token_id: this.config.image_token_index, ...e3, image_features: n3 });
      }
    }
    class Yn2 extends se2 {
      forward_params = ["input_ids", "attention_mask", "inputs_embeds", "per_layer_inputs", "position_ids", "pixel_values", "input_features", "input_features_mask", "past_key_values"];
    }
    class Zn2 extends Yn2 {
      async forward({ input_ids: e3 = null, attention_mask: t3 = null, pixel_values: n3 = null, input_features: r3 = null, input_features_mask: s3 = null, position_ids: a3 = null, inputs_embeds: o3 = null, per_layer_inputs: i3 = null, past_key_values: l3 = null, generation_config: d3 = null, logits_processor: u3 = null, ...c3 }) {
        if (!(o3 && i3 || ({ inputs_embeds: o3, per_layer_inputs: i3 } = await N2(this.sessions.embed_tokens, { input_ids: e3 }), 1 === e3.dims[1]))) {
          if (n3) {
            const { image_features: r4 } = await N2(this.sessions.vision_encoder, { pixel_values: n3 });
            ({ inputs_embeds: o3, attention_mask: t3 } = this._merge_input_ids_with_image_features({ image_features: r4, inputs_embeds: o3, input_ids: e3, attention_mask: t3 }));
          }
          if (r3) {
            const { audio_features: n4 } = await N2(this.sessions.audio_encoder, { input_features: r3, input_features_mask: s3 });
            ({ inputs_embeds: o3, attention_mask: t3 } = this._merge_input_ids_with_audio_features({ audio_features: n4, inputs_embeds: o3, input_ids: e3, attention_mask: t3 }));
          }
        }
        return await W2(this, { inputs_embeds: o3, per_layer_inputs: i3, past_key_values: l3, attention_mask: t3, position_ids: a3, generation_config: d3, logits_processor: u3 }, true);
      }
      _merge_input_ids_with_image_features(e3) {
        const t3 = e3.image_features.dims.at(-1), n3 = e3.image_features.view(-1, t3);
        return Q2({ image_token_id: this.config.image_token_id, ...e3, image_features: n3 });
      }
      _merge_input_ids_with_audio_features(e3) {
        const t3 = e3.audio_features.dims.at(-1), n3 = e3.audio_features.view(-1, t3);
        return K2({ audio_token_id: this.config.audio_token_id, ...e3, audio_features: n3 });
      }
    }
    class er2 extends se2 {
      forward_params = ["input_ids", "attention_mask", "pixel_values", "pixel_attention_mask", "position_ids", "past_key_values"];
    }
    class tr2 extends er2 {
      async encode_image({ pixel_values: e3, pixel_attention_mask: t3 }) {
        return (await N2(this.sessions.vision_encoder, { pixel_values: e3, pixel_attention_mask: t3 })).image_features;
      }
      _merge_input_ids_with_image_features(e3) {
        const t3 = e3.image_features.dims.at(-1), n3 = e3.image_features.view(-1, t3);
        return Q2({ image_token_id: this.config.image_token_id, ...e3, image_features: n3 });
      }
    }
    class nr2 extends tr2 {
    }
    class rr2 extends se2 {
      forward_params = ["input_ids", "inputs_embeds", "attention_mask", "position_ids", "pixel_values", "image_sizes", "past_key_values"];
    }
    class sr2 extends rr2 {
      async forward({ input_ids: e3 = null, attention_mask: t3 = null, pixel_values: n3 = null, image_sizes: r3 = null, position_ids: s3 = null, inputs_embeds: a3 = null, past_key_values: o3 = null, generation_config: i3 = null, logits_processor: l3 = null, ...d3 }) {
        if (!a3) {
          let t4;
          if (n3 && 1 !== e3.dims[1]) {
            if (!r3) throw new Error("`image_sizes` must be provided when `pixel_values` is provided.");
            ({ image_features: t4 } = await N2(this.sessions.vision_encoder, { pixel_values: n3, image_sizes: r3 }));
          } else {
            const e4 = this.config.normalized_config.hidden_size;
            t4 = new p2.Tensor("float32", [], [0, e4]);
          }
          ({ inputs_embeds: a3 } = await N2(this.sessions.prepare_inputs_embeds, { input_ids: e3, image_features: t4 }));
        }
        return await W2(this, { inputs_embeds: a3, past_key_values: o3, attention_mask: t3, position_ids: s3, generation_config: i3, logits_processor: l3 }, false);
      }
    }
    class ar2 extends se2 {
    }
    class or2 extends ar2 {
    }
    class ir2 extends ar2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "text_model" });
      }
    }
    class lr2 extends ar2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "text_model" });
      }
    }
    class dr2 extends ar2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "vision_model" });
      }
    }
    class ur2 extends ar2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "vision_model" });
      }
    }
    class cr2 extends se2 {
    }
    class pr2 extends cr2 {
    }
    class mr2 extends cr2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "text_model" });
      }
    }
    class hr2 extends ar2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "vision_model" });
      }
    }
    class fr2 extends se2 {
    }
    class _r2 extends fr2 {
    }
    class gr2 extends se2 {
    }
    class wr2 extends gr2 {
      async forward(e3) {
        const t3 = !e3.input_ids, n3 = !e3.pixel_values;
        if (t3 && n3) throw new Error("Either `input_ids` or `pixel_values` should be provided.");
        if (t3 && (e3.input_ids = (0, p2.ones)([e3.pixel_values.dims[0], 1])), n3) {
          const { image_size: t4 } = this.config.vision_config;
          e3.pixel_values = (0, p2.full)([0, 3, t4, t4], 0);
        }
        const { text_embeddings: r3, image_embeddings: s3, l2norm_text_embeddings: a3, l2norm_image_embeddings: o3 } = await super.forward(e3), i3 = {};
        return t3 || (i3.text_embeddings = r3, i3.l2norm_text_embeddings = a3), n3 || (i3.image_embeddings = s3, i3.l2norm_image_embeddings = o3), i3;
      }
    }
    class br2 extends gr2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "text_model" });
      }
    }
    class yr2 extends gr2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "vision_model" });
      }
    }
    class Mr2 extends se2 {
    }
    class xr2 extends Mr2 {
    }
    class vr2 extends Mr2 {
    }
    class Tr2 extends se2 {
    }
    class kr2 extends Tr2 {
    }
    class Pr2 extends Tr2 {
    }
    class $r2 extends se2 {
    }
    class Cr2 extends $r2 {
    }
    class Sr2 extends $r2 {
    }
    class Fr2 extends se2 {
    }
    class Er2 extends Fr2 {
    }
    class Ir2 extends Fr2 {
    }
    class Ar2 extends se2 {
    }
    class zr2 extends Ar2 {
    }
    class Lr2 extends Ar2 {
    }
    class Or2 extends se2 {
    }
    class Dr2 extends Or2 {
    }
    class Br2 extends Or2 {
    }
    class Nr2 extends se2 {
    }
    class jr2 extends Nr2 {
    }
    class Rr2 extends Nr2 {
    }
    class Vr2 extends se2 {
    }
    class Gr2 extends Vr2 {
    }
    class qr2 extends Vr2 {
    }
    class Ur2 extends se2 {
    }
    class Wr2 extends Ur2 {
    }
    class Hr2 extends Ur2 {
    }
    class Qr2 extends se2 {
    }
    class Kr2 extends Qr2 {
    }
    class Xr2 extends se2 {
    }
    class Jr2 extends Xr2 {
    }
    class Yr2 extends Xr2 {
    }
    class Zr2 extends se2 {
    }
    class es2 extends Zr2 {
    }
    class ts2 extends Zr2 {
    }
    class ns2 extends se2 {
    }
    class rs2 extends ns2 {
    }
    class ss2 extends ns2 {
    }
    class as2 extends se2 {
    }
    class os2 extends as2 {
    }
    class is2 extends as2 {
    }
    class ls2 extends se2 {
    }
    class ds2 extends ls2 {
    }
    class us2 extends ls2 {
    }
    class cs2 extends se2 {
    }
    class ps2 extends cs2 {
    }
    class ms2 extends cs2 {
    }
    class hs2 extends se2 {
    }
    class fs2 extends hs2 {
    }
    class _s2 extends hs2 {
    }
    class gs2 extends se2 {
    }
    class ws2 extends gs2 {
    }
    class bs2 extends gs2 {
    }
    class ys2 extends se2 {
    }
    class Ms2 extends ys2 {
    }
    class xs2 extends ys2 {
    }
    class vs2 extends se2 {
    }
    class Ts2 extends vs2 {
    }
    class ks2 extends vs2 {
    }
    class Ps2 extends se2 {
    }
    class $s2 extends Ps2 {
    }
    class Cs2 extends Ps2 {
    }
    class Ss2 extends se2 {
    }
    class Fs2 extends Ss2 {
    }
    class Es2 extends Ss2 {
    }
    class Is2 extends se2 {
    }
    class As2 extends Is2 {
    }
    class zs2 extends Is2 {
    }
    class Ls2 extends se2 {
    }
    class Os2 extends Ls2 {
    }
    class Ds2 extends Ls2 {
    }
    class Bs2 extends se2 {
    }
    class Ns2 extends Bs2 {
    }
    class js2 extends Bs2 {
    }
    class Rs2 extends se2 {
    }
    class Vs2 extends Rs2 {
    }
    class Gs2 extends Rs2 {
    }
    class qs2 extends se2 {
    }
    class Us2 extends qs2 {
    }
    class Ws2 extends qs2 {
    }
    class Hs2 extends se2 {
    }
    class Qs2 extends Hs2 {
    }
    class Ks2 extends Hs2 {
    }
    class Xs2 extends se2 {
    }
    class Js2 extends Xs2 {
    }
    class Ys2 extends Xs2 {
    }
    class Zs2 extends se2 {
    }
    class ea2 extends Zs2 {
    }
    class ta2 extends Zs2 {
    }
    class na2 extends se2 {
      forward_params = ["input_ids", "attention_mask", "position_ids", "past_key_values", "pixel_values", "image_grid_thw"];
    }
    class ra2 extends na2 {
      get_rope_index(e3, t3, n3, r3) {
        const { vision_config: s3, image_token_id: a3, video_token_id: o3, vision_start_token_id: i3 } = this.config, l3 = s3.spatial_merge_size ?? 2, d3 = [];
        if (t3 || n3) {
          let s4 = e3.tolist();
          r3 || (r3 = (0, p2.ones_like)(e3));
          const u3 = r3.tolist(), c3 = Array.from({ length: 3 }, ((t4) => Array.from({ length: e3.dims[0] }, ((t5) => Array.from({ length: e3.dims[1] }, ((e4) => 1)))))), m3 = t3 ? t3.tolist() : [], f3 = n3 ? n3.tolist() : [];
          let _3 = 0, g3 = 0;
          for (let e4 = 0; e4 < s4.length; ++e4) {
            const t4 = s4[e4].filter(((t5, n5) => 1 == u3[e4][n5])), n4 = t4.reduce(((e5, t5, n5) => (t5 == i3 && e5.push(n5), e5)), []).map(((e5) => t4[e5 + 1])), r4 = n4.filter(((e5) => e5 == a3)).length, p3 = n4.filter(((e5) => e5 == o3)).length;
            let w3 = [], b3 = 0, y3 = r4, M3 = p3;
            for (let e5 = 0; e5 < n4.length; ++e5) {
              const e6 = t4.findIndex(((e7, t5) => t5 > b3 && e7 == a3)), n5 = t4.findIndex(((e7, t5) => t5 > b3 && e7 == o3)), r5 = y3 > 0 && -1 !== e6 ? e6 : t4.length + 1, s5 = M3 > 0 && -1 !== n5 ? n5 : t4.length + 1;
              let i4, d4, u4, c4;
              r5 < s5 ? ([d4, u4, c4] = m3[_3], ++_3, --y3, i4 = r5) : ([d4, u4, c4] = f3[g3], ++g3, --M3, i4 = s5);
              const [p4, x4, v4] = [Number(d4), Math.floor(Number(u4) / l3), Math.floor(Number(c4) / l3)], T4 = i4 - b3, k4 = w3.length > 0 ? (0, h2.max)(w3.at(-1))[0] + 1 : 0;
              w3.push(Array.from({ length: 3 * T4 }, ((e7, t5) => k4 + t5 % T4)));
              const P4 = T4 + k4, $4 = p4 * x4 * v4, C3 = Array.from({ length: $4 }, ((e7, t5) => P4 + Math.floor(t5 / (x4 * v4)))), S3 = Array.from({ length: $4 }, ((e7, t5) => P4 + Math.floor(t5 / v4) % x4)), F3 = Array.from({ length: $4 }, ((e7, t5) => P4 + t5 % v4));
              w3.push([C3, S3, F3].flat()), b3 = i4 + $4;
            }
            if (b3 < t4.length) {
              const e5 = w3.length > 0 ? (0, h2.max)(w3.at(-1))[0] + 1 : 0, n5 = t4.length - b3;
              w3.push(Array.from({ length: 3 * n5 }, ((t5, r5) => e5 + r5 % n5)));
            }
            const x3 = w3.reduce(((e5, t5) => e5 + t5.length), 0), v3 = new Array(x3);
            let T3 = 0;
            for (let e5 = 0; e5 < 3; ++e5) for (let t5 = 0; t5 < w3.length; ++t5) {
              const n5 = w3[t5], r5 = n5.length / 3;
              for (let t6 = e5 * r5; t6 < (e5 + 1) * r5; ++t6) v3[T3++] = n5[t6];
            }
            let k3 = 0;
            const P3 = u3[e4];
            for (let t5 = 0; t5 < P3.length; ++t5) if (1 == P3[t5]) {
              for (let n5 = 0; n5 < 3; ++n5) c3[n5][e4][t5] = v3[n5 * x3 / 3 + k3];
              ++k3;
            }
            const $3 = (0, h2.max)(v3)[0];
            d3.push($3 + 1 - s4[e4].length);
          }
          return [new p2.Tensor("int64", c3.flat(1 / 0), [3, e3.dims[0], e3.dims[1]]), new p2.Tensor("int64", d3, [d3.length, 1])];
        }
        if (r3) {
          const { data: e4, dims: t4 } = Z2(r3), n4 = BigInt64Array.from({ length: 3 * e4.length }, ((t5, n5) => e4[n5 % e4.length])), s4 = Array.from({ length: t4[0] }, ((n5, r4) => (0, h2.max)(e4.subarray(t4[1] * r4, t4[1] * (r4 + 1)))[0] + 1n + BigInt(t4[1])));
          return [new p2.Tensor("int64", n4, [3, ...t4]), new p2.Tensor("int64", s4, [s4.length, 1])];
        }
        {
          const [t4, n4] = e3.dims, r4 = BigInt64Array.from({ length: 3 * t4 * n4 }, ((e4, r5) => BigInt(Math.floor(r5 % n4 / t4))));
          return [new p2.Tensor("int64", r4, [3, ...e3.dims]), (0, p2.zeros)([t4, 1])];
        }
      }
      async encode_image({ pixel_values: e3, image_grid_thw: t3 }) {
        return (await N2(this.sessions.vision_encoder, { pixel_values: e3, grid_thw: t3 })).image_features;
      }
      _merge_input_ids_with_image_features(e3) {
        return Q2({ image_token_id: this.config.image_token_id, ...e3 });
      }
      prepare_inputs_for_generation(e3, t3, n3) {
        if (t3.attention_mask && !t3.position_ids) if (t3.past_key_values) {
          t3.pixel_values = null;
          const e4 = BigInt(Object.values(t3.past_key_values)[0].dims.at(-2)), n4 = t3.rope_deltas.map(((t4) => e4 + t4));
          t3.position_ids = (0, p2.stack)([n4, n4, n4], 0);
        } else [t3.position_ids, t3.rope_deltas] = this.get_rope_index(t3.input_ids, t3.image_grid_thw, t3.video_grid_thw, t3.attention_mask);
        return t3;
      }
    }
    class sa2 extends se2 {
    }
    class aa2 extends sa2 {
    }
    class oa2 extends sa2 {
    }
    class ia2 extends se2 {
    }
    class la2 extends ia2 {
    }
    class da2 extends ia2 {
    }
    class ua2 extends se2 {
    }
    class ca2 extends ua2 {
    }
    class pa2 extends ua2 {
    }
    class ma2 extends se2 {
    }
    class ha2 extends ma2 {
    }
    class fa2 extends ma2 {
    }
    class _a2 extends se2 {
    }
    class ga2 extends _a2 {
    }
    class wa2 extends _a2 {
    }
    class ba2 extends se2 {
    }
    class ya2 extends ba2 {
    }
    class Ma2 extends ba2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class xa2 extends se2 {
    }
    class va2 extends xa2 {
    }
    class Ta2 extends xa2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class ka2 extends se2 {
    }
    class Pa2 extends ka2 {
    }
    class $a2 extends se2 {
    }
    class Ca2 extends $a2 {
    }
    class Sa2 extends $a2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Fa2 extends se2 {
    }
    class Ea2 extends Fa2 {
    }
    class Ia2 extends se2 {
    }
    class Aa2 extends Ia2 {
    }
    class za2 extends Ia2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class La2 extends se2 {
    }
    class Oa2 extends La2 {
    }
    class Da2 extends se2 {
    }
    class Ba2 extends Da2 {
    }
    class Na2 extends Da2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class ja2 extends se2 {
    }
    class Ra2 extends ja2 {
      async _call(e3) {
        return new Nc2(await super._call(e3));
      }
    }
    class Va2 extends se2 {
    }
    class Ga2 extends Va2 {
    }
    class qa2 extends Va2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Ua2 extends se2 {
    }
    class Wa2 extends Ua2 {
    }
    class Ha2 extends Ua2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Qa2 extends se2 {
    }
    class Ka2 extends Qa2 {
    }
    class Xa2 extends Qa2 {
    }
    class Ja2 extends se2 {
    }
    class Ya2 extends Ja2 {
    }
    class Za2 extends Ja2 {
    }
    class eo2 extends se2 {
    }
    class to2 extends eo2 {
    }
    class no2 extends eo2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class ro2 extends se2 {
    }
    class so2 extends ro2 {
    }
    class ao2 extends ro2 {
      async _call(e3) {
        return new io2(await super._call(e3));
      }
    }
    class oo2 extends ro2 {
      async _call(e3) {
        return new lo2(await super._call(e3));
      }
    }
    class io2 extends ae2 {
      constructor({ logits: e3, pred_boxes: t3 }) {
        super(), this.logits = e3, this.pred_boxes = t3;
      }
    }
    class lo2 extends ae2 {
      constructor({ logits: e3, pred_boxes: t3, pred_masks: n3 }) {
        super(), this.logits = e3, this.pred_boxes = t3, this.pred_masks = n3;
      }
    }
    class uo2 extends se2 {
    }
    class co2 extends uo2 {
    }
    class po2 extends uo2 {
      async _call(e3) {
        return new mo2(await super._call(e3));
      }
    }
    class mo2 extends ae2 {
      constructor({ logits: e3, pred_boxes: t3 }) {
        super(), this.logits = e3, this.pred_boxes = t3;
      }
    }
    class ho2 extends se2 {
    }
    class fo2 extends ho2 {
    }
    class _o2 extends ho2 {
      async _call(e3) {
        return new go2(await super._call(e3));
      }
    }
    class go2 extends mo2 {
    }
    class wo2 extends se2 {
    }
    class bo2 extends wo2 {
    }
    class yo2 extends wo2 {
      async _call(e3) {
        return new Mo2(await super._call(e3));
      }
    }
    class Mo2 extends mo2 {
    }
    class xo2 extends se2 {
    }
    class vo2 extends xo2 {
    }
    class To2 extends xo2 {
      async _call(e3) {
        return new mo2(await super._call(e3));
      }
    }
    class ko2 extends se2 {
    }
    class Po2 extends ko2 {
    }
    class $o2 extends ko2 {
      async _call(e3) {
        return new Co2(await super._call(e3));
      }
    }
    class Co2 extends io2 {
    }
    class So2 extends se2 {
    }
    class Fo2 extends So2 {
    }
    class Eo2 extends So2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Io2 extends se2 {
    }
    class Ao2 extends Io2 {
    }
    class zo2 extends Io2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Lo2 extends se2 {
    }
    class Oo2 extends Lo2 {
    }
    class Do2 extends Lo2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Bo2 extends se2 {
    }
    class No2 extends Bo2 {
    }
    class jo2 extends Bo2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Ro2 extends Bo2 {
    }
    class Vo2 extends se2 {
    }
    class Go2 extends Vo2 {
    }
    class qo2 extends Vo2 {
    }
    class Uo2 extends se2 {
    }
    class Wo2 extends Uo2 {
    }
    class Ho2 extends Uo2 {
    }
    class Qo2 extends se2 {
    }
    class Ko2 extends Qo2 {
    }
    class Xo2 extends se2 {
    }
    class Jo2 extends Xo2 {
    }
    class Yo2 extends Xo2 {
    }
    class Zo2 extends Xo2 {
    }
    class ei2 extends se2 {
    }
    class ti2 extends ei2 {
    }
    class ni2 extends se2 {
    }
    class ri2 extends ni2 {
    }
    class si2 extends se2 {
    }
    class ai2 extends si2 {
    }
    class oi2 extends se2 {
    }
    class ii2 extends oi2 {
    }
    class li2 extends oi2 {
    }
    class di2 extends se2 {
    }
    class ui2 extends di2 {
    }
    class ci2 extends di2 {
    }
    class pi2 extends se2 {
    }
    class mi2 extends pi2 {
    }
    class hi2 extends se2 {
    }
    class fi2 extends hi2 {
    }
    class _i2 extends hi2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class gi2 extends se2 {
    }
    class wi2 extends gi2 {
    }
    class bi2 extends gi2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class yi2 extends se2 {
    }
    class Mi2 extends yi2 {
    }
    class xi2 extends yi2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class vi2 extends se2 {
    }
    class Ti2 extends vi2 {
    }
    class ki2 extends vi2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Pi2 extends se2 {
    }
    class $i2 extends Pi2 {
    }
    class Ci2 extends se2 {
    }
    class Si2 extends Ci2 {
    }
    class Fi2 extends se2 {
    }
    class Ei2 extends Fi2 {
    }
    class Ii2 extends se2 {
    }
    class Ai2 extends Ii2 {
    }
    class zi2 extends Ii2 {
      async _call(e3) {
        return new Li2(await super._call(e3));
      }
    }
    class Li2 extends ae2 {
      constructor({ logits: e3, pred_boxes: t3 }) {
        super(), this.logits = e3, this.pred_boxes = t3;
      }
    }
    class Oi2 extends se2 {
    }
    class Di2 extends Oi2 {
      async get_image_embeddings({ pixel_values: e3 }) {
        return await q2(this, { pixel_values: e3 });
      }
      async forward(e3) {
        e3 = e3.image_embeddings && e3.image_positional_embeddings ? { ...e3 } : { ...e3, ...await this.get_image_embeddings(e3) }, e3.input_labels ??= (0, p2.ones)(e3.input_points.dims.slice(0, -1));
        const t3 = { image_embeddings: e3.image_embeddings, image_positional_embeddings: e3.image_positional_embeddings };
        return e3.input_points && (t3.input_points = e3.input_points), e3.input_labels && (t3.input_labels = e3.input_labels), e3.input_boxes && (t3.input_boxes = e3.input_boxes), await N2(this.sessions.prompt_encoder_mask_decoder, t3);
      }
      async _call(e3) {
        return new Bi2(await super._call(e3));
      }
    }
    class Bi2 extends ae2 {
      constructor({ iou_scores: e3, pred_masks: t3 }) {
        super(), this.iou_scores = e3, this.pred_masks = t3;
      }
    }
    class Ni2 extends ae2 {
      constructor({ iou_scores: e3, pred_masks: t3, object_score_logits: n3 }) {
        super(), this.iou_scores = e3, this.pred_masks = t3, this.object_score_logits = n3;
      }
    }
    class ji2 extends se2 {
    }
    class Ri2 extends ji2 {
      async get_image_embeddings({ pixel_values: e3 }) {
        return await q2(this, { pixel_values: e3 });
      }
      async forward(e3) {
        const { num_feature_levels: t3 } = this.config.vision_config, n3 = Array.from({ length: t3 }, ((e4, t4) => `image_embeddings.${t4}`));
        if ((e3 = n3.some(((t4) => !e3[t4])) ? { ...e3, ...await this.get_image_embeddings(e3) } : { ...e3 }).input_points) {
          if (e3.input_boxes && 1 !== e3.input_boxes.dims[1]) throw new Error("When both `input_points` and `input_boxes` are provided, the number of boxes per image must be 1.");
          const t4 = e3.input_points.dims;
          e3.input_labels ??= (0, p2.ones)(t4.slice(0, -1)), e3.input_boxes ??= (0, p2.full)([t4[0], 0, 4], 0);
        } else {
          if (!e3.input_boxes) throw new Error("At least one of `input_points` or `input_boxes` must be provided.");
          {
            const t4 = e3.input_boxes.dims;
            e3.input_labels = (0, p2.full)([t4[0], t4[1], 0], -1n), e3.input_points = (0, p2.full)([t4[0], 1, 0, 2], 0);
          }
        }
        const r3 = this.sessions.prompt_encoder_mask_decoder, s3 = (0, i2.pick)(e3, r3.inputNames);
        return await N2(r3, s3);
      }
      async _call(e3) {
        return new Ni2(await super._call(e3));
      }
    }
    class Vi2 extends Ri2 {
    }
    class Gi2 extends Ri2 {
    }
    class qi2 extends se2 {
    }
    class Ui2 extends qi2 {
    }
    class Wi2 extends qi2 {
    }
    class Hi2 extends se2 {
    }
    class Qi2 extends Hi2 {
    }
    class Ki2 extends Hi2 {
    }
    class Xi2 extends se2 {
    }
    class Ji2 extends Xi2 {
    }
    class Yi2 extends Xi2 {
      async _call(e3) {
        return new Dc2(await super._call(e3));
      }
    }
    class Zi2 extends Xi2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class el2 extends Xi2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class tl2 extends se2 {
    }
    class nl2 extends tl2 {
      async _call(e3) {
        return new Dc2(await super._call(e3));
      }
    }
    class rl2 extends se2 {
    }
    class sl2 extends rl2 {
    }
    class al2 extends rl2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class ol2 extends se2 {
    }
    class il2 extends ol2 {
    }
    class ll2 extends se2 {
    }
    class dl2 extends ll2 {
    }
    class ul2 extends ll2 {
      async _call(e3) {
        return new Dc2(await super._call(e3));
      }
    }
    class cl2 extends ll2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class pl2 extends se2 {
    }
    class ml2 extends pl2 {
    }
    class hl2 extends pl2 {
      async _call(e3) {
        return new Dc2(await super._call(e3));
      }
    }
    class fl2 extends pl2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class _l2 extends pl2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class gl2 extends se2 {
    }
    class wl2 extends gl2 {
    }
    class bl2 extends gl2 {
      async _call(e3) {
        return new Dc2(await super._call(e3));
      }
    }
    class yl2 extends gl2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Ml2 extends se2 {
    }
    class xl2 extends Xi2 {
    }
    class vl2 extends Xi2 {
      async _call(e3) {
        return new Dc2(await super._call(e3));
      }
    }
    class Tl2 extends Xi2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class kl2 extends se2 {
    }
    class Pl2 extends kl2 {
    }
    class $l2 extends kl2 {
      async _call(e3) {
        return new Dc2(await super._call(e3));
      }
    }
    class Cl2 extends kl2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Sl2 extends kl2 {
      async _call(e3) {
        return new Ac2(await super._call(e3));
      }
    }
    class Fl2 extends kl2 {
      async _call(e3) {
        return new zc2(await super._call(e3));
      }
    }
    class El2 extends se2 {
    }
    class Il2 extends El2 {
    }
    class Al2 extends se2 {
    }
    class zl2 extends Al2 {
    }
    class Ll2 extends Al2 {
    }
    class Ol2 extends Al2 {
      async generate_speech(e3, t3, { threshold: n3 = 0.5, minlenratio: r3 = 0, maxlenratio: s3 = 20, vocoder: a3 = null } = {}) {
        const o3 = { input_ids: e3 }, { encoder_outputs: i3, encoder_attention_mask: l3 } = await q2(this, o3), d3 = i3.dims[1] / this.config.reduction_factor, u3 = Math.floor(d3 * s3), c3 = Math.floor(d3 * r3), m3 = this.config.num_mel_bins;
        let h3 = [], f3 = null, _3 = null, g3 = 0;
        for (; ; ) {
          ++g3;
          const e4 = V2(!!_3);
          let r4;
          r4 = _3 ? _3.output_sequence_out : new p2.Tensor("float32", new Float32Array(m3), [1, 1, m3]);
          let s4 = { use_cache_branch: e4, output_sequence: r4, encoder_attention_mask: l3, speaker_embeddings: t3, encoder_hidden_states: i3 };
          this.addPastKeyValues(s4, f3), _3 = await N2(this.sessions.decoder_model_merged, s4), f3 = this.getPastKeyValues(_3, f3);
          const { prob: a4, spectrum: o4 } = _3;
          if (h3.push(o4), g3 >= c3 && (Array.from(a4.data).filter(((e5) => e5 >= n3)).length > 0 || g3 >= u3)) break;
        }
        const w3 = (0, p2.cat)(h3), { waveform: b3 } = await N2(a3.sessions.model, { spectrogram: w3 });
        return { spectrogram: w3, waveform: b3 };
      }
    }
    class Dl2 extends se2 {
      main_input_name = "spectrogram";
    }
    class Bl2 extends se2 {
    }
    class Nl2 extends Bl2 {
      async generate_speech({ input_ids: e3, attention_mask: t3, style: n3, num_inference_steps: r3 = 5, speed: s3 = 1.05 }) {
        const { sampling_rate: a3, chunk_compress_factor: o3, base_chunk_size: i3, latent_dim: l3 } = this.config, { last_hidden_state: d3, durations: u3 } = await N2(this.sessions.text_encoder, { input_ids: e3, attention_mask: t3, style: n3 });
        u3.div_(s3);
        const c3 = u3.max().item() * a3, m3 = i3 * o3, h3 = Math.floor((c3 + m3 - 1) / m3), f3 = e3.dims[0], _3 = (0, p2.ones)([f3, h3]), g3 = (0, p2.full)([f3], r3);
        let w3 = (0, p2.randn)([f3, l3 * o3, h3]);
        for (let e4 = 0; e4 < r3; ++e4) {
          const r4 = (0, p2.full)([f3], e4);
          ({ denoised_latents: w3 } = await N2(this.sessions.latent_denoiser, { style: n3, noisy_latents: w3, latent_mask: _3, encoder_outputs: d3, attention_mask: t3, timestep: r4, num_inference_steps: g3 }));
        }
        const { waveform: b3 } = await N2(this.sessions.voice_decoder, { latents: w3 });
        return { waveform: b3, durations: u3 };
      }
    }
    class jl2 extends se2 {
    }
    class Rl2 extends jl2 {
    }
    class Vl2 extends se2 {
    }
    class Gl2 extends Vl2 {
    }
    class ql2 extends Vl2 {
    }
    class Ul2 extends se2 {
    }
    class Wl2 extends Ul2 {
    }
    class Hl2 extends Ul2 {
    }
    class Ql2 extends se2 {
    }
    class Kl2 extends Ql2 {
    }
    class Xl2 extends Ql2 {
    }
    class Jl2 extends se2 {
    }
    class Yl2 extends Jl2 {
    }
    class Zl2 extends Jl2 {
    }
    class ed2 extends se2 {
    }
    class td2 extends ed2 {
    }
    class nd2 extends ed2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "text_model" });
      }
    }
    class rd2 extends ed2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "audio_model" });
      }
    }
    class sd2 extends se2 {
    }
    class ad2 extends sd2 {
      async _call(e3) {
        return new jc2(await super._call(e3));
      }
    }
    class od2 extends se2 {
    }
    class id2 extends od2 {
    }
    class ld2 extends od2 {
    }
    class dd2 extends od2 {
    }
    class ud2 extends se2 {
    }
    class cd2 extends ud2 {
    }
    class pd2 extends ud2 {
    }
    class md2 extends se2 {
    }
    class hd2 extends md2 {
    }
    class fd2 extends md2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class _d2 extends se2 {
    }
    class gd2 extends _d2 {
    }
    class wd2 extends _d2 {
    }
    class bd2 extends se2 {
      forward_params = ["input_ids", "attention_mask", "encoder_outputs", "decoder_input_ids", "decoder_attention_mask", "past_key_values"];
      _apply_and_filter_by_delay_pattern_mask(e3) {
        const [t3, n3] = e3.dims, r3 = this.config.decoder.num_codebooks, s3 = n3 - r3;
        let a3 = 0;
        for (let t4 = 0; t4 < e3.size; ++t4) {
          if (e3.data[t4] === this.config.decoder.pad_token_id) continue;
          const o4 = t4 % n3 - Math.floor(t4 / n3) % r3;
          o4 > 0 && o4 <= s3 && (e3.data[a3++] = e3.data[t4]);
        }
        const o3 = Math.floor(t3 / r3), i3 = a3 / (o3 * r3);
        return new p2.Tensor(e3.type, e3.data.slice(0, a3), [o3, r3, i3]);
      }
      prepare_inputs_for_generation(e3, t3, n3) {
        let r3 = structuredClone(e3);
        for (let e4 = 0; e4 < r3.length; ++e4) for (let t4 = 0; t4 < r3[e4].length; ++t4) e4 % this.config.decoder.num_codebooks >= t4 && (r3[e4][t4] = BigInt(this.config.decoder.pad_token_id));
        null !== n3.guidance_scale && n3.guidance_scale > 1 && (r3 = r3.concat(r3));
        return super.prepare_inputs_for_generation(r3, t3, n3);
      }
      async generate(e3) {
        const t3 = await super.generate(e3), n3 = this._apply_and_filter_by_delay_pattern_mask(t3).unsqueeze_(0), { audio_values: r3 } = await N2(this.sessions.encodec_decode, { audio_codes: n3 });
        return r3;
      }
    }
    class yd2 extends se2 {
    }
    class Md2 extends yd2 {
    }
    class xd2 extends yd2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class vd2 extends yd2 {
    }
    class Td2 extends se2 {
    }
    class kd2 extends Td2 {
    }
    class Pd2 extends Td2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class $d2 extends Td2 {
    }
    class Cd2 extends se2 {
    }
    class Sd2 extends Cd2 {
    }
    class Fd2 extends Cd2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Ed2 extends Cd2 {
    }
    class Id2 extends se2 {
    }
    class Ad2 extends Id2 {
    }
    class zd2 extends Id2 {
      async _call(e3) {
        return new Ic2(await super._call(e3));
      }
    }
    class Ld2 extends Id2 {
    }
    class Od2 extends se2 {
    }
    class Dd2 extends Od2 {
    }
    class Bd2 extends se2 {
    }
    class Nd2 extends Bd2 {
      forward_params = ["input_ids", "pixel_values", "images_seq_mask", "images_emb_mask", "attention_mask", "position_ids", "past_key_values"];
      constructor(...e3) {
        super(...e3), this._generation_mode = "text";
      }
      async forward(e3) {
        const t3 = this._generation_mode ?? "text";
        let n3;
        if ("text" !== t3 && e3.past_key_values) {
          const t4 = this.sessions.gen_img_embeds, r4 = (0, i2.pick)({ image_ids: e3.input_ids }, t4.inputNames);
          n3 = await N2(t4, r4);
        } else {
          const t4 = this.sessions.prepare_inputs_embeds, r4 = (0, i2.pick)(e3, t4.inputNames);
          n3 = await N2(t4, r4);
        }
        const r3 = { ...e3, ...n3 }, s3 = await W2(this, r3), a3 = this.sessions["text" === t3 ? "lm_head" : "gen_head"];
        if (!a3) throw new Error(`Unable to find "${a3}" generation head`);
        const o3 = await N2(a3, (0, i2.pick)(s3, a3.inputNames));
        return { ...n3, ...s3, ...o3 };
      }
      async generate(e3) {
        return this._generation_mode = "text", super.generate(e3);
      }
      async generate_images(e3) {
        this._generation_mode = "image";
        const t3 = (e3.inputs ?? e3[this.main_input_name]).dims[1], n3 = (await super.generate(e3)).slice(null, [t3, null]), r3 = this.sessions.image_decode, { decoded_image: s3 } = await N2(r3, { generated_tokens: n3 }), a3 = s3.add_(1).mul_(127.5).clamp_(0, 255).to("uint8"), o3 = [];
        for (const e4 of a3) {
          const t4 = m2.RawImage.fromTensor(e4);
          o3.push(t4);
        }
        return o3;
      }
    }
    class jd2 extends ae2 {
      constructor({ char_logits: e3, bpe_logits: t3, wp_logits: n3 }) {
        super(), this.char_logits = e3, this.bpe_logits = t3, this.wp_logits = n3;
      }
      get logits() {
        return [this.char_logits, this.bpe_logits, this.wp_logits];
      }
    }
    class Rd2 extends se2 {
    }
    class Vd2 extends Rd2 {
      async _call(e3) {
        return new jd2(await super._call(e3));
      }
    }
    class Gd2 extends se2 {
    }
    class qd2 extends Gd2 {
    }
    class Ud2 extends Gd2 {
    }
    class Wd2 extends se2 {
    }
    class Hd2 extends Wd2 {
    }
    class Qd2 extends Wd2 {
    }
    class Kd2 extends se2 {
      forward_params = ["input_ids", "attention_mask", "position_ids", "audio_values", "past_key_values"];
    }
    class Xd2 extends Kd2 {
      _merge_input_ids_with_audio_features(e3) {
        const t3 = e3.audio_features.dims.at(-1), n3 = e3.audio_features.view(-1, t3);
        return K2({ audio_token_id: this.config.ignore_index ?? this.config.audio_token_id, ...e3, audio_features: n3 });
      }
    }
    class Jd2 extends Xd2 {
    }
    class Yd2 extends se2 {
      main_input_name = "input_values";
      forward_params = ["input_values"];
    }
    class Zd2 extends ae2 {
      constructor({ audio_codes: e3 }) {
        super(), this.audio_codes = e3;
      }
    }
    class eu2 extends ae2 {
      constructor({ audio_values: e3 }) {
        super(), this.audio_values = e3;
      }
    }
    class tu2 extends Yd2 {
      async encode(e3) {
        return new Zd2(await N2(this.sessions.encoder_model, e3));
      }
      async decode(e3) {
        return new eu2(await N2(this.sessions.decoder_model, e3));
      }
    }
    class nu2 extends Yd2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "encoder_model" });
      }
    }
    class ru2 extends Yd2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "decoder_model" });
      }
    }
    class su2 extends se2 {
      main_input_name = "input_values";
      forward_params = ["input_values"];
    }
    class au2 extends ae2 {
      constructor({ audio_codes: e3 }) {
        super(), this.audio_codes = e3;
      }
    }
    class ou2 extends ae2 {
      constructor({ audio_values: e3 }) {
        super(), this.audio_values = e3;
      }
    }
    class iu2 extends su2 {
      async encode(e3) {
        return new au2(await N2(this.sessions.encoder_model, e3));
      }
      async decode(e3) {
        return new ou2(await N2(this.sessions.decoder_model, e3));
      }
    }
    class lu2 extends su2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "encoder_model" });
      }
    }
    class du2 extends su2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "decoder_model" });
      }
    }
    class uu2 extends se2 {
      main_input_name = "input_values";
      forward_params = ["input_values"];
    }
    class cu2 extends uu2 {
      async encode(e3) {
        return await N2(this.sessions.encoder_model, e3);
      }
      async decode(e3) {
        return await N2(this.sessions.decoder_model, e3);
      }
    }
    class pu2 extends uu2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "encoder_model" });
      }
    }
    class mu2 extends uu2 {
      static async from_pretrained(e3, t3 = {}) {
        return super.from_pretrained(e3, { ...t3, model_file_name: t3.model_file_name ?? "decoder_model" });
      }
    }
    class hu2 {
      static MODEL_CLASS_MAPPINGS = null;
      static BASE_IF_FAIL = false;
      static async from_pretrained(e3, { progress_callback: t3 = null, config: n3 = null, cache_dir: s3 = null, local_files_only: a3 = false, revision: o3 = "main", model_file_name: i3 = null, subfolder: l3 = "onnx", device: d3 = null, dtype: u3 = null, use_external_data_format: c3 = null, session_options: p3 = {} } = {}) {
        const m3 = { progress_callback: t3, config: n3, cache_dir: s3, local_files_only: a3, revision: o3, model_file_name: i3, subfolder: l3, device: d3, dtype: u3, use_external_data_format: c3, session_options: p3 };
        if (m3.config = await r2.AutoConfig.from_pretrained(e3, m3), !this.MODEL_CLASS_MAPPINGS) throw new Error("`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: " + this.name);
        const h3 = m3.config.model_type;
        for (const t4 of this.MODEL_CLASS_MAPPINGS) {
          let n4 = t4.get(h3);
          if (!n4) {
            for (const e4 of t4.values()) if (e4[0] === h3) {
              n4 = e4;
              break;
            }
            if (!n4) continue;
          }
          return await n4[1].from_pretrained(e3, m3);
        }
        if (this.BASE_IF_FAIL) return Zu2.has(h3) || console.warn(`Unknown model class "${h3}", attempting to construct from base class.`), await se2.from_pretrained(e3, m3);
        throw Error(`Unsupported model type: ${h3}`);
      }
    }
    const fu2 = /* @__PURE__ */ new Map([["bert", ["BertModel", le2]], ["neobert", ["NeoBertModel", he2]], ["modernbert", ["ModernBertModel", ye2]], ["nomic_bert", ["NomicBertModel", Ce2]], ["roformer", ["RoFormerModel", Fe2]], ["electra", ["ElectraModel", Ve2]], ["esm", ["EsmModel", wt2]], ["convbert", ["ConvBertModel", Oe2]], ["camembert", ["CamembertModel", Qe2]], ["deberta", ["DebertaModel", et2]], ["deberta-v2", ["DebertaV2Model", ot2]], ["mpnet", ["MPNetModel", Ct2]], ["albert", ["AlbertModel", Nt2]], ["distilbert", ["DistilBertModel", pt2]], ["roberta", ["RobertaModel", fn2]], ["xlm", ["XLMModel", Mn2]], ["xlm-roberta", ["XLMRobertaModel", $n2]], ["clap", ["ClapModel", td2]], ["clip", ["CLIPModel", or2]], ["clipseg", ["CLIPSegModel", xr2]], ["chinese_clip", ["ChineseCLIPModel", _r2]], ["siglip", ["SiglipModel", pr2]], ["jina_clip", ["JinaCLIPModel", wr2]], ["mobilebert", ["MobileBertModel", vt2]], ["squeezebert", ["SqueezeBertModel", zt2]], ["wav2vec2", ["Wav2Vec2Model", Ji2]], ["wav2vec2-bert", ["Wav2Vec2BertModel", wl2]], ["unispeech", ["UniSpeechModel", dl2]], ["unispeech-sat", ["UniSpeechSatModel", ml2]], ["hubert", ["HubertModel", xl2]], ["wavlm", ["WavLMModel", Pl2]], ["audio-spectrogram-transformer", ["ASTModel", An2]], ["vits", ["VitsModel", ad2]], ["pyannote", ["PyAnnoteModel", sl2]], ["wespeaker-resnet", ["WeSpeakerResNetModel", il2]], ["detr", ["DetrModel", so2]], ["rt_detr", ["RTDetrModel", co2]], ["rt_detr_v2", ["RTDetrV2Model", fo2]], ["rf_detr", ["RFDetrModel", bo2]], ["d_fine", ["DFineModel", vo2]], ["table-transformer", ["TableTransformerModel", Po2]], ["vit", ["ViTModel", ya2]], ["ijepa", ["IJepaModel", va2]], ["pvt", ["PvtModel", Ca2]], ["vit_msn", ["ViTMSNModel", Aa2]], ["vit_mae", ["ViTMAEModel", Ea2]], ["groupvit", ["GroupViTModel", Oa2]], ["fastvit", ["FastViTModel", Ba2]], ["mobilevit", ["MobileViTModel", Ga2]], ["mobilevitv2", ["MobileViTV2Model", Wa2]], ["owlvit", ["OwlViTModel", Ka2]], ["owlv2", ["Owlv2Model", Ya2]], ["beit", ["BeitModel", to2]], ["deit", ["DeiTModel", Fo2]], ["hiera", ["HieraModel", Ao2]], ["convnext", ["ConvNextModel", fi2]], ["convnextv2", ["ConvNextV2Model", wi2]], ["dinov2", ["Dinov2Model", Mi2]], ["dinov2_with_registers", ["Dinov2WithRegistersModel", Ti2]], ["dinov3_vit", ["DINOv3ViTModel", $i2]], ["dinov3_convnext", ["DINOv3ConvNextModel", Si2]], ["resnet", ["ResNetModel", Oo2]], ["swin", ["SwinModel", No2]], ["swin2sr", ["Swin2SRModel", Go2]], ["donut-swin", ["DonutSwinModel", mi2]], ["yolos", ["YolosModel", Ai2]], ["dpt", ["DPTModel", Wo2]], ["glpn", ["GLPNModel", ui2]], ["hifigan", ["SpeechT5HifiGan", Dl2]], ["efficientnet", ["EfficientNetModel", hd2]], ["decision_transformer", ["DecisionTransformerModel", Dd2]], ["patchtst", ["PatchTSTForPrediction", qd2]], ["patchtsmixer", ["PatchTSMixerForPrediction", Hd2]], ["mobilenet_v1", ["MobileNetV1Model", Md2]], ["mobilenet_v2", ["MobileNetV2Model", kd2]], ["mobilenet_v3", ["MobileNetV3Model", Sd2]], ["mobilenet_v4", ["MobileNetV4Model", Ad2]], ["maskformer", ["MaskFormerModel", ii2]], ["mgp-str", ["MgpstrForSceneTextRecognition", Vd2]], ["style_text_to_speech_2", ["StyleTextToSpeech2Model", Il2]]]), _u2 = /* @__PURE__ */ new Map([["t5", ["T5Model", qt2]], ["longt5", ["LongT5Model", Ht2]], ["mt5", ["MT5Model", Xt2]], ["bart", ["BartModel", Zt2]], ["mbart", ["MBartModel", rn2]], ["marian", ["MarianModel", Ui2]], ["whisper", ["WhisperModel", On2]], ["m2m_100", ["M2M100Model", Qi2]], ["blenderbot", ["BlenderbotModel", dn2]], ["blenderbot-small", ["BlenderbotSmallModel", pn2]]]), gu2 = /* @__PURE__ */ new Map([["mimi", ["MimiModel", tu2]], ["dac", ["DacModel", iu2]], ["snac", ["SnacModel", cu2]]]), wu2 = /* @__PURE__ */ new Map([["bloom", ["BloomModel", ca2]], ["jais", ["JAISModel", Cr2]], ["gpt2", ["GPT2Model", kr2]], ["gptj", ["GPTJModel", Dr2]], ["gpt_bigcode", ["GPTBigCodeModel", jr2]], ["gpt_neo", ["GPTNeoModel", Er2]], ["gpt_neox", ["GPTNeoXModel", zr2]], ["codegen", ["CodeGenModel", Gr2]], ["llama", ["LlamaModel", Wr2]], ["nanochat", ["NanoChatModel", Jr2]], ["arcee", ["ArceeModel", es2]], ["lfm2", ["Lfm2Model", rs2]], ["smollm3", ["SmolLM3Model", os2]], ["exaone", ["ExaoneModel", fs2]], ["olmo", ["OlmoModel", Ms2]], ["olmo2", ["Olmo2Model", Ts2]], ["mobilellm", ["MobileLLMModel", ws2]], ["granite", ["GraniteModel", $s2]], ["granitemoehybrid", ["GraniteMoeHybridModel", Fs2]], ["cohere", ["CohereModel", As2]], ["gemma", ["GemmaModel", Os2]], ["gemma2", ["Gemma2Model", Ns2]], ["vaultgemma", ["VaultGemmaModel", Vs2]], ["gemma3_text", ["Gemma3Model", Us2]], ["helium", ["HeliumModel", ds2]], ["glm", ["GlmModel", ps2]], ["openelm", ["OpenELMModel", Qs2]], ["qwen2", ["Qwen2Model", Js2]], ["qwen3", ["Qwen3Model", ea2]], ["phi", ["PhiModel", aa2]], ["phi3", ["Phi3Model", la2]], ["mpt", ["MptModel", ha2]], ["opt", ["OPTModel", ga2]], ["mistral", ["MistralModel", Gl2]], ["ernie4_5", ["Ernie4_5_Model", Wl2]], ["starcoder2", ["Starcoder2Model", Kl2]], ["falcon", ["FalconModel", Yl2]], ["stablelm", ["StableLmModel", cd2]], ["modernbert-decoder", ["ModernBertDecoderModel", ke2]]]), bu2 = /* @__PURE__ */ new Map([["speecht5", ["SpeechT5ForSpeechToText", Ll2]], ["whisper", ["WhisperForConditionalGeneration", Dn2]], ["lite-whisper", ["LiteWhisperForConditionalGeneration", Bn2]], ["moonshine", ["MoonshineForConditionalGeneration", Rn2]]]), yu2 = /* @__PURE__ */ new Map([["speecht5", ["SpeechT5ForTextToSpeech", Ol2]]]), Mu2 = /* @__PURE__ */ new Map([["vits", ["VitsModel", ad2]], ["musicgen", ["MusicgenForConditionalGeneration", bd2]], ["supertonic", ["SupertonicForConditionalGeneration", Nl2]]]), xu2 = /* @__PURE__ */ new Map([["bert", ["BertForSequenceClassification", ue2]], ["neobert", ["NeoBertForSequenceClassification", _e2]], ["modernbert", ["ModernBertForSequenceClassification", xe2]], ["roformer", ["RoFormerForSequenceClassification", Ie2]], ["electra", ["ElectraForSequenceClassification", qe2]], ["esm", ["EsmForSequenceClassification", yt2]], ["convbert", ["ConvBertForSequenceClassification", Be2]], ["camembert", ["CamembertForSequenceClassification", Xe2]], ["deberta", ["DebertaForSequenceClassification", nt2]], ["deberta-v2", ["DebertaV2ForSequenceClassification", lt2]], ["mpnet", ["MPNetForSequenceClassification", Ft2]], ["albert", ["AlbertForSequenceClassification", jt2]], ["distilbert", ["DistilBertForSequenceClassification", mt2]], ["roberta", ["RobertaForSequenceClassification", gn2]], ["xlm", ["XLMForSequenceClassification", vn2]], ["xlm-roberta", ["XLMRobertaForSequenceClassification", Sn2]], ["bart", ["BartForSequenceClassification", tn2]], ["mbart", ["MBartForSequenceClassification", an2]], ["mobilebert", ["MobileBertForSequenceClassification", kt2]], ["squeezebert", ["SqueezeBertForSequenceClassification", Ot2]]]), vu2 = /* @__PURE__ */ new Map([["bert", ["BertForTokenClassification", ce2]], ["neobert", ["NeoBertForTokenClassification", ge2]], ["modernbert", ["ModernBertForTokenClassification", ve2]], ["roformer", ["RoFormerForTokenClassification", Ae2]], ["electra", ["ElectraForTokenClassification", Ue2]], ["esm", ["EsmForTokenClassification", Mt2]], ["convbert", ["ConvBertForTokenClassification", Ne2]], ["camembert", ["CamembertForTokenClassification", Je2]], ["deberta", ["DebertaForTokenClassification", rt2]], ["deberta-v2", ["DebertaV2ForTokenClassification", dt2]], ["mpnet", ["MPNetForTokenClassification", Et2]], ["distilbert", ["DistilBertForTokenClassification", ht2]], ["roberta", ["RobertaForTokenClassification", wn2]], ["xlm", ["XLMForTokenClassification", Tn2]], ["xlm-roberta", ["XLMRobertaForTokenClassification", Fn2]]]), Tu2 = /* @__PURE__ */ new Map([["t5", ["T5ForConditionalGeneration", Ut2]], ["longt5", ["LongT5ForConditionalGeneration", Qt2]], ["mt5", ["MT5ForConditionalGeneration", Jt2]], ["bart", ["BartForConditionalGeneration", en2]], ["mbart", ["MBartForConditionalGeneration", sn2]], ["marian", ["MarianMTModel", Wi2]], ["m2m_100", ["M2M100ForConditionalGeneration", Ki2]], ["blenderbot", ["BlenderbotForConditionalGeneration", un2]], ["blenderbot-small", ["BlenderbotSmallForConditionalGeneration", mn2]]]), ku2 = /* @__PURE__ */ new Map([["bloom", ["BloomForCausalLM", pa2]], ["gpt2", ["GPT2LMHeadModel", Pr2]], ["jais", ["JAISLMHeadModel", Sr2]], ["gptj", ["GPTJForCausalLM", Br2]], ["gpt_bigcode", ["GPTBigCodeForCausalLM", Rr2]], ["gpt_neo", ["GPTNeoForCausalLM", Ir2]], ["gpt_neox", ["GPTNeoXForCausalLM", Lr2]], ["codegen", ["CodeGenForCausalLM", qr2]], ["llama", ["LlamaForCausalLM", Hr2]], ["nanochat", ["NanoChatForCausalLM", Yr2]], ["llama4_text", ["Llama4ForCausalLM", Kr2]], ["arcee", ["ArceeForCausalLM", ts2]], ["lfm2", ["Lfm2ForCausalLM", ss2]], ["smollm3", ["SmolLM3ForCausalLM", is2]], ["exaone", ["ExaoneForCausalLM", _s2]], ["olmo", ["OlmoForCausalLM", xs2]], ["olmo2", ["Olmo2ForCausalLM", ks2]], ["mobilellm", ["MobileLLMForCausalLM", bs2]], ["granite", ["GraniteForCausalLM", Cs2]], ["granitemoehybrid", ["GraniteMoeHybridForCausalLM", Es2]], ["cohere", ["CohereForCausalLM", zs2]], ["gemma", ["GemmaForCausalLM", Ds2]], ["gemma2", ["Gemma2ForCausalLM", js2]], ["vaultgemma", ["VaultGemmaForCausalLM", Gs2]], ["gemma3_text", ["Gemma3ForCausalLM", Ws2]], ["helium", ["HeliumForCausalLM", us2]], ["glm", ["GlmForCausalLM", ms2]], ["openelm", ["OpenELMForCausalLM", Ks2]], ["qwen2", ["Qwen2ForCausalLM", Ys2]], ["qwen3", ["Qwen3ForCausalLM", ta2]], ["phi", ["PhiForCausalLM", oa2]], ["phi3", ["Phi3ForCausalLM", da2]], ["mpt", ["MptForCausalLM", fa2]], ["opt", ["OPTForCausalLM", wa2]], ["mbart", ["MBartForCausalLM", on2]], ["mistral", ["MistralForCausalLM", ql2]], ["ernie4_5", ["Ernie4_5_ForCausalLM", Hl2]], ["starcoder2", ["Starcoder2ForCausalLM", Xl2]], ["falcon", ["FalconForCausalLM", Zl2]], ["trocr", ["TrOCRForCausalLM", Rl2]], ["stablelm", ["StableLmForCausalLM", pd2]], ["modernbert-decoder", ["ModernBertDecoderForCausalLM", Pe2]], ["phi3_v", ["Phi3VForCausalLM", sr2]]]), Pu2 = /* @__PURE__ */ new Map([["multi_modality", ["MultiModalityCausalLM", Nd2]]]), $u2 = /* @__PURE__ */ new Map([["bert", ["BertForMaskedLM", de2]], ["neobert", ["NeoBertForMaskedLM", fe2]], ["modernbert", ["ModernBertForMaskedLM", Me2]], ["roformer", ["RoFormerForMaskedLM", Ee2]], ["electra", ["ElectraForMaskedLM", Ge2]], ["esm", ["EsmForMaskedLM", bt2]], ["convbert", ["ConvBertForMaskedLM", De2]], ["camembert", ["CamembertForMaskedLM", Ke2]], ["deberta", ["DebertaForMaskedLM", tt2]], ["deberta-v2", ["DebertaV2ForMaskedLM", it2]], ["mpnet", ["MPNetForMaskedLM", St2]], ["albert", ["AlbertForMaskedLM", Vt2]], ["distilbert", ["DistilBertForMaskedLM", _t2]], ["roberta", ["RobertaForMaskedLM", _n2]], ["xlm", ["XLMWithLMHeadModel", xn2]], ["xlm-roberta", ["XLMRobertaForMaskedLM", Cn2]], ["mobilebert", ["MobileBertForMaskedLM", Tt2]], ["squeezebert", ["SqueezeBertForMaskedLM", Lt2]]]), Cu2 = /* @__PURE__ */ new Map([["bert", ["BertForQuestionAnswering", pe2]], ["neobert", ["NeoBertForQuestionAnswering", we2]], ["roformer", ["RoFormerForQuestionAnswering", ze2]], ["electra", ["ElectraForQuestionAnswering", We2]], ["convbert", ["ConvBertForQuestionAnswering", je2]], ["camembert", ["CamembertForQuestionAnswering", Ye2]], ["deberta", ["DebertaForQuestionAnswering", st2]], ["deberta-v2", ["DebertaV2ForQuestionAnswering", ut2]], ["mpnet", ["MPNetForQuestionAnswering", It2]], ["albert", ["AlbertForQuestionAnswering", Rt2]], ["distilbert", ["DistilBertForQuestionAnswering", ft2]], ["roberta", ["RobertaForQuestionAnswering", bn2]], ["xlm", ["XLMForQuestionAnswering", kn2]], ["xlm-roberta", ["XLMRobertaForQuestionAnswering", En2]], ["mobilebert", ["MobileBertForQuestionAnswering", Pt2]], ["squeezebert", ["SqueezeBertForQuestionAnswering", Dt2]]]), Su2 = /* @__PURE__ */ new Map([["vision-encoder-decoder", ["VisionEncoderDecoderModel", Vn2]], ["idefics3", ["Idefics3ForConditionalGeneration", tr2]], ["smolvlm", ["SmolVLMForConditionalGeneration", nr2]]]), Fu2 = /* @__PURE__ */ new Map([["llava", ["LlavaForConditionalGeneration", qn2]], ["llava_onevision", ["LlavaOnevisionForConditionalGeneration", Un2]], ["moondream1", ["Moondream1ForConditionalGeneration", Wn2]], ["florence2", ["Florence2ForConditionalGeneration", Qn2]], ["qwen2-vl", ["Qwen2VLForConditionalGeneration", ra2]], ["idefics3", ["Idefics3ForConditionalGeneration", tr2]], ["smolvlm", ["SmolVLMForConditionalGeneration", nr2]], ["paligemma", ["PaliGemmaForConditionalGeneration", Xn2]], ["llava_qwen2", ["LlavaQwen2ForCausalLM", Jn2]], ["gemma3n", ["Gemma3nForConditionalGeneration", Zn2]]]), Eu2 = /* @__PURE__ */ new Map([["ultravox", ["UltravoxModel", Xd2]], ["voxtral", ["VoxtralForConditionalGeneration", Jd2]]]), Iu2 = /* @__PURE__ */ new Map([["vision-encoder-decoder", ["VisionEncoderDecoderModel", Vn2]]]), Au2 = /* @__PURE__ */ new Map([["vit", ["ViTForImageClassification", Ma2]], ["ijepa", ["IJepaForImageClassification", Ta2]], ["pvt", ["PvtForImageClassification", Sa2]], ["vit_msn", ["ViTMSNForImageClassification", za2]], ["fastvit", ["FastViTForImageClassification", Na2]], ["mobilevit", ["MobileViTForImageClassification", qa2]], ["mobilevitv2", ["MobileViTV2ForImageClassification", Ha2]], ["beit", ["BeitForImageClassification", no2]], ["deit", ["DeiTForImageClassification", Eo2]], ["hiera", ["HieraForImageClassification", zo2]], ["convnext", ["ConvNextForImageClassification", _i2]], ["convnextv2", ["ConvNextV2ForImageClassification", bi2]], ["dinov2", ["Dinov2ForImageClassification", xi2]], ["dinov2_with_registers", ["Dinov2WithRegistersForImageClassification", ki2]], ["resnet", ["ResNetForImageClassification", Do2]], ["swin", ["SwinForImageClassification", jo2]], ["segformer", ["SegformerForImageClassification", ld2]], ["efficientnet", ["EfficientNetForImageClassification", fd2]], ["mobilenet_v1", ["MobileNetV1ForImageClassification", xd2]], ["mobilenet_v2", ["MobileNetV2ForImageClassification", Pd2]], ["mobilenet_v3", ["MobileNetV3ForImageClassification", Fd2]], ["mobilenet_v4", ["MobileNetV4ForImageClassification", zd2]]]), zu2 = /* @__PURE__ */ new Map([["detr", ["DetrForObjectDetection", ao2]], ["rt_detr", ["RTDetrForObjectDetection", po2]], ["rt_detr_v2", ["RTDetrV2ForObjectDetection", _o2]], ["rf_detr", ["RFDetrForObjectDetection", yo2]], ["d_fine", ["DFineForObjectDetection", To2]], ["table-transformer", ["TableTransformerForObjectDetection", $o2]], ["yolos", ["YolosForObjectDetection", zi2]]]), Lu2 = /* @__PURE__ */ new Map([["owlvit", ["OwlViTForObjectDetection", Xa2]], ["owlv2", ["Owlv2ForObjectDetection", Za2]], ["grounding-dino", ["GroundingDinoForObjectDetection", Ei2]]]), Ou2 = /* @__PURE__ */ new Map([["detr", ["DetrForSegmentation", oo2]], ["clipseg", ["CLIPSegForImageSegmentation", vr2]]]), Du2 = /* @__PURE__ */ new Map([["segformer", ["SegformerForSemanticSegmentation", dd2]], ["sapiens", ["SapiensForSemanticSegmentation", Jo2]], ["swin", ["SwinForSemanticSegmentation", Ro2]], ["mobilenet_v1", ["MobileNetV1ForSemanticSegmentation", vd2]], ["mobilenet_v2", ["MobileNetV2ForSemanticSegmentation", $d2]], ["mobilenet_v3", ["MobileNetV3ForSemanticSegmentation", Ed2]], ["mobilenet_v4", ["MobileNetV4ForSemanticSegmentation", Ld2]]]), Bu2 = /* @__PURE__ */ new Map([["detr", ["DetrForSegmentation", oo2]], ["maskformer", ["MaskFormerForInstanceSegmentation", li2]]]), Nu2 = /* @__PURE__ */ new Map([["sam", ["SamModel", Di2]], ["sam2", ["Sam2Model", Ri2]], ["edgetam", ["EdgeTamModel", Vi2]], ["sam3_tracker", ["Sam3TrackerModel", Gi2]]]), ju2 = /* @__PURE__ */ new Map([["wav2vec2", ["Wav2Vec2ForCTC", Yi2]], ["wav2vec2-bert", ["Wav2Vec2BertForCTC", bl2]], ["unispeech", ["UniSpeechForCTC", ul2]], ["unispeech-sat", ["UniSpeechSatForCTC", hl2]], ["wavlm", ["WavLMForCTC", $l2]], ["hubert", ["HubertForCTC", vl2]], ["parakeet_ctc", ["ParakeetForCTC", nl2]]]), Ru2 = /* @__PURE__ */ new Map([["wav2vec2", ["Wav2Vec2ForSequenceClassification", Zi2]], ["wav2vec2-bert", ["Wav2Vec2BertForSequenceClassification", yl2]], ["unispeech", ["UniSpeechForSequenceClassification", cl2]], ["unispeech-sat", ["UniSpeechSatForSequenceClassification", fl2]], ["wavlm", ["WavLMForSequenceClassification", Cl2]], ["hubert", ["HubertForSequenceClassification", Tl2]], ["audio-spectrogram-transformer", ["ASTForAudioClassification", zn2]]]), Vu2 = /* @__PURE__ */ new Map([["wavlm", ["WavLMForXVector", Sl2]]]), Gu2 = /* @__PURE__ */ new Map([["unispeech-sat", ["UniSpeechSatForAudioFrameClassification", _l2]], ["wavlm", ["WavLMForAudioFrameClassification", Fl2]], ["wav2vec2", ["Wav2Vec2ForAudioFrameClassification", el2]], ["pyannote", ["PyAnnoteForAudioFrameClassification", al2]]]), qu2 = /* @__PURE__ */ new Map([["vitmatte", ["VitMatteForImageMatting", Ra2]]]), Uu2 = /* @__PURE__ */ new Map([["patchtst", ["PatchTSTForPrediction", Ud2]], ["patchtsmixer", ["PatchTSMixerForPrediction", Qd2]]]), Wu2 = /* @__PURE__ */ new Map([["swin2sr", ["Swin2SRForImageSuperResolution", qo2]]]), Hu2 = /* @__PURE__ */ new Map([["dpt", ["DPTForDepthEstimation", Ho2]], ["depth_anything", ["DepthAnythingForDepthEstimation", Ko2]], ["glpn", ["GLPNForDepthEstimation", ci2]], ["sapiens", ["SapiensForDepthEstimation", Yo2]], ["depth_pro", ["DepthProForDepthEstimation", ti2]], ["metric3d", ["Metric3DForDepthEstimation", ri2]], ["metric3dv2", ["Metric3Dv2ForDepthEstimation", ai2]]]), Qu2 = /* @__PURE__ */ new Map([["sapiens", ["SapiensForNormalEstimation", Zo2]]]), Ku2 = /* @__PURE__ */ new Map([["vitpose", ["VitPoseForPoseEstimation", Pa2]]]), Xu2 = /* @__PURE__ */ new Map([["clip", ["CLIPVisionModelWithProjection", ur2]], ["siglip", ["SiglipVisionModel", hr2]], ["jina_clip", ["JinaCLIPVisionModel", yr2]]]), Ju2 = [[fu2, y2], [_u2, M2], [wu2, T2], [gu2, E2], [xu2, y2], [vu2, y2], [Tu2, x2], [bu2, x2], [ku2, T2], [Pu2, C2], [$u2, y2], [Cu2, y2], [Su2, v2], [Fu2, P2], [Eu2, F2], [Au2, y2], [Ou2, y2], [Bu2, y2], [Du2, y2], [qu2, y2], [Uu2, y2], [Wu2, y2], [Hu2, y2], [Qu2, y2], [Ku2, y2], [zu2, y2], [Lu2, y2], [Nu2, k2], [ju2, y2], [Ru2, y2], [yu2, x2], [Mu2, y2], [Vu2, y2], [Gu2, y2], [Xu2, y2]];
    for (const [e3, t3] of Ju2) for (const [n3, r3] of e3.values()) z2.set(n3, t3), O2.set(r3, n3), L2.set(n3, r3);
    const Yu2 = [["MusicgenForConditionalGeneration", bd2, $2], ["Phi3VForCausalLM", sr2, S2], ["CLIPTextModelWithProjection", lr2, y2], ["SiglipTextModel", mr2, y2], ["JinaCLIPTextModel", br2, y2], ["ClapTextModelWithProjection", nd2, y2], ["ClapAudioModelWithProjection", rd2, y2], ["DacEncoderModel", lu2, y2], ["DacDecoderModel", du2, y2], ["MimiEncoderModel", nu2, y2], ["MimiDecoderModel", ru2, y2], ["SnacEncoderModel", pu2, y2], ["SnacDecoderModel", mu2, y2], ["Gemma3nForConditionalGeneration", Zn2, I2], ["SupertonicForConditionalGeneration", Nl2, A2]];
    for (const [e3, t3, n3] of Yu2) z2.set(e3, n3), O2.set(t3, e3), L2.set(e3, t3);
    const Zu2 = /* @__PURE__ */ new Map([["modnet", Ou2], ["birefnet", Ou2], ["isnet", Ou2], ["ben", Ou2]]);
    for (const [e3, t3] of Zu2.entries()) t3.set(e3, ["PreTrainedModel", se2]), z2.set(e3, y2), O2.set(se2, e3), L2.set(e3, se2);
    class ec2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = Ju2.map(((e3) => e3[0]));
      static BASE_IF_FAIL = true;
    }
    class tc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [xu2];
    }
    class nc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [vu2];
    }
    class rc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Tu2];
    }
    class sc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [bu2];
    }
    class ac2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [yu2];
    }
    class oc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Mu2];
    }
    class ic2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [ku2];
    }
    class lc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [$u2];
    }
    class dc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Cu2];
    }
    class uc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Su2];
    }
    class cc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Au2];
    }
    class pc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Ou2];
    }
    class mc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Du2];
    }
    class hc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Bu2];
    }
    class fc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [zu2];
    }
    class _c2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Lu2];
    }
    class gc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Nu2];
    }
    class wc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [ju2];
    }
    class bc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Ru2];
    }
    class yc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Vu2];
    }
    class Mc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Gu2];
    }
    class xc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Iu2];
    }
    class vc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [qu2];
    }
    class Tc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Wu2];
    }
    class kc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Hu2];
    }
    class Pc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Qu2];
    }
    class $c2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Ku2];
    }
    class Cc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Xu2];
    }
    class Sc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Fu2];
    }
    class Fc2 extends hu2 {
      static MODEL_CLASS_MAPPINGS = [Eu2];
    }
    class Ec2 extends ae2 {
      constructor({ logits: e3, past_key_values: t3, encoder_outputs: n3, decoder_attentions: r3 = null, cross_attentions: s3 = null }) {
        super(), this.logits = e3, this.past_key_values = t3, this.encoder_outputs = n3, this.decoder_attentions = r3, this.cross_attentions = s3;
      }
    }
    class Ic2 extends ae2 {
      constructor({ logits: e3, ...t3 }) {
        super(), this.logits = e3;
        const n3 = Object.values(t3);
        n3.length > 0 && (this.attentions = n3);
      }
    }
    class Ac2 extends ae2 {
      constructor({ logits: e3, embeddings: t3 }) {
        super(), this.logits = e3, this.embeddings = t3;
      }
    }
    class zc2 extends ae2 {
      constructor({ logits: e3 }) {
        super(), this.logits = e3;
      }
    }
    class Lc2 extends ae2 {
      constructor({ logits: e3 }) {
        super(), this.logits = e3;
      }
    }
    class Oc2 extends ae2 {
      constructor({ start_logits: e3, end_logits: t3 }) {
        super(), this.start_logits = e3, this.end_logits = t3;
      }
    }
    class Dc2 extends ae2 {
      constructor({ logits: e3 }) {
        super(), this.logits = e3;
      }
    }
    class Bc2 extends ae2 {
      constructor({ logits: e3, past_key_values: t3 }) {
        super(), this.logits = e3, this.past_key_values = t3;
      }
    }
    class Nc2 extends ae2 {
      constructor({ alphas: e3 }) {
        super(), this.alphas = e3;
      }
    }
    class jc2 extends ae2 {
      constructor({ waveform: e3, spectrogram: t3 }) {
        super(), this.waveform = e3, this.spectrogram = t3;
      }
    }
  }, "./src/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { ASTFeatureExtractor: () => a2 });
    var r2 = n2("./src/base/feature_extraction_utils.js"), s2 = (n2("./src/utils/tensor.js"), n2("./src/utils/audio.js"));
    class a2 extends r2.FeatureExtractor {
      constructor(e3) {
        super(e3);
        const t3 = this.config.sampling_rate, n3 = (0, s2.mel_filter_bank)(257, this.config.num_mel_bins, 20, Math.floor(t3 / 2), t3, null, "kaldi", true);
        this.mel_filters = n3, this.window = (0, s2.window_function)(400, "hann", { periodic: false }), this.mean = this.config.mean, this.std = this.config.std;
      }
      async _extract_fbank_features(e3, t3) {
        return (0, s2.spectrogram)(e3, this.window, 400, 160, { fft_length: 512, power: 2, center: false, preemphasis: 0.97, mel_filters: this.mel_filters, log_mel: "log", mel_floor: 1192092955078125e-22, remove_dc_offset: true, max_num_frames: t3, transpose: true });
      }
      async _call(e3) {
        (0, r2.validate_audio_inputs)(e3, "ASTFeatureExtractor");
        const t3 = await this._extract_fbank_features(e3, this.config.max_length);
        if (this.config.do_normalize) {
          const e4 = 2 * this.std, n3 = t3.data;
          for (let t4 = 0; t4 < n3.length; ++t4) n3[t4] = (n3[t4] - this.mean) / e4;
        }
        return { input_values: t3.unsqueeze_(0) };
      }
    }
  }, "./src/models/auto/feature_extraction_auto.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { AutoFeatureExtractor: () => o2 });
    var r2 = n2("./src/utils/constants.js"), s2 = n2("./src/utils/hub.js"), a2 = (n2("./src/base/feature_extraction_utils.js"), n2("./src/models/feature_extractors.js"));
    class o2 {
      static async from_pretrained(e3, t3 = {}) {
        const n3 = await (0, s2.getModelJSON)(e3, r2.FEATURE_EXTRACTOR_NAME, true, t3), o3 = n3.feature_extractor_type, i2 = a2[o3];
        if (!i2) throw new Error(`Unknown feature_extractor_type: '${o3}'. Please report this at ${r2.GITHUB_ISSUE_URL}.`);
        return new i2(n3);
      }
    }
  }, "./src/models/auto/image_processing_auto.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { AutoImageProcessor: () => i2 });
    var r2 = n2("./src/utils/constants.js"), s2 = n2("./src/utils/hub.js"), a2 = n2("./src/base/image_processors_utils.js"), o2 = n2("./src/models/image_processors.js");
    class i2 {
      static async from_pretrained(e3, t3 = {}) {
        const n3 = await (0, s2.getModelJSON)(e3, r2.IMAGE_PROCESSOR_NAME, true, t3), i3 = n3.image_processor_type ?? n3.feature_extractor_type;
        let l2 = o2[i3?.replace(/Fast$/, "")];
        return l2 || (void 0 !== i3 && console.warn(`Image processor type '${i3}' not found, assuming base ImageProcessor. Please report this at ${r2.GITHUB_ISSUE_URL}.`), l2 = a2.ImageProcessor), new l2(n3);
      }
    }
  }, "./src/models/auto/processing_auto.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { AutoProcessor: () => d2 });
    var r2 = n2("./src/utils/constants.js"), s2 = n2("./src/utils/hub.js"), a2 = n2("./src/base/processing_utils.js"), o2 = n2("./src/models/processors.js"), i2 = n2("./src/models/image_processors.js"), l2 = n2("./src/models/feature_extractors.js");
    class d2 {
      static async from_pretrained(e3, t3 = {}) {
        const n3 = await (0, s2.getModelJSON)(e3, r2.IMAGE_PROCESSOR_NAME, true, t3), { image_processor_type: d3, feature_extractor_type: u2, processor_class: c2 } = n3;
        if (c2 && o2[c2]) return o2[c2].from_pretrained(e3, t3);
        if (!d3 && !u2) throw new Error("No `image_processor_type` or `feature_extractor_type` found in the config.");
        const p2 = {};
        if (d3) {
          const e4 = i2[d3.replace(/Fast$/, "")];
          if (!e4) throw new Error(`Unknown image_processor_type: '${d3}'.`);
          p2.image_processor = new e4(n3);
        }
        if (u2) {
          const e4 = i2[u2];
          if (e4) p2.image_processor = new e4(n3);
          else {
            const e5 = l2[u2];
            if (!e5) throw new Error(`Unknown feature_extractor_type: '${u2}'.`);
            p2.feature_extractor = new e5(n3);
          }
        }
        return new a2.Processor({}, p2, null);
      }
    }
  }, "./src/models/beit/image_processing_beit.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { BeitFeatureExtractor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
  }, "./src/models/bit/image_processing_bit.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { BitImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
  }, "./src/models/chinese_clip/image_processing_chinese_clip.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { ChineseCLIPFeatureExtractor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
  }, "./src/models/clap/feature_extraction_clap.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { ClapFeatureExtractor: () => a2 });
    var r2 = n2("./src/base/feature_extraction_utils.js"), s2 = (n2("./src/utils/tensor.js"), n2("./src/utils/audio.js"));
    class a2 extends r2.FeatureExtractor {
      constructor(e3) {
        super(e3), this.mel_filters = (0, s2.mel_filter_bank)(this.config.nb_frequency_bins, this.config.feature_size, this.config.frequency_min, this.config.frequency_max, this.config.sampling_rate, null, "htk"), this.mel_filters_slaney = (0, s2.mel_filter_bank)(this.config.nb_frequency_bins, this.config.feature_size, this.config.frequency_min, this.config.frequency_max, this.config.sampling_rate, "slaney", "slaney"), this.window = (0, s2.window_function)(this.config.fft_window_size, "hann");
      }
      async _get_input_mel(e3, t3, n3, r3) {
        let s3, a3 = false;
        const o2 = e3.length - t3;
        if (o2 > 0) {
          if ("rand_trunc" !== n3) throw new Error(`Truncation strategy "${n3}" not implemented`);
          {
            a3 = true;
            const n4 = Math.floor(Math.random() * (o2 + 1));
            e3 = e3.subarray(n4, n4 + t3), s3 = await this._extract_fbank_features(e3, this.mel_filters_slaney, this.config.nb_max_samples);
          }
        } else {
          if (o2 < 0) {
            let n4 = new Float64Array(t3);
            if (n4.set(e3), "repeat" === r3) for (let r4 = e3.length; r4 < t3; r4 += e3.length) n4.set(e3.subarray(0, Math.min(e3.length, t3 - r4)), r4);
            else if ("repeatpad" === r3) for (let t4 = e3.length; t4 < -o2; t4 += e3.length) n4.set(e3, t4);
            e3 = n4;
          }
          if ("fusion" === n3) throw new Error(`Truncation strategy "${n3}" not implemented`);
          s3 = await this._extract_fbank_features(e3, this.mel_filters_slaney, this.config.nb_max_samples);
        }
        return s3.unsqueeze_(0);
      }
      async _extract_fbank_features(e3, t3, n3 = null) {
        return (0, s2.spectrogram)(e3, this.window, this.config.fft_window_size, this.config.hop_length, { power: 2, mel_filters: t3, log_mel: "dB", max_num_frames: n3, do_pad: false, transpose: true });
      }
      async _call(e3, { max_length: t3 = null } = {}) {
        (0, r2.validate_audio_inputs)(e3, "ClapFeatureExtractor");
        return { input_features: (await this._get_input_mel(e3, t3 ?? this.config.nb_max_samples, this.config.truncation, this.config.padding)).unsqueeze_(0) };
      }
    }
  }, "./src/models/clip/image_processing_clip.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { CLIPFeatureExtractor: () => a2, CLIPImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
    class a2 extends s2 {
    }
  }, "./src/models/convnext/image_processing_convnext.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { ConvNextFeatureExtractor: () => a2, ConvNextImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
      constructor(e3) {
        super(e3), this.crop_pct = this.config.crop_pct ?? 0.875;
      }
      async resize(e3) {
        const t3 = this.size?.shortest_edge;
        if (void 0 === t3) throw new Error("Size dictionary must contain 'shortest_edge' key.");
        if (t3 < 384) {
          const n3 = Math.floor(t3 / this.crop_pct), [r3, s3] = this.get_resize_output_image_size(e3, { shortest_edge: n3 });
          e3 = await e3.resize(r3, s3, { resample: this.resample }), e3 = await e3.center_crop(t3, t3);
        } else e3 = await e3.resize(t3, t3, { resample: this.resample });
        return e3;
      }
    }
    class a2 extends s2 {
    }
  }, "./src/models/dac/feature_extraction_dac.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { DacFeatureExtractor: () => s2 });
    var r2 = n2("./src/models/encodec/feature_extraction_encodec.js");
    class s2 extends r2.EncodecFeatureExtractor {
    }
  }, "./src/models/deit/image_processing_deit.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { DeiTFeatureExtractor: () => a2, DeiTImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
    class a2 extends s2 {
    }
  }, "./src/models/detr/image_processing_detr.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { DetrFeatureExtractor: () => o2, DetrImageProcessor: () => a2 });
    var r2 = n2("./src/base/image_processors_utils.js"), s2 = n2("./src/utils/tensor.js");
    class a2 extends r2.ImageProcessor {
      async _call(e3) {
        const t3 = await super._call(e3), n3 = [t3.pixel_values.dims[0], 64, 64], r3 = (0, s2.full)(n3, 1n);
        return { ...t3, pixel_mask: r3 };
      }
      post_process_object_detection(...e3) {
        return (0, r2.post_process_object_detection)(...e3);
      }
      post_process_panoptic_segmentation(...e3) {
        return (0, r2.post_process_panoptic_segmentation)(...e3);
      }
      post_process_instance_segmentation(...e3) {
        return (0, r2.post_process_instance_segmentation)(...e3);
      }
    }
    class o2 extends a2 {
    }
  }, "./src/models/dinov3_vit/image_processing_dinov3_vit.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { DINOv3ViTImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
  }, "./src/models/donut/image_processing_donut.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { DonutFeatureExtractor: () => a2, DonutImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
      pad_image(e3, t3, n3, r3 = {}) {
        const [s3, a3, o2] = t3;
        let i2 = this.image_mean;
        Array.isArray(this.image_mean) || (i2 = new Array(o2).fill(i2));
        let l2 = this.image_std;
        Array.isArray(l2) || (l2 = new Array(o2).fill(i2));
        const d2 = i2.map(((e4, t4) => -e4 / l2[t4]));
        return super.pad_image(e3, t3, n3, { center: true, constant_values: d2, ...r3 });
      }
    }
    class a2 extends s2 {
    }
  }, "./src/models/dpt/image_processing_dpt.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { DPTFeatureExtractor: () => a2, DPTImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
    class a2 extends s2 {
    }
  }, "./src/models/efficientnet/image_processing_efficientnet.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { EfficientNetImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
      constructor(e3) {
        super(e3), this.include_top = this.config.include_top ?? true, this.include_top && (this.image_std = this.image_std.map(((e4) => e4 * e4)));
      }
    }
  }, "./src/models/encodec/feature_extraction_encodec.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { EncodecFeatureExtractor: () => a2 });
    var r2 = n2("./src/base/feature_extraction_utils.js"), s2 = n2("./src/utils/tensor.js");
    class a2 extends r2.FeatureExtractor {
      async _call(e3) {
        (0, r2.validate_audio_inputs)(e3, "EncodecFeatureExtractor"), e3 instanceof Float64Array && (e3 = new Float32Array(e3));
        const t3 = this.config.feature_size;
        if (e3.length % t3 != 0) throw new Error(`The length of the audio data must be a multiple of the number of channels (${t3}).`);
        const n3 = [1, t3, e3.length / t3];
        return { input_values: new s2.Tensor("float32", e3, n3) };
      }
    }
  }, "./src/models/feature_extractors.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { ASTFeatureExtractor: () => r2.ASTFeatureExtractor, ClapFeatureExtractor: () => a2.ClapFeatureExtractor, DacFeatureExtractor: () => o2.DacFeatureExtractor, EncodecFeatureExtractor: () => s2.EncodecFeatureExtractor, Gemma3nAudioFeatureExtractor: () => i2.Gemma3nAudioFeatureExtractor, ImageFeatureExtractor: () => g2.ImageProcessor, MoonshineFeatureExtractor: () => l2.MoonshineFeatureExtractor, ParakeetFeatureExtractor: () => d2.ParakeetFeatureExtractor, PyAnnoteFeatureExtractor: () => u2.PyAnnoteFeatureExtractor, SeamlessM4TFeatureExtractor: () => c2.SeamlessM4TFeatureExtractor, SnacFeatureExtractor: () => p2.SnacFeatureExtractor, SpeechT5FeatureExtractor: () => m2.SpeechT5FeatureExtractor, Wav2Vec2FeatureExtractor: () => h2.Wav2Vec2FeatureExtractor, WeSpeakerFeatureExtractor: () => f2.WeSpeakerFeatureExtractor, WhisperFeatureExtractor: () => _2.WhisperFeatureExtractor });
    var r2 = n2("./src/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.js"), s2 = n2("./src/models/encodec/feature_extraction_encodec.js"), a2 = n2("./src/models/clap/feature_extraction_clap.js"), o2 = n2("./src/models/dac/feature_extraction_dac.js"), i2 = n2("./src/models/gemma3n/feature_extraction_gemma3n.js"), l2 = n2("./src/models/moonshine/feature_extraction_moonshine.js"), d2 = n2("./src/models/parakeet/feature_extraction_parakeet.js"), u2 = n2("./src/models/pyannote/feature_extraction_pyannote.js"), c2 = n2("./src/models/seamless_m4t/feature_extraction_seamless_m4t.js"), p2 = n2("./src/models/snac/feature_extraction_snac.js"), m2 = n2("./src/models/speecht5/feature_extraction_speecht5.js"), h2 = n2("./src/models/wav2vec2/feature_extraction_wav2vec2.js"), f2 = n2("./src/models/wespeaker/feature_extraction_wespeaker.js"), _2 = n2("./src/models/whisper/feature_extraction_whisper.js"), g2 = n2("./src/base/image_processors_utils.js");
  }, "./src/models/florence2/processing_florence2.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Florence2Processor: () => o2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js"), a2 = n2("./src/tokenizers.js");
    class o2 extends r2.Processor {
      static tokenizer_class = a2.AutoTokenizer;
      static image_processor_class = s2.AutoImageProcessor;
      constructor(e3, t3, n3) {
        super(e3, t3, n3);
        const { tasks_answer_post_processing_type: r3, task_prompts_without_inputs: s3, task_prompts_with_input: a3 } = this.image_processor.config;
        this.tasks_answer_post_processing_type = new Map(Object.entries(r3 ?? {})), this.task_prompts_without_inputs = new Map(Object.entries(s3 ?? {})), this.task_prompts_with_input = new Map(Object.entries(a3 ?? {})), this.regexes = { quad_boxes: /(.+?)<loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)>/gm, bboxes: /([^<]+)?<loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)>/gm }, this.size_per_bin = 1e3;
      }
      construct_prompts(e3) {
        "string" == typeof e3 && (e3 = [e3]);
        const t3 = [];
        for (const n3 of e3) if (this.task_prompts_without_inputs.has(n3)) t3.push(this.task_prompts_without_inputs.get(n3));
        else {
          for (const [e4, r3] of this.task_prompts_with_input) if (n3.includes(e4)) {
            t3.push(r3.replaceAll("{input}", n3).replaceAll(e4, ""));
            break;
          }
          t3.length !== e3.length && t3.push(n3);
        }
        return t3;
      }
      post_process_generation(e3, t3, n3) {
        const r3 = this.tasks_answer_post_processing_type.get(t3) ?? "pure_text";
        let s3;
        switch (e3 = e3.replaceAll("<s>", "").replaceAll("</s>", ""), r3) {
          case "pure_text":
            s3 = e3;
            break;
          case "description_with_bboxes":
          case "bboxes":
          case "phrase_grounding":
          case "ocr":
            const a3 = "ocr" === r3 ? "quad_boxes" : "bboxes", o3 = e3.matchAll(this.regexes[a3]), i2 = [], l2 = [];
            for (const [e4, t4, ...r4] of o3) i2.push(t4 ? t4.trim() : i2.at(-1) ?? ""), l2.push(r4.map(((e5, t5) => (Number(e5) + 0.5) / this.size_per_bin * n3[t5 % 2])));
            s3 = { labels: i2, [a3]: l2 };
            break;
          default:
            throw new Error(`Task "${t3}" (of type "${r3}") not yet implemented.`);
        }
        return { [t3]: s3 };
      }
      async _call(e3, t3 = null, n3 = {}) {
        if (!e3 && !t3) throw new Error("Either text or images must be provided");
        return { ...await this.image_processor(e3, n3), ...t3 ? this.tokenizer(this.construct_prompts(t3), n3) : {} };
      }
    }
  }, "./src/models/gemma3n/feature_extraction_gemma3n.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Gemma3nAudioFeatureExtractor: () => o2 });
    var r2 = n2("./src/base/feature_extraction_utils.js"), s2 = n2("./src/utils/tensor.js"), a2 = n2("./src/utils/audio.js");
    class o2 extends r2.FeatureExtractor {
      constructor(e3) {
        super(e3);
        const { fft_length: t3, feature_size: n3, min_frequency: r3, max_frequency: s3, sampling_rate: o3, frame_length: i2 } = this.config, l2 = (0, a2.mel_filter_bank)(Math.floor(1 + t3 / 2), n3, r3, s3, o3, null, "htk", false);
        this.mel_filters = l2, this.window = (0, a2.window_function)(i2, "hann");
      }
      async _extract_fbank_features(e3, t3) {
        return (0, a2.spectrogram)(e3, this.window, this.config.frame_length, this.config.hop_length, { fft_length: this.config.fft_length, center: false, onesided: true, preemphasis: this.config.preemphasis, preemphasis_htk_flavor: this.config.preemphasis_htk_flavor, mel_filters: this.mel_filters, log_mel: "log", mel_floor: this.config.mel_floor, remove_dc_offset: false, transpose: true });
      }
      async _call(e3, { max_length: t3 = 48e4, truncation: n3 = true, padding: a3 = true, pad_to_multiple_of: o3 = 128 } = {}) {
        if ((0, r2.validate_audio_inputs)(e3, "Gemma3nAudioFeatureExtractor"), n3 && e3.length > t3 && (e3 = e3.slice(0, t3)), a3 && e3.length % o3 != 0) {
          const t4 = o3 - e3.length % o3, n4 = new Float64Array(e3.length + t4);
          n4.set(e3), 0 !== this.config.padding_value && n4.fill(this.config.padding_value, e3.length), e3 = n4;
        }
        const i2 = await this._extract_fbank_features(e3, this.config.max_length), l2 = (0, s2.full)([1, i2.dims[0]], true);
        return { input_features: i2.unsqueeze_(0), input_features_mask: l2 };
      }
    }
  }, "./src/models/gemma3n/processing_gemma3n.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Gemma3nProcessor: () => i2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js"), a2 = n2("./src/models/auto/feature_extraction_auto.js"), o2 = n2("./src/tokenizers.js");
    n2("./src/utils/image.js"), n2("./src/utils/audio.js");
    class i2 extends r2.Processor {
      static image_processor_class = s2.AutoImageProcessor;
      static feature_extractor_class = a2.AutoFeatureExtractor;
      static tokenizer_class = o2.AutoTokenizer;
      static uses_processor_config = true;
      static uses_chat_template_file = true;
      constructor(e3, t3, n3) {
        super(e3, t3, n3), this.audio_seq_length = this.config.audio_seq_length, this.image_seq_length = this.config.image_seq_length;
        const { audio_token_id: r3, boa_token: s3, audio_token: a3, eoa_token: o3, image_token_id: i3, boi_token: l2, image_token: d2, eoi_token: u2 } = this.tokenizer.config;
        this.audio_token_id = r3, this.boa_token = s3, this.audio_token = a3;
        const c2 = a3.repeat(this.audio_seq_length);
        this.full_audio_sequence = `

${s3}${c2}${o3}

`, this.image_token_id = i3, this.boi_token = l2, this.image_token = d2;
        const p2 = d2.repeat(this.image_seq_length);
        this.full_image_sequence = `

${l2}${p2}${u2}

`;
      }
      async _call(e3, t3 = null, n3 = null, r3 = {}) {
        let s3, a3;
        return "string" == typeof e3 && (e3 = [e3]), n3 && (s3 = await this.feature_extractor(n3, r3), e3 = e3.map(((e4) => e4.replaceAll(this.audio_token, this.full_audio_sequence)))), t3 && (a3 = await this.image_processor(t3, r3), e3 = e3.map(((e4) => e4.replaceAll(this.image_token, this.full_image_sequence)))), { ...this.tokenizer(e3, r3), ...a3, ...s3 };
      }
    }
  }, "./src/models/glpn/image_processing_glpn.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { GLPNFeatureExtractor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
  }, "./src/models/grounding_dino/image_processing_grounding_dino.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { GroundingDinoImageProcessor: () => a2 });
    var r2 = n2("./src/base/image_processors_utils.js"), s2 = n2("./src/utils/tensor.js");
    class a2 extends r2.ImageProcessor {
      async _call(e3) {
        const t3 = await super._call(e3), n3 = t3.pixel_values.dims, r3 = (0, s2.ones)([n3[0], n3[2], n3[3]]);
        return { ...t3, pixel_mask: r3 };
      }
    }
  }, "./src/models/grounding_dino/processing_grounding_dino.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { GroundingDinoProcessor: () => l2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js"), a2 = n2("./src/tokenizers.js"), o2 = n2("./src/base/image_processors_utils.js");
    function i2(e3, t3) {
      const n3 = e3.dims.at(-1) - 1, r3 = e3.tolist();
      r3.fill(false, 0, 1), r3.fill(false, n3);
      const s3 = t3.tolist();
      return r3.map(((e4, t4) => e4 ? t4 : null)).filter(((e4) => null !== e4)).map(((e4) => s3[e4]));
    }
    class l2 extends r2.Processor {
      static tokenizer_class = a2.AutoTokenizer;
      static image_processor_class = s2.AutoImageProcessor;
      async _call(e3, t3, n3 = {}) {
        const r3 = e3 ? await this.image_processor(e3, n3) : {};
        return { ...t3 ? this.tokenizer(t3, n3) : {}, ...r3 };
      }
      post_process_grounded_object_detection(e3, t3, { box_threshold: n3 = 0.25, text_threshold: r3 = 0.25, target_sizes: s3 = null } = {}) {
        const { logits: a3, pred_boxes: l3 } = e3, d2 = a3.dims[0];
        if (null !== s3 && s3.length !== d2) throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");
        const u2 = a3.dims.at(1), c2 = a3.sigmoid(), p2 = c2.max(-1).tolist(), m2 = l3.tolist().map(((e4) => e4.map(((e5) => (0, o2.center_to_corners_format)(e5))))), h2 = [];
        for (let e4 = 0; e4 < d2; ++e4) {
          const a4 = null !== s3 ? s3[e4] : null;
          null !== a4 && (m2[e4] = m2[e4].map(((e5) => e5.map(((e6, t4) => e6 * a4[(t4 + 1) % 2])))));
          const o3 = p2[e4], l4 = [], d3 = [], f2 = [];
          for (let s4 = 0; s4 < u2; ++s4) {
            const a5 = o3[s4];
            if (a5 <= n3) continue;
            const u3 = m2[e4][s4], p3 = c2[e4][s4];
            l4.push(a5), f2.push(u3);
            const h3 = i2(p3.gt(r3), t3[e4]);
            d3.push(h3);
          }
          h2.push({ scores: l4, boxes: f2, labels: this.batch_decode(d3) });
        }
        return h2;
      }
    }
  }, "./src/models/idefics3/image_processing_idefics3.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Idefics3ImageProcessor: () => a2 });
    var r2 = n2("./src/base/image_processors_utils.js"), s2 = n2("./src/utils/tensor.js");
    class a2 extends r2.ImageProcessor {
      constructor(e3) {
        super(e3), this.do_image_splitting = e3.do_image_splitting ?? true, this.max_image_size = e3.max_image_size;
      }
      get_resize_for_vision_encoder(e3, t3) {
        let [n3, r3] = e3.dims.slice(-2);
        const s3 = r3 / n3;
        return r3 >= n3 ? (r3 = Math.ceil(r3 / t3) * t3, n3 = Math.floor(r3 / s3), n3 = Math.ceil(n3 / t3) * t3) : (n3 = Math.ceil(n3 / t3) * t3, r3 = Math.floor(n3 * s3), r3 = Math.ceil(r3 / t3) * t3), { height: n3, width: r3 };
      }
      async _call(e3, { do_image_splitting: t3 = null, return_row_col_info: n3 = false } = {}) {
        let r3;
        if (Array.isArray(e3)) {
          if (0 === e3.length || !e3[0]) throw new Error("No images provided.");
          r3 = Array.isArray(e3[0]) ? e3 : [e3];
        } else r3 = [[e3]];
        let a3 = [], o2 = [], i2 = [];
        const l2 = [], d2 = [];
        for (const e4 of r3) {
          let n4 = await Promise.all(e4.map(((e5) => this.preprocess(e5))));
          l2.push(...n4.map(((e5) => e5.original_size))), d2.push(...n4.map(((e5) => e5.reshaped_input_size))), n4.forEach(((e5) => e5.pixel_values.unsqueeze_(0)));
          const { longest_edge: r4 } = this.max_image_size;
          let u3;
          if (t3 ?? this.do_image_splitting) {
            let e5 = new Array(n4.length), t4 = new Array(n4.length);
            u3 = await Promise.all(n4.map((async (n5, a4) => {
              const o3 = this.get_resize_for_vision_encoder(n5.pixel_values, r4), i3 = await (0, s2.interpolate_4d)(n5.pixel_values, { size: [o3.height, o3.width] }), { frames: l3, num_splits_h: d3, num_splits_w: u4 } = await this.split_image(i3, this.max_image_size);
              return e5[a4] = d3, t4[a4] = u4, (0, s2.cat)(l3, 0);
            }))), o2.push(e5), i2.push(t4);
          } else {
            const e5 = [r4, r4];
            u3 = await Promise.all(n4.map(((t4) => (0, s2.interpolate_4d)(t4.pixel_values, { size: e5 })))), o2.push(new Array(n4.length).fill(0)), i2.push(new Array(n4.length).fill(0));
          }
          a3.push((0, s2.cat)(u3, 0));
        }
        const u2 = a3.length, [c2, p2, m2, h2] = a3[0].dims;
        let f2, _2;
        if (1 === u2) f2 = a3[0].unsqueeze_(0), _2 = (0, s2.full)([u2, c2, m2, h2], true);
        else {
          const e4 = Math.max(...a3.map(((e5) => e5.dims.at(0))));
          _2 = (0, s2.full)([u2, e4, m2, h2], true);
          const t4 = _2.data, n4 = e4 * m2 * h2;
          for (let r4 = 0; r4 < u2; ++r4) {
            const o3 = a3[r4].dims[0];
            if (o3 < e4) {
              a3[r4] = (0, s2.cat)([a3[r4], (0, s2.full)([e4 - o3, p2, m2, h2], 0)], 0);
              const i3 = r4 * n4 + o3 * m2 * h2, l3 = (r4 + 1) * n4;
              t4.fill(false, i3, l3);
            }
          }
          f2 = (0, s2.stack)(a3, 0);
        }
        return { pixel_values: f2, pixel_attention_mask: _2, original_sizes: l2, reshaped_input_sizes: d2, ...n3 ? { rows: o2, cols: i2 } : {} };
      }
      async split_image(e3, { longest_edge: t3 }) {
        const n3 = t3, r3 = t3, a3 = [], [o2, i2] = e3.dims.slice(-2);
        let l2 = 0, d2 = 0;
        if (o2 > n3 || i2 > r3) {
          l2 = Math.ceil(o2 / n3), d2 = Math.ceil(i2 / r3);
          const t4 = Math.ceil(o2 / l2), u2 = Math.ceil(i2 / d2);
          for (let n4 = 0; n4 < l2; ++n4) for (let r4 = 0; r4 < d2; ++r4) {
            let c3, p3, m2, h2;
            n4 === l2 - 1 ? (p3 = o2 - t4, h2 = o2) : (p3 = n4 * t4, h2 = (n4 + 1) * t4), r4 === d2 - 1 ? (c3 = i2 - u2, m2 = i2) : (c3 = r4 * u2, m2 = (r4 + 1) * u2);
            const f2 = [p3, c3], _2 = [h2, m2], g2 = await (0, s2.slice)(e3, f2, _2, [2, 3]);
            a3.push(g2);
          }
          const c2 = n3, p2 = r3;
          o2 === c2 && i2 === p2 || (e3 = await (0, s2.interpolate_4d)(e3, { size: [c2, p2] }));
        }
        return a3.push(e3), { frames: a3, num_splits_h: l2, num_splits_w: d2 };
      }
    }
  }, "./src/models/idefics3/processing_idefics3.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Idefics3Processor: () => l2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js"), a2 = n2("./src/tokenizers.js"), o2 = (n2("./src/utils/image.js"), n2("./src/utils/core.js"));
    function i2(e3, t3, n3, r3, s3, a3) {
      return 0 === e3 && 0 === t3 ? (function(e4, t4, n4, r4) {
        return `${t4}${r4}` + n4.repeat(e4) + `${t4}`;
      })(n3, r3, s3, a3) : (function(e4, t4, n4, r4, s4, a4) {
        let o3 = "";
        for (let a5 = 0; a5 < t4; ++a5) {
          for (let t5 = 0; t5 < n4; ++t5) o3 += r4 + `<row_${a5 + 1}_col_${t5 + 1}>` + s4.repeat(e4);
          o3 += "\n";
        }
        return o3 += `
${r4}${a4}` + s4.repeat(e4) + `${r4}`, o3;
      })(n3, e3, t3, r3, s3, a3);
    }
    class l2 extends r2.Processor {
      static image_processor_class = s2.AutoImageProcessor;
      static tokenizer_class = a2.AutoTokenizer;
      static uses_processor_config = true;
      fake_image_token = "<fake_token_around_image>";
      image_token = "<image>";
      global_img_token = "<global-img>";
      async _call(e3, t3 = null, n3 = {}) {
        let r3;
        n3.return_row_col_info ??= true, t3 && (r3 = await this.image_processor(t3, n3)), Array.isArray(e3) || (e3 = [e3]);
        const s3 = r3.rows ?? [new Array(e3.length).fill(0)], a3 = r3.cols ?? [new Array(e3.length).fill(0)], l3 = this.config.image_seq_len, d2 = [], u2 = [];
        for (let t4 = 0; t4 < e3.length; ++t4) {
          const n4 = e3[t4], r4 = s3[t4], c2 = a3[t4];
          d2.push((0, o2.count)(n4, this.image_token));
          const p2 = r4.map(((e4, t5) => i2(e4, c2[t5], l3, this.fake_image_token, this.image_token, this.global_img_token))), m2 = n4.split(this.image_token);
          if (0 === m2.length) throw new Error("The image token should be present in the text.");
          let h2 = m2[0];
          for (let e4 = 0; e4 < p2.length; ++e4) h2 += p2[e4] + m2[e4 + 1];
          u2.push(h2);
        }
        return { ...this.tokenizer(u2), ...r3 };
      }
    }
  }, "./src/models/image_processors.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { BeitFeatureExtractor: () => r2.BeitFeatureExtractor, BitImageProcessor: () => s2.BitImageProcessor, CLIPFeatureExtractor: () => o2.CLIPFeatureExtractor, CLIPImageProcessor: () => o2.CLIPImageProcessor, ChineseCLIPFeatureExtractor: () => a2.ChineseCLIPFeatureExtractor, ConvNextFeatureExtractor: () => i2.ConvNextFeatureExtractor, ConvNextImageProcessor: () => i2.ConvNextImageProcessor, DINOv3ViTImageProcessor: () => u2.DINOv3ViTImageProcessor, DPTFeatureExtractor: () => p2.DPTFeatureExtractor, DPTImageProcessor: () => p2.DPTImageProcessor, DeiTFeatureExtractor: () => l2.DeiTFeatureExtractor, DeiTImageProcessor: () => l2.DeiTImageProcessor, DetrFeatureExtractor: () => d2.DetrFeatureExtractor, DetrImageProcessor: () => d2.DetrImageProcessor, DonutFeatureExtractor: () => c2.DonutFeatureExtractor, DonutImageProcessor: () => c2.DonutImageProcessor, EfficientNetImageProcessor: () => m2.EfficientNetImageProcessor, GLPNFeatureExtractor: () => h2.GLPNFeatureExtractor, GroundingDinoImageProcessor: () => f2.GroundingDinoImageProcessor, Idefics3ImageProcessor: () => _2.Idefics3ImageProcessor, JinaCLIPImageProcessor: () => w2.JinaCLIPImageProcessor, LlavaOnevisionImageProcessor: () => b2.LlavaOnevisionImageProcessor, Mask2FormerImageProcessor: () => y2.Mask2FormerImageProcessor, MaskFormerFeatureExtractor: () => M2.MaskFormerFeatureExtractor, MaskFormerImageProcessor: () => M2.MaskFormerImageProcessor, MobileNetV1FeatureExtractor: () => x2.MobileNetV1FeatureExtractor, MobileNetV1ImageProcessor: () => x2.MobileNetV1ImageProcessor, MobileNetV2FeatureExtractor: () => v2.MobileNetV2FeatureExtractor, MobileNetV2ImageProcessor: () => v2.MobileNetV2ImageProcessor, MobileNetV3FeatureExtractor: () => T2.MobileNetV3FeatureExtractor, MobileNetV3ImageProcessor: () => T2.MobileNetV3ImageProcessor, MobileNetV4FeatureExtractor: () => k2.MobileNetV4FeatureExtractor, MobileNetV4ImageProcessor: () => k2.MobileNetV4ImageProcessor, MobileViTFeatureExtractor: () => P2.MobileViTFeatureExtractor, MobileViTImageProcessor: () => P2.MobileViTImageProcessor, NougatImageProcessor: () => $2.NougatImageProcessor, OwlViTFeatureExtractor: () => S2.OwlViTFeatureExtractor, OwlViTImageProcessor: () => S2.OwlViTImageProcessor, Owlv2ImageProcessor: () => C2.Owlv2ImageProcessor, Phi3VImageProcessor: () => F2.Phi3VImageProcessor, PvtImageProcessor: () => E2.PvtImageProcessor, Qwen2VLImageProcessor: () => I2.Qwen2VLImageProcessor, RTDetrImageProcessor: () => A2.RTDetrImageProcessor, Sam2ImageProcessor: () => L2.Sam2ImageProcessor, Sam3ImageProcessor: () => O2.Sam3ImageProcessor, SamImageProcessor: () => z2.SamImageProcessor, SegformerFeatureExtractor: () => D2.SegformerFeatureExtractor, SegformerImageProcessor: () => D2.SegformerImageProcessor, SiglipImageProcessor: () => B2.SiglipImageProcessor, SmolVLMImageProcessor: () => N2.SmolVLMImageProcessor, Swin2SRImageProcessor: () => j2.Swin2SRImageProcessor, VLMImageProcessor: () => g2.VLMImageProcessor, ViTFeatureExtractor: () => R2.ViTFeatureExtractor, ViTImageProcessor: () => R2.ViTImageProcessor, VitMatteImageProcessor: () => V2.VitMatteImageProcessor, VitPoseImageProcessor: () => G2.VitPoseImageProcessor, YolosFeatureExtractor: () => q2.YolosFeatureExtractor, YolosImageProcessor: () => q2.YolosImageProcessor });
    var r2 = n2("./src/models/beit/image_processing_beit.js"), s2 = n2("./src/models/bit/image_processing_bit.js"), a2 = n2("./src/models/chinese_clip/image_processing_chinese_clip.js"), o2 = n2("./src/models/clip/image_processing_clip.js"), i2 = n2("./src/models/convnext/image_processing_convnext.js"), l2 = n2("./src/models/deit/image_processing_deit.js"), d2 = n2("./src/models/detr/image_processing_detr.js"), u2 = n2("./src/models/dinov3_vit/image_processing_dinov3_vit.js"), c2 = n2("./src/models/donut/image_processing_donut.js"), p2 = n2("./src/models/dpt/image_processing_dpt.js"), m2 = n2("./src/models/efficientnet/image_processing_efficientnet.js"), h2 = n2("./src/models/glpn/image_processing_glpn.js"), f2 = n2("./src/models/grounding_dino/image_processing_grounding_dino.js"), _2 = n2("./src/models/idefics3/image_processing_idefics3.js"), g2 = n2("./src/models/janus/image_processing_janus.js"), w2 = n2("./src/models/jina_clip/image_processing_jina_clip.js"), b2 = n2("./src/models/llava_onevision/image_processing_llava_onevision.js"), y2 = n2("./src/models/mask2former/image_processing_mask2former.js"), M2 = n2("./src/models/maskformer/image_processing_maskformer.js"), x2 = n2("./src/models/mobilenet_v1/image_processing_mobilenet_v1.js"), v2 = n2("./src/models/mobilenet_v2/image_processing_mobilenet_v2.js"), T2 = n2("./src/models/mobilenet_v3/image_processing_mobilenet_v3.js"), k2 = n2("./src/models/mobilenet_v4/image_processing_mobilenet_v4.js"), P2 = n2("./src/models/mobilevit/image_processing_mobilevit.js"), $2 = n2("./src/models/nougat/image_processing_nougat.js"), C2 = n2("./src/models/owlv2/image_processing_owlv2.js"), S2 = n2("./src/models/owlvit/image_processing_owlvit.js"), F2 = n2("./src/models/phi3_v/image_processing_phi3_v.js"), E2 = n2("./src/models/pvt/image_processing_pvt.js"), I2 = n2("./src/models/qwen2_vl/image_processing_qwen2_vl.js"), A2 = n2("./src/models/rt_detr/image_processing_rt_detr.js"), z2 = n2("./src/models/sam/image_processing_sam.js"), L2 = n2("./src/models/sam2/image_processing_sam2.js"), O2 = n2("./src/models/sam3/image_processing_sam3.js"), D2 = n2("./src/models/segformer/image_processing_segformer.js"), B2 = n2("./src/models/siglip/image_processing_siglip.js"), N2 = n2("./src/models/smolvlm/image_processing_smolvlm.js"), j2 = n2("./src/models/swin2sr/image_processing_swin2sr.js"), R2 = n2("./src/models/vit/image_processing_vit.js"), V2 = n2("./src/models/vitmatte/image_processing_vitmatte.js"), G2 = n2("./src/models/vitpose/image_processing_vitpose.js"), q2 = n2("./src/models/yolos/image_processing_yolos.js");
  }, "./src/models/janus/image_processing_janus.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { VLMImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
      constructor(e3) {
        super({ do_pad: true, pad_size: { width: e3.image_size, height: e3.image_size }, ...e3 }), this.constant_values = this.config.background_color.map(((e4) => e4 * this.rescale_factor));
      }
      pad_image(e3, t3, n3, r3) {
        return super.pad_image(e3, t3, n3, { constant_values: this.constant_values, center: true, ...r3 });
      }
    }
  }, "./src/models/janus/processing_janus.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { VLChatProcessor: () => d2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js"), a2 = n2("./src/tokenizers.js"), o2 = n2("./src/utils/core.js"), i2 = n2("./src/utils/tensor.js"), l2 = n2("./src/utils/image.js");
    class d2 extends r2.Processor {
      static image_processor_class = s2.AutoImageProcessor;
      static tokenizer_class = a2.AutoTokenizer;
      static uses_processor_config = true;
      constructor(e3, t3, n3) {
        super(e3, t3, n3), this.image_tag = this.config.image_tag, this.image_start_tag = this.config.image_start_tag, this.image_end_tag = this.config.image_end_tag, this.num_image_tokens = this.config.num_image_tokens;
      }
      async _call(e3, { images: t3 = null, chat_template: n3 = "default" } = {}) {
        t3 ? Array.isArray(t3) || (t3 = [t3]) : t3 = await Promise.all(e3.filter(((e4) => e4.images)).flatMap(((e4) => e4.images)).map(((e4) => l2.RawImage.read(e4))));
        const r3 = this.tokenizer, s3 = (e4) => r3.encode(e4, { add_special_tokens: false }), a3 = r3.apply_chat_template(e3, { tokenize: false, add_generation_prompt: true, chat_template: n3 }).split(this.image_tag), d3 = a3.length - 1;
        if (t3.length !== d3) throw new Error(`Number of images provided (${t3.length}) does not match number of "${this.image_tag}" image tags (${d3})`);
        const [u2, c2, p2] = r3.model.convert_tokens_to_ids([this.image_tag, this.image_start_tag, this.image_end_tag]);
        let m2 = s3(a3[0]), h2 = new Array(m2.length).fill(false);
        for (let e4 = 1; e4 < a3.length; ++e4) {
          const t4 = new Array(this.num_image_tokens).fill(u2), n4 = s3(a3[e4]);
          m2 = (0, o2.mergeArrays)(m2, [c2], t4, [p2], n4);
          const r4 = new Array(this.num_image_tokens).fill(true);
          h2 = (0, o2.mergeArrays)(h2, [false], r4, [false], new Array(n4.length).fill(false));
        }
        const f2 = [1, m2.length], _2 = { input_ids: new i2.Tensor("int64", m2, f2), attention_mask: new i2.Tensor("int64", new Array(m2.length).fill(1), f2), images_seq_mask: new i2.Tensor("bool", h2, f2), images_emb_mask: new i2.Tensor("bool", new Array(d3 * this.num_image_tokens).fill(true), [1, d3, this.num_image_tokens]) };
        if (t3 && t3.length > 0) {
          const e4 = await this.image_processor(t3);
          return e4.pixel_values.unsqueeze_(0), { ..._2, ...e4 };
        }
        return _2;
      }
    }
  }, "./src/models/jina_clip/image_processing_jina_clip.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { JinaCLIPImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
      constructor(e3) {
        const { resize_mode: t3, fill_color: n3, interpolation: r3, size: s3, ...a2 } = e3;
        super({ ...a2, size: "squash" === t3 ? { width: s3, height: s3 } : "shortest" === t3 ? { shortest_edge: s3 } : { longest_edge: s3 }, resample: "bicubic" === r3 ? 3 : 2, do_center_crop: true, crop_size: s3, do_normalize: true });
      }
    }
  }, "./src/models/jina_clip/processing_jina_clip.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { JinaCLIPProcessor: () => o2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js"), a2 = n2("./src/tokenizers.js");
    class o2 extends r2.Processor {
      static tokenizer_class = a2.AutoTokenizer;
      static image_processor_class = s2.AutoImageProcessor;
      async _call(e3 = null, t3 = null, n3 = {}) {
        if (!e3 && !t3) throw new Error("Either text or images must be provided");
        return { ...e3 ? this.tokenizer(e3, n3) : {}, ...t3 ? await this.image_processor(t3, n3) : {} };
      }
    }
  }, "./src/models/llava/processing_llava.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { LlavaProcessor: () => o2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js"), a2 = n2("./src/tokenizers.js");
    class o2 extends r2.Processor {
      static tokenizer_class = a2.AutoTokenizer;
      static image_processor_class = s2.AutoImageProcessor;
      static uses_processor_config = true;
      async _call(e3, t3 = null, n3 = {}) {
        const r3 = await this.image_processor(e3, n3);
        if (t3) {
          const [e4, n4] = r3.pixel_values.dims.slice(-2), { image_token: s4, patch_size: a3, num_additional_image_tokens: o3 } = this.config, i2 = Math.floor(e4 / a3) * Math.floor(n4 / a3) + o3;
          t3 = structuredClone(t3), Array.isArray(t3) || (t3 = [t3]);
          for (let e5 = 0; e5 < t3.length; ++e5) t3[e5] = t3[e5].replace(s4, s4.repeat(i2));
        }
        const s3 = t3 ? this.tokenizer(t3, n3) : {};
        return { ...r3, ...s3 };
      }
    }
  }, "./src/models/llava_onevision/image_processing_llava_onevision.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { LlavaOnevisionImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
  }, "./src/models/mask2former/image_processing_mask2former.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Mask2FormerImageProcessor: () => s2 });
    var r2 = n2("./src/models/maskformer/image_processing_maskformer.js");
    class s2 extends r2.MaskFormerImageProcessor {
    }
  }, "./src/models/maskformer/image_processing_maskformer.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { MaskFormerFeatureExtractor: () => a2, MaskFormerImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
      post_process_panoptic_segmentation(...e3) {
        return (0, r2.post_process_panoptic_segmentation)(...e3);
      }
      post_process_instance_segmentation(...e3) {
        return (0, r2.post_process_instance_segmentation)(...e3);
      }
    }
    class a2 extends s2 {
    }
  }, "./src/models/mgp_str/processing_mgp_str.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { MgpstrProcessor: () => l2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js"), a2 = n2("./src/tokenizers.js"), o2 = n2("./src/utils/maths.js");
    const i2 = { char: ["char_decode", 1], bpe: ["bpe_decode", 2], wp: ["wp_decode", 102] };
    class l2 extends r2.Processor {
      static tokenizer_class = a2.AutoTokenizer;
      static image_processor_class = s2.AutoImageProcessor;
      get char_tokenizer() {
        return this.components.char_tokenizer;
      }
      get bpe_tokenizer() {
        return this.components.bpe_tokenizer;
      }
      get wp_tokenizer() {
        return this.components.wp_tokenizer;
      }
      _decode_helper(e3, t3) {
        if (!i2.hasOwnProperty(t3)) throw new Error(`Format ${t3} is not supported.`);
        const [n3, r3] = i2[t3], s3 = this[n3].bind(this), [a3, l3] = e3.dims, d2 = [], u2 = [], c2 = e3.tolist();
        for (let e4 = 0; e4 < a3; ++e4) {
          const t4 = c2[e4], n4 = [], s4 = [];
          for (let e5 = 1; e5 < l3; ++e5) {
            const [a5, i3] = (0, o2.max)((0, o2.softmax)(t4[e5]));
            if (s4.push(a5), i3 == r3) break;
            n4.push(i3);
          }
          const a4 = s4.length > 0 ? s4.reduce(((e5, t5) => e5 * t5), 1) : 0;
          u2.push(n4), d2.push(a4);
        }
        return [s3(u2), d2];
      }
      char_decode(e3) {
        return this.char_tokenizer.batch_decode(e3).map(((e4) => e4.replaceAll(" ", "")));
      }
      bpe_decode(e3) {
        return this.bpe_tokenizer.batch_decode(e3);
      }
      wp_decode(e3) {
        return this.wp_tokenizer.batch_decode(e3).map(((e4) => e4.replaceAll(" ", "")));
      }
      batch_decode([e3, t3, n3]) {
        const [r3, s3] = this._decode_helper(e3, "char"), [a3, i3] = this._decode_helper(t3, "bpe"), [l3, d2] = this._decode_helper(n3, "wp"), u2 = [], c2 = [];
        for (let e4 = 0; e4 < r3.length; ++e4) {
          const [t4, n4] = (0, o2.max)([s3[e4], i3[e4], d2[e4]]);
          u2.push([r3[e4], a3[e4], l3[e4]][n4]), c2.push(t4);
        }
        return { generated_text: u2, scores: c2, char_preds: r3, bpe_preds: a3, wp_preds: l3 };
      }
      static async from_pretrained(...e3) {
        const t3 = await super.from_pretrained(...e3), n3 = await a2.AutoTokenizer.from_pretrained("Xenova/gpt2"), r3 = await a2.AutoTokenizer.from_pretrained("Xenova/bert-base-uncased");
        return t3.components = { image_processor: t3.image_processor, char_tokenizer: t3.tokenizer, bpe_tokenizer: n3, wp_tokenizer: r3 }, t3;
      }
      async _call(e3, t3 = null) {
        const n3 = await this.image_processor(e3);
        return t3 && (n3.labels = this.tokenizer(t3).input_ids), n3;
      }
    }
  }, "./src/models/mobilenet_v1/image_processing_mobilenet_v1.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { MobileNetV1FeatureExtractor: () => a2, MobileNetV1ImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
    class a2 extends s2 {
    }
  }, "./src/models/mobilenet_v2/image_processing_mobilenet_v2.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { MobileNetV2FeatureExtractor: () => a2, MobileNetV2ImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
    class a2 extends s2 {
    }
  }, "./src/models/mobilenet_v3/image_processing_mobilenet_v3.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { MobileNetV3FeatureExtractor: () => a2, MobileNetV3ImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
    class a2 extends s2 {
    }
  }, "./src/models/mobilenet_v4/image_processing_mobilenet_v4.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { MobileNetV4FeatureExtractor: () => a2, MobileNetV4ImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
    class a2 extends s2 {
    }
  }, "./src/models/mobilevit/image_processing_mobilevit.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { MobileViTFeatureExtractor: () => a2, MobileViTImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
    class a2 extends s2 {
    }
  }, "./src/models/moonshine/feature_extraction_moonshine.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { MoonshineFeatureExtractor: () => a2 });
    var r2 = n2("./src/base/feature_extraction_utils.js"), s2 = n2("./src/utils/tensor.js");
    class a2 extends r2.FeatureExtractor {
      async _call(e3) {
        (0, r2.validate_audio_inputs)(e3, "MoonshineFeatureExtractor"), e3 instanceof Float64Array && (e3 = new Float32Array(e3));
        const t3 = [1, e3.length];
        return { input_values: new s2.Tensor("float32", e3, t3) };
      }
    }
  }, "./src/models/moonshine/processing_moonshine.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { MoonshineProcessor: () => o2 });
    var r2 = n2("./src/models/auto/feature_extraction_auto.js"), s2 = n2("./src/tokenizers.js"), a2 = n2("./src/base/processing_utils.js");
    class o2 extends a2.Processor {
      static tokenizer_class = s2.AutoTokenizer;
      static feature_extractor_class = r2.AutoFeatureExtractor;
      async _call(e3) {
        return await this.feature_extractor(e3);
      }
    }
  }, "./src/models/nougat/image_processing_nougat.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { NougatImageProcessor: () => s2 });
    var r2 = n2("./src/models/donut/image_processing_donut.js");
    class s2 extends r2.DonutImageProcessor {
    }
  }, "./src/models/owlv2/image_processing_owlv2.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Owlv2ImageProcessor: () => s2 });
    var r2 = n2("./src/models/owlvit/image_processing_owlvit.js");
    class s2 extends r2.OwlViTImageProcessor {
    }
  }, "./src/models/owlvit/image_processing_owlvit.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { OwlViTFeatureExtractor: () => a2, OwlViTImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
      post_process_object_detection(...e3) {
        return (0, r2.post_process_object_detection)(...e3);
      }
    }
    class a2 extends s2 {
    }
  }, "./src/models/owlvit/processing_owlvit.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { OwlViTProcessor: () => o2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js"), a2 = n2("./src/tokenizers.js");
    class o2 extends r2.Processor {
      static tokenizer_class = a2.AutoTokenizer;
      static image_processor_class = s2.AutoImageProcessor;
    }
  }, "./src/models/paligemma/processing_paligemma.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { PaliGemmaProcessor: () => i2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js"), a2 = n2("./src/tokenizers.js");
    const o2 = "<image>";
    class i2 extends r2.Processor {
      static tokenizer_class = a2.AutoTokenizer;
      static image_processor_class = s2.AutoImageProcessor;
      static uses_processor_config = false;
      async _call(e3, t3 = null, n3 = {}) {
        t3 || (console.warn("You are using PaliGemma without a text prefix. It will perform as a picture-captioning model."), t3 = ""), Array.isArray(e3) || (e3 = [e3]), Array.isArray(t3) || (t3 = [t3]);
        const r3 = this.tokenizer.bos_token, s3 = this.image_processor.config.image_seq_length;
        let a3;
        t3.some(((e4) => e4.includes(o2))) ? a3 = t3.map(((e4) => {
          const t4 = e4.replaceAll(o2, o2.repeat(s3)), n4 = t4.lastIndexOf(o2), a4 = -1 === n4 ? 0 : n4 + 7;
          return t4.slice(0, a4) + r3 + t4.slice(a4) + "\n";
        })) : (console.warn("You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens."), a3 = t3.map(((t4) => (function(e4, t5, n4, r4, s4) {
          return `${r4.repeat(n4 * s4)}${t5}${e4}
`;
        })(t4, r3, s3, o2, e3.length))));
        const i3 = this.tokenizer(a3, n3);
        return { ...await this.image_processor(e3, n3), ...i3 };
      }
    }
  }, "./src/models/parakeet/feature_extraction_parakeet.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { ParakeetFeatureExtractor: () => o2 });
    var r2 = n2("./src/base/feature_extraction_utils.js"), s2 = n2("./src/utils/tensor.js"), a2 = n2("./src/utils/audio.js");
    class o2 extends r2.FeatureExtractor {
      constructor(e3) {
        super(e3), this.config.mel_filters ??= (0, a2.mel_filter_bank)(Math.floor(1 + this.config.n_fft / 2), this.config.feature_size, 0, this.config.sampling_rate / 2, this.config.sampling_rate, "slaney", "slaney");
        const t3 = (0, a2.window_function)(this.config.win_length, "hann", { periodic: false });
        this.window = new Float64Array(this.config.n_fft);
        const n3 = Math.floor((this.config.n_fft - this.config.win_length) / 2);
        this.window.set(t3, n3);
      }
      async _extract_fbank_features(e3) {
        const t3 = this.config.preemphasis;
        for (let n3 = (e3 = new Float64Array(e3)).length - 1; n3 >= 1; --n3) e3[n3] -= t3 * e3[n3 - 1];
        return await (0, a2.spectrogram)(e3, this.window, this.window.length, this.config.hop_length, { fft_length: this.config.n_fft, power: 2, mel_filters: this.config.mel_filters, log_mel: "log", mel_floor: -1 / 0, pad_mode: "constant", center: true, transpose: true, mel_offset: 2 ** -24 });
      }
      async _call(e3) {
        (0, r2.validate_audio_inputs)(e3, "ParakeetFeatureExtractor");
        const t3 = await this._extract_fbank_features(e3), n3 = Math.floor((e3.length + 2 * Math.floor(this.config.n_fft / 2) - this.config.n_fft) / this.config.hop_length), a3 = t3.data;
        a3.fill(0, n3 * t3.dims[1]);
        const [o3, i2] = t3.dims, l2 = new Float64Array(i2), d2 = new Float64Array(i2);
        for (let e4 = 0; e4 < n3; ++e4) {
          const t4 = e4 * i2;
          for (let e5 = 0; e5 < i2; ++e5) {
            const n4 = a3[t4 + e5];
            l2[e5] += n4, d2[e5] += n4 * n4;
          }
        }
        const u2 = n3 > 1 ? n3 - 1 : 1;
        for (let e4 = 0; e4 < i2; ++e4) {
          const t4 = l2[e4] / n3, r3 = (d2[e4] - n3 * t4 * t4) / u2, s3 = 1 / (Math.sqrt(r3) + 1e-5);
          for (let r4 = 0; r4 < n3; ++r4) {
            const n4 = r4 * i2 + e4;
            a3[n4] = (a3[n4] - t4) * s3;
          }
        }
        const c2 = new BigInt64Array(o3);
        return c2.fill(1n, 0, n3), { input_features: t3.unsqueeze_(0), attention_mask: new s2.Tensor("int64", c2, [1, o3]) };
      }
    }
  }, "./src/models/phi3_v/image_processing_phi3_v.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Phi3VImageProcessor: () => u2 });
    var r2 = n2("./src/base/image_processors_utils.js"), s2 = n2("./src/utils/tensor.js");
    const a2 = 336, o2 = [2, 3], { ceil: i2, floor: l2, sqrt: d2 } = Math;
    class u2 extends r2.ImageProcessor {
      constructor(e3) {
        super({ ...e3, do_normalize: true, do_pad: true, pad_size: "custom", do_convert_rgb: true, do_resize: true }), this._num_crops = e3.num_crops;
      }
      calc_num_image_tokens_from_image_size(e3, t3) {
        const { num_img_tokens: n3 } = this.config;
        return l2((l2(t3 / a2) * l2(e3 / a2) + 1) * n3 + 1 + (l2(t3 / a2) + 1) * d2(n3));
      }
      get_resize_output_image_size(e3, t3) {
        const n3 = this._num_crops, [r3, s3] = e3.size;
        let a3 = r3 / s3, o3 = 1;
        for (; o3 * Math.ceil(o3 / a3) <= n3; ) o3 += 1;
        o3 -= 1;
        const i3 = Math.floor(336 * o3);
        return [i3, Math.floor(i3 / a3)];
      }
      pad_image(e3, t3, n3, r3 = {}) {
        const [s3, o3] = t3, l3 = a2 * i2(s3 / a2), d3 = a2 * i2(o3 / a2), u3 = [1, 1, 1].map(((e4, t4) => (e4 - this.image_mean[t4]) / this.image_std[t4]));
        return super.pad_image(e3, t3, { width: d3, height: l3 }, { center: true, constant_values: u3, ...r3 });
      }
      async _call(e3, { num_crops: t3 = null } = {}) {
        if (this._num_crops = t3 ??= this.config.num_crops, t3 < 4 || d2(t3) % 1 != 0) throw new Error("num_crops must be a square number >= 4");
        Array.isArray(e3) || (e3 = [e3]);
        const n3 = e3.length, r3 = await Promise.all(e3.map(((e4) => this.preprocess(e4)))), u3 = r3.map(((e4) => e4.original_size)), c2 = r3.map(((e4) => e4.reshaped_input_size)), p2 = [];
        for (const { pixel_values: e4 } of r3) {
          e4.unsqueeze_(0);
          const [n4, r4] = e4.dims.slice(-2), i3 = await (0, s2.interpolate_4d)(e4, { size: [a2, a2], mode: "bicubic" });
          if (t3 > 0) {
            const u4 = [], c3 = d2(t3), m3 = l2(r4 / c3), h3 = l2(n4 / c3);
            for (let t4 = 0; t4 < c3; ++t4) for (let a3 = 0; a3 < c3; ++a3) {
              let i4, l3, d3, p3;
              t4 === c3 - 1 ? (l3 = n4 - h3, p3 = n4) : (l3 = t4 * h3, p3 = (t4 + 1) * h3), a3 === c3 - 1 ? (i4 = r4 - m3, d3 = r4) : (i4 = a3 * m3, d3 = (a3 + 1) * m3);
              const f3 = [l3, i4], _2 = [p3, d3], g2 = await (0, s2.slice)(e4, f3, _2, o2);
              u4.push(g2);
            }
            const f2 = await (0, s2.interpolate_4d)((0, s2.cat)(u4, 0), { size: [a2, a2], mode: "bicubic" });
            p2.push((0, s2.cat)([i3, f2], 0));
          } else p2.push(i3);
        }
        const m2 = (0, s2.stack)(p2, 0), h2 = c2.map(((e4) => e4.map(((e5) => a2 * i2(e5 / a2)))));
        return { pixel_values: m2, original_sizes: u3, reshaped_input_sizes: c2, image_sizes: new s2.Tensor("int64", h2.flat(), [n3, 2]), num_img_tokens: h2.map((([e4, t4]) => this.calc_num_image_tokens_from_image_size(t4, e4))) };
      }
    }
  }, "./src/models/phi3_v/processing_phi3_v.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Phi3VProcessor: () => l2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js"), a2 = n2("./src/tokenizers.js");
    n2("./src/utils/image.js");
    const o2 = "<|image|>", i2 = /<\|image_\d+\|>/g;
    class l2 extends r2.Processor {
      static image_processor_class = s2.AutoImageProcessor;
      static tokenizer_class = a2.AutoTokenizer;
      async _call(e3, t3 = null, { padding: n3 = true, truncation: r3 = true, num_crops: s3 = null } = {}) {
        let a3, l3;
        if (Array.isArray(e3) || (e3 = [e3]), t3) {
          l3 = await this.image_processor(t3, { num_crops: s3 });
          const { num_img_tokens: d2 } = l3, u2 = e3.map(((e4, t4) => e4.split(i2).join(o2.repeat(d2[t4]))));
          a3 = this.tokenizer(u2, { padding: n3, truncation: r3 });
          const c2 = this.tokenizer.model.convert_tokens_to_ids([o2])[0];
          a3.input_ids.map_(((e4) => e4 == c2 ? -e4 : e4));
        } else a3 = this.tokenizer(e3);
        return { ...a3, ...l3 };
      }
    }
  }, "./src/models/processors.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Florence2Processor: () => r2.Florence2Processor, Gemma3nProcessor: () => s2.Gemma3nProcessor, GroundingDinoProcessor: () => a2.GroundingDinoProcessor, Idefics3Processor: () => o2.Idefics3Processor, JinaCLIPProcessor: () => l2.JinaCLIPProcessor, LlavaProcessor: () => d2.LlavaProcessor, MgpstrProcessor: () => u2.MgpstrProcessor, MoonshineProcessor: () => c2.MoonshineProcessor, OwlViTProcessor: () => p2.OwlViTProcessor, PaliGemmaProcessor: () => h2.PaliGemmaProcessor, Phi3VProcessor: () => m2.Phi3VProcessor, PyAnnoteProcessor: () => f2.PyAnnoteProcessor, Qwen2VLProcessor: () => _2.Qwen2VLProcessor, Sam2Processor: () => w2.Sam2Processor, Sam2VideoProcessor: () => w2.Sam2VideoProcessor, SamProcessor: () => g2.SamProcessor, SmolVLMProcessor: () => b2.SmolVLMProcessor, SpeechT5Processor: () => y2.SpeechT5Processor, UltravoxProcessor: () => M2.UltravoxProcessor, VLChatProcessor: () => i2.VLChatProcessor, VoxtralProcessor: () => x2.VoxtralProcessor, Wav2Vec2Processor: () => v2.Wav2Vec2Processor, Wav2Vec2ProcessorWithLM: () => T2.Wav2Vec2ProcessorWithLM, WhisperProcessor: () => k2.WhisperProcessor });
    var r2 = n2("./src/models/florence2/processing_florence2.js"), s2 = n2("./src/models/gemma3n/processing_gemma3n.js"), a2 = n2("./src/models/grounding_dino/processing_grounding_dino.js"), o2 = n2("./src/models/idefics3/processing_idefics3.js"), i2 = n2("./src/models/janus/processing_janus.js"), l2 = n2("./src/models/jina_clip/processing_jina_clip.js"), d2 = n2("./src/models/llava/processing_llava.js"), u2 = n2("./src/models/mgp_str/processing_mgp_str.js"), c2 = n2("./src/models/moonshine/processing_moonshine.js"), p2 = n2("./src/models/owlvit/processing_owlvit.js"), m2 = n2("./src/models/phi3_v/processing_phi3_v.js"), h2 = n2("./src/models/paligemma/processing_paligemma.js"), f2 = n2("./src/models/pyannote/processing_pyannote.js"), _2 = n2("./src/models/qwen2_vl/processing_qwen2_vl.js"), g2 = n2("./src/models/sam/processing_sam.js"), w2 = n2("./src/models/sam2/processing_sam2.js"), b2 = n2("./src/models/smolvlm/processing_smolvlm.js"), y2 = n2("./src/models/speecht5/processing_speecht5.js"), M2 = n2("./src/models/ultravox/processing_ultravox.js"), x2 = n2("./src/models/voxtral/processing_voxtral.js"), v2 = n2("./src/models/wav2vec2/processing_wav2vec2.js"), T2 = n2("./src/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.js"), k2 = n2("./src/models/whisper/processing_whisper.js");
  }, "./src/models/pvt/image_processing_pvt.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { PvtImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
  }, "./src/models/pyannote/feature_extraction_pyannote.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { PyAnnoteFeatureExtractor: () => o2 });
    var r2 = n2("./src/base/feature_extraction_utils.js"), s2 = n2("./src/utils/tensor.js"), a2 = n2("./src/utils/maths.js");
    class o2 extends r2.FeatureExtractor {
      async _call(e3) {
        (0, r2.validate_audio_inputs)(e3, "PyAnnoteFeatureExtractor"), e3 instanceof Float64Array && (e3 = new Float32Array(e3));
        const t3 = [1, 1, e3.length];
        return { input_values: new s2.Tensor("float32", e3, t3) };
      }
      samples_to_frames(e3) {
        return (e3 - this.config.offset) / this.config.step;
      }
      post_process_speaker_diarization(e3, t3) {
        const n3 = t3 / this.samples_to_frames(t3) / this.config.sampling_rate, r3 = [];
        for (const t4 of e3.tolist()) {
          const e4 = [];
          let s3 = -1;
          for (let n4 = 0; n4 < t4.length; ++n4) {
            const r4 = (0, a2.softmax)(t4[n4]), [o3, i2] = (0, a2.max)(r4), [l2, d2] = [n4, n4 + 1];
            i2 !== s3 ? (s3 = i2, e4.push({ id: i2, start: l2, end: d2, score: o3 })) : (e4.at(-1).end = d2, e4.at(-1).score += o3);
          }
          r3.push(e4.map((({ id: e5, start: t5, end: r4, score: s4 }) => ({ id: e5, start: t5 * n3, end: r4 * n3, confidence: s4 / (r4 - t5) }))));
        }
        return r3;
      }
    }
  }, "./src/models/pyannote/processing_pyannote.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { PyAnnoteProcessor: () => a2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/pyannote/feature_extraction_pyannote.js");
    class a2 extends r2.Processor {
      static feature_extractor_class = s2.PyAnnoteFeatureExtractor;
      async _call(e3) {
        return await this.feature_extractor(e3);
      }
      post_process_speaker_diarization(...e3) {
        return this.feature_extractor.post_process_speaker_diarization(...e3);
      }
      get sampling_rate() {
        return this.feature_extractor.config.sampling_rate;
      }
    }
  }, "./src/models/qwen2_vl/image_processing_qwen2_vl.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Qwen2VLImageProcessor: () => a2 });
    var r2 = n2("./src/base/image_processors_utils.js"), s2 = n2("./src/utils/tensor.js");
    class a2 extends r2.ImageProcessor {
      async _call(e3, ...t3) {
        const { pixel_values: n3, original_sizes: r3, reshaped_input_sizes: a3 } = await super._call(e3, ...t3);
        let o2 = n3;
        const { temporal_patch_size: i2, merge_size: l2, patch_size: d2 } = this.config;
        1 === o2.dims[0] && (o2 = (0, s2.cat)(Array.from({ length: i2 }, (() => o2)), 0));
        const u2 = o2.dims[0] / i2, c2 = o2.dims[1], p2 = Math.floor(o2.dims[2] / d2), m2 = Math.floor(o2.dims[3] / d2);
        return { pixel_values: o2.view(u2, i2, c2, Math.floor(p2 / l2), l2, d2, Math.floor(m2 / l2), l2, d2).permute(0, 3, 6, 4, 7, 2, 1, 5, 8).view(u2 * p2 * m2, c2 * i2 * d2 * d2), image_grid_thw: new s2.Tensor("int64", [u2, p2, m2], [1, 3]), original_sizes: r3, reshaped_input_sizes: a3 };
      }
    }
  }, "./src/models/qwen2_vl/processing_qwen2_vl.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Qwen2VLProcessor: () => o2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js"), a2 = n2("./src/tokenizers.js");
    n2("./src/utils/image.js");
    class o2 extends r2.Processor {
      static image_processor_class = s2.AutoImageProcessor;
      static tokenizer_class = a2.AutoTokenizer;
      async _call(e3, t3 = null, ...n3) {
        let r3, s3;
        if (Array.isArray(e3) || (e3 = [e3]), t3 && (r3 = await this.image_processor(t3), s3 = r3.image_grid_thw), s3) {
          let t4 = this.image_processor.config.merge_size ** 2, n4 = 0;
          const r4 = s3.tolist();
          e3 = e3.map(((e4) => {
            for (; e4.includes("<|image_pad|>"); ) {
              const s4 = Number(r4[n4++].reduce(((e5, t5) => e5 * t5), 1n));
              e4 = e4.replace("<|image_pad|>", "<|placeholder|>".repeat(Math.floor(s4 / t4)));
            }
            return e4.replaceAll("<|placeholder|>", "<|image_pad|>");
          }));
        }
        return { ...this.tokenizer(e3), ...r3 };
      }
    }
  }, "./src/models/rt_detr/image_processing_rt_detr.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { RTDetrImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
      post_process_object_detection(...e3) {
        return (0, r2.post_process_object_detection)(...e3);
      }
    }
  }, "./src/models/sam/image_processing_sam.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { SamImageProcessor: () => o2 });
    var r2 = n2("./src/base/image_processors_utils.js"), s2 = n2("./src/utils/core.js"), a2 = n2("./src/utils/tensor.js");
    class o2 extends r2.ImageProcessor {
      reshape_input_points(e3, t3, n3, r3 = false) {
        e3 = structuredClone(e3);
        let o3 = (0, s2.calculateDimensions)(e3);
        if (3 === o3.length) r3 || (o3 = [1, ...o3]), e3 = [e3];
        else if (4 !== o3.length) throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");
        for (let r4 = 0; r4 < e3.length; ++r4) {
          const [s3, a3] = t3[r4], [o4, i2] = n3[r4], l2 = [i2 / a3, o4 / s3];
          for (let t4 = 0; t4 < e3[r4].length; ++t4) for (let n4 = 0; n4 < e3[r4][t4].length; ++n4) for (let s4 = 0; s4 < e3[r4][t4][n4].length; ++s4) e3[r4][t4][n4][s4] *= l2[s4 % 2];
        }
        return new a2.Tensor("float32", Float32Array.from(e3.flat(1 / 0)), o3);
      }
      add_input_labels(e3, t3) {
        let n3 = (0, s2.calculateDimensions)(e3);
        if (2 === n3.length) n3 = [1, ...n3], e3 = [e3];
        else if (3 !== n3.length) throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");
        if (n3.some(((e4, n4) => e4 !== t3.dims[n4]))) throw Error(`The first ${n3.length} dimensions of 'input_points' and 'input_labels' must be the same.`);
        return new a2.Tensor("int64", e3.flat(1 / 0).map(BigInt), n3);
      }
      async _call(e3, { input_points: t3 = null, input_labels: n3 = null, input_boxes: r3 = null } = {}) {
        const s3 = await super._call(e3);
        if (t3 && (s3.input_points = this.reshape_input_points(t3, s3.original_sizes, s3.reshaped_input_sizes)), n3) {
          if (!s3.input_points) throw Error("`input_points` must be provided if `input_labels` are provided.");
          s3.input_labels = this.add_input_labels(n3, s3.input_points);
        }
        return r3 && (s3.input_boxes = this.reshape_input_points(r3, s3.original_sizes, s3.reshaped_input_sizes, true)), s3;
      }
      async post_process_masks(e3, t3, n3, { mask_threshold: r3 = 0, binarize: s3 = true, pad_size: o3 = null } = {}) {
        const i2 = [], l2 = [(o3 = o3 ?? this.pad_size ?? this.size).height, o3.width];
        for (let o4 = 0; o4 < t3.length; ++o4) {
          const d2 = t3[o4], u2 = n3[o4];
          let c2 = await (0, a2.interpolate_4d)(e3[o4], { mode: "bilinear", size: l2 });
          if (c2 = c2.slice(null, null, [0, u2[0]], [0, u2[1]]), c2 = await (0, a2.interpolate_4d)(c2, { mode: "bilinear", size: d2 }), s3) {
            const e4 = c2.data, t4 = new Uint8Array(e4.length);
            for (let n4 = 0; n4 < e4.length; ++n4) e4[n4] > r3 && (t4[n4] = 1);
            c2 = new a2.Tensor("bool", t4, c2.dims);
          }
          i2.push(c2);
        }
        return i2;
      }
      generate_crop_boxes(e3, t3, { crop_n_layers: n3 = 0, overlap_ratio: r3 = 512 / 1500, points_per_crop: s3 = 32, crop_n_points_downscale_factor: a3 = 1 } = {}) {
      }
    }
  }, "./src/models/sam/processing_sam.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { SamProcessor: () => a2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/models/auto/image_processing_auto.js");
    class a2 extends r2.Processor {
      static image_processor_class = s2.AutoImageProcessor;
      async _call(...e3) {
        return await this.image_processor(...e3);
      }
      post_process_masks(...e3) {
        return this.image_processor.post_process_masks(...e3);
      }
      reshape_input_points(...e3) {
        return this.image_processor.reshape_input_points(...e3);
      }
    }
  }, "./src/models/sam2/image_processing_sam2.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Sam2ImageProcessor: () => r2.SamImageProcessor });
    var r2 = n2("./src/models/sam/image_processing_sam.js");
  }, "./src/models/sam2/processing_sam2.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Sam2Processor: () => s2, Sam2VideoProcessor: () => a2 });
    var r2 = n2("./src/models/sam/processing_sam.js");
    class s2 extends r2.SamProcessor {
    }
    class a2 extends s2 {
    }
  }, "./src/models/sam3/image_processing_sam3.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Sam3ImageProcessor: () => r2.Sam2ImageProcessor });
    var r2 = n2("./src/models/sam2/image_processing_sam2.js");
  }, "./src/models/seamless_m4t/feature_extraction_seamless_m4t.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { SeamlessM4TFeatureExtractor: () => o2 });
    var r2 = n2("./src/base/feature_extraction_utils.js"), s2 = n2("./src/utils/tensor.js"), a2 = n2("./src/utils/audio.js");
    class o2 extends r2.FeatureExtractor {
      constructor(e3) {
        super(e3);
        const t3 = this.config.sampling_rate, n3 = (0, a2.mel_filter_bank)(257, this.config.num_mel_bins, 20, Math.floor(t3 / 2), t3, null, "kaldi", true);
        this.mel_filters = n3, this.window = (0, a2.window_function)(400, "povey", { periodic: false });
      }
      async _extract_fbank_features(e3, t3) {
        return e3 = e3.map(((e4) => 32768 * e4)), (0, a2.spectrogram)(e3, this.window, 400, 160, { fft_length: 512, power: 2, center: false, preemphasis: 0.97, mel_filters: this.mel_filters, log_mel: "log", mel_floor: 1192092955078125e-22, remove_dc_offset: true, max_num_frames: t3, transpose: true });
      }
      async _call(e3, { padding: t3 = true, pad_to_multiple_of: n3 = 2, do_normalize_per_mel_bins: a3 = true, return_attention_mask: o3 = true } = {}) {
        (0, r2.validate_audio_inputs)(e3, "SeamlessM4TFeatureExtractor");
        let i2, l2 = await this._extract_fbank_features(e3, this.config.max_length);
        if (a3) {
          const [e4, t4] = l2.dims, n4 = l2.data;
          for (let r3 = 0; r3 < t4; ++r3) {
            let s3 = 0;
            for (let a5 = 0; a5 < e4; ++a5) s3 += n4[a5 * t4 + r3];
            const a4 = s3 / e4;
            let o4 = 0;
            for (let s4 = 0; s4 < e4; ++s4) o4 += (n4[s4 * t4 + r3] - a4) ** 2;
            o4 /= e4 - 1;
            const i3 = Math.sqrt(o4 + 1e-7);
            for (let s4 = 0; s4 < e4; ++s4) {
              const e5 = s4 * t4 + r3;
              n4[e5] = (n4[e5] - a4) / i3;
            }
          }
        }
        if (t3) {
          const [e4, t4] = l2.dims, r3 = l2.data, a4 = e4 % n3;
          if (a4 > 0) {
            const n4 = new Float32Array(t4 * (e4 + a4));
            n4.set(r3), n4.fill(this.config.padding_value, r3.length);
            const d3 = e4 + a4;
            l2 = new s2.Tensor(l2.type, n4, [d3, t4]), o3 && (i2 = new s2.Tensor("int64", new BigInt64Array(d3), [1, d3]), i2.data.fill(1n, 0, e4));
          }
        }
        const [d2, u2] = l2.dims, c2 = this.config.stride;
        if (0 !== d2 % c2) throw new Error(`The number of frames (${d2}) must be a multiple of the stride (${c2}).`);
        const p2 = l2.view(1, Math.floor(d2 / c2), u2 * c2), m2 = { input_features: p2 };
        if (o3) {
          const e4 = p2.dims[1], t4 = new BigInt64Array(e4);
          if (i2) {
            const e5 = i2.data;
            for (let n4 = 1, r3 = 0; n4 < d2; n4 += c2, ++r3) t4[r3] = e5[n4];
          } else t4.fill(1n);
          m2.attention_mask = new s2.Tensor("int64", t4, [1, e4]);
        }
        return m2;
      }
    }
  }, "./src/models/segformer/image_processing_segformer.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { SegformerFeatureExtractor: () => a2, SegformerImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
      post_process_semantic_segmentation(...e3) {
        return (0, r2.post_process_semantic_segmentation)(...e3);
      }
    }
    class a2 extends s2 {
    }
  }, "./src/models/siglip/image_processing_siglip.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { SiglipImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
  }, "./src/models/smolvlm/image_processing_smolvlm.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { SmolVLMImageProcessor: () => r2.Idefics3ImageProcessor });
    var r2 = n2("./src/models/idefics3/image_processing_idefics3.js");
  }, "./src/models/smolvlm/processing_smolvlm.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { SmolVLMProcessor: () => r2.Idefics3Processor });
    var r2 = n2("./src/models/idefics3/processing_idefics3.js");
  }, "./src/models/snac/feature_extraction_snac.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { SnacFeatureExtractor: () => s2 });
    var r2 = n2("./src/models/dac/feature_extraction_dac.js");
    class s2 extends r2.DacFeatureExtractor {
    }
  }, "./src/models/speecht5/feature_extraction_speecht5.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { SpeechT5FeatureExtractor: () => s2 });
    var r2 = n2("./src/base/feature_extraction_utils.js");
    class s2 extends r2.FeatureExtractor {
    }
  }, "./src/models/speecht5/processing_speecht5.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { SpeechT5Processor: () => o2 });
    var r2 = n2("./src/base/processing_utils.js"), s2 = n2("./src/tokenizers.js"), a2 = n2("./src/models/auto/feature_extraction_auto.js");
    class o2 extends r2.Processor {
      static tokenizer_class = s2.AutoTokenizer;
      static feature_extractor_class = a2.AutoFeatureExtractor;
      async _call(e3) {
        return await this.feature_extractor(e3);
      }
    }
  }, "./src/models/swin2sr/image_processing_swin2sr.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Swin2SRImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
      pad_image(e3, t3, n3, r3 = {}) {
        const [s3, a2, o2] = t3;
        return super.pad_image(e3, t3, { width: a2 + (n3 - a2 % n3) % n3, height: s3 + (n3 - s3 % n3) % n3 }, { mode: "symmetric", center: false, constant_values: -1, ...r3 });
      }
    }
  }, "./src/models/ultravox/processing_ultravox.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { UltravoxProcessor: () => o2 });
    var r2 = n2("./src/models/auto/feature_extraction_auto.js"), s2 = n2("./src/tokenizers.js"), a2 = n2("./src/base/processing_utils.js");
    class o2 extends a2.Processor {
      static tokenizer_class = s2.AutoTokenizer;
      static feature_extractor_class = r2.AutoFeatureExtractor;
      static uses_processor_config = true;
      async _call(e3, t3 = null, n3 = {}) {
        if (Array.isArray(e3)) throw new Error("Batched inputs are not supported yet.");
        let r3 = {};
        if (t3) {
          const s3 = t3.length, { input_features: a3 } = await this.feature_extractor(t3, { ...n3, max_length: s3 }), o3 = Math.round(s3 / this.config.encoder_ds_factor + 1e-4), i2 = 1 + Math.ceil(o3 / this.config.stack_factor);
          r3.audio_token_len = [i2], r3.audio_values = a3;
          const l2 = this.config.audio_placeholder;
          if (!e3.includes(l2)) throw new Error(`The input text does not contain the image token ${l2}.`);
          e3 = e3.replaceAll(l2, l2.repeat(i2));
        }
        return { ...this.tokenizer(e3, { add_special_tokens: false, ...n3 }), ...r3 };
      }
    }
  }, "./src/models/vit/image_processing_vit.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { ViTFeatureExtractor: () => a2, ViTImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
    }
    class a2 extends s2 {
    }
  }, "./src/models/vitmatte/image_processing_vitmatte.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { VitMatteImageProcessor: () => a2 });
    var r2 = n2("./src/base/image_processors_utils.js"), s2 = n2("./src/utils/tensor.js");
    class a2 extends r2.ImageProcessor {
      async _call(e3, t3) {
        Array.isArray(e3) || (e3 = [e3]), Array.isArray(t3) || (t3 = [t3]);
        const n3 = await Promise.all(e3.map(((e4) => this.preprocess(e4)))), r3 = await Promise.all(t3.map(((e4) => this.preprocess(e4, { do_normalize: false, do_convert_rgb: false, do_convert_grayscale: true }))));
        return { pixel_values: (0, s2.stack)(n3.map(((e4, t4) => (0, s2.cat)([e4.pixel_values, r3[t4].pixel_values], 0))), 0), original_sizes: n3.map(((e4) => e4.original_size)), reshaped_input_sizes: n3.map(((e4) => e4.reshaped_input_size)) };
      }
    }
  }, "./src/models/vitpose/image_processing_vitpose.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { VitPoseImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
      post_process_pose_estimation(e3, t3, { threshold: n3 = null } = {}) {
        const r3 = e3.tolist(), [s3, a2, o2, i2] = e3.dims, l2 = [];
        for (let e4 = 0; e4 < s3; ++e4) {
          const s4 = r3[e4], a3 = t3[e4], d2 = [];
          for (let e5 = 0; e5 < a3.length; ++e5) {
            const t4 = a3[e5], r4 = [], l3 = [], u2 = [], c2 = t4.at(-2) / i2, p2 = t4.at(-1) / o2;
            for (let e6 = 0; e6 < s4.length; ++e6) {
              let [t5, a4] = [0, 0], o3 = 0, i3 = -1 / 0;
              const d3 = s4[e6];
              for (let e7 = 0; e7 < d3.length; ++e7) {
                const n4 = d3[e7];
                for (let r5 = 0; r5 < n4.length; ++r5) {
                  const s5 = n4[r5];
                  o3 += s5, i3 = Math.max(i3, s5), t5 += (r5 + 0.5) * s5, a4 += e7 * s5;
                }
              }
              if (null != n3 && i3 < n3) continue;
              const m2 = [c2 * t5 / o3, p2 * a4 / o3];
              r4.push(m2), u2.push(e6), l3.push(i3);
            }
            d2.push({ bbox: t4, scores: l3, labels: u2, keypoints: r4 });
          }
          l2.push(d2);
        }
        return l2;
      }
    }
  }, "./src/models/voxtral/processing_voxtral.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { VoxtralProcessor: () => l2 });
    var r2 = n2("./src/models/auto/feature_extraction_auto.js"), s2 = n2("./src/tokenizers.js"), a2 = n2("./src/base/processing_utils.js"), o2 = n2("./src/utils/tensor.js");
    const i2 = "[AUDIO]";
    class l2 extends a2.Processor {
      static tokenizer_class = s2.AutoTokenizer;
      static feature_extractor_class = r2.AutoFeatureExtractor;
      static uses_processor_config = false;
      async _call(e3, t3 = null, n3 = {}) {
        if (Array.isArray(e3)) throw new Error("Batched inputs are not supported yet.");
        const r3 = {};
        if (t3) {
          if (!e3.includes(i2)) throw new Error(`The input text does not contain the audio token ${i2}.`);
          Array.isArray(t3) || (t3 = [t3]);
          const s3 = e3.split(i2), a3 = s3.length - 1;
          if (a3 !== t3.length) throw new Error(`The number of audio inputs (${t3.length}) does not match the number of audio tokens in the text (${a3}).`);
          const l3 = this.feature_extractor.config.n_samples, d2 = t3.map(((e4) => (function(e5, t4) {
            const n4 = [];
            for (let r4 = 0; r4 < e5.length; r4 += t4) n4.push(e5.subarray(r4, Math.min(r4 + t4, e5.length)));
            return n4;
          })(e4, l3))), u2 = d2.map(((e4) => e4.length)), c2 = d2.flat(), p2 = (await Promise.all(c2.map(((e4) => this.feature_extractor(e4, n3))))).map(((e4) => e4.input_features));
          r3.audio_values = p2.length > 1 ? (0, o2.cat)(p2, 0) : p2[0];
          let m2 = s3[0];
          for (let e4 = 0; e4 < u2.length; ++e4) {
            m2 += "[BEGIN_AUDIO]";
            for (let t4 = 0; t4 < u2[e4]; ++t4) m2 += i2.repeat(375);
            m2 += s3[e4 + 1];
          }
          e3 = m2;
        }
        return { ...this.tokenizer(e3, { add_special_tokens: false, ...n3 }), ...r3 };
      }
    }
  }, "./src/models/wav2vec2/feature_extraction_wav2vec2.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Wav2Vec2FeatureExtractor: () => a2 });
    var r2 = n2("./src/base/feature_extraction_utils.js"), s2 = n2("./src/utils/tensor.js");
    class a2 extends r2.FeatureExtractor {
      _zero_mean_unit_var_norm(e3) {
        const t3 = e3.reduce(((e4, t4) => e4 + t4), 0) / e3.length, n3 = e3.reduce(((e4, n4) => e4 + (n4 - t3) ** 2), 0) / e3.length;
        return e3.map(((e4) => (e4 - t3) / Math.sqrt(n3 + 1e-7)));
      }
      async _call(e3) {
        (0, r2.validate_audio_inputs)(e3, "Wav2Vec2FeatureExtractor"), e3 instanceof Float64Array && (e3 = new Float32Array(e3));
        let t3 = e3;
        this.config.do_normalize && (t3 = this._zero_mean_unit_var_norm(t3));
        const n3 = [1, t3.length];
        return { input_values: new s2.Tensor("float32", t3, n3), attention_mask: new s2.Tensor("int64", new BigInt64Array(t3.length).fill(1n), n3) };
      }
    }
  }, "./src/models/wav2vec2/processing_wav2vec2.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Wav2Vec2Processor: () => o2 });
    var r2 = n2("./src/tokenizers.js"), s2 = n2("./src/models/auto/feature_extraction_auto.js"), a2 = n2("./src/base/processing_utils.js");
    class o2 extends a2.Processor {
      static tokenizer_class = r2.AutoTokenizer;
      static feature_extractor_class = s2.AutoFeatureExtractor;
      async _call(e3) {
        return await this.feature_extractor(e3);
      }
    }
  }, "./src/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Wav2Vec2ProcessorWithLM: () => o2 });
    var r2 = n2("./src/tokenizers.js"), s2 = n2("./src/models/auto/feature_extraction_auto.js"), a2 = n2("./src/base/processing_utils.js");
    class o2 extends a2.Processor {
      static tokenizer_class = r2.AutoTokenizer;
      static feature_extractor_class = s2.AutoFeatureExtractor;
      async _call(e3) {
        return await this.feature_extractor(e3);
      }
    }
  }, "./src/models/wespeaker/feature_extraction_wespeaker.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { WeSpeakerFeatureExtractor: () => a2 });
    var r2 = n2("./src/base/feature_extraction_utils.js"), s2 = (n2("./src/utils/tensor.js"), n2("./src/utils/audio.js"));
    class a2 extends r2.FeatureExtractor {
      constructor(e3) {
        super(e3);
        const t3 = this.config.sampling_rate, n3 = (0, s2.mel_filter_bank)(257, this.config.num_mel_bins, 20, Math.floor(t3 / 2), t3, null, "kaldi", true);
        this.mel_filters = n3, this.window = (0, s2.window_function)(400, "hamming", { periodic: false }), this.min_num_frames = this.config.min_num_frames;
      }
      async _extract_fbank_features(e3) {
        return e3 = e3.map(((e4) => 32768 * e4)), (0, s2.spectrogram)(e3, this.window, 400, 160, { fft_length: 512, power: 2, center: false, preemphasis: 0.97, mel_filters: this.mel_filters, log_mel: "log", mel_floor: 1192092955078125e-22, remove_dc_offset: true, transpose: true, min_num_frames: this.min_num_frames });
      }
      async _call(e3) {
        (0, r2.validate_audio_inputs)(e3, "WeSpeakerFeatureExtractor");
        const t3 = (await this._extract_fbank_features(e3)).unsqueeze_(0);
        if (null === this.config.fbank_centering_span) {
          const e4 = t3.mean(1).data, n3 = t3.data, [r3, s3, a3] = t3.dims;
          for (let t4 = 0; t4 < r3; ++t4) {
            const r4 = t4 * s3 * a3, o2 = t4 * a3;
            for (let t5 = 0; t5 < s3; ++t5) {
              const s4 = r4 + t5 * a3;
              for (let t6 = 0; t6 < a3; ++t6) n3[s4 + t6] -= e4[o2 + t6];
            }
          }
        }
        return { input_features: t3 };
      }
    }
  }, "./src/models/whisper/common_whisper.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { WHISPER_LANGUAGE_MAPPING: () => s2, WHISPER_TO_LANGUAGE_CODE_MAPPING: () => a2, whisper_language_to_code: () => o2 });
    const r2 = [["en", "english"], ["zh", "chinese"], ["de", "german"], ["es", "spanish"], ["ru", "russian"], ["ko", "korean"], ["fr", "french"], ["ja", "japanese"], ["pt", "portuguese"], ["tr", "turkish"], ["pl", "polish"], ["ca", "catalan"], ["nl", "dutch"], ["ar", "arabic"], ["sv", "swedish"], ["it", "italian"], ["id", "indonesian"], ["hi", "hindi"], ["fi", "finnish"], ["vi", "vietnamese"], ["he", "hebrew"], ["uk", "ukrainian"], ["el", "greek"], ["ms", "malay"], ["cs", "czech"], ["ro", "romanian"], ["da", "danish"], ["hu", "hungarian"], ["ta", "tamil"], ["no", "norwegian"], ["th", "thai"], ["ur", "urdu"], ["hr", "croatian"], ["bg", "bulgarian"], ["lt", "lithuanian"], ["la", "latin"], ["mi", "maori"], ["ml", "malayalam"], ["cy", "welsh"], ["sk", "slovak"], ["te", "telugu"], ["fa", "persian"], ["lv", "latvian"], ["bn", "bengali"], ["sr", "serbian"], ["az", "azerbaijani"], ["sl", "slovenian"], ["kn", "kannada"], ["et", "estonian"], ["mk", "macedonian"], ["br", "breton"], ["eu", "basque"], ["is", "icelandic"], ["hy", "armenian"], ["ne", "nepali"], ["mn", "mongolian"], ["bs", "bosnian"], ["kk", "kazakh"], ["sq", "albanian"], ["sw", "swahili"], ["gl", "galician"], ["mr", "marathi"], ["pa", "punjabi"], ["si", "sinhala"], ["km", "khmer"], ["sn", "shona"], ["yo", "yoruba"], ["so", "somali"], ["af", "afrikaans"], ["oc", "occitan"], ["ka", "georgian"], ["be", "belarusian"], ["tg", "tajik"], ["sd", "sindhi"], ["gu", "gujarati"], ["am", "amharic"], ["yi", "yiddish"], ["lo", "lao"], ["uz", "uzbek"], ["fo", "faroese"], ["ht", "haitian creole"], ["ps", "pashto"], ["tk", "turkmen"], ["nn", "nynorsk"], ["mt", "maltese"], ["sa", "sanskrit"], ["lb", "luxembourgish"], ["my", "myanmar"], ["bo", "tibetan"], ["tl", "tagalog"], ["mg", "malagasy"], ["as", "assamese"], ["tt", "tatar"], ["haw", "hawaiian"], ["ln", "lingala"], ["ha", "hausa"], ["ba", "bashkir"], ["jw", "javanese"], ["su", "sundanese"]], s2 = new Map(r2), a2 = new Map([...r2.map((([e3, t3]) => [t3, e3])), ["burmese", "my"], ["valencian", "ca"], ["flemish", "nl"], ["haitian", "ht"], ["letzeburgesch", "lb"], ["pushto", "ps"], ["panjabi", "pa"], ["moldavian", "ro"], ["moldovan", "ro"], ["sinhalese", "si"], ["castilian", "es"]]);
    function o2(e3) {
      e3 = e3.toLowerCase();
      let t3 = a2.get(e3);
      if (void 0 === t3) {
        const n3 = e3.match(/^<\|([a-z]{2})\|>$/);
        if (n3 && (e3 = n3[1]), !s2.has(e3)) {
          const t4 = 2 === e3.length ? s2.keys() : s2.values();
          throw new Error(`Language "${e3}" is not supported. Must be one of: ${JSON.stringify(Array.from(t4))}`);
        }
        t3 = e3;
      }
      return t3;
    }
  }, "./src/models/whisper/feature_extraction_whisper.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { WhisperFeatureExtractor: () => o2 });
    var r2 = n2("./src/base/feature_extraction_utils.js"), s2 = (n2("./src/utils/tensor.js"), n2("./src/utils/audio.js")), a2 = n2("./src/utils/maths.js");
    class o2 extends r2.FeatureExtractor {
      constructor(e3) {
        super(e3), this.config.mel_filters ??= (0, s2.mel_filter_bank)(Math.floor(1 + this.config.n_fft / 2), this.config.feature_size, 0, 8e3, this.config.sampling_rate, "slaney", "slaney"), this.window = (0, s2.window_function)(this.config.n_fft, "hann");
      }
      async _extract_fbank_features(e3) {
        const t3 = await (0, s2.spectrogram)(e3, this.window, this.config.n_fft, this.config.hop_length, { power: 2, mel_filters: this.config.mel_filters, log_mel: "log10", max_num_frames: Math.min(Math.floor(e3.length / this.config.hop_length), this.config.nb_max_frames) }), n3 = t3.data, r3 = (0, a2.max)(n3)[0];
        for (let e4 = 0; e4 < n3.length; ++e4) n3[e4] = (Math.max(n3[e4], r3 - 8) + 4) / 4;
        return t3;
      }
      async _call(e3, { max_length: t3 = null } = {}) {
        let n3;
        (0, r2.validate_audio_inputs)(e3, "WhisperFeatureExtractor");
        const s3 = t3 ?? this.config.n_samples;
        e3.length > s3 ? (e3.length > this.config.n_samples && console.warn("Attempting to extract features for audio longer than 30 seconds. If using a pipeline to extract transcript from a long audio clip, remember to specify `chunk_length_s` and/or `stride_length_s`."), n3 = e3.slice(0, s3)) : (n3 = new Float32Array(s3), n3.set(e3));
        return { input_features: (await this._extract_fbank_features(n3)).unsqueeze_(0) };
      }
    }
  }, "./src/models/whisper/generation_whisper.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { WhisperGenerationConfig: () => s2 });
    var r2 = n2("./src/generation/configuration_utils.js");
    class s2 extends r2.GenerationConfig {
      return_timestamps = null;
      return_token_timestamps = null;
      num_frames = null;
      alignment_heads = null;
      task = null;
      language = null;
      no_timestamps_token_id = null;
      prompt_ids = null;
      is_multilingual = null;
      lang_to_id = null;
      task_to_id = null;
      max_initial_timestamp_index = 1;
    }
  }, "./src/models/whisper/processing_whisper.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { WhisperProcessor: () => o2 });
    var r2 = n2("./src/models/auto/feature_extraction_auto.js"), s2 = n2("./src/tokenizers.js"), a2 = n2("./src/base/processing_utils.js");
    class o2 extends a2.Processor {
      static tokenizer_class = s2.AutoTokenizer;
      static feature_extractor_class = r2.AutoFeatureExtractor;
      async _call(e3) {
        return await this.feature_extractor(e3);
      }
    }
  }, "./src/models/yolos/image_processing_yolos.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { YolosFeatureExtractor: () => a2, YolosImageProcessor: () => s2 });
    var r2 = n2("./src/base/image_processors_utils.js");
    class s2 extends r2.ImageProcessor {
      post_process_object_detection(...e3) {
        return (0, r2.post_process_object_detection)(...e3);
      }
    }
    class a2 extends s2 {
    }
  }, "./src/ops/registry.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { TensorOpRegistry: () => o2 });
    var r2 = n2("./src/backends/onnx.js"), s2 = n2("./src/utils/tensor.js");
    const a2 = async (e3, t3, n3) => {
      const a3 = await (0, r2.createInferenceSession)(new Uint8Array(e3), t3);
      return async (e4) => {
        const t4 = (0, r2.isONNXProxy)(), o3 = Object.fromEntries(Object.entries(e4).map((([e5, n4]) => [e5, (t4 ? n4.clone() : n4).ort_tensor]))), i2 = await (0, r2.runInferenceSession)(a3, o3);
        return Array.isArray(n3) ? n3.map(((e5) => new s2.Tensor(i2[e5]))) : new s2.Tensor(i2[n3]);
      };
    };
    class o2 {
      static session_options = {};
      static get nearest_interpolate_4d() {
        return this._nearest_interpolate_4d || (this._nearest_interpolate_4d = a2([8, 10, 18, 0, 58, 129, 1, 10, 41, 10, 1, 120, 10, 0, 10, 0, 10, 1, 115, 18, 1, 121, 34, 6, 82, 101, 115, 105, 122, 101, 42, 18, 10, 4, 109, 111, 100, 101, 34, 7, 110, 101, 97, 114, 101, 115, 116, 160, 1, 3, 18, 1, 114, 90, 31, 10, 1, 120, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 99, 10, 3, 18, 1, 104, 10, 3, 18, 1, 119, 90, 15, 10, 1, 115, 18, 10, 10, 8, 8, 7, 18, 4, 10, 2, 8, 4, 98, 31, 10, 1, 121, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 99, 10, 3, 18, 1, 104, 10, 3, 18, 1, 119, 66, 2, 16, 21], this.session_options, "y")), this._nearest_interpolate_4d;
      }
      static get bilinear_interpolate_4d() {
        return this._bilinear_interpolate_4d || (this._bilinear_interpolate_4d = a2([8, 9, 18, 0, 58, 128, 1, 10, 40, 10, 1, 120, 10, 0, 10, 0, 10, 1, 115, 18, 1, 121, 34, 6, 82, 101, 115, 105, 122, 101, 42, 17, 10, 4, 109, 111, 100, 101, 34, 6, 108, 105, 110, 101, 97, 114, 160, 1, 3, 18, 1, 114, 90, 31, 10, 1, 120, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 99, 10, 3, 18, 1, 104, 10, 3, 18, 1, 119, 90, 15, 10, 1, 115, 18, 10, 10, 8, 8, 7, 18, 4, 10, 2, 8, 4, 98, 31, 10, 1, 121, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 99, 10, 3, 18, 1, 104, 10, 3, 18, 1, 119, 66, 2, 16, 20], this.session_options, "y")), this._bilinear_interpolate_4d;
      }
      static get bicubic_interpolate_4d() {
        return this._bicubic_interpolate_4d || (this._bicubic_interpolate_4d = a2([8, 9, 18, 0, 58, 127, 10, 39, 10, 1, 120, 10, 0, 10, 0, 10, 1, 115, 18, 1, 121, 34, 6, 82, 101, 115, 105, 122, 101, 42, 16, 10, 4, 109, 111, 100, 101, 34, 5, 99, 117, 98, 105, 99, 160, 1, 3, 18, 1, 114, 90, 31, 10, 1, 120, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 99, 10, 3, 18, 1, 104, 10, 3, 18, 1, 119, 90, 15, 10, 1, 115, 18, 10, 10, 8, 8, 7, 18, 4, 10, 2, 8, 4, 98, 31, 10, 1, 121, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 99, 10, 3, 18, 1, 104, 10, 3, 18, 1, 119, 66, 2, 16, 20], this.session_options, "y")), this._bicubic_interpolate_4d;
      }
      static get matmul() {
        return this._matmul || (this._matmul = a2([8, 9, 18, 0, 58, 55, 10, 17, 10, 1, 97, 10, 1, 98, 18, 1, 99, 34, 6, 77, 97, 116, 77, 117, 108, 18, 1, 114, 90, 9, 10, 1, 97, 18, 4, 10, 2, 8, 1, 90, 9, 10, 1, 98, 18, 4, 10, 2, 8, 1, 98, 9, 10, 1, 99, 18, 4, 10, 2, 8, 1, 66, 2, 16, 20], this.session_options, "c")), this._matmul;
      }
      static get stft() {
        return this._stft || (this._stft = a2([8, 7, 18, 0, 58, 148, 1, 10, 38, 10, 1, 115, 10, 1, 106, 10, 1, 119, 10, 1, 108, 18, 1, 111, 34, 4, 83, 84, 70, 84, 42, 15, 10, 8, 111, 110, 101, 115, 105, 100, 101, 100, 24, 1, 160, 1, 2, 18, 1, 115, 90, 26, 10, 1, 115, 18, 21, 10, 19, 8, 1, 18, 15, 10, 3, 18, 1, 98, 10, 3, 18, 1, 115, 10, 3, 18, 1, 99, 90, 11, 10, 1, 106, 18, 6, 10, 4, 8, 7, 18, 0, 90, 16, 10, 1, 119, 18, 11, 10, 9, 8, 1, 18, 5, 10, 3, 18, 1, 119, 90, 11, 10, 1, 108, 18, 6, 10, 4, 8, 7, 18, 0, 98, 31, 10, 1, 111, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 102, 10, 3, 18, 1, 100, 10, 3, 18, 1, 99, 66, 2, 16, 17], this.session_options, "o")), this._stft;
      }
      static get rfft() {
        return this._rfft || (this._rfft = a2([8, 9, 18, 0, 58, 97, 10, 33, 10, 1, 120, 10, 0, 10, 1, 97, 18, 1, 121, 34, 3, 68, 70, 84, 42, 15, 10, 8, 111, 110, 101, 115, 105, 100, 101, 100, 24, 1, 160, 1, 2, 18, 1, 100, 90, 21, 10, 1, 120, 18, 16, 10, 14, 8, 1, 18, 10, 10, 3, 18, 1, 115, 10, 3, 18, 1, 99, 90, 11, 10, 1, 97, 18, 6, 10, 4, 8, 7, 18, 0, 98, 21, 10, 1, 121, 18, 16, 10, 14, 8, 1, 18, 10, 10, 3, 18, 1, 115, 10, 3, 18, 1, 99, 66, 2, 16, 20], this.session_options, "y")), this._rfft;
      }
      static get top_k() {
        return this._top_k || (this._top_k = a2([8, 10, 18, 0, 58, 73, 10, 18, 10, 1, 120, 10, 1, 107, 18, 1, 118, 18, 1, 105, 34, 4, 84, 111, 112, 75, 18, 1, 116, 90, 9, 10, 1, 120, 18, 4, 10, 2, 8, 1, 90, 15, 10, 1, 107, 18, 10, 10, 8, 8, 7, 18, 4, 10, 2, 8, 1, 98, 9, 10, 1, 118, 18, 4, 10, 2, 8, 1, 98, 9, 10, 1, 105, 18, 4, 10, 2, 8, 7, 66, 2, 16, 21], this.session_options, ["v", "i"])), this._top_k;
      }
      static get slice() {
        return this._slice || (this._slice = a2([8, 7, 18, 0, 58, 96, 10, 25, 10, 1, 120, 10, 1, 115, 10, 1, 101, 10, 1, 97, 10, 1, 116, 18, 1, 121, 34, 5, 83, 108, 105, 99, 101, 18, 1, 114, 90, 9, 10, 1, 120, 18, 4, 10, 2, 8, 1, 90, 9, 10, 1, 115, 18, 4, 10, 2, 8, 7, 90, 9, 10, 1, 101, 18, 4, 10, 2, 8, 7, 90, 9, 10, 1, 97, 18, 4, 10, 2, 8, 7, 90, 9, 10, 1, 116, 18, 4, 10, 2, 8, 7, 98, 9, 10, 1, 121, 18, 4, 10, 2, 8, 1, 66, 2, 16, 13], this.session_options, "y")), this._slice;
      }
    }
  }, "./src/pipelines.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { AudioClassificationPipeline: () => C2, AutomaticSpeechRecognitionPipeline: () => F2, BackgroundRemovalPipeline: () => z2, DepthEstimationPipeline: () => R2, DocumentQuestionAnsweringPipeline: () => B2, FeatureExtractionPipeline: () => P2, FillMaskPipeline: () => b2, ImageClassificationPipeline: () => I2, ImageFeatureExtractionPipeline: () => $2, ImageSegmentationPipeline: () => A2, ImageToImagePipeline: () => j2, ImageToTextPipeline: () => E2, ObjectDetectionPipeline: () => O2, Pipeline: () => f2, QuestionAnsweringPipeline: () => w2, SummarizationPipeline: () => M2, Text2TextGenerationPipeline: () => y2, TextClassificationPipeline: () => _2, TextGenerationPipeline: () => T2, TextToAudioPipeline: () => N2, TokenClassificationPipeline: () => g2, TranslationPipeline: () => x2, ZeroShotAudioClassificationPipeline: () => S2, ZeroShotClassificationPipeline: () => k2, ZeroShotImageClassificationPipeline: () => L2, ZeroShotObjectDetectionPipeline: () => D2, pipeline: () => q2 });
    var r2 = n2("./src/tokenizers.js"), s2 = n2("./src/models.js"), a2 = n2("./src/models/auto/processing_auto.js"), o2 = (n2("./src/base/processing_utils.js"), n2("./src/utils/generic.js")), i2 = n2("./src/utils/core.js"), l2 = n2("./src/utils/maths.js"), d2 = n2("./src/utils/audio.js"), u2 = n2("./src/utils/tensor.js"), c2 = n2("./src/utils/image.js");
    async function p2(e3) {
      return Array.isArray(e3) || (e3 = [e3]), await Promise.all(e3.map(((e4) => c2.RawImage.read(e4))));
    }
    async function m2(e3, t3) {
      return Array.isArray(e3) || (e3 = [e3]), await Promise.all(e3.map(((e4) => "string" == typeof e4 || e4 instanceof URL ? (0, d2.read_audio)(e4, t3) : e4 instanceof Float64Array ? new Float32Array(e4) : e4)));
    }
    function h2(e3, t3) {
      t3 && (e3 = e3.map(((e4) => 0 | e4)));
      const [n3, r3, s3, a3] = e3;
      return { xmin: n3, ymin: r3, xmax: s3, ymax: a3 };
    }
    class f2 extends o2.Callable {
      constructor({ task: e3, model: t3, tokenizer: n3 = null, processor: r3 = null }) {
        super(), this.task = e3, this.model = t3, this.tokenizer = n3, this.processor = r3;
      }
      async dispose() {
        await this.model.dispose();
      }
    }
    class _2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, { top_k: t3 = 1 } = {}) {
        const n3 = this.tokenizer(e3, { padding: true, truncation: true }), r3 = await this.model(n3), s3 = "multi_label_classification" === this.model.config.problem_type ? (e4) => e4.sigmoid() : (e4) => new u2.Tensor("float32", (0, l2.softmax)(e4.data), e4.dims), a3 = this.model.config.id2label, o3 = [];
        for (const e4 of r3.logits) {
          const n4 = s3(e4), r4 = await (0, u2.topk)(n4, t3), i3 = r4[0].tolist(), l3 = r4[1].tolist().map(((e5, t4) => ({ label: a3 ? a3[e5] : `LABEL_${e5}`, score: i3[t4] })));
          1 === t3 ? o3.push(...l3) : o3.push(l3);
        }
        return Array.isArray(e3) || 1 === t3 ? o3 : o3[0];
      }
    }
    class g2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, { ignore_labels: t3 = ["O"] } = {}) {
        const n3 = Array.isArray(e3), r3 = this.tokenizer(n3 ? e3 : [e3], { padding: true, truncation: true }), s3 = (await this.model(r3)).logits, a3 = this.model.config.id2label, o3 = [];
        for (let e4 = 0; e4 < s3.dims[0]; ++e4) {
          const n4 = r3.input_ids[e4], i3 = s3[e4], d3 = [];
          for (let e5 = 0; e5 < i3.dims[0]; ++e5) {
            const r4 = i3[e5], s4 = (0, l2.max)(r4.data)[1], o4 = a3 ? a3[s4] : `LABEL_${s4}`;
            if (t3.includes(o4)) continue;
            const u3 = this.tokenizer.decode([n4[e5].item()], { skip_special_tokens: true });
            if ("" === u3) continue;
            const c3 = (0, l2.softmax)(r4.data);
            d3.push({ entity: o4, score: c3[s4], index: e5, word: u3 });
          }
          o3.push(d3);
        }
        return n3 ? o3 : o3[0];
      }
    }
    class w2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, t3, { top_k: n3 = 1 } = {}) {
        const r3 = this.tokenizer(e3, { text_pair: t3, padding: true, truncation: true }), { start_logits: s3, end_logits: a3 } = await this.model(r3), o3 = r3.input_ids.tolist(), d3 = r3.attention_mask.tolist(), u3 = this.tokenizer.all_special_ids, c3 = [];
        for (let e4 = 0; e4 < s3.dims[0]; ++e4) {
          const t4 = o3[e4], r4 = t4.findIndex(((e5) => e5 == this.tokenizer.sep_token_id)), p3 = (d3[e4].map(((e5, n4) => 1 == e5 && (0 === n4 || n4 > r4 && -1 === u3.findIndex(((e6) => e6 == t4[n4]))))), s3[e4].tolist()), m3 = a3[e4].tolist();
          for (let n4 = 1; n4 < p3.length; ++n4) (0 == d3[e4] || n4 <= r4 || -1 !== u3.findIndex(((e5) => e5 == t4[n4]))) && (p3[n4] = -1 / 0, m3[n4] = -1 / 0);
          const h3 = (0, l2.softmax)(p3).map(((e5, t5) => [e5, t5])), f3 = (0, l2.softmax)(m3).map(((e5, t5) => [e5, t5]));
          h3[0][0] = 0, f3[0][0] = 0;
          const _3 = (0, i2.product)(h3, f3).filter(((e5) => e5[0][1] <= e5[1][1])).map(((e5) => [e5[0][1], e5[1][1], e5[0][0] * e5[1][0]])).sort(((e5, t5) => t5[2] - e5[2]));
          for (let e5 = 0; e5 < Math.min(_3.length, n3); ++e5) {
            const [n4, r5, s4] = _3[e5], a4 = t4.slice(n4, r5 + 1), o4 = this.tokenizer.decode(a4, { skip_special_tokens: true });
            c3.push({ answer: o4, score: s4 });
          }
        }
        return 1 === n3 ? c3[0] : c3;
      }
    }
    class b2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, { top_k: t3 = 5 } = {}) {
        const n3 = this.tokenizer(e3, { padding: true, truncation: true }), { logits: r3 } = await this.model(n3), s3 = [], a3 = n3.input_ids.tolist();
        for (let e4 = 0; e4 < a3.length; ++e4) {
          const n4 = a3[e4], o3 = n4.findIndex(((e5) => e5 == this.tokenizer.mask_token_id));
          if (-1 === o3) throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`);
          const i3 = r3[e4][o3], d3 = await (0, u2.topk)(new u2.Tensor("float32", (0, l2.softmax)(i3.data), i3.dims), t3), c3 = d3[0].tolist(), p3 = d3[1].tolist();
          s3.push(p3.map(((e5, t4) => {
            const r4 = n4.slice();
            return r4[o3] = e5, { score: c3[t4], token: Number(e5), token_str: this.tokenizer.decode([e5]), sequence: this.tokenizer.decode(r4, { skip_special_tokens: true }) };
          })));
        }
        return Array.isArray(e3) ? s3 : s3[0];
      }
    }
    class y2 extends f2 {
      _key = "generated_text";
      constructor(e3) {
        super(e3);
      }
      async _call(e3, t3 = {}) {
        Array.isArray(e3) || (e3 = [e3]), this.model.config.prefix && (e3 = e3.map(((e4) => this.model.config.prefix + e4)));
        const n3 = this.model.config.task_specific_params;
        n3 && n3[this.task] && n3[this.task].prefix && (e3 = e3.map(((e4) => n3[this.task].prefix + e4)));
        const r3 = this.tokenizer, s3 = { padding: true, truncation: true };
        let a3;
        a3 = this instanceof x2 && "_build_translation_inputs" in r3 ? r3._build_translation_inputs(e3, s3, t3) : r3(e3, s3);
        const o3 = await this.model.generate({ ...a3, ...t3 });
        return r3.batch_decode(o3, { skip_special_tokens: true }).map(((e4) => ({ [this._key]: e4 })));
      }
    }
    class M2 extends y2 {
      _key = "summary_text";
      constructor(e3) {
        super(e3);
      }
    }
    class x2 extends y2 {
      _key = "translation_text";
      constructor(e3) {
        super(e3);
      }
    }
    function v2(e3) {
      return Array.isArray(e3) && e3.every(((e4) => "role" in e4 && "content" in e4));
    }
    class T2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, t3 = {}) {
        let n3, r3 = false, s3 = false, a3 = t3.add_special_tokens ?? (this.tokenizer.add_bos_token || this.tokenizer.add_eos_token) ?? false;
        if ("string" == typeof e3) n3 = e3 = [e3];
        else if (Array.isArray(e3) && e3.every(((e4) => "string" == typeof e4))) r3 = true, n3 = e3;
        else {
          if (v2(e3)) e3 = [e3];
          else {
            if (!Array.isArray(e3) || !e3.every(v2)) throw new Error("Input must be a string, an array of strings, a Chat, or an array of Chats");
            r3 = true;
          }
          s3 = true, n3 = e3.map(((e4) => this.tokenizer.apply_chat_template(e4, { tokenize: false, add_generation_prompt: true }))), a3 = false;
        }
        const o3 = !s3 && (t3.return_full_text ?? true);
        this.tokenizer.padding_side = "left";
        const i3 = this.tokenizer(n3, { add_special_tokens: a3, padding: true, truncation: true }), l3 = await this.model.generate({ ...i3, ...t3 }), d3 = this.tokenizer.batch_decode(l3, { skip_special_tokens: true });
        let u3;
        !o3 && i3.input_ids.dims.at(-1) > 0 && (u3 = this.tokenizer.batch_decode(i3.input_ids, { skip_special_tokens: true }).map(((e4) => e4.length)));
        const c3 = Array.from({ length: e3.length }, ((e4) => []));
        for (let t4 = 0; t4 < d3.length; ++t4) {
          const n4 = Math.floor(t4 / l3.dims[0] * e3.length);
          u3 && (d3[t4] = d3[t4].slice(u3[n4])), c3[n4].push({ generated_text: s3 ? [...e3[n4], { role: "assistant", content: d3[t4] }] : d3[t4] });
        }
        return r3 || 1 !== c3.length ? c3 : c3[0];
      }
    }
    class k2 extends f2 {
      constructor(e3) {
        super(e3), this.label2id = Object.fromEntries(Object.entries(this.model.config.label2id).map((([e4, t3]) => [e4.toLowerCase(), t3]))), this.entailment_id = this.label2id.entailment, void 0 === this.entailment_id && (console.warn("Could not find 'entailment' in label2id mapping. Using 2 as entailment_id."), this.entailment_id = 2), this.contradiction_id = this.label2id.contradiction ?? this.label2id.not_entailment, void 0 === this.contradiction_id && (console.warn("Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id."), this.contradiction_id = 0);
      }
      async _call(e3, t3, { hypothesis_template: n3 = "This example is {}.", multi_label: r3 = false } = {}) {
        const s3 = Array.isArray(e3);
        s3 || (e3 = [e3]), Array.isArray(t3) || (t3 = [t3]);
        const a3 = t3.map(((e4) => n3.replace("{}", e4))), o3 = r3 || 1 === t3.length, i3 = [];
        for (const n4 of e3) {
          const e4 = [];
          for (const t4 of a3) {
            const r5 = this.tokenizer(n4, { text_pair: t4, padding: true, truncation: true }), s4 = await this.model(r5);
            o3 ? e4.push([s4.logits.data[this.contradiction_id], s4.logits.data[this.entailment_id]]) : e4.push(s4.logits.data[this.entailment_id]);
          }
          const r4 = (o3 ? e4.map(((e5) => (0, l2.softmax)(e5)[1])) : (0, l2.softmax)(e4)).map(((e5, t4) => [e5, t4])).sort(((e5, t4) => t4[0] - e5[0]));
          i3.push({ sequence: n4, labels: r4.map(((e5) => t3[e5[1]])), scores: r4.map(((e5) => e5[0])) });
        }
        return s3 ? i3 : i3[0];
      }
    }
    class P2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, { pooling: t3 = "none", normalize: n3 = false, quantize: r3 = false, precision: s3 = "binary" } = {}) {
        const a3 = this.tokenizer(e3, { padding: true, truncation: true }), o3 = await this.model(a3);
        let i3 = o3.last_hidden_state ?? o3.logits ?? o3.token_embeddings;
        switch (t3) {
          case "none":
            break;
          case "mean":
            i3 = (0, u2.mean_pooling)(i3, a3.attention_mask);
            break;
          case "first_token":
          case "cls":
            i3 = i3.slice(null, 0);
            break;
          case "last_token":
          case "eos":
            i3 = i3.slice(null, -1);
            break;
          default:
            throw Error(`Pooling method '${t3}' not supported.`);
        }
        return n3 && (i3 = i3.normalize(2, -1)), r3 && (i3 = (0, u2.quantize_embeddings)(i3, s3)), i3;
      }
    }
    class $2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, { pool: t3 = null } = {}) {
        const n3 = await p2(e3), { pixel_values: r3 } = await this.processor(n3), s3 = await this.model({ pixel_values: r3 });
        let a3;
        if (t3) {
          if (!("pooler_output" in s3)) throw Error("No pooled output was returned. Make sure the model has a 'pooler' layer when using the 'pool' option.");
          a3 = s3.pooler_output;
        } else a3 = s3.last_hidden_state ?? s3.logits ?? s3.image_embeds;
        return a3;
      }
    }
    class C2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, { top_k: t3 = 5 } = {}) {
        const n3 = this.processor.feature_extractor.config.sampling_rate, r3 = await m2(e3, n3), s3 = this.model.config.id2label, a3 = [];
        for (const e4 of r3) {
          const n4 = await this.processor(e4), r4 = (await this.model(n4)).logits[0], o3 = await (0, u2.topk)(new u2.Tensor("float32", (0, l2.softmax)(r4.data), r4.dims), t3), i3 = o3[0].tolist(), d3 = o3[1].tolist().map(((e5, t4) => ({ label: s3 ? s3[e5] : `LABEL_${e5}`, score: i3[t4] })));
          a3.push(d3);
        }
        return Array.isArray(e3) ? a3 : a3[0];
      }
    }
    class S2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, t3, { hypothesis_template: n3 = "This is a sound of {}." } = {}) {
        const r3 = !Array.isArray(e3);
        r3 && (e3 = [e3]);
        const s3 = t3.map(((e4) => n3.replace("{}", e4))), a3 = this.tokenizer(s3, { padding: true, truncation: true }), o3 = this.processor.feature_extractor.config.sampling_rate, i3 = await m2(e3, o3), d3 = [];
        for (const e4 of i3) {
          const n4 = await this.processor(e4), r4 = await this.model({ ...a3, ...n4 }), s4 = (0, l2.softmax)(r4.logits_per_audio.data);
          d3.push([...s4].map(((e5, n5) => ({ score: e5, label: t3[n5] }))));
        }
        return r3 ? d3[0] : d3;
      }
    }
    class F2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, t3 = {}) {
        switch (this.model.config.model_type) {
          case "whisper":
          case "lite-whisper":
            return this._call_whisper(e3, t3);
          case "wav2vec2":
          case "wav2vec2-bert":
          case "unispeech":
          case "unispeech-sat":
          case "hubert":
          case "parakeet_ctc":
            return this._call_wav2vec2(e3, t3);
          case "moonshine":
            return this._call_moonshine(e3, t3);
          default:
            throw new Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`);
        }
      }
      async _call_wav2vec2(e3, t3) {
        t3.language && console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to "English".'), t3.task && console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to "transcribe".');
        const n3 = !Array.isArray(e3);
        n3 && (e3 = [e3]);
        const r3 = this.processor.feature_extractor.config.sampling_rate, s3 = await m2(e3, r3), a3 = [];
        for (const e4 of s3) {
          const t4 = await this.processor(e4), n4 = (await this.model(t4)).logits[0], r4 = [];
          for (const e5 of n4) r4.push((0, l2.max)(e5.data)[1]);
          const s4 = this.tokenizer.decode(r4, { skip_special_tokens: true }).trim();
          a3.push({ text: s4 });
        }
        return n3 ? a3[0] : a3;
      }
      async _call_whisper(e3, t3) {
        const n3 = t3.return_timestamps ?? false, r3 = t3.chunk_length_s ?? 0, s3 = t3.force_full_sequences ?? false;
        let a3 = t3.stride_length_s ?? null;
        const o3 = { ...t3 };
        "word" === n3 && (o3.return_token_timestamps = true, o3.return_timestamps = false);
        const i3 = !Array.isArray(e3);
        i3 && (e3 = [e3]);
        const d3 = this.processor.feature_extractor.config.chunk_length / this.model.config.max_source_positions, u3 = this.processor.feature_extractor.config.hop_length, c3 = this.processor.feature_extractor.config.sampling_rate, p3 = await m2(e3, c3), h3 = [];
        for (const e4 of p3) {
          let t4 = [];
          if (r3 > 0) {
            if (null === a3) a3 = r3 / 6;
            else if (r3 <= a3) throw Error("`chunk_length_s` must be larger than `stride_length_s`.");
            const n4 = c3 * r3, s4 = c3 * a3, o4 = n4 - 2 * s4;
            let i5 = 0;
            for (; ; ) {
              const r4 = i5 + n4, a4 = e4.subarray(i5, r4), l3 = await this.processor(a4), d4 = 0 === i5, u4 = r4 >= e4.length;
              if (t4.push({ stride: [a4.length, d4 ? 0 : s4, u4 ? 0 : s4], input_features: l3.input_features, is_last: u4 }), u4) break;
              i5 += o4;
            }
          } else t4 = [{ stride: [e4.length, 0, 0], input_features: (await this.processor(e4)).input_features, is_last: true }];
          for (const e5 of t4) {
            o3.num_frames = Math.floor(e5.stride[0] / u3);
            const t5 = await this.model.generate({ inputs: e5.input_features, ...o3 });
            "word" === n3 ? (e5.tokens = t5.sequences.tolist()[0], e5.token_timestamps = t5.token_timestamps.tolist()[0].map(((e6) => (0, l2.round)(e6, 2)))) : e5.tokens = t5[0].tolist(), e5.stride = e5.stride.map(((e6) => e6 / c3));
          }
          const [i4, p4] = this.tokenizer._decode_asr(t4, { time_precision: d3, return_timestamps: n3, force_full_sequences: s3 });
          h3.push({ text: i4, ...p4 });
        }
        return i3 ? h3[0] : h3;
      }
      async _call_moonshine(e3, t3) {
        const n3 = !Array.isArray(e3);
        n3 && (e3 = [e3]);
        const r3 = this.processor.feature_extractor.config.sampling_rate, s3 = await m2(e3, r3), a3 = [];
        for (const e4 of s3) {
          const n4 = await this.processor(e4), s4 = 6 * Math.floor(e4.length / r3), o3 = await this.model.generate({ max_new_tokens: s4, ...t3, ...n4 }), i3 = this.processor.batch_decode(o3, { skip_special_tokens: true })[0];
          a3.push({ text: i3 });
        }
        return n3 ? a3[0] : a3;
      }
    }
    class E2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, t3 = {}) {
        const n3 = Array.isArray(e3), r3 = await p2(e3), { pixel_values: s3 } = await this.processor(r3), a3 = [];
        for (const e4 of s3) {
          e4.dims = [1, ...e4.dims];
          const n4 = await this.model.generate({ inputs: e4, ...t3 }), r4 = this.tokenizer.batch_decode(n4, { skip_special_tokens: true }).map(((e5) => ({ generated_text: e5.trim() })));
          a3.push(r4);
        }
        return n3 ? a3 : a3[0];
      }
    }
    class I2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, { top_k: t3 = 5 } = {}) {
        const n3 = await p2(e3), { pixel_values: r3 } = await this.processor(n3), s3 = await this.model({ pixel_values: r3 }), a3 = this.model.config.id2label, o3 = [];
        for (const e4 of s3.logits) {
          const n4 = await (0, u2.topk)(new u2.Tensor("float32", (0, l2.softmax)(e4.data), e4.dims), t3), r4 = n4[0].tolist(), s4 = n4[1].tolist().map(((e5, t4) => ({ label: a3 ? a3[e5] : `LABEL_${e5}`, score: r4[t4] })));
          o3.push(s4);
        }
        return Array.isArray(e3) ? o3 : o3[0];
      }
    }
    class A2 extends f2 {
      constructor(e3) {
        super(e3), this.subtasks_mapping = { panoptic: "post_process_panoptic_segmentation", instance: "post_process_instance_segmentation", semantic: "post_process_semantic_segmentation" };
      }
      async _call(e3, { threshold: t3 = 0.5, mask_threshold: n3 = 0.5, overlap_mask_area_threshold: r3 = 0.8, label_ids_to_fuse: s3 = null, target_sizes: a3 = null, subtask: o3 = null } = {}) {
        if (Array.isArray(e3) && 1 !== e3.length) throw Error("Image segmentation pipeline currently only supports a batch size of 1.");
        const i3 = await p2(e3), l3 = i3.map(((e4) => [e4.height, e4.width])), d3 = await this.processor(i3), { inputNames: u3, outputNames: m3 } = this.model.sessions.model;
        if (!u3.includes("pixel_values")) {
          if (1 !== u3.length) throw Error(`Expected a single input name, but got ${u3.length} inputs: ${u3}.`);
          const e4 = u3[0];
          if (e4 in d3) throw Error(`Input name ${e4} already exists in the inputs.`);
          d3[e4] = d3.pixel_values;
        }
        const h3 = await this.model(d3);
        let f3 = null;
        if (null !== o3) f3 = this.subtasks_mapping[o3];
        else if (this.processor.image_processor) {
          for (const [e4, t4] of Object.entries(this.subtasks_mapping)) if (t4 in this.processor.image_processor) {
            f3 = this.processor.image_processor[t4].bind(this.processor.image_processor), o3 = e4;
            break;
          }
        }
        const _3 = this.model.config.id2label, g3 = [];
        if (o3) if ("panoptic" === o3 || "instance" === o3) {
          const e4 = f3(h3, t3, n3, r3, s3, a3 ?? l3)[0], o4 = e4.segmentation;
          for (const t4 of e4.segments_info) {
            const e5 = new Uint8ClampedArray(o4.data.length);
            for (let n5 = 0; n5 < o4.data.length; ++n5) o4.data[n5] === t4.id && (e5[n5] = 255);
            const n4 = new c2.RawImage(e5, o4.dims[1], o4.dims[0], 1);
            g3.push({ score: t4.score, label: _3[t4.label_id], mask: n4 });
          }
        } else {
          if ("semantic" !== o3) throw Error(`Subtask ${o3} not supported.`);
          {
            const { segmentation: e4, labels: t4 } = f3(h3, a3 ?? l3)[0];
            for (const n4 of t4) {
              const t5 = new Uint8ClampedArray(e4.data.length);
              for (let r5 = 0; r5 < e4.data.length; ++r5) e4.data[r5] === n4 && (t5[r5] = 255);
              const r4 = new c2.RawImage(t5, e4.dims[1], e4.dims[0], 1);
              g3.push({ score: null, label: _3[n4], mask: r4 });
            }
          }
        }
        else {
          const e4 = 1e-5, t4 = h3[m3[0]];
          for (let n4 = 0; n4 < l3.length; ++n4) {
            const r4 = l3[n4], s4 = t4[n4];
            s4.data.some(((t5) => t5 < -e4 || t5 > 1 + e4)) && s4.sigmoid_();
            const a4 = await c2.RawImage.fromTensor(s4.mul_(255).to("uint8")).resize(r4[1], r4[0]);
            g3.push({ label: null, score: null, mask: a4 });
          }
        }
        return g3;
      }
    }
    class z2 extends A2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, t3 = {}) {
        if (Array.isArray(e3) && 1 !== e3.length) throw Error("Background removal pipeline currently only supports a batch size of 1.");
        const n3 = await p2(e3), r3 = await super._call(e3, t3);
        return n3.map(((e4, t4) => {
          const n4 = e4.clone();
          return n4.putAlpha(r3[t4].mask), n4;
        }));
      }
    }
    class L2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, t3, { hypothesis_template: n3 = "This is a photo of {}" } = {}) {
        const r3 = Array.isArray(e3), s3 = await p2(e3), a3 = t3.map(((e4) => n3.replace("{}", e4))), o3 = this.tokenizer(a3, { padding: "siglip" !== this.model.config.model_type || "max_length", truncation: true }), { pixel_values: i3 } = await this.processor(s3), d3 = await this.model({ ...o3, pixel_values: i3 }), u3 = "siglip" === this.model.config.model_type ? (e4) => e4.sigmoid().data : (e4) => (0, l2.softmax)(e4.data), c3 = [];
        for (const e4 of d3.logits_per_image) {
          const n4 = [...u3(e4)].map(((e5, n5) => ({ score: e5, label: t3[n5] })));
          n4.sort(((e5, t4) => t4.score - e5.score)), c3.push(n4);
        }
        return r3 ? c3 : c3[0];
      }
    }
    class O2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, { threshold: t3 = 0.9, percentage: n3 = false } = {}) {
        const r3 = Array.isArray(e3);
        if (r3 && 1 !== e3.length) throw Error("Object detection pipeline currently only supports a batch size of 1.");
        const s3 = await p2(e3), a3 = n3 ? null : s3.map(((e4) => [e4.height, e4.width])), { pixel_values: o3, pixel_mask: i3 } = await this.processor(s3), l3 = await this.model({ pixel_values: o3, pixel_mask: i3 }), d3 = this.processor.image_processor.post_process_object_detection(l3, t3, a3), u3 = this.model.config.id2label, c3 = d3.map(((e4) => e4.boxes.map(((t4, r4) => ({ score: e4.scores[r4], label: u3[e4.classes[r4]], box: h2(t4, !n3) })))));
        return r3 ? c3 : c3[0];
      }
    }
    class D2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, t3, { threshold: n3 = 0.1, top_k: r3 = null, percentage: s3 = false } = {}) {
        const a3 = Array.isArray(e3), o3 = await p2(e3), i3 = this.tokenizer(t3, { padding: true, truncation: true }), l3 = await this.processor(o3), d3 = [];
        for (let e4 = 0; e4 < o3.length; ++e4) {
          const a4 = o3[e4], u3 = s3 ? null : [[a4.height, a4.width]], c3 = l3.pixel_values[e4].unsqueeze_(0), p3 = await this.model({ ...i3, pixel_values: c3 });
          let m3;
          if ("post_process_grounded_object_detection" in this.processor) {
            const e5 = this.processor.post_process_grounded_object_detection(p3, i3.input_ids, { box_threshold: n3, text_threshold: n3, target_sizes: u3 })[0];
            m3 = e5.boxes.map(((t4, n4) => ({ score: e5.scores[n4], label: e5.labels[n4], box: h2(t4, !s3) })));
          } else {
            const e5 = this.processor.image_processor.post_process_object_detection(p3, n3, u3, true)[0];
            m3 = e5.boxes.map(((n4, r4) => ({ score: e5.scores[r4], label: t3[e5.classes[r4]], box: h2(n4, !s3) })));
          }
          m3.sort(((e5, t4) => t4.score - e5.score)), null !== r3 && (m3 = m3.slice(0, r3)), d3.push(m3);
        }
        return a3 ? d3 : d3[0];
      }
    }
    class B2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3, t3, n3 = {}) {
        const r3 = (await p2(e3))[0], { pixel_values: s3 } = await this.processor(r3), a3 = `<s_docvqa><s_question>${t3}</s_question><s_answer>`, o3 = this.tokenizer(a3, { add_special_tokens: false, padding: true, truncation: true }).input_ids, i3 = await this.model.generate({ inputs: s3, max_length: this.model.config.decoder.max_position_embeddings, decoder_input_ids: o3, ...n3 }), l3 = this.tokenizer.batch_decode(i3)[0].match(/<s_answer>(.*?)<\/s_answer>/);
        let d3 = null;
        return l3 && l3.length >= 2 && (d3 = l3[1].trim()), [{ answer: d3 }];
      }
    }
    class N2 extends f2 {
      DEFAULT_VOCODER_ID = "Xenova/speecht5_hifigan";
      constructor(e3) {
        super(e3), this.vocoder = e3.vocoder ?? null;
      }
      async _prepare_speaker_embeddings(e3) {
        if (("string" == typeof e3 || e3 instanceof URL) && (e3 = new Float32Array(await (await fetch(e3)).arrayBuffer())), e3 instanceof Float32Array) e3 = new u2.Tensor("float32", e3, [e3.length]);
        else if (!(e3 instanceof u2.Tensor)) throw new Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.");
        return e3;
      }
      async _call(e3, { speaker_embeddings: t3 = null, num_inference_steps: n3, speed: r3 } = {}) {
        return this.processor ? this._call_text_to_spectrogram(e3, { speaker_embeddings: t3 }) : "supertonic" === this.model.config.model_type ? this._call_supertonic(e3, { speaker_embeddings: t3, num_inference_steps: n3, speed: r3 }) : this._call_text_to_waveform(e3);
      }
      async _call_supertonic(e3, { speaker_embeddings: t3, num_inference_steps: n3, speed: r3 }) {
        if (!t3) throw new Error("Speaker embeddings must be provided for Supertonic models.");
        t3 = await this._prepare_speaker_embeddings(t3);
        const { sampling_rate: s3, style_dim: a3 } = this.model.config;
        t3 = t3.view(1, -1, a3);
        const o3 = this.tokenizer(e3, { padding: true, truncation: true }), { waveform: i3 } = await this.model.generate_speech({ ...o3, style: t3, num_inference_steps: n3, speed: r3 });
        return new d2.RawAudio(i3.data, s3);
      }
      async _call_text_to_waveform(e3) {
        const t3 = this.tokenizer(e3, { padding: true, truncation: true }), { waveform: n3 } = await this.model(t3), r3 = this.model.config.sampling_rate;
        return new d2.RawAudio(n3.data, r3);
      }
      async _call_text_to_spectrogram(e3, { speaker_embeddings: t3 }) {
        this.vocoder || (console.log("No vocoder specified, using default HifiGan vocoder."), this.vocoder = await s2.AutoModel.from_pretrained(this.DEFAULT_VOCODER_ID, { dtype: "fp32" }));
        const { input_ids: n3 } = this.tokenizer(e3, { padding: true, truncation: true });
        t3 = (t3 = await this._prepare_speaker_embeddings(t3)).view(1, -1);
        const { waveform: r3 } = await this.model.generate_speech(n3, t3, { vocoder: this.vocoder }), a3 = this.processor.feature_extractor.config.sampling_rate;
        return new d2.RawAudio(r3.data, a3);
      }
    }
    class j2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3) {
        const t3 = await p2(e3), n3 = await this.processor(t3), r3 = await this.model(n3), s3 = [];
        for (const e4 of r3.reconstruction) {
          const t4 = e4.squeeze().clamp_(0, 1).mul_(255).round_().to("uint8");
          s3.push(c2.RawImage.fromTensor(t4));
        }
        return s3.length > 1 ? s3 : s3[0];
      }
    }
    class R2 extends f2 {
      constructor(e3) {
        super(e3);
      }
      async _call(e3) {
        const t3 = await p2(e3), n3 = await this.processor(t3), { predicted_depth: r3 } = await this.model(n3), s3 = [];
        for (let e4 = 0; e4 < t3.length; ++e4) {
          const n4 = r3[e4], [a3, o3] = n4.dims.slice(-2), [i3, l3] = t3[e4].size, d3 = (await (0, u2.interpolate_4d)(n4.view(1, 1, a3, o3), { size: [l3, i3], mode: "bilinear" })).view(l3, i3), p3 = d3.min().item(), m3 = d3.max().item(), h3 = d3.sub(p3).div_(m3 - p3).mul_(255).to("uint8").unsqueeze(0), f3 = c2.RawImage.fromTensor(h3);
          s3.push({ predicted_depth: d3, depth: f3 });
        }
        return s3.length > 1 ? s3 : s3[0];
      }
    }
    const V2 = Object.freeze({ "text-classification": { tokenizer: r2.AutoTokenizer, pipeline: _2, model: s2.AutoModelForSequenceClassification, default: { model: "Xenova/distilbert-base-uncased-finetuned-sst-2-english" }, type: "text" }, "token-classification": { tokenizer: r2.AutoTokenizer, pipeline: g2, model: s2.AutoModelForTokenClassification, default: { model: "Xenova/bert-base-multilingual-cased-ner-hrl" }, type: "text" }, "question-answering": { tokenizer: r2.AutoTokenizer, pipeline: w2, model: s2.AutoModelForQuestionAnswering, default: { model: "Xenova/distilbert-base-cased-distilled-squad" }, type: "text" }, "fill-mask": { tokenizer: r2.AutoTokenizer, pipeline: b2, model: s2.AutoModelForMaskedLM, default: { model: "Xenova/bert-base-uncased" }, type: "text" }, summarization: { tokenizer: r2.AutoTokenizer, pipeline: M2, model: s2.AutoModelForSeq2SeqLM, default: { model: "Xenova/distilbart-cnn-6-6" }, type: "text" }, translation: { tokenizer: r2.AutoTokenizer, pipeline: x2, model: s2.AutoModelForSeq2SeqLM, default: { model: "Xenova/t5-small" }, type: "text" }, "text2text-generation": { tokenizer: r2.AutoTokenizer, pipeline: y2, model: s2.AutoModelForSeq2SeqLM, default: { model: "Xenova/flan-t5-small" }, type: "text" }, "text-generation": { tokenizer: r2.AutoTokenizer, pipeline: T2, model: s2.AutoModelForCausalLM, default: { model: "Xenova/gpt2" }, type: "text" }, "zero-shot-classification": { tokenizer: r2.AutoTokenizer, pipeline: k2, model: s2.AutoModelForSequenceClassification, default: { model: "Xenova/distilbert-base-uncased-mnli" }, type: "text" }, "audio-classification": { pipeline: C2, model: s2.AutoModelForAudioClassification, processor: a2.AutoProcessor, default: { model: "Xenova/wav2vec2-base-superb-ks" }, type: "audio" }, "zero-shot-audio-classification": { tokenizer: r2.AutoTokenizer, pipeline: S2, model: s2.AutoModel, processor: a2.AutoProcessor, default: { model: "Xenova/clap-htsat-unfused" }, type: "multimodal" }, "automatic-speech-recognition": { tokenizer: r2.AutoTokenizer, pipeline: F2, model: [s2.AutoModelForSpeechSeq2Seq, s2.AutoModelForCTC], processor: a2.AutoProcessor, default: { model: "Xenova/whisper-tiny.en" }, type: "multimodal" }, "text-to-audio": { tokenizer: r2.AutoTokenizer, pipeline: N2, model: [s2.AutoModelForTextToWaveform, s2.AutoModelForTextToSpectrogram], processor: [a2.AutoProcessor, null], default: { model: "Xenova/speecht5_tts" }, type: "text" }, "image-to-text": { tokenizer: r2.AutoTokenizer, pipeline: E2, model: s2.AutoModelForVision2Seq, processor: a2.AutoProcessor, default: { model: "Xenova/vit-gpt2-image-captioning" }, type: "multimodal" }, "image-classification": { pipeline: I2, model: s2.AutoModelForImageClassification, processor: a2.AutoProcessor, default: { model: "Xenova/vit-base-patch16-224" }, type: "multimodal" }, "image-segmentation": { pipeline: A2, model: [s2.AutoModelForImageSegmentation, s2.AutoModelForSemanticSegmentation, s2.AutoModelForUniversalSegmentation], processor: a2.AutoProcessor, default: { model: "Xenova/detr-resnet-50-panoptic" }, type: "multimodal" }, "background-removal": { pipeline: z2, model: [s2.AutoModelForImageSegmentation, s2.AutoModelForSemanticSegmentation, s2.AutoModelForUniversalSegmentation], processor: a2.AutoProcessor, default: { model: "Xenova/modnet" }, type: "image" }, "zero-shot-image-classification": { tokenizer: r2.AutoTokenizer, pipeline: L2, model: s2.AutoModel, processor: a2.AutoProcessor, default: { model: "Xenova/clip-vit-base-patch32" }, type: "multimodal" }, "object-detection": { pipeline: O2, model: s2.AutoModelForObjectDetection, processor: a2.AutoProcessor, default: { model: "Xenova/detr-resnet-50" }, type: "multimodal" }, "zero-shot-object-detection": { tokenizer: r2.AutoTokenizer, pipeline: D2, model: s2.AutoModelForZeroShotObjectDetection, processor: a2.AutoProcessor, default: { model: "Xenova/owlvit-base-patch32" }, type: "multimodal" }, "document-question-answering": { tokenizer: r2.AutoTokenizer, pipeline: B2, model: s2.AutoModelForDocumentQuestionAnswering, processor: a2.AutoProcessor, default: { model: "Xenova/donut-base-finetuned-docvqa" }, type: "multimodal" }, "image-to-image": { pipeline: j2, model: s2.AutoModelForImageToImage, processor: a2.AutoProcessor, default: { model: "Xenova/swin2SR-classical-sr-x2-64" }, type: "image" }, "depth-estimation": { pipeline: R2, model: s2.AutoModelForDepthEstimation, processor: a2.AutoProcessor, default: { model: "Xenova/dpt-large" }, type: "image" }, "feature-extraction": { tokenizer: r2.AutoTokenizer, pipeline: P2, model: s2.AutoModel, default: { model: "Xenova/all-MiniLM-L6-v2" }, type: "text" }, "image-feature-extraction": { processor: a2.AutoProcessor, pipeline: $2, model: [s2.AutoModelForImageFeatureExtraction, s2.AutoModel], default: { model: "Xenova/vit-base-patch16-224-in21k" }, type: "image" } }), G2 = Object.freeze({ "sentiment-analysis": "text-classification", ner: "token-classification", asr: "automatic-speech-recognition", "text-to-speech": "text-to-audio", embeddings: "feature-extraction" });
    async function q2(e3, t3 = null, { progress_callback: n3 = null, config: r3 = null, cache_dir: s3 = null, local_files_only: a3 = false, revision: o3 = "main", device: l3 = null, dtype: d3 = null, subfolder: u3 = "onnx", use_external_data_format: c3 = null, model_file_name: p3 = null, session_options: m3 = {} } = {}) {
      e3 = G2[e3] ?? e3;
      const h3 = V2[e3.split("_", 1)[0]];
      if (!h3) throw Error(`Unsupported pipeline: ${e3}. Must be one of [${Object.keys(V2)}]`);
      t3 || (t3 = h3.default.model, console.log(`No model specified. Using default model: "${t3}".`));
      const f3 = { progress_callback: n3, config: r3, cache_dir: s3, local_files_only: a3, revision: o3, device: l3, dtype: d3, subfolder: u3, use_external_data_format: c3, model_file_name: p3, session_options: m3 }, _3 = /* @__PURE__ */ new Map([["tokenizer", h3.tokenizer], ["model", h3.model], ["processor", h3.processor]]), g3 = await (async function(e4, t4, n4) {
        const r4 = /* @__PURE__ */ Object.create(null), s4 = [];
        for (const [a4, o4] of e4.entries()) {
          if (!o4) continue;
          let e5;
          e5 = Array.isArray(o4) ? new Promise((async (e6, r5) => {
            let s5;
            for (const a5 of o4) {
              if (null === a5) return void e6(null);
              try {
                return void e6(await a5.from_pretrained(t4, n4));
              } catch (e7) {
                if (e7.message?.includes("Unsupported model type")) s5 = e7;
                else {
                  if (!e7.message?.includes("Could not locate file")) return void r5(e7);
                  s5 = e7;
                }
              }
            }
            r5(s5);
          })) : o4.from_pretrained(t4, n4), r4[a4] = e5, s4.push(e5);
        }
        await Promise.all(s4);
        for (const [e5, t5] of Object.entries(r4)) r4[e5] = await t5;
        return r4;
      })(_3, t3, f3);
      g3.task = e3, (0, i2.dispatchCallback)(n3, { status: "ready", task: e3, model: t3 });
      return new (0, h3.pipeline)(g3);
    }
  }, "./src/tokenizers.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { AlbertTokenizer: () => ke2, AutoTokenizer: () => wt2, BartTokenizer: () => Ne2, BertTokenizer: () => Te2, BlenderbotSmallTokenizer: () => ct2, BlenderbotTokenizer: () => ut2, BloomTokenizer: () => Ge2, CLIPTokenizer: () => ot2, CamembertTokenizer: () => ze2, CodeGenTokenizer: () => at2, CodeLlamaTokenizer: () => We2, CohereTokenizer: () => ft2, ConvBertTokenizer: () => Ee2, DebertaTokenizer: () => Ce2, DebertaV2Tokenizer: () => Se2, DistilBertTokenizer: () => Ae2, ElectraTokenizer: () => Oe2, Ernie4_5_Tokenizer: () => gt2, EsmTokenizer: () => Je2, FalconTokenizer: () => Ke2, GPT2Tokenizer: () => Be2, GPTNeoXTokenizer: () => Xe2, GemmaTokenizer: () => Ze2, Grok1Tokenizer: () => et2, HerbertTokenizer: () => Fe2, LlamaTokenizer: () => Ue2, M2M100Tokenizer: () => rt2, MBart50Tokenizer: () => Re2, MBartTokenizer: () => je2, MPNetTokenizer: () => Qe2, MarianTokenizer: () => lt2, MgpstrTokenizer: () => _t2, MobileBertTokenizer: () => Pe2, NllbTokenizer: () => nt2, NougatTokenizer: () => mt2, PreTrainedTokenizer: () => ve2, Qwen2Tokenizer: () => Ye2, RoFormerTokenizer: () => Ie2, RobertaTokenizer: () => Ve2, SiglipTokenizer: () => it2, SpeechT5Tokenizer: () => pt2, SqueezeBertTokenizer: () => $e2, T5Tokenizer: () => De2, TokenizerModel: () => v2, VitsTokenizer: () => ht2, Wav2Vec2CTCTokenizer: () => dt2, WhisperTokenizer: () => st2, XLMRobertaTokenizer: () => He2, XLMTokenizer: () => Le2, is_chinese_char: () => g2 });
    var r2 = n2("./src/utils/generic.js"), s2 = n2("./src/utils/core.js"), a2 = n2("./src/utils/hub.js"), o2 = n2("./src/utils/maths.js"), i2 = n2("./src/utils/tensor.js"), l2 = n2("./src/utils/data-structures.js"), d2 = n2("./node_modules/@huggingface/jinja/dist/index.js"), u2 = n2("./src/models/whisper/common_whisper.js");
    async function c2(e3, t3) {
      const n3 = await Promise.all([(0, a2.getModelJSON)(e3, "tokenizer.json", true, t3), (0, a2.getModelJSON)(e3, "tokenizer_config.json", true, t3)]);
      return null !== t3.legacy && (n3[1].legacy = t3.legacy), n3;
    }
    function p2(e3, t3 = true) {
      if (void 0 !== e3.Regex) {
        let t4 = e3.Regex.replace(/\\([#&~])/g, "$1");
        for (const [e4, n3] of M2) t4 = t4.replaceAll(e4, n3);
        return new RegExp(t4, "gu");
      }
      if (void 0 !== e3.String) {
        const n3 = (0, s2.escapeRegExp)(e3.String);
        return new RegExp(t3 ? n3 : `(${n3})`, "gu");
      }
      return console.warn("Unknown pattern type:", e3), null;
    }
    function m2(e3) {
      return new Map(Object.entries(e3));
    }
    function h2(e3) {
      const t3 = e3.dims;
      switch (t3.length) {
        case 1:
          return e3.tolist();
        case 2:
          if (1 !== t3[0]) throw new Error("Unable to decode tensor with `batch size !== 1`. Use `tokenizer.batch_decode(...)` for batched inputs.");
          return e3.tolist()[0];
        default:
          throw new Error(`Expected tensor to have 1-2 dimensions, got ${t3.length}.`);
      }
    }
    function f2(e3) {
      return e3.replace(/ \./g, ".").replace(/ \?/g, "?").replace(/ \!/g, "!").replace(/ ,/g, ",").replace(/ \' /g, "'").replace(/ n\'t/g, "n't").replace(/ \'m/g, "'m").replace(/ \'s/g, "'s").replace(/ \'ve/g, "'ve").replace(/ \'re/g, "'re");
    }
    function _2(e3) {
      return e3.replace(/\p{M}/gu, "");
    }
    function g2(e3) {
      return e3 >= 19968 && e3 <= 40959 || e3 >= 13312 && e3 <= 19903 || e3 >= 131072 && e3 <= 173791 || e3 >= 173824 && e3 <= 177983 || e3 >= 177984 && e3 <= 178207 || e3 >= 178208 && e3 <= 183983 || e3 >= 63744 && e3 <= 64255 || e3 >= 194560 && e3 <= 195103;
    }
    const w2 = "\\p{P}\\u0021-\\u002F\\u003A-\\u0040\\u005B-\\u0060\\u007B-\\u007E", b2 = new RegExp(`^[${w2}]+$`, "gu"), y2 = ".,!?\u2026\u3002\uFF0C\u3001\u0964\u06D4\u060C", M2 = /* @__PURE__ */ new Map([["(?i:'s|'t|'re|'ve|'m|'ll|'d)", "(?:'([sS]|[tT]|[rR][eE]|[vV][eE]|[mM]|[lL][lL]|[dD]))"], ["(?i:[sdmt]|ll|ve|re)", "(?:[sS]|[dD]|[mM]|[tT]|[lL][lL]|[vV][eE]|[rR][eE])"], ["[^\\r\\n\\p{L}\\p{N}]?+", "[^\\r\\n\\p{L}\\p{N}]?"], ["[^\\s\\p{L}\\p{N}]++", "[^\\s\\p{L}\\p{N}]+"], [` ?[^(\\s|[${y2}])]+`, ` ?[^\\s${y2}]+`]]);
    class x2 {
      constructor(e3) {
        this.content = e3.content, this.id = e3.id, this.single_word = e3.single_word ?? false, this.lstrip = e3.lstrip ?? false, this.rstrip = e3.rstrip ?? false, this.special = e3.special ?? false, this.normalized = e3.normalized ?? null;
      }
    }
    class v2 extends r2.Callable {
      constructor(e3) {
        super(), this.config = e3, this.vocab = [], this.tokens_to_ids = /* @__PURE__ */ new Map(), this.unk_token_id = void 0, this.unk_token = void 0, this.end_of_word_suffix = void 0, this.fuse_unk = this.config.fuse_unk ?? false;
      }
      static fromConfig(e3, ...t3) {
        switch (e3.type) {
          case "WordPiece":
            return new T2(e3);
          case "Unigram":
            return new k2(e3, ...t3);
          case "BPE":
            return new C2(e3);
          default:
            if (e3.vocab) return Array.isArray(e3.vocab) ? new k2(e3, ...t3) : Object.hasOwn(e3, "continuing_subword_prefix") && Object.hasOwn(e3, "unk_token") ? Object.hasOwn(e3, "merges") ? new C2(e3) : new T2(e3) : new S2(e3, ...t3);
            throw new Error(`Unknown TokenizerModel type: ${e3.type}`);
        }
      }
      _call(e3) {
        return e3 = this.encode(e3), this.fuse_unk && (e3 = (function(e4, t3, n3) {
          const r3 = [];
          let s3 = 0;
          for (; s3 < e4.length; ) if (r3.push(e4[s3]), (t3.get(e4[s3]) ?? n3) === n3) for (; ++s3 < e4.length && (t3.get(e4[s3]) ?? n3) === n3; ) t3.get(r3.at(-1)) !== n3 && (r3[r3.length - 1] += e4[s3]);
          else ++s3;
          return r3;
        })(e3, this.tokens_to_ids, this.unk_token_id)), e3;
      }
      encode(e3) {
        throw Error("encode should be implemented in subclass.");
      }
      convert_tokens_to_ids(e3) {
        return e3.map(((e4) => this.tokens_to_ids.get(e4) ?? this.unk_token_id));
      }
      convert_ids_to_tokens(e3) {
        return e3.map(((e4) => this.vocab[e4] ?? this.unk_token));
      }
    }
    class T2 extends v2 {
      constructor(e3) {
        super(e3), this.tokens_to_ids = m2(e3.vocab), this.unk_token_id = this.tokens_to_ids.get(e3.unk_token), this.unk_token = e3.unk_token, this.max_input_chars_per_word = e3.max_input_chars_per_word ?? 100, this.vocab = new Array(this.tokens_to_ids.size);
        for (const [e4, t3] of this.tokens_to_ids) this.vocab[t3] = e4;
      }
      encode(e3) {
        const t3 = [];
        for (const n3 of e3) {
          const e4 = [...n3];
          if (e4.length > this.max_input_chars_per_word) {
            t3.push(this.unk_token);
            continue;
          }
          let r3 = false, s3 = 0;
          const a3 = [];
          for (; s3 < e4.length; ) {
            let t4 = e4.length, n4 = null;
            for (; s3 < t4; ) {
              let r4 = e4.slice(s3, t4).join("");
              if (s3 > 0 && (r4 = this.config.continuing_subword_prefix + r4), this.tokens_to_ids.has(r4)) {
                n4 = r4;
                break;
              }
              --t4;
            }
            if (null === n4) {
              r3 = true;
              break;
            }
            a3.push(n4), s3 = t4;
          }
          r3 ? t3.push(this.unk_token) : t3.push(...a3);
        }
        return t3;
      }
    }
    class k2 extends v2 {
      constructor(e3, t3) {
        super(e3);
        const n3 = e3.vocab.length;
        this.vocab = new Array(n3), this.scores = new Array(n3);
        for (let t4 = 0; t4 < n3; ++t4) [this.vocab[t4], this.scores[t4]] = e3.vocab[t4];
        this.unk_token_id = e3.unk_id, this.unk_token = this.vocab[e3.unk_id], this.tokens_to_ids = new Map(this.vocab.map(((e4, t4) => [e4, t4]))), this.bos_token = " ", this.bos_token_id = this.tokens_to_ids.get(this.bos_token), this.eos_token = t3.eos_token, this.eos_token_id = this.tokens_to_ids.get(this.eos_token), this.unk_token = this.vocab[this.unk_token_id], this.minScore = (0, o2.min)(this.scores)[0], this.unk_score = this.minScore - 10, this.scores[this.unk_token_id] = this.unk_score, this.trie = new l2.CharTrie(), this.trie.extend(this.vocab), this.fuse_unk = true;
      }
      populateNodes(e3) {
        const t3 = e3.chars;
        let n3 = 0;
        for (; n3 < t3.length; ) {
          let r3 = false;
          const a3 = [], o3 = t3.slice(n3).join(""), i3 = this.trie.commonPrefixSearch(o3);
          for (const t4 of i3) {
            a3.push(t4);
            const o4 = this.tokens_to_ids.get(t4), i4 = this.scores[o4], l3 = (0, s2.len)(t4);
            e3.insert(n3, l3, i4, o4), r3 || 1 !== l3 || (r3 = true);
          }
          r3 || e3.insert(n3, 1, this.unk_score, this.unk_token_id), n3 += 1;
        }
      }
      tokenize(e3) {
        const t3 = new l2.TokenLattice(e3, this.bos_token_id, this.eos_token_id);
        return this.populateNodes(t3), t3.tokens();
      }
      encode(e3) {
        const t3 = [];
        for (const n3 of e3) {
          const e4 = this.tokenize(n3);
          t3.push(...e4);
        }
        return t3;
      }
    }
    const P2 = (() => {
      const e3 = [...Array.from({ length: "~".charCodeAt(0) - "!".charCodeAt(0) + 1 }, ((e4, t4) => t4 + "!".charCodeAt(0))), ...Array.from({ length: "\xAC".charCodeAt(0) - "\xA1".charCodeAt(0) + 1 }, ((e4, t4) => t4 + "\xA1".charCodeAt(0))), ...Array.from({ length: "\xFF".charCodeAt(0) - "\xAE".charCodeAt(0) + 1 }, ((e4, t4) => t4 + "\xAE".charCodeAt(0)))], t3 = e3.slice();
      let n3 = 0;
      for (let r4 = 0; r4 < 256; ++r4) e3.includes(r4) || (e3.push(r4), t3.push(256 + n3), n3 += 1);
      const r3 = t3.map(((e4) => String.fromCharCode(e4)));
      return Object.fromEntries(e3.map(((e4, t4) => [e4, r3[t4]])));
    })(), $2 = (0, s2.reverseDictionary)(P2);
    class C2 extends v2 {
      constructor(e3) {
        super(e3), this.tokens_to_ids = m2(e3.vocab), this.unk_token_id = this.tokens_to_ids.get(e3.unk_token), this.unk_token = e3.unk_token, this.vocab = new Array(this.tokens_to_ids.size);
        for (const [e4, t4] of this.tokens_to_ids) this.vocab[t4] = e4;
        const t3 = Array.isArray(e3.merges[0]);
        this.merges = t3 ? e3.merges : e3.merges.map(((e4) => e4.split(" ", 2))), this.bpe_ranks = new Map(this.merges.map(((e4, t4) => [JSON.stringify(e4), t4]))), this.end_of_word_suffix = e3.end_of_word_suffix, this.continuing_subword_suffix = e3.continuing_subword_suffix ?? null, this.byte_fallback = this.config.byte_fallback ?? false, this.byte_fallback && (this.text_encoder = new TextEncoder()), this.ignore_merges = this.config.ignore_merges ?? false, this.max_length_to_cache = 256, this.cache_capacity = 1e4, this.cache = new l2.LRUCache(this.cache_capacity);
      }
      clear_cache() {
        this.cache.clear();
      }
      bpe(e3) {
        if (0 === e3.length) return [];
        const t3 = this.cache.get(e3);
        if (void 0 !== t3) return t3;
        const n3 = Array.from(e3);
        this.end_of_word_suffix && (n3[n3.length - 1] += this.end_of_word_suffix);
        let r3 = [];
        if (n3.length > 1) {
          const e4 = new l2.PriorityQueue(((e5, t5) => e5.score < t5.score));
          let t4 = { token: n3[0], bias: 0, prev: null, next: null }, s3 = t4;
          for (let t5 = 1; t5 < n3.length; ++t5) {
            const r4 = { bias: t5 / n3.length, token: n3[t5], prev: s3, next: null };
            s3.next = r4, this._add_node(e4, s3), s3 = r4;
          }
          for (; !e4.isEmpty(); ) {
            const n4 = e4.pop();
            if (n4.deleted || !n4.next || n4.next.deleted) continue;
            if (n4.deleted = true, n4.next.deleted = true, n4.prev) {
              const e5 = { ...n4.prev };
              n4.prev.deleted = true, n4.prev = e5, e5.prev ? e5.prev.next = e5 : t4 = e5;
            }
            const r4 = { token: n4.token + n4.next.token, bias: n4.bias, prev: n4.prev, next: n4.next.next };
            r4.prev ? (r4.prev.next = r4, this._add_node(e4, r4.prev)) : t4 = r4, r4.next && (r4.next.prev = r4, this._add_node(e4, r4));
          }
          for (let e5 = t4; null !== e5; e5 = e5.next) r3.push(e5.token);
        } else r3 = n3;
        if (this.continuing_subword_suffix) for (let e4 = 0; e4 < r3.length - 1; ++e4) r3[e4] += this.continuing_subword_suffix;
        return e3.length < this.max_length_to_cache && this.cache.put(e3, r3), r3;
      }
      _add_node(e3, t3) {
        const n3 = this.bpe_ranks.get(JSON.stringify([t3.token, t3.next.token]));
        void 0 !== n3 && (t3.score = n3 + t3.bias, e3.push(t3));
      }
      encode(e3) {
        const t3 = [];
        for (const n3 of e3) {
          if (this.ignore_merges && this.tokens_to_ids.has(n3)) {
            t3.push(n3);
            continue;
          }
          const e4 = this.bpe(n3);
          for (const n4 of e4) if (this.tokens_to_ids.has(n4)) t3.push(n4);
          else if (this.byte_fallback) {
            const e5 = Array.from(this.text_encoder.encode(n4)).map(((e6) => `<0x${e6.toString(16).toUpperCase().padStart(2, "0")}>`));
            e5.every(((e6) => this.tokens_to_ids.has(e6))) ? t3.push(...e5) : t3.push(this.unk_token);
          } else t3.push(this.unk_token);
        }
        return t3;
      }
    }
    class S2 extends v2 {
      constructor(e3, t3) {
        super(e3), this.tokens_to_ids = m2(t3.target_lang ? e3.vocab[t3.target_lang] : e3.vocab), this.bos_token = t3.bos_token, this.bos_token_id = this.tokens_to_ids.get(this.bos_token), this.eos_token = t3.eos_token, this.eos_token_id = this.tokens_to_ids.get(this.eos_token), this.pad_token = t3.pad_token, this.pad_token_id = this.tokens_to_ids.get(this.pad_token), this.unk_token = t3.unk_token, this.unk_token_id = this.tokens_to_ids.get(this.unk_token), this.vocab = new Array(this.tokens_to_ids.size);
        for (const [e4, t4] of this.tokens_to_ids) this.vocab[t4] = e4;
      }
      encode(e3) {
        return e3;
      }
    }
    class F2 extends r2.Callable {
      constructor(e3) {
        super(), this.config = e3;
      }
      static fromConfig(e3) {
        if (null === e3) return null;
        switch (e3.type) {
          case "BertNormalizer":
            return new V2(e3);
          case "Precompiled":
            return new he2(e3);
          case "Sequence":
            return new R2(e3);
          case "Replace":
            return new E2(e3);
          case "NFC":
            return new A2(e3);
          case "NFD":
            return new z2(e3);
          case "NFKC":
            return new L2(e3);
          case "NFKD":
            return new O2(e3);
          case "Strip":
            return new D2(e3);
          case "StripAccents":
            return new B2(e3);
          case "Lowercase":
            return new N2(e3);
          case "Prepend":
            return new j2(e3);
          default:
            throw new Error(`Unknown Normalizer type: ${e3.type}`);
        }
      }
      normalize(e3) {
        throw Error("normalize should be implemented in subclass.");
      }
      _call(e3) {
        return this.normalize(e3);
      }
    }
    class E2 extends F2 {
      normalize(e3) {
        const t3 = p2(this.config.pattern);
        return null === t3 ? e3 : e3.replaceAll(t3, this.config.content);
      }
    }
    class I2 extends F2 {
      form = void 0;
      normalize(e3) {
        return e3 = e3.normalize(this.form);
      }
    }
    class A2 extends I2 {
      form = "NFC";
    }
    class z2 extends I2 {
      form = "NFD";
    }
    class L2 extends I2 {
      form = "NFKC";
    }
    class O2 extends I2 {
      form = "NFKD";
    }
    class D2 extends F2 {
      normalize(e3) {
        return this.config.strip_left && this.config.strip_right ? e3 = e3.trim() : (this.config.strip_left && (e3 = e3.trimStart()), this.config.strip_right && (e3 = e3.trimEnd())), e3;
      }
    }
    class B2 extends F2 {
      normalize(e3) {
        return e3 = _2(e3);
      }
    }
    class N2 extends F2 {
      normalize(e3) {
        return e3 = e3.toLowerCase();
      }
    }
    class j2 extends F2 {
      normalize(e3) {
        return e3 = this.config.prepend + e3;
      }
    }
    class R2 extends F2 {
      constructor(e3) {
        super(e3), this.normalizers = e3.normalizers.map(((e4) => F2.fromConfig(e4)));
      }
      normalize(e3) {
        return this.normalizers.reduce(((e4, t3) => t3.normalize(e4)), e3);
      }
    }
    class V2 extends F2 {
      _tokenize_chinese_chars(e3) {
        const t3 = [];
        for (let n3 = 0; n3 < e3.length; ++n3) {
          const r3 = e3[n3];
          g2(r3.charCodeAt(0)) ? (t3.push(" "), t3.push(r3), t3.push(" ")) : t3.push(r3);
        }
        return t3.join("");
      }
      stripAccents(e3) {
        return e3.normalize("NFD").replace(/\p{Mn}/gu, "");
      }
      _is_control(e3) {
        switch (e3) {
          case "	":
          case "\n":
          case "\r":
            return false;
          default:
            return /^\p{Cc}|\p{Cf}|\p{Co}|\p{Cs}$/u.test(e3);
        }
      }
      _clean_text(e3) {
        const t3 = [];
        for (const n3 of e3) {
          const e4 = n3.charCodeAt(0);
          0 === e4 || 65533 === e4 || this._is_control(n3) || (/^\s$/.test(n3) ? t3.push(" ") : t3.push(n3));
        }
        return t3.join("");
      }
      normalize(e3) {
        return this.config.clean_text && (e3 = this._clean_text(e3)), this.config.handle_chinese_chars && (e3 = this._tokenize_chinese_chars(e3)), this.config.lowercase ? (e3 = e3.toLowerCase(), false !== this.config.strip_accents && (e3 = this.stripAccents(e3))) : this.config.strip_accents && (e3 = this.stripAccents(e3)), e3;
      }
    }
    class G2 extends r2.Callable {
      static fromConfig(e3) {
        if (null === e3) return null;
        switch (e3.type) {
          case "BertPreTokenizer":
            return new q2(e3);
          case "Sequence":
            return new fe2(e3);
          case "Whitespace":
            return new _e2(e3);
          case "WhitespaceSplit":
            return new ge2(e3);
          case "Metaspace":
            return new pe2(e3);
          case "ByteLevel":
            return new U2(e3);
          case "Split":
            return new W2(e3);
          case "Punctuation":
            return new H2(e3);
          case "Digits":
            return new Q2(e3);
          case "Replace":
            return new we2(e3);
          case "FixedLength":
            return new be2(e3);
          default:
            throw new Error(`Unknown PreTokenizer type: ${e3.type}`);
        }
      }
      pre_tokenize_text(e3, t3) {
        throw Error("pre_tokenize_text should be implemented in subclass.");
      }
      pre_tokenize(e3, t3) {
        return (Array.isArray(e3) ? e3.map(((e4) => this.pre_tokenize_text(e4, t3))) : this.pre_tokenize_text(e3, t3)).flat();
      }
      _call(e3, t3) {
        return this.pre_tokenize(e3, t3);
      }
    }
    class q2 extends G2 {
      constructor(e3) {
        super(), this.pattern = new RegExp(`[^\\s${w2}]+|[${w2}]`, "gu");
      }
      pre_tokenize_text(e3, t3) {
        return e3.trim().match(this.pattern) || [];
      }
    }
    class U2 extends G2 {
      constructor(e3) {
        super(), this.config = e3, this.add_prefix_space = this.config.add_prefix_space, this.trim_offsets = this.config.trim_offsets, this.use_regex = this.config.use_regex ?? true, this.pattern = /'s|'t|'re|'ve|'m|'ll|'d| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+/gu, this.byte_encoder = P2, this.text_encoder = new TextEncoder();
      }
      pre_tokenize_text(e3, t3) {
        this.add_prefix_space && !e3.startsWith(" ") && (e3 = " " + e3);
        return (this.use_regex ? e3.match(this.pattern) || [] : [e3]).map(((e4) => Array.from(this.text_encoder.encode(e4), ((e5) => this.byte_encoder[e5])).join("")));
      }
    }
    class W2 extends G2 {
      constructor(e3) {
        super(), this.config = e3, this.pattern = p2(this.config.pattern, this.config.invert);
      }
      pre_tokenize_text(e3, t3) {
        return null === this.pattern ? [] : this.config.invert ? e3.match(this.pattern) || [] : "removed" === this.config.behavior?.toLowerCase() ? e3.split(this.pattern).filter(((e4) => e4)) : (function(e4, t4) {
          const n3 = [];
          let r3 = 0;
          for (const s3 of e4.matchAll(t4)) {
            const t5 = s3[0];
            r3 < s3.index && n3.push(e4.slice(r3, s3.index)), t5.length > 0 && n3.push(t5), r3 = s3.index + t5.length;
          }
          return r3 < e4.length && n3.push(e4.slice(r3)), n3;
        })(e3, this.pattern);
      }
    }
    class H2 extends G2 {
      constructor(e3) {
        super(), this.config = e3, this.pattern = new RegExp(`[^${w2}]+|[${w2}]+`, "gu");
      }
      pre_tokenize_text(e3, t3) {
        return e3.match(this.pattern) || [];
      }
    }
    class Q2 extends G2 {
      constructor(e3) {
        super(), this.config = e3;
        const t3 = "[^\\d]+|\\d" + (this.config.individual_digits ? "" : "+");
        this.pattern = new RegExp(t3, "gu");
      }
      pre_tokenize_text(e3, t3) {
        return e3.match(this.pattern) || [];
      }
    }
    class K2 extends r2.Callable {
      constructor(e3) {
        super(), this.config = e3;
      }
      static fromConfig(e3) {
        if (null === e3) return null;
        switch (e3.type) {
          case "TemplateProcessing":
            return new Y2(e3);
          case "ByteLevel":
            return new Z2(e3);
          case "RobertaProcessing":
            return new J2(e3);
          case "BertProcessing":
            return new X2(e3);
          case "Sequence":
            return new ee2(e3);
          default:
            throw new Error(`Unknown PostProcessor type: ${e3.type}`);
        }
      }
      post_process(e3, ...t3) {
        throw Error("post_process should be implemented in subclass.");
      }
      _call(e3, ...t3) {
        return this.post_process(e3, ...t3);
      }
    }
    class X2 extends K2 {
      constructor(e3) {
        super(e3), this.cls = e3.cls[0], this.sep = e3.sep[0];
      }
      post_process(e3, t3 = null, { add_special_tokens: n3 = true } = {}) {
        n3 && (e3 = (0, s2.mergeArrays)([this.cls], e3, [this.sep]));
        let r3 = new Array(e3.length).fill(0);
        if (null !== t3) {
          const a3 = n3 && this instanceof J2 ? [this.sep] : [], o3 = n3 ? [this.sep] : [];
          e3 = (0, s2.mergeArrays)(e3, a3, t3, o3), r3 = (0, s2.mergeArrays)(r3, new Array(t3.length + a3.length + o3.length).fill(1));
        }
        return { tokens: e3, token_type_ids: r3 };
      }
    }
    class J2 extends X2 {
    }
    class Y2 extends K2 {
      constructor(e3) {
        super(e3), this.single = e3.single, this.pair = e3.pair;
      }
      post_process(e3, t3 = null, { add_special_tokens: n3 = true } = {}) {
        const r3 = null === t3 ? this.single : this.pair;
        let a3 = [], o3 = [];
        for (const i3 of r3) "SpecialToken" in i3 ? n3 && (a3.push(i3.SpecialToken.id), o3.push(i3.SpecialToken.type_id)) : "Sequence" in i3 && ("A" === i3.Sequence.id ? (a3 = (0, s2.mergeArrays)(a3, e3), o3 = (0, s2.mergeArrays)(o3, new Array(e3.length).fill(i3.Sequence.type_id))) : "B" === i3.Sequence.id && (a3 = (0, s2.mergeArrays)(a3, t3), o3 = (0, s2.mergeArrays)(o3, new Array(t3.length).fill(i3.Sequence.type_id))));
        return { tokens: a3, token_type_ids: o3 };
      }
    }
    class Z2 extends K2 {
      post_process(e3, t3 = null) {
        return t3 && (e3 = (0, s2.mergeArrays)(e3, t3)), { tokens: e3 };
      }
    }
    class ee2 extends K2 {
      constructor(e3) {
        super(e3), this.processors = e3.processors.map(((e4) => K2.fromConfig(e4)));
      }
      post_process(e3, t3 = null, n3 = {}) {
        let r3;
        for (const s3 of this.processors) if (s3 instanceof Z2) {
          if (e3 = s3.post_process(e3).tokens, t3) {
            t3 = s3.post_process(t3).tokens;
          }
        } else {
          const a3 = s3.post_process(e3, t3, n3);
          e3 = a3.tokens, r3 = a3.token_type_ids;
        }
        return { tokens: e3, token_type_ids: r3 };
      }
    }
    class te2 extends r2.Callable {
      constructor(e3) {
        super(), this.config = e3, this.added_tokens = [], this.end_of_word_suffix = null, this.trim_offsets = e3.trim_offsets;
      }
      static fromConfig(e3) {
        if (null === e3) return null;
        switch (e3.type) {
          case "WordPiece":
            return new oe2(e3);
          case "Metaspace":
            return new me2(e3);
          case "ByteLevel":
            return new ie2(e3);
          case "Replace":
            return new ne2(e3);
          case "ByteFallback":
            return new re2(e3);
          case "Fuse":
            return new se2(e3);
          case "Strip":
            return new ae2(e3);
          case "Sequence":
            return new de2(e3);
          case "CTC":
            return new le2(e3);
          case "BPEDecoder":
            return new ue2(e3);
          default:
            throw new Error(`Unknown Decoder type: ${e3.type}`);
        }
      }
      _call(e3) {
        return this.decode(e3);
      }
      decode(e3) {
        return this.decode_chain(e3).join("");
      }
      decode_chain(e3) {
        throw Error("`decode_chain` should be implemented in subclass.");
      }
    }
    class ne2 extends te2 {
      decode_chain(e3) {
        const t3 = p2(this.config.pattern);
        return null === t3 ? e3 : e3.map(((e4) => e4.replaceAll(t3, this.config.content)));
      }
    }
    class re2 extends te2 {
      constructor(e3) {
        super(e3), this.text_decoder = new TextDecoder();
      }
      decode_chain(e3) {
        const t3 = [];
        let n3 = [];
        for (const r3 of e3) {
          let e4 = null;
          if (6 === r3.length && r3.startsWith("<0x") && r3.endsWith(">")) {
            const t4 = parseInt(r3.slice(3, 5), 16);
            isNaN(t4) || (e4 = t4);
          }
          if (null !== e4) n3.push(e4);
          else {
            if (n3.length > 0) {
              const e5 = this.text_decoder.decode(Uint8Array.from(n3));
              t3.push(e5), n3 = [];
            }
            t3.push(r3);
          }
        }
        if (n3.length > 0) {
          const e4 = this.text_decoder.decode(Uint8Array.from(n3));
          t3.push(e4), n3 = [];
        }
        return t3;
      }
    }
    class se2 extends te2 {
      decode_chain(e3) {
        return [e3.join("")];
      }
    }
    class ae2 extends te2 {
      constructor(e3) {
        super(e3), this.content = this.config.content, this.start = this.config.start, this.stop = this.config.stop;
      }
      decode_chain(e3) {
        return e3.map(((e4) => {
          let t3 = 0;
          for (let n4 = 0; n4 < this.start && e4[n4] === this.content; ++n4) t3 = n4 + 1;
          let n3 = e4.length;
          for (let t4 = 0; t4 < this.stop; ++t4) {
            const r3 = e4.length - t4 - 1;
            if (e4[r3] !== this.content) break;
            n3 = r3;
          }
          return e4.slice(t3, n3);
        }));
      }
    }
    class oe2 extends te2 {
      constructor(e3) {
        super(e3), this.cleanup = e3.cleanup;
      }
      decode_chain(e3) {
        return e3.map(((e4, t3) => (0 !== t3 && (e4 = e4.startsWith(this.config.prefix) ? e4.replace(this.config.prefix, "") : " " + e4), this.cleanup && (e4 = f2(e4)), e4)));
      }
    }
    class ie2 extends te2 {
      constructor(e3) {
        super(e3), this.byte_decoder = $2, this.text_decoder = new TextDecoder("utf-8", { fatal: false, ignoreBOM: true }), this.end_of_word_suffix = null;
      }
      convert_tokens_to_string(e3) {
        const t3 = e3.join(""), n3 = new Uint8Array([...t3].map(((e4) => this.byte_decoder[e4])));
        return this.text_decoder.decode(n3);
      }
      decode_chain(e3) {
        const t3 = [];
        let n3 = [];
        for (const r3 of e3) void 0 !== this.added_tokens.find(((e4) => e4.content === r3)) ? (n3.length > 0 && (t3.push(this.convert_tokens_to_string(n3)), n3 = []), t3.push(r3)) : n3.push(r3);
        return n3.length > 0 && t3.push(this.convert_tokens_to_string(n3)), t3;
      }
    }
    class le2 extends te2 {
      constructor(e3) {
        super(e3), this.pad_token = this.config.pad_token, this.word_delimiter_token = this.config.word_delimiter_token, this.cleanup = this.config.cleanup;
      }
      convert_tokens_to_string(e3) {
        if (0 === e3.length) return "";
        const t3 = [e3[0]];
        for (let n4 = 1; n4 < e3.length; ++n4) e3[n4] !== t3.at(-1) && t3.push(e3[n4]);
        let n3 = t3.filter(((e4) => e4 !== this.pad_token)).join("");
        return this.cleanup && (n3 = f2(n3).replaceAll(this.word_delimiter_token, " ").trim()), n3;
      }
      decode_chain(e3) {
        return [this.convert_tokens_to_string(e3)];
      }
    }
    class de2 extends te2 {
      constructor(e3) {
        super(e3), this.decoders = e3.decoders.map(((e4) => te2.fromConfig(e4)));
      }
      decode_chain(e3) {
        return this.decoders.reduce(((e4, t3) => t3.decode_chain(e4)), e3);
      }
    }
    class ue2 extends te2 {
      constructor(e3) {
        super(e3), this.suffix = this.config.suffix;
      }
      decode_chain(e3) {
        return e3.map(((t3, n3) => t3.replaceAll(this.suffix, n3 === e3.length - 1 ? "" : " ")));
      }
    }
    class ce2 extends te2 {
      decode_chain(e3) {
        let t3 = "";
        for (let n3 = 1; n3 < e3.length; n3 += 2) t3 += e3[n3];
        return [t3];
      }
    }
    class pe2 extends G2 {
      constructor(e3) {
        super(), this.replacement = e3.replacement, this.strRep = e3.str_rep || this.replacement, this.prepend_scheme = e3.prepend_scheme ?? "always";
      }
      pre_tokenize_text(e3, { section_index: t3 } = {}) {
        let n3 = e3.replaceAll(" ", this.strRep);
        return n3.startsWith(this.replacement) || "always" !== this.prepend_scheme && ("first" !== this.prepend_scheme || 0 !== t3) || (n3 = this.strRep + n3), [n3];
      }
    }
    class me2 extends te2 {
      constructor(e3) {
        super(e3), this.replacement = e3.replacement;
      }
      decode_chain(e3) {
        const t3 = [];
        for (let n3 = 0; n3 < e3.length; ++n3) {
          let r3 = e3[n3].replaceAll(this.replacement, " ");
          0 == n3 && r3.startsWith(" ") && (r3 = r3.substring(1)), t3.push(r3);
        }
        return t3;
      }
    }
    class he2 extends F2 {
      constructor(e3) {
        super(e3), this.charsmap = e3.precompiled_charsmap;
      }
      normalize(e3) {
        if ((e3 = (e3 = e3.replace(/[\u0001-\u0008\u000B\u000E-\u001F\u007F\u008F\u009F]/gm, "")).replace(/[\u0009\u000A\u000C\u000D\u00A0\u1680\u2000-\u200F\u2028\u2029\u202F\u205F\u2581\u3000\uFEFF\uFFFD]/gm, " ")).includes("\uFF5E")) {
          const t3 = e3.split("\uFF5E");
          e3 = t3.map(((e4) => e4.normalize("NFKC"))).join("\uFF5E");
        } else e3 = e3.normalize("NFKC");
        return e3;
      }
    }
    class fe2 extends G2 {
      constructor(e3) {
        super(), this.tokenizers = e3.pretokenizers.map(((e4) => G2.fromConfig(e4)));
      }
      pre_tokenize_text(e3, t3) {
        return this.tokenizers.reduce(((e4, n3) => n3.pre_tokenize(e4, t3)), [e3]);
      }
    }
    class _e2 extends G2 {
      constructor(e3) {
        super();
      }
      pre_tokenize_text(e3, t3) {
        return e3.match(/\w+|[^\w\s]+/g) || [];
      }
    }
    class ge2 extends G2 {
      constructor(e3) {
        super();
      }
      pre_tokenize_text(e3, t3) {
        return (function(e4) {
          return e4.match(/\S+/g) || [];
        })(e3);
      }
    }
    class we2 extends G2 {
      constructor(e3) {
        super(), this.config = e3, this.pattern = p2(this.config.pattern), this.content = this.config.content;
      }
      pre_tokenize_text(e3, t3) {
        return null === this.pattern ? [e3] : [e3.replaceAll(this.pattern, this.config.content)];
      }
    }
    class be2 extends G2 {
      constructor(e3) {
        super(), this._length = e3.length;
      }
      pre_tokenize_text(e3, t3) {
        const n3 = [];
        for (let t4 = 0; t4 < e3.length; t4 += this._length) n3.push(e3.slice(t4, t4 + this._length));
        return n3;
      }
    }
    const ye2 = ["bos_token", "eos_token", "unk_token", "sep_token", "pad_token", "cls_token", "mask_token"];
    function Me2(e3, t3, n3, r3) {
      for (const a3 of Object.keys(e3)) {
        const o3 = t3 - e3[a3].length, i3 = n3(a3), l3 = new Array(o3).fill(i3);
        e3[a3] = "right" === r3 ? (0, s2.mergeArrays)(e3[a3], l3) : (0, s2.mergeArrays)(l3, e3[a3]);
      }
    }
    function xe2(e3, t3) {
      for (const n3 of Object.keys(e3)) e3[n3].length = t3;
    }
    class ve2 extends r2.Callable {
      return_token_type_ids = false;
      padding_side = "right";
      constructor(e3, t3) {
        super(), this.config = t3, this.normalizer = F2.fromConfig(e3.normalizer), this.pre_tokenizer = G2.fromConfig(e3.pre_tokenizer), this.model = v2.fromConfig(e3.model, t3), this.post_processor = K2.fromConfig(e3.post_processor), this.decoder = te2.fromConfig(e3.decoder), this.special_tokens = [], this.all_special_ids = [], this.added_tokens = [];
        for (const t4 of e3.added_tokens) {
          const e4 = new x2(t4);
          this.added_tokens.push(e4), this.model.tokens_to_ids.set(e4.content, e4.id), this.model.vocab[e4.id] = e4.content, e4.special && (this.special_tokens.push(e4.content), this.all_special_ids.push(e4.id));
        }
        if (this.additional_special_tokens = t3.additional_special_tokens ?? [], this.special_tokens.push(...this.additional_special_tokens), this.special_tokens = [...new Set(this.special_tokens)], this.decoder && (this.decoder.added_tokens = this.added_tokens, this.decoder.end_of_word_suffix = this.model.end_of_word_suffix), this.added_tokens_splitter = new l2.DictionarySplitter(this.added_tokens.map(((e4) => e4.content))), this.added_tokens_map = new Map(this.added_tokens.map(((e4) => [e4.content, e4]))), this.mask_token = this.getToken("mask_token"), this.mask_token_id = this.model.tokens_to_ids.get(this.mask_token), this.pad_token = this.getToken("pad_token", "eos_token"), this.pad_token_id = this.model.tokens_to_ids.get(this.pad_token), this.sep_token = this.getToken("sep_token"), this.sep_token_id = this.model.tokens_to_ids.get(this.sep_token), this.unk_token = this.getToken("unk_token"), this.unk_token_id = this.model.tokens_to_ids.get(this.unk_token), this.bos_token = this.getToken("bos_token"), this.bos_token_id = this.model.tokens_to_ids.get(this.bos_token), this.eos_token = this.getToken("eos_token"), this.eos_token_id = this.model.tokens_to_ids.get(this.eos_token), this.model_max_length = t3.model_max_length, this.remove_space = t3.remove_space, this.clean_up_tokenization_spaces = t3.clean_up_tokenization_spaces ?? true, this.do_lowercase_and_remove_accent = t3.do_lowercase_and_remove_accent ?? false, t3.padding_side && (this.padding_side = t3.padding_side), this.add_bos_token = t3.add_bos_token, this.add_eos_token = t3.add_eos_token, this.legacy = false, this.chat_template = t3.chat_template ?? null, Array.isArray(this.chat_template)) {
          const e4 = /* @__PURE__ */ Object.create(null);
          for (const { name: t4, template: n3 } of this.chat_template) {
            if ("string" != typeof t4 || "string" != typeof n3) throw new Error('Chat template must be a list of objects with "name" and "template" properties');
            e4[t4] = n3;
          }
          this.chat_template = e4;
        }
        this._compiled_template_cache = /* @__PURE__ */ new Map();
      }
      getToken(...e3) {
        for (const t3 of e3) {
          const e4 = this.config[t3];
          if (e4) {
            if ("object" == typeof e4) {
              if ("AddedToken" === e4.__type) return e4.content;
              throw Error(`Unknown token: ${e4}`);
            }
            return e4;
          }
        }
        return null;
      }
      static async from_pretrained(e3, { progress_callback: t3 = null, config: n3 = null, cache_dir: r3 = null, local_files_only: s3 = false, revision: a3 = "main", legacy: o3 = null } = {}) {
        return new this(...await c2(e3, { progress_callback: t3, config: n3, cache_dir: r3, local_files_only: s3, revision: a3, legacy: o3 }));
      }
      _call(e3, { text_pair: t3 = null, add_special_tokens: n3 = true, padding: r3 = false, truncation: s3 = null, max_length: a3 = null, return_tensor: l3 = true, return_token_type_ids: d3 = null } = {}) {
        const u3 = Array.isArray(e3);
        let c3;
        if (u3) {
          if (0 === e3.length) throw Error("text array must be non-empty");
          if (null !== t3) {
            if (!Array.isArray(t3)) throw Error("text_pair must also be an array");
            if (e3.length !== t3.length) throw Error("text and text_pair must have the same length");
            c3 = e3.map(((e4, r4) => this._encode_plus(e4, { text_pair: t3[r4], add_special_tokens: n3, return_token_type_ids: d3 })));
          } else c3 = e3.map(((e4) => this._encode_plus(e4, { add_special_tokens: n3, return_token_type_ids: d3 })));
        } else {
          if (null == e3) throw Error("text may not be null or undefined");
          if (Array.isArray(t3)) throw Error("When specifying `text_pair`, since `text` is a string, `text_pair` must also be a string (i.e., not an array).");
          c3 = [this._encode_plus(e3, { text_pair: t3, add_special_tokens: n3, return_token_type_ids: d3 })];
        }
        if (null === a3 ? a3 = this.model_max_length : null === s3 && (true === r3 ? (console.warn("`max_length` is ignored when `padding: true` and there is no truncation strategy. To pad to max length, use `padding: 'max_length'`."), a3 = this.model_max_length) : false === r3 && (console.warn("Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation: true` to explicitly truncate examples to max length."), s3 = true)), true === r3 && (a3 = Math.min((0, o2.max)(c3.map(((e4) => e4.input_ids.length)))[0], a3 ?? 1 / 0)), a3 = Math.min(a3, this.model_max_length ?? 1 / 0), r3 || s3) for (let e4 = 0; e4 < c3.length; ++e4) c3[e4].input_ids.length !== a3 && (c3[e4].input_ids.length > a3 ? s3 && xe2(c3[e4], a3) : r3 && Me2(c3[e4], a3, ((e5) => "input_ids" === e5 ? this.pad_token_id : 0), this.padding_side));
        const p3 = {};
        if (l3) {
          if ((!r3 || !s3) && c3.some(((e5) => {
            for (const t4 of Object.keys(e5)) if (e5[t4].length !== c3[0][t4]?.length) return true;
            return false;
          }))) throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=true' and 'truncation=true' to have batched tensors with the same length.");
          const e4 = [c3.length, c3[0].input_ids.length];
          for (const t4 of Object.keys(c3[0])) p3[t4] = new i2.Tensor("int64", BigInt64Array.from(c3.flatMap(((e5) => e5[t4])).map(BigInt)), e4);
        } else {
          for (const e4 of Object.keys(c3[0])) p3[e4] = c3.map(((t4) => t4[e4]));
          if (!u3) for (const e4 of Object.keys(p3)) p3[e4] = p3[e4][0];
        }
        return p3;
      }
      _encode_text(e3) {
        if (null === e3) return null;
        const t3 = this.added_tokens_splitter.split(e3);
        for (let e4 = 0; e4 < t3.length; ++e4) {
          const n4 = this.added_tokens_map.get(t3[e4]);
          n4 && (n4.lstrip && e4 > 0 && (t3[e4 - 1] = t3[e4 - 1].trimEnd()), n4.rstrip && e4 < t3.length - 1 && (t3[e4 + 1] = t3[e4 + 1].trimStart()));
        }
        const n3 = t3.flatMap(((e4, t4) => {
          if (0 === e4.length) return [];
          if (this.added_tokens_map.has(e4)) return [e4];
          if (true === this.remove_space && (e4 = e4.trim().split(/\s+/).join(" ")), this.do_lowercase_and_remove_accent && (e4 = (function(e5) {
            return _2(e5.toLowerCase());
          })(e4)), null !== this.normalizer && (e4 = this.normalizer(e4)), 0 === e4.length) return [];
          const n4 = null !== this.pre_tokenizer ? this.pre_tokenizer(e4, { section_index: t4 }) : [e4];
          return this.model(n4);
        }));
        return n3;
      }
      _encode_plus(e3, { text_pair: t3 = null, add_special_tokens: n3 = true, return_token_type_ids: r3 = null } = {}) {
        const { tokens: s3, token_type_ids: a3 } = this._tokenize_helper(e3, { pair: t3, add_special_tokens: n3 }), o3 = this.model.convert_tokens_to_ids(s3), i3 = { input_ids: o3, attention_mask: new Array(o3.length).fill(1) };
        return (r3 ?? this.return_token_type_ids) && a3 && (i3.token_type_ids = a3), i3;
      }
      _tokenize_helper(e3, { pair: t3 = null, add_special_tokens: n3 = false } = {}) {
        const r3 = this._encode_text(e3), a3 = this._encode_text(t3);
        return this.post_processor ? this.post_processor(r3, a3, { add_special_tokens: n3 }) : { tokens: (0, s2.mergeArrays)(r3 ?? [], a3 ?? []) };
      }
      tokenize(e3, { pair: t3 = null, add_special_tokens: n3 = false } = {}) {
        return this._tokenize_helper(e3, { pair: t3, add_special_tokens: n3 }).tokens;
      }
      encode(e3, { text_pair: t3 = null, add_special_tokens: n3 = true, return_token_type_ids: r3 = null } = {}) {
        return this._encode_plus(e3, { text_pair: t3, add_special_tokens: n3, return_token_type_ids: r3 }).input_ids;
      }
      batch_decode(e3, t3 = {}) {
        return e3 instanceof i2.Tensor && (e3 = e3.tolist()), e3.map(((e4) => this.decode(e4, t3)));
      }
      decode(e3, t3 = {}) {
        if (e3 instanceof i2.Tensor && (e3 = h2(e3)), !Array.isArray(e3) || 0 === e3.length || !(0, s2.isIntegralNumber)(e3[0])) throw Error("token_ids must be a non-empty array of integers.");
        return this.decode_single(e3, t3);
      }
      decode_single(e3, { skip_special_tokens: t3 = false, clean_up_tokenization_spaces: n3 = null }) {
        let r3 = this.model.convert_ids_to_tokens(e3);
        t3 && (r3 = r3.filter(((e4) => !this.special_tokens.includes(e4))));
        let s3 = this.decoder ? this.decoder(r3) : r3.join(" ");
        return this.decoder && this.decoder.end_of_word_suffix && (s3 = s3.replaceAll(this.decoder.end_of_word_suffix, " "), t3 && (s3 = s3.trim())), (n3 ?? this.clean_up_tokenization_spaces) && (s3 = f2(s3)), s3;
      }
      get_chat_template({ chat_template: e3 = null, tools: t3 = null } = {}) {
        if (this.chat_template && "object" == typeof this.chat_template) {
          const n3 = this.chat_template;
          if (null !== e3 && Object.hasOwn(n3, e3)) e3 = n3[e3];
          else if (null === e3) if (null !== t3 && "tool_use" in n3) e3 = n3.tool_use;
          else {
            if (!("default" in n3)) throw Error(`This model has multiple chat templates with no default specified! Please either pass a chat template or the name of the template you wish to use to the 'chat_template' argument. Available template names are ${Object.keys(n3).sort()}.`);
            e3 = n3.default;
          }
        } else if (null === e3) {
          if (!this.chat_template) throw Error("Cannot use apply_chat_template() because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating");
          e3 = this.chat_template;
        }
        return e3;
      }
      apply_chat_template(e3, { tools: t3 = null, documents: n3 = null, chat_template: r3 = null, add_generation_prompt: s3 = false, tokenize: a3 = true, padding: o3 = false, truncation: i3 = false, max_length: l3 = null, return_tensor: u3 = true, return_dict: c3 = false, tokenizer_kwargs: p3 = {}, ...m3 } = {}) {
        if ("string" != typeof (r3 = this.get_chat_template({ chat_template: r3, tools: t3 }))) throw Error("chat_template must be a string, but got " + typeof r3);
        let h3 = this._compiled_template_cache.get(r3);
        void 0 === h3 && (h3 = new d2.Template(r3), this._compiled_template_cache.set(r3, h3));
        const f3 = /* @__PURE__ */ Object.create(null);
        for (const e4 of ye2) {
          const t4 = this.getToken(e4);
          t4 && (f3[e4] = t4);
        }
        const _3 = h3.render({ messages: e3, add_generation_prompt: s3, tools: t3, documents: n3, ...f3, ...m3 });
        if (a3) {
          const e4 = this._call(_3, { add_special_tokens: false, padding: o3, truncation: i3, max_length: l3, return_tensor: u3, ...p3 });
          return c3 ? e4 : e4.input_ids;
        }
        return _3;
      }
    }
    class Te2 extends ve2 {
      return_token_type_ids = true;
    }
    class ke2 extends ve2 {
      return_token_type_ids = true;
    }
    class Pe2 extends ve2 {
      return_token_type_ids = true;
    }
    class $e2 extends ve2 {
      return_token_type_ids = true;
    }
    class Ce2 extends ve2 {
      return_token_type_ids = true;
    }
    class Se2 extends ve2 {
      return_token_type_ids = true;
    }
    class Fe2 extends ve2 {
      return_token_type_ids = true;
    }
    class Ee2 extends ve2 {
      return_token_type_ids = true;
    }
    class Ie2 extends ve2 {
      return_token_type_ids = true;
    }
    class Ae2 extends ve2 {
    }
    class ze2 extends ve2 {
    }
    class Le2 extends ve2 {
      return_token_type_ids = true;
      constructor(e3, t3) {
        super(e3, t3), console.warn('WARNING: `XLMTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.');
      }
    }
    class Oe2 extends ve2 {
      return_token_type_ids = true;
    }
    class De2 extends ve2 {
    }
    class Be2 extends ve2 {
    }
    class Ne2 extends ve2 {
    }
    class je2 extends ve2 {
      constructor(e3, t3) {
        super(e3, t3), this.languageRegex = /^[a-z]{2}_[A-Z]{2}$/, this.language_codes = this.special_tokens.filter(((e4) => this.languageRegex.test(e4))), this.lang_to_token = (e4) => e4;
      }
      _build_translation_inputs(e3, t3, n3) {
        return tt2(this, e3, t3, n3);
      }
    }
    class Re2 extends je2 {
    }
    class Ve2 extends ve2 {
    }
    class Ge2 extends ve2 {
    }
    const qe2 = "\u2581";
    class Ue2 extends ve2 {
      padding_side = "left";
      constructor(e3, t3) {
        super(e3, t3), this.legacy = t3.legacy ?? true, this.legacy || (this.normalizer = null, this.pre_tokenizer = new pe2({ replacement: qe2, prepend_scheme: "first" }));
      }
      _encode_text(e3) {
        if (null === e3) return null;
        if (this.legacy || 0 === e3.length) return super._encode_text(e3);
        let t3 = super._encode_text(qe2 + e3.replaceAll(qe2, " "));
        return t3.length > 1 && t3[0] === qe2 && this.special_tokens.includes(t3[1]) && (t3 = t3.slice(1)), t3;
      }
    }
    class We2 extends ve2 {
    }
    class He2 extends ve2 {
    }
    class Qe2 extends ve2 {
    }
    class Ke2 extends ve2 {
    }
    class Xe2 extends ve2 {
    }
    class Je2 extends ve2 {
    }
    class Ye2 extends ve2 {
    }
    class Ze2 extends ve2 {
    }
    class et2 extends ve2 {
    }
    function tt2(e3, t3, n3, r3) {
      if (!("language_codes" in e3) || !Array.isArray(e3.language_codes)) throw new Error("Tokenizer must have `language_codes` attribute set and it should be an array of language ids.");
      if (!("languageRegex" in e3 && e3.languageRegex instanceof RegExp)) throw new Error("Tokenizer must have `languageRegex` attribute set and it should be a regular expression.");
      if (!("lang_to_token" in e3) || "function" != typeof e3.lang_to_token) throw new Error("Tokenizer must have `lang_to_token` attribute set and it should be a function.");
      const s3 = r3.src_lang, a3 = r3.tgt_lang;
      if (!e3.language_codes.includes(a3)) throw new Error(`Target language code "${a3}" is not valid. Must be one of: {${e3.language_codes.join(", ")}}`);
      if (void 0 !== s3) {
        if (!e3.language_codes.includes(s3)) throw new Error(`Source language code "${s3}" is not valid. Must be one of: {${e3.language_codes.join(", ")}}`);
        for (const t4 of e3.post_processor.config.single) if ("SpecialToken" in t4 && e3.languageRegex.test(t4.SpecialToken.id)) {
          t4.SpecialToken.id = e3.lang_to_token(s3);
          break;
        }
      }
      return r3.forced_bos_token_id = e3.model.convert_tokens_to_ids([e3.lang_to_token(a3)])[0], e3._call(t3, n3);
    }
    class nt2 extends ve2 {
      constructor(e3, t3) {
        super(e3, t3), this.languageRegex = /^[a-z]{3}_[A-Z][a-z]{3}$/, this.language_codes = this.special_tokens.filter(((e4) => this.languageRegex.test(e4))), this.lang_to_token = (e4) => e4;
      }
      _build_translation_inputs(e3, t3, n3) {
        return tt2(this, e3, t3, n3);
      }
    }
    class rt2 extends ve2 {
      constructor(e3, t3) {
        super(e3, t3), this.languageRegex = /^__[a-z]{2,3}__$/, this.language_codes = this.special_tokens.filter(((e4) => this.languageRegex.test(e4))).map(((e4) => e4.slice(2, -2))), this.lang_to_token = (e4) => `__${e4}__`;
      }
      _build_translation_inputs(e3, t3, n3) {
        return tt2(this, e3, t3, n3);
      }
    }
    class st2 extends ve2 {
      get timestamp_begin() {
        return this.model.convert_tokens_to_ids(["<|notimestamps|>"])[0] + 1;
      }
      _decode_asr(e3, { return_timestamps: t3 = false, return_language: n3 = false, time_precision: r3 = null, force_full_sequences: s3 = true } = {}) {
        if (null === r3) throw Error("Must specify time_precision");
        let a3 = null;
        const i3 = "word" === t3;
        function l3() {
          return { language: a3, timestamp: [null, null], text: "" };
        }
        const d3 = [];
        let c3 = l3(), p3 = 0;
        const m3 = this.timestamp_begin, h3 = m3 + 1500;
        let f3 = [], _3 = [], g3 = false, w3 = null;
        const y3 = new Set(this.all_special_ids);
        for (const n4 of e3) {
          const e4 = n4.tokens, s4 = i3 ? n4.token_timestamps : null;
          let M4 = null, x4 = m3;
          if ("stride" in n4) {
            const [t4, s5, a4] = n4.stride;
            if (p3 -= s5, w3 = t4 - a4, s5 && (x4 = s5 / r3 + m3), a4) for (let t5 = e4.length - 1; t5 >= 0; --t5) {
              const n5 = Number(e4[t5]);
              if (n5 >= m3) {
                if (null !== M4 && (n5 - m3) * r3 < w3) break;
                M4 = n5;
              }
            }
          }
          let v3 = [], T3 = [];
          for (let n5 = 0; n5 < e4.length; ++n5) {
            const w4 = Number(e4[n5]);
            if (y3.has(w4)) {
              const e5 = this.decode([w4]), n6 = u2.WHISPER_LANGUAGE_MAPPING.get(e5.slice(2, -2));
              if (void 0 !== n6) {
                if (null !== a3 && n6 !== a3 && !t3) {
                  f3.push(v3);
                  const e6 = this.findLongestCommonSequence(f3)[0], t4 = this.decode(e6);
                  c3.text = t4, d3.push(c3), f3 = [], v3 = [], c3 = l3();
                }
                a3 = c3.language = n6;
              }
            } else if (w4 >= m3 && w4 <= h3) {
              const e5 = (w4 - m3) * r3 + p3, t4 = (0, o2.round)(e5, 2);
              if (null !== M4 && w4 >= M4) g3 = true;
              else if (g3 || f3.length > 0 && w4 < x4) g3 = false;
              else if (null === c3.timestamp[0]) c3.timestamp[0] = t4;
              else if (t4 === c3.timestamp[0]) ;
              else {
                c3.timestamp[1] = t4, f3.push(v3), i3 && _3.push(T3);
                const [e6, n6] = this.findLongestCommonSequence(f3, _3), r4 = this.decode(e6);
                c3.text = r4, i3 && (c3.words = this.collateWordTimestamps(e6, n6, a3)), d3.push(c3), f3 = [], v3 = [], _3 = [], T3 = [], c3 = l3();
              }
            } else if (v3.push(w4), i3) {
              let e5, t4 = (0, o2.round)(s4[n5] + p3, 2);
              if (n5 + 1 < s4.length) {
                e5 = (0, o2.round)(s4[n5 + 1] + p3, 2);
                const a4 = this.decode([w4]);
                b2.test(a4) && (e5 = (0, o2.round)(Math.min(t4 + r3, e5), 2));
              } else e5 = null;
              T3.push([t4, e5]);
            }
          }
          if ("stride" in n4) {
            const [e5, t4, r4] = n4.stride;
            p3 += e5 - r4;
          }
          v3.length > 0 ? (f3.push(v3), i3 && _3.push(T3)) : f3.every(((e5) => 0 === e5.length)) && (c3 = l3(), f3 = [], v3 = [], _3 = [], T3 = []);
        }
        if (f3.length > 0) {
          if (s3 && t3) throw new Error("Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.");
          const [e4, n4] = this.findLongestCommonSequence(f3, _3), r4 = this.decode(e4);
          c3.text = r4, i3 && (c3.words = this.collateWordTimestamps(e4, n4, a3)), d3.push(c3);
        }
        let M3 = /* @__PURE__ */ Object.create(null);
        const x3 = d3.map(((e4) => e4.text)).join("");
        if (t3 || n3) {
          for (let e4 = 0; e4 < d3.length; ++e4) {
            const r4 = d3[e4];
            t3 || delete r4.timestamp, n3 || delete r4.language;
          }
          if (i3) {
            const e4 = [];
            for (const t4 of d3) for (const n4 of t4.words) e4.push(n4);
            M3 = { chunks: e4 };
          } else M3 = { chunks: d3 };
        }
        return [x3, M3];
      }
      findLongestCommonSequence(e3, t3 = null) {
        let n3 = e3[0], r3 = n3.length, s3 = [];
        const a3 = Array.isArray(t3) && t3.length > 0;
        let o3 = a3 ? [] : null, i3 = a3 ? t3[0] : null;
        for (let l3 = 1; l3 < e3.length; ++l3) {
          const d3 = e3[l3];
          let u3 = 0, c3 = [r3, r3, 0, 0];
          const p3 = d3.length;
          for (let e4 = 1; e4 < r3 + p3; ++e4) {
            const s4 = Math.max(0, r3 - e4), o4 = Math.min(r3, r3 + p3 - e4), m4 = n3.slice(s4, o4), h4 = Math.max(0, e4 - r3), f4 = Math.min(p3, e4), _4 = d3.slice(h4, f4);
            if (m4.length !== _4.length) throw new Error("There is a bug within whisper `decode_asr` function, please report it. Dropping to prevent bad inference.");
            let g4;
            g4 = a3 ? m4.filter(((e5, n4) => e5 === _4[n4] && i3[s4 + n4] <= t3[l3][h4 + n4])).length : m4.filter(((e5, t4) => e5 === _4[t4])).length;
            const w4 = g4 / e4 + e4 / 1e4;
            g4 > 1 && w4 > u3 && (u3 = w4, c3 = [s4, o4, h4, f4]);
          }
          const [m3, h3, f3, _3] = c3, g3 = Math.floor((h3 + m3) / 2), w3 = Math.floor((_3 + f3) / 2);
          s3.push(...n3.slice(0, g3)), n3 = d3.slice(w3), r3 = n3.length, a3 && (o3.push(...i3.slice(0, g3)), i3 = t3[l3].slice(w3));
        }
        return s3.push(...n3), a3 ? (o3.push(...i3), [s3, o3]) : [s3, []];
      }
      collateWordTimestamps(e3, t3, n3) {
        const [r3, s3, a3] = this.combineTokensIntoWords(e3, n3), o3 = [];
        for (let e4 = 0; e4 < r3.length; ++e4) {
          const n4 = a3[e4];
          o3.push({ text: r3[e4], timestamp: [t3[n4.at(0)][0], t3[n4.at(-1)][1]] });
        }
        return o3;
      }
      combineTokensIntoWords(e3, t3, n3 = `"'\u201C\xA1\xBF([{-`, r3 = `"'.\u3002,\uFF0C!\uFF01?\uFF1F:\uFF1A\u201D)]}\u3001`) {
        let s3, a3, o3;
        return ["chinese", "japanese", "thai", "lao", "myanmar"].includes(t3 = t3 ?? "english") ? [s3, a3, o3] = this.splitTokensOnUnicode(e3) : [s3, a3, o3] = this.splitTokensOnSpaces(e3), this.mergePunctuations(s3, a3, o3, n3, r3);
      }
      decode(e3, t3) {
        let n3;
        return t3?.decode_with_timestamps ? (e3 instanceof i2.Tensor && (e3 = h2(e3)), n3 = this.decodeWithTimestamps(e3, t3)) : n3 = super.decode(e3, t3), n3;
      }
      decodeWithTimestamps(e3, t3) {
        const n3 = t3?.time_precision ?? 0.02, r3 = Array.from(this.all_special_ids).at(-1) + 1;
        let s3 = [[]];
        for (let t4 of e3) if (t4 = Number(t4), t4 >= r3) {
          const e4 = ((t4 - r3) * n3).toFixed(2);
          s3.push(`<|${e4}|>`), s3.push([]);
        } else s3[s3.length - 1].push(t4);
        return s3 = s3.map(((e4) => "string" == typeof e4 ? e4 : super.decode(e4, t3))), s3.join("");
      }
      splitTokensOnUnicode(e3) {
        const t3 = this.decode(e3, { decode_with_timestamps: true }), n3 = [], r3 = [], s3 = [];
        let a3 = [], o3 = [], i3 = 0;
        for (let l3 = 0; l3 < e3.length; ++l3) {
          const d3 = e3[l3];
          a3.push(d3), o3.push(l3);
          const u3 = this.decode(a3, { decode_with_timestamps: true });
          u3.includes("\uFFFD") && "\uFFFD" !== t3[i3 + u3.indexOf("\uFFFD")] || (n3.push(u3), r3.push(a3), s3.push(o3), a3 = [], o3 = [], i3 += u3.length);
        }
        return [n3, r3, s3];
      }
      splitTokensOnSpaces(e3) {
        const [t3, n3, r3] = this.splitTokensOnUnicode(e3), s3 = [], a3 = [], o3 = [], i3 = new RegExp(`^[${w2}]$`, "gu");
        for (let e4 = 0; e4 < t3.length; ++e4) {
          const l3 = t3[e4], d3 = n3[e4], u3 = r3[e4], c3 = d3[0] >= this.model.tokens_to_ids.get("<|endoftext|>"), p3 = l3.startsWith(" "), m3 = l3.trim(), h3 = i3.test(m3);
          if (c3 || p3 || h3 || 0 === s3.length) s3.push(l3), a3.push(d3), o3.push(u3);
          else {
            const e5 = s3.length - 1;
            s3[e5] += l3, a3[e5].push(...d3), o3[e5].push(...u3);
          }
        }
        return [s3, a3, o3];
      }
      mergePunctuations(e3, t3, n3, r3, a3) {
        const o3 = structuredClone(e3), i3 = structuredClone(t3), l3 = structuredClone(n3);
        let d3 = o3.length - 2, u3 = o3.length - 1;
        for (; d3 >= 0; ) o3[d3].startsWith(" ") && r3.includes(o3[d3].trim()) ? (o3[u3] = o3[d3] + o3[u3], i3[u3] = (0, s2.mergeArrays)(i3[d3], i3[u3]), l3[u3] = (0, s2.mergeArrays)(l3[d3], l3[u3]), o3[d3] = "", i3[d3] = [], l3[d3] = []) : u3 = d3, --d3;
        for (d3 = 0, u3 = 1; u3 < o3.length; ) !o3[d3].endsWith(" ") && a3.includes(o3[u3]) ? (o3[d3] += o3[u3], i3[d3] = (0, s2.mergeArrays)(i3[d3], i3[u3]), l3[d3] = (0, s2.mergeArrays)(l3[d3], l3[u3]), o3[u3] = "", i3[u3] = [], l3[u3] = []) : d3 = u3, ++u3;
        return [o3.filter(((e4) => e4)), i3.filter(((e4) => e4.length > 0)), l3.filter(((e4) => e4.length > 0))];
      }
    }
    class at2 extends ve2 {
    }
    class ot2 extends ve2 {
    }
    class it2 extends ve2 {
    }
    class lt2 extends ve2 {
      constructor(e3, t3) {
        super(e3, t3), this.languageRegex = /^(>>\w+<<)\s*/g, this.supported_language_codes = this.model.vocab.filter(((e4) => this.languageRegex.test(e4))), console.warn('WARNING: `MarianTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.');
      }
      _encode_text(e3) {
        if (null === e3) return null;
        const [t3, ...n3] = e3.trim().split(this.languageRegex);
        if (0 === n3.length) return super._encode_text(t3);
        if (2 === n3.length) {
          const [e4, t4] = n3;
          return this.supported_language_codes.includes(e4) || console.warn(`Unsupported language code "${e4}" detected, which may lead to unexpected behavior. Should be one of: ${JSON.stringify(this.supported_language_codes)}`), (0, s2.mergeArrays)([e4], super._encode_text(t4));
        }
      }
    }
    class dt2 extends ve2 {
    }
    class ut2 extends ve2 {
    }
    class ct2 extends ve2 {
    }
    class pt2 extends ve2 {
    }
    class mt2 extends ve2 {
    }
    class ht2 extends ve2 {
      constructor(e3, t3) {
        super(e3, t3), this.decoder = new ce2({});
      }
    }
    class ft2 extends ve2 {
    }
    class _t2 extends ve2 {
    }
    class gt2 extends ve2 {
    }
    class wt2 {
      static TOKENIZER_CLASS_MAPPING = { T5Tokenizer: De2, DistilBertTokenizer: Ae2, CamembertTokenizer: ze2, DebertaTokenizer: Ce2, DebertaV2Tokenizer: Se2, BertTokenizer: Te2, HerbertTokenizer: Fe2, ConvBertTokenizer: Ee2, RoFormerTokenizer: Ie2, XLMTokenizer: Le2, ElectraTokenizer: Oe2, MobileBertTokenizer: Pe2, SqueezeBertTokenizer: $e2, AlbertTokenizer: ke2, GPT2Tokenizer: Be2, BartTokenizer: Ne2, MBartTokenizer: je2, MBart50Tokenizer: Re2, RobertaTokenizer: Ve2, WhisperTokenizer: st2, CodeGenTokenizer: at2, CLIPTokenizer: ot2, SiglipTokenizer: it2, MarianTokenizer: lt2, BloomTokenizer: Ge2, NllbTokenizer: nt2, M2M100Tokenizer: rt2, LlamaTokenizer: Ue2, CodeLlamaTokenizer: We2, XLMRobertaTokenizer: He2, MPNetTokenizer: Qe2, FalconTokenizer: Ke2, GPTNeoXTokenizer: Xe2, EsmTokenizer: Je2, Wav2Vec2CTCTokenizer: dt2, BlenderbotTokenizer: ut2, BlenderbotSmallTokenizer: ct2, SpeechT5Tokenizer: pt2, NougatTokenizer: mt2, VitsTokenizer: ht2, Qwen2Tokenizer: Ye2, GemmaTokenizer: Ze2, Grok1Tokenizer: et2, CohereTokenizer: ft2, MgpstrTokenizer: _t2, Ernie4_5_Tokenizer: gt2, PreTrainedTokenizer: ve2 };
      static async from_pretrained(e3, { progress_callback: t3 = null, config: n3 = null, cache_dir: r3 = null, local_files_only: s3 = false, revision: a3 = "main", legacy: o3 = null } = {}) {
        const [i3, l3] = await c2(e3, { progress_callback: t3, config: n3, cache_dir: r3, local_files_only: s3, revision: a3, legacy: o3 }), d3 = l3.tokenizer_class?.replace(/Fast$/, "") ?? "PreTrainedTokenizer";
        let u3 = this.TOKENIZER_CLASS_MAPPING[d3];
        return u3 || (console.warn(`Unknown tokenizer class "${d3}", attempting to construct from base class.`), u3 = ve2), new u3(i3, l3);
      }
    }
  }, "./src/utils/audio.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { RawAudio: () => x2, hamming: () => p2, hanning: () => c2, mel_filter_bank: () => g2, read_audio: () => d2, spectrogram: () => b2, window_function: () => y2 });
    var r2 = n2("./src/utils/hub.js"), s2 = n2("./src/utils/maths.js"), a2 = n2("./src/utils/core.js"), o2 = n2("./src/env.js"), i2 = n2("./src/utils/tensor.js"), l2 = n2("?7992");
    async function d2(e3, t3) {
      if ("undefined" == typeof AudioContext) throw Error("Unable to load audio from path/URL since `AudioContext` is not available in your environment. Instead, audio data should be passed directly to the pipeline/processor. For more information and some example code, see https://huggingface.co/docs/transformers.js/guides/node-audio-processing.");
      const n3 = await (await (0, r2.getFile)(e3)).arrayBuffer(), s3 = new AudioContext({ sampleRate: t3 });
      void 0 === t3 && console.warn(`No sampling rate provided, using default of ${s3.sampleRate}Hz.`);
      const a3 = await s3.decodeAudioData(n3);
      let o3;
      if (2 === a3.numberOfChannels) {
        const e4 = Math.sqrt(2), t4 = a3.getChannelData(0), n4 = a3.getChannelData(1);
        o3 = new Float32Array(t4.length);
        for (let r3 = 0; r3 < a3.length; ++r3) o3[r3] = e4 * (t4[r3] + n4[r3]) / 2;
      } else o3 = a3.getChannelData(0);
      return o3;
    }
    function u2(e3, t3) {
      if (e3 < 1) return new Float64Array();
      if (1 === e3) return new Float64Array([1]);
      const n3 = 1 - t3, r3 = 2 * Math.PI / (e3 - 1), s3 = new Float64Array(e3);
      for (let a3 = 0; a3 < e3; ++a3) s3[a3] = t3 - n3 * Math.cos(a3 * r3);
      return s3;
    }
    function c2(e3) {
      return u2(e3, 0.5);
    }
    function p2(e3) {
      return u2(e3, 0.54);
    }
    const m2 = { htk: (e3) => 2595 * Math.log10(1 + e3 / 700), kaldi: (e3) => 1127 * Math.log(1 + e3 / 700), slaney: (e3, t3 = 1e3, n3 = 15, r3 = 27 / Math.log(6.4)) => e3 >= t3 ? n3 + Math.log(e3 / t3) * r3 : 3 * e3 / 200 };
    function h2(e3, t3 = "htk") {
      const n3 = m2[t3];
      if (!n3) throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');
      return "number" == typeof e3 ? n3(e3) : e3.map(((e4) => n3(e4)));
    }
    const f2 = { htk: (e3) => 700 * (10 ** (e3 / 2595) - 1), kaldi: (e3) => 700 * (Math.exp(e3 / 1127) - 1), slaney: (e3, t3 = 1e3, n3 = 15, r3 = Math.log(6.4) / 27) => e3 >= n3 ? t3 * Math.exp(r3 * (e3 - n3)) : 200 * e3 / 3 };
    function _2(e3, t3, n3) {
      const r3 = (t3 - e3) / (n3 - 1);
      return Float64Array.from({ length: n3 }, ((t4, n4) => e3 + r3 * n4));
    }
    function g2(e3, t3, n3, r3, s3, a3 = null, o3 = "htk", i3 = false) {
      if (null !== a3 && "slaney" !== a3) throw new Error('norm must be one of null or "slaney"');
      if (e3 < 2) throw new Error(`Require num_frequency_bins: ${e3} >= 2`);
      if (n3 > r3) throw new Error(`Require min_frequency: ${n3} <= max_frequency: ${r3}`);
      const l3 = _2(h2(n3, o3), h2(r3, o3), t3 + 2);
      let d3, u3 = (function(e4, t4 = "htk") {
        const n4 = f2[t4];
        if (!n4) throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');
        return "number" == typeof e4 ? n4(e4) : e4.map(((e5) => n4(e5)));
      })(l3, o3);
      if (i3) {
        const t4 = s3 / (2 * (e3 - 1));
        d3 = h2(Float64Array.from({ length: e3 }, ((e4, n4) => n4 * t4)), o3), u3 = l3;
      } else d3 = _2(0, Math.floor(s3 / 2), e3);
      const c3 = (function(e4, t4) {
        const n4 = Float64Array.from({ length: t4.length - 1 }, ((e5, n5) => t4[n5 + 1] - t4[n5])), r4 = Array.from({ length: e4.length }, (() => new Array(t4.length)));
        for (let n5 = 0; n5 < e4.length; ++n5) {
          const s5 = r4[n5];
          for (let r5 = 0; r5 < t4.length; ++r5) s5[r5] = t4[r5] - e4[n5];
        }
        const s4 = t4.length - 2, a4 = Array.from({ length: s4 }, (() => new Array(e4.length)));
        for (let t5 = 0; t5 < e4.length; ++t5) {
          const e5 = r4[t5];
          for (let r5 = 0; r5 < s4; ++r5) {
            const s5 = -e5[r5] / n4[r5], o4 = e5[r5 + 2] / n4[r5 + 1];
            a4[r5][t5] = Math.max(0, Math.min(s5, o4));
          }
        }
        return a4;
      })(d3, u3);
      if (null !== a3 && "slaney" === a3) for (let n4 = 0; n4 < t3; ++n4) {
        const t4 = c3[n4], r4 = 2 / (u3[n4 + 2] - u3[n4]);
        for (let n5 = 0; n5 < e3; ++n5) t4[n5] *= r4;
      }
      return c3;
    }
    function w2(e3, t3, n3, r3, a3) {
      if (n3 <= 0) throw new Error("reference must be greater than zero");
      if (r3 <= 0) throw new Error("min_value must be greater than zero");
      n3 = Math.max(r3, n3);
      const o3 = Math.log10(n3);
      for (let n4 = 0; n4 < e3.length; ++n4) e3[n4] = t3 * Math.log10(Math.max(r3, e3[n4]) - o3);
      if (null !== a3) {
        if (a3 <= 0) throw new Error("db_range must be greater than zero");
        const t4 = (0, s2.max)(e3)[0] - a3;
        for (let n4 = 0; n4 < e3.length; ++n4) e3[n4] = Math.max(e3[n4], t4);
      }
      return e3;
    }
    async function b2(e3, t3, n3, r3, { fft_length: o3 = null, power: l3 = 1, center: d3 = true, pad_mode: u3 = "reflect", onesided: c3 = true, preemphasis: p3 = null, preemphasis_htk_flavor: m3 = true, mel_filters: h3 = null, mel_floor: f3 = 1e-10, log_mel: _3 = null, reference: g3 = 1, min_value: b3 = 1e-10, db_range: y3 = null, remove_dc_offset: M3 = null, min_num_frames: x3 = null, max_num_frames: v2 = null, do_pad: T2 = true, transpose: k2 = false, mel_offset: P2 = 0 } = {}) {
      const $2 = t3.length;
      if (null === o3 && (o3 = n3), n3 > o3) throw Error(`frame_length (${n3}) may not be larger than fft_length (${o3})`);
      if ($2 !== n3) throw new Error(`Length of the window (${$2}) must equal frame_length (${n3})`);
      if (r3 <= 0) throw new Error("hop_length must be greater than zero");
      if (null === l3 && null !== h3) throw new Error("You have provided `mel_filters` but `power` is `None`. Mel spectrogram computation is not yet supported for complex-valued spectrogram. Specify `power` to fix this issue.");
      if (!m3) throw new Error("`preemphasis_htk_flavor=false` is not currently supported.");
      if (d3) switch (u3) {
        case "reflect": {
          const t4 = Math.floor((o3 - 1) / 2) + 1;
          e3 = (function(e4, t5, n4) {
            const r4 = new e4.constructor(e4.length + t5 + n4), s3 = e4.length - 1;
            for (let n5 = 0; n5 < e4.length; ++n5) r4[t5 + n5] = e4[n5];
            for (let n5 = 1; n5 <= t5; ++n5) r4[t5 - n5] = e4[(0, a2.calculateReflectOffset)(n5, s3)];
            for (let o4 = 1; o4 <= n4; ++o4) r4[s3 + t5 + o4] = e4[(0, a2.calculateReflectOffset)(s3 - o4, s3)];
            return r4;
          })(e3, t4, t4);
          break;
        }
        case "constant": {
          const t4 = Math.floor(o3 / 2), n4 = new e3.constructor(e3.length + 2 * t4);
          n4.set(e3, t4), e3 = n4;
          break;
        }
        default:
          throw new Error(`pad_mode="${u3}" not implemented yet.`);
      }
      let C2 = Math.floor(1 + Math.floor((e3.length - n3) / r3));
      null !== x3 && C2 < x3 && (C2 = x3);
      const S2 = c3 ? Math.floor(o3 / 2) + 1 : o3;
      let F2 = C2, E2 = C2;
      null !== v2 && (v2 > C2 ? T2 && (E2 = v2) : E2 = F2 = v2);
      const I2 = new s2.FFT(o3), A2 = new Float64Array(o3), z2 = new Float64Array(I2.outputBufferSize), L2 = new Float32Array(S2 * E2);
      for (let s3 = 0; s3 < F2; ++s3) {
        const a3 = s3 * r3, o4 = Math.min(e3.length - a3, n3);
        o4 !== n3 && A2.fill(0, 0, n3);
        for (let t4 = 0; t4 < o4; ++t4) A2[t4] = e3[a3 + t4];
        if (M3) {
          let e4 = 0;
          for (let t5 = 0; t5 < o4; ++t5) e4 += A2[t5];
          const t4 = e4 / o4;
          for (let e5 = 0; e5 < o4; ++e5) A2[e5] -= t4;
        }
        if (null !== p3) {
          for (let e4 = o4 - 1; e4 >= 1; --e4) A2[e4] -= p3 * A2[e4 - 1];
          A2[0] *= 1 - p3;
        }
        for (let e4 = 0; e4 < t3.length; ++e4) A2[e4] *= t3[e4];
        I2.realTransform(z2, A2);
        for (let e4 = 0; e4 < S2; ++e4) {
          const t4 = e4 << 1;
          L2[e4 * E2 + s3] = z2[t4] ** 2 + z2[t4 + 1] ** 2;
        }
      }
      if (null !== l3 && 2 !== l3) {
        const e4 = l3 / 2;
        for (let t4 = 0; t4 < L2.length; ++t4) L2[t4] **= e4;
      }
      const O2 = h3.length;
      let D2 = await (0, i2.matmul)(new i2.Tensor("float32", h3.flat(), [O2, S2]), new i2.Tensor("float32", L2, [S2, E2]));
      k2 && (D2 = D2.transpose(1, 0));
      const B2 = D2.data;
      for (let e4 = 0; e4 < B2.length; ++e4) B2[e4] = P2 + Math.max(f3, B2[e4]);
      if (null !== l3 && null !== _3) {
        const e4 = Math.min(B2.length, F2 * O2);
        switch (_3) {
          case "log":
            for (let t4 = 0; t4 < e4; ++t4) B2[t4] = Math.log(B2[t4]);
            break;
          case "log10":
            for (let t4 = 0; t4 < e4; ++t4) B2[t4] = Math.log10(B2[t4]);
            break;
          case "dB":
            if (1 === l3) !(function(e5, t4 = 1, n4 = 1e-5, r4 = null) {
              w2(e5, 20, t4, n4, r4);
            })(B2, g3, b3, y3);
            else {
              if (2 !== l3) throw new Error(`Cannot use log_mel option '${_3}' with power ${l3}`);
              !(function(e5, t4 = 1, n4 = 1e-10, r4 = null) {
                w2(e5, 10, t4, n4, r4);
              })(B2, g3, b3, y3);
            }
            break;
          default:
            throw new Error(`log_mel must be one of null, 'log', 'log10' or 'dB'. Got '${_3}'`);
        }
      }
      return D2;
    }
    function y2(e3, t3, { periodic: n3 = true, frame_length: r3 = null, center: s3 = true } = {}) {
      const a3 = n3 ? e3 + 1 : e3;
      let o3;
      switch (t3) {
        case "boxcar":
          o3 = new Float64Array(a3).fill(1);
          break;
        case "hann":
        case "hann_window":
          o3 = c2(a3);
          break;
        case "hamming":
          o3 = p2(a3);
          break;
        case "povey":
          o3 = c2(a3).map(((e4) => Math.pow(e4, 0.85)));
          break;
        default:
          throw new Error(`Unknown window type ${t3}.`);
      }
      if (n3 && (o3 = o3.subarray(0, e3)), null === r3) return o3;
      if (e3 > r3) throw new Error(`Length of the window (${e3}) may not be larger than frame_length (${r3})`);
      return o3;
    }
    function M2(e3, t3, n3) {
      for (let r3 = 0; r3 < n3.length; ++r3) e3.setUint8(t3 + r3, n3.charCodeAt(r3));
    }
    class x2 {
      constructor(e3, t3) {
        this.audio = e3, this.sampling_rate = t3;
      }
      toWav() {
        return (function(e3, t3) {
          let n3 = 44;
          const r3 = new ArrayBuffer(n3 + 4 * e3.length), s3 = new DataView(r3);
          M2(s3, 0, "RIFF"), s3.setUint32(4, 36 + 4 * e3.length, true), M2(s3, 8, "WAVE"), M2(s3, 12, "fmt "), s3.setUint32(16, 16, true), s3.setUint16(20, 3, true), s3.setUint16(22, 1, true), s3.setUint32(24, t3, true), s3.setUint32(28, 4 * t3, true), s3.setUint16(32, 4, true), s3.setUint16(34, 32, true), M2(s3, 36, "data"), s3.setUint32(40, 4 * e3.length, true);
          for (let t4 = 0; t4 < e3.length; ++t4, n3 += 4) s3.setFloat32(n3, e3[t4], true);
          return r3;
        })(this.audio, this.sampling_rate);
      }
      toBlob() {
        const e3 = this.toWav();
        return new Blob([e3], { type: "audio/wav" });
      }
      async save(e3) {
        let t3;
        if (o2.apis.IS_BROWSER_ENV) {
          if (o2.apis.IS_WEBWORKER_ENV) throw new Error("Unable to save a file from a Web Worker.");
          t3 = a2.saveBlob;
        } else {
          if (!o2.apis.IS_FS_AVAILABLE) throw new Error("Unable to save because filesystem is disabled in this environment.");
          t3 = async (e4, t4) => {
            let n3 = await t4.arrayBuffer();
            l2.writeFileSync(e4, Buffer.from(n3));
          };
        }
        await t3(e3, this.toBlob());
      }
    }
  }, "./src/utils/constants.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { CHAT_TEMPLATE_NAME: () => l2, CONFIG_NAME: () => s2, FEATURE_EXTRACTOR_NAME: () => a2, GENERATION_CONFIG_NAME: () => d2, GITHUB_ISSUE_URL: () => r2, IMAGE_PROCESSOR_NAME: () => o2, PROCESSOR_NAME: () => i2 });
    const r2 = "https://github.com/huggingface/transformers.js/issues/new/choose", s2 = "config.json", a2 = "preprocessor_config.json", o2 = a2, i2 = "processor_config.json", l2 = "chat_template.jinja", d2 = "generation_config.json";
  }, "./src/utils/core.js": (e2, t2, n2) => {
    function r2(e3, t3) {
      e3 && e3(t3);
    }
    function s2(e3) {
      return Object.fromEntries(Object.entries(e3).map((([e4, t3]) => [t3, e4])));
    }
    function a2(e3) {
      return e3.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
    }
    function o2(e3) {
      return "TypedArray" === e3?.prototype?.__proto__?.constructor?.name;
    }
    function i2(e3) {
      return Number.isInteger(e3) || "bigint" == typeof e3;
    }
    function l2(e3) {
      return null == e3 || -1 === e3;
    }
    function d2(e3) {
      const t3 = [];
      let n3 = e3;
      for (; Array.isArray(n3); ) t3.push(n3.length), n3 = n3[0];
      return t3;
    }
    function u2(e3, t3, n3 = void 0) {
      const r3 = e3[t3];
      if (void 0 !== r3) return delete e3[t3], r3;
      if (void 0 === n3) throw Error(`Key ${t3} does not exist in object.`);
      return n3;
    }
    function c2(...e3) {
      return Array.prototype.concat.apply([], e3);
    }
    function p2(...e3) {
      return e3.reduce(((e4, t3) => e4.flatMap(((e5) => t3.map(((t4) => [e5, t4]))))));
    }
    function m2(e3, t3) {
      return Math.abs((e3 + t3) % (2 * t3) - t3);
    }
    function h2(e3, t3) {
      const n3 = URL.createObjectURL(t3), r3 = document.createElement("a");
      r3.href = n3, r3.download = e3, r3.click(), r3.remove(), URL.revokeObjectURL(n3);
    }
    function f2(e3, t3) {
      return Object.assign({}, ...t3.map(((t4) => {
        if (void 0 !== e3[t4]) return { [t4]: e3[t4] };
      })));
    }
    function _2(e3) {
      let t3 = 0;
      for (const n3 of e3) ++t3;
      return t3;
    }
    function g2(e3, t3) {
      let n3 = 0;
      for (const r3 of e3) r3 === t3 && ++n3;
      return n3;
    }
    n2.r(t2), n2.d(t2, { calculateDimensions: () => d2, calculateReflectOffset: () => m2, count: () => g2, dispatchCallback: () => r2, escapeRegExp: () => a2, isIntegralNumber: () => i2, isNullishDimension: () => l2, isTypedArray: () => o2, len: () => _2, mergeArrays: () => c2, pick: () => f2, pop: () => u2, product: () => p2, reverseDictionary: () => s2, saveBlob: () => h2 });
  }, "./src/utils/data-structures.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { CharTrie: () => s2, DictionarySplitter: () => l2, LRUCache: () => d2, PriorityQueue: () => r2, TokenLattice: () => o2 });
    class r2 {
      constructor(e3 = (e4, t4) => e4 > t4, t3 = 1 / 0) {
        this._heap = [], this._comparator = e3, this._maxSize = t3;
      }
      get size() {
        return this._heap.length;
      }
      isEmpty() {
        return 0 === this.size;
      }
      peek() {
        return this._heap[0];
      }
      push(...e3) {
        return this.extend(e3);
      }
      extend(e3) {
        for (const t3 of e3) if (this.size < this._maxSize) this._heap.push(t3), this._siftUp();
        else {
          const e4 = this._smallest();
          this._comparator(t3, this._heap[e4]) && (this._heap[e4] = t3, this._siftUpFrom(e4));
        }
        return this.size;
      }
      pop() {
        const e3 = this.peek(), t3 = this.size - 1;
        return t3 > 0 && this._swap(0, t3), this._heap.pop(), this._siftDown(), e3;
      }
      replace(e3) {
        const t3 = this.peek();
        return this._heap[0] = e3, this._siftDown(), t3;
      }
      _parent(e3) {
        return (e3 + 1 >>> 1) - 1;
      }
      _left(e3) {
        return 1 + (e3 << 1);
      }
      _right(e3) {
        return e3 + 1 << 1;
      }
      _greater(e3, t3) {
        return this._comparator(this._heap[e3], this._heap[t3]);
      }
      _swap(e3, t3) {
        const n3 = this._heap[e3];
        this._heap[e3] = this._heap[t3], this._heap[t3] = n3;
      }
      _siftUp() {
        this._siftUpFrom(this.size - 1);
      }
      _siftUpFrom(e3) {
        for (; e3 > 0 && this._greater(e3, this._parent(e3)); ) this._swap(e3, this._parent(e3)), e3 = this._parent(e3);
      }
      _siftDown() {
        let e3 = 0;
        for (; this._left(e3) < this.size && this._greater(this._left(e3), e3) || this._right(e3) < this.size && this._greater(this._right(e3), e3); ) {
          const t3 = this._right(e3) < this.size && this._greater(this._right(e3), this._left(e3)) ? this._right(e3) : this._left(e3);
          this._swap(e3, t3), e3 = t3;
        }
      }
      _smallest() {
        return 2 ** Math.floor(Math.log2(this.size)) - 1;
      }
    }
    class s2 {
      constructor() {
        this.root = a2.default();
      }
      extend(e3) {
        for (const t3 of e3) this.push(t3);
      }
      push(e3) {
        let t3 = this.root;
        for (const n3 of e3) {
          let e4 = t3.children.get(n3);
          void 0 === e4 && (e4 = a2.default(), t3.children.set(n3, e4)), t3 = e4;
        }
        t3.isLeaf = true;
      }
      *commonPrefixSearch(e3) {
        let t3 = this.root;
        if (void 0 === t3) return;
        let n3 = "";
        for (const r3 of e3) {
          if (n3 += r3, t3 = t3.children.get(r3), void 0 === t3) return;
          t3.isLeaf && (yield n3);
        }
      }
    }
    class a2 {
      constructor(e3, t3) {
        this.isLeaf = e3, this.children = t3;
      }
      static default() {
        return new a2(false, /* @__PURE__ */ new Map());
      }
    }
    class o2 {
      constructor(e3, t3, n3) {
        this.chars = Array.from(e3), this.len = this.chars.length, this.bosTokenId = t3, this.eosTokenId = n3, this.nodes = [], this.beginNodes = Array.from({ length: this.len + 1 }, (() => [])), this.endNodes = Array.from({ length: this.len + 1 }, (() => []));
        const r3 = new i2(this.bosTokenId, 0, 0, 0, 0), s3 = new i2(this.eosTokenId, 1, this.len, 0, 0);
        this.nodes.push(r3.clone()), this.nodes.push(s3.clone()), this.beginNodes[this.len].push(s3), this.endNodes[0].push(r3);
      }
      insert(e3, t3, n3, r3) {
        const s3 = this.nodes.length, a3 = new i2(r3, s3, e3, t3, n3);
        this.beginNodes[e3].push(a3), this.endNodes[e3 + t3].push(a3), this.nodes.push(a3);
      }
      viterbi() {
        const e3 = this.len;
        let t3 = 0;
        for (; t3 <= e3; ) {
          if (0 == this.beginNodes[t3].length) return [];
          for (let e4 of this.beginNodes[t3]) {
            e4.prev = null;
            let n4 = 0, r4 = null;
            for (let s4 of this.endNodes[t3]) {
              const t4 = s4.backtraceScore + e4.score;
              (null === r4 || t4 > n4) && (r4 = s4.clone(), n4 = t4);
            }
            if (null === r4) return [];
            e4.prev = r4, e4.backtraceScore = n4;
          }
          ++t3;
        }
        const n3 = [], r3 = this.beginNodes[e3][0].prev;
        if (null === r3) return [];
        let s3 = r3.clone();
        for (; null !== s3.prev; ) {
          n3.push(s3.clone());
          const e4 = s3.clone();
          s3 = e4.prev.clone();
        }
        return n3.reverse(), n3;
      }
      piece(e3) {
        return this.chars.slice(e3.pos, e3.pos + e3.length).join("");
      }
      tokens() {
        return this.viterbi().map(((e3) => this.piece(e3)));
      }
      tokenIds() {
        return this.viterbi().map(((e3) => e3.tokenId));
      }
    }
    class i2 {
      constructor(e3, t3, n3, r3, s3) {
        this.tokenId = e3, this.nodeId = t3, this.pos = n3, this.length = r3, this.score = s3, this.prev = null, this.backtraceScore = 0;
      }
      clone() {
        const e3 = new i2(this.tokenId, this.nodeId, this.pos, this.length, this.score);
        return e3.prev = this.prev, e3.backtraceScore = this.backtraceScore, e3;
      }
    }
    class l2 {
      constructor(e3) {
        this.trie = this._buildTrie(e3);
      }
      _buildTrie(e3) {
        const t3 = /* @__PURE__ */ Object.create(null);
        for (const n3 of e3) {
          let e4 = t3;
          for (let t4 = 0; t4 < n3.length; ++t4) e4 = e4[n3[t4]] ??= /* @__PURE__ */ Object.create(null);
          e4.end = n3;
        }
        return t3;
      }
      split(e3) {
        const t3 = [], n3 = e3.length;
        let r3 = 0, s3 = 0;
        for (; s3 < n3; ) {
          let a3 = this.trie, o3 = null, i3 = s3;
          for (; i3 < n3 && (a3 = a3[e3[i3]]); ) a3.end && (o3 = a3.end), ++i3;
          o3 ? (s3 > r3 && t3.push(e3.slice(r3, s3)), t3.push(o3), s3 += o3.length, r3 = s3) : ++s3;
        }
        return r3 < n3 && t3.push(e3.slice(r3)), t3;
      }
    }
    class d2 {
      constructor(e3) {
        this.capacity = e3, this.cache = /* @__PURE__ */ new Map();
      }
      get(e3) {
        if (!this.cache.has(e3)) return;
        const t3 = this.cache.get(e3);
        return this.cache.delete(e3), this.cache.set(e3, t3), t3;
      }
      put(e3, t3) {
        this.cache.has(e3) && this.cache.delete(e3), this.cache.set(e3, t3), this.cache.size > this.capacity && this.cache.delete(this.cache.keys().next().value);
      }
      clear() {
        this.cache.clear();
      }
    }
  }, "./src/utils/devices.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { DEVICE_TYPES: () => r2 });
    const r2 = Object.freeze({ auto: "auto", gpu: "gpu", cpu: "cpu", wasm: "wasm", webgpu: "webgpu", cuda: "cuda", dml: "dml", webnn: "webnn", "webnn-npu": "webnn-npu", "webnn-gpu": "webnn-gpu", "webnn-cpu": "webnn-cpu" });
  }, "./src/utils/dtypes.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { DATA_TYPES: () => o2, DEFAULT_DEVICE_DTYPE_MAPPING: () => i2, DEFAULT_DTYPE_SUFFIX_MAPPING: () => l2, isWebGpuFp16Supported: () => a2 });
    var r2 = n2("./src/env.js"), s2 = n2("./src/utils/devices.js");
    const a2 = /* @__PURE__ */ (function() {
      let e3;
      return async function() {
        if (void 0 === e3) if (r2.apis.IS_WEBGPU_AVAILABLE) try {
          const t3 = await navigator.gpu.requestAdapter();
          e3 = t3.features.has("shader-f16");
        } catch (t3) {
          e3 = false;
        }
        else e3 = false;
        return e3;
      };
    })(), o2 = Object.freeze({ auto: "auto", fp32: "fp32", fp16: "fp16", q8: "q8", int8: "int8", uint8: "uint8", q4: "q4", bnb4: "bnb4", q4f16: "q4f16" }), i2 = Object.freeze({ [s2.DEVICE_TYPES.wasm]: o2.q8 }), l2 = Object.freeze({ [o2.fp32]: "", [o2.fp16]: "_fp16", [o2.int8]: "_int8", [o2.uint8]: "_uint8", [o2.q8]: "_quantized", [o2.q4]: "_q4", [o2.q4f16]: "_q4f16", [o2.bnb4]: "_bnb4" });
  }, "./src/utils/generic.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { Callable: () => r2 });
    const r2 = class {
      constructor() {
        let e3 = function(...t3) {
          return e3._call(...t3);
        };
        return Object.setPrototypeOf(e3, new.target.prototype);
      }
      _call(...e3) {
        throw Error("Must implement _call method in subclass");
      }
    };
  }, "./src/utils/hub.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { MAX_EXTERNAL_DATA_CHUNKS: () => i2, getFile: () => p2, getModelFile: () => f2, getModelJSON: () => g2, getModelText: () => _2 });
    var r2 = n2("?7992"), s2 = n2("?5af5"), a2 = n2("./src/env.js"), o2 = n2("./src/utils/core.js");
    const i2 = 100, l2 = { txt: "text/plain", html: "text/html", css: "text/css", js: "text/javascript", json: "application/json", png: "image/png", jpg: "image/jpeg", jpeg: "image/jpeg", gif: "image/gif" };
    class d2 {
      constructor(e3) {
        if (this.filePath = e3, this.headers = new Headers(), this.exists = r2.existsSync(e3), this.exists) {
          this.status = 200, this.statusText = "OK";
          let t3 = r2.statSync(e3);
          this.headers.set("content-length", t3.size.toString()), this.updateContentType();
          const n3 = r2.createReadStream(e3);
          this.body = new ReadableStream({ start(e4) {
            n3.on("data", ((t4) => e4.enqueue(t4))), n3.on("end", (() => e4.close())), n3.on("error", ((t4) => e4.error(t4)));
          }, cancel() {
            n3.destroy();
          } });
        } else this.status = 404, this.statusText = "Not Found", this.body = null;
      }
      updateContentType() {
        const e3 = this.filePath.toString().split(".").pop().toLowerCase();
        this.headers.set("content-type", l2[e3] ?? "application/octet-stream");
      }
      clone() {
        let e3 = new d2(this.filePath);
        return e3.exists = this.exists, e3.status = this.status, e3.statusText = this.statusText, e3.headers = new Headers(this.headers), e3;
      }
      async arrayBuffer() {
        return (await r2.promises.readFile(this.filePath)).buffer;
      }
      async blob() {
        const e3 = await r2.promises.readFile(this.filePath);
        return new Blob([e3], { type: this.headers.get("content-type") });
      }
      async text() {
        return await r2.promises.readFile(this.filePath, "utf8");
      }
      async json() {
        return JSON.parse(await this.text());
      }
    }
    function u2(e3, t3 = null, n3 = null) {
      let r3;
      try {
        r3 = new URL(e3);
      } catch (e4) {
        return false;
      }
      return !(t3 && !t3.includes(r3.protocol)) && !(n3 && !n3.includes(r3.hostname));
    }
    const c2 = /^(\b[\w\-.]+\b\/)?\b[\w\-.]{1,96}\b$/;
    async function p2(e3) {
      if (a2.env.useFS && !u2(e3, ["http:", "https:", "blob:"])) return new d2(e3 instanceof URL ? "file:" === e3.protocol ? e3.pathname : e3.toString() : e3);
      if ("undefined" != typeof process && "node" === process?.release?.name) {
        const t3 = !!process.env?.TESTING_REMOTELY, n3 = a2.env.version, r3 = new Headers();
        r3.set("User-Agent", `transformers.js/${n3}; is_ci/${t3};`);
        if (u2(e3, ["http:", "https:"], ["huggingface.co", "hf.co"])) {
          const e4 = process.env?.HF_TOKEN ?? process.env?.HF_ACCESS_TOKEN;
          e4 && r3.set("Authorization", `Bearer ${e4}`);
        }
        return fetch(e3, { headers: r3 });
      }
      return fetch(e3);
    }
    const m2 = { 400: "Bad request error occurred while trying to load file", 401: "Unauthorized access to file", 403: "Forbidden access to file", 404: "Could not locate file", 408: "Request timeout error occurred while trying to load file", 500: "Internal server error error occurred while trying to load file", 502: "Bad gateway error occurred while trying to load file", 503: "Service unavailable error occurred while trying to load file", 504: "Gateway timeout error occurred while trying to load file" };
    class h2 {
      constructor(e3) {
        this.path = e3;
      }
      async match(e3) {
        let t3 = s2.join(this.path, e3), n3 = new d2(t3);
        return n3.exists ? n3 : void 0;
      }
      async put(e3, t3, n3 = void 0) {
        let a3 = s2.join(this.path, e3);
        try {
          const e4 = t3.headers.get("Content-Length"), o3 = parseInt(e4 ?? "0");
          let i3 = 0;
          await r2.promises.mkdir(s2.dirname(a3), { recursive: true });
          const l3 = r2.createWriteStream(a3), d3 = t3.body.getReader();
          for (; ; ) {
            const { done: e5, value: t4 } = await d3.read();
            if (e5) break;
            await new Promise(((e6, n4) => {
              l3.write(t4, ((t5) => {
                t5 ? n4(t5) : e6();
              }));
            })), i3 += t4.length;
            const r3 = o3 ? i3 / o3 * 100 : 0;
            n3?.({ progress: r3, loaded: i3, total: o3 });
          }
          l3.close();
        } catch (e4) {
          try {
            await r2.promises.unlink(a3);
          } catch {
          }
          throw e4;
        }
      }
    }
    async function f2(e3, t3, n3 = true, r3 = {}, s3 = false) {
      if (!a2.env.allowLocalModels) {
        if (r3.local_files_only) throw Error("Invalid configuration detected: local models are disabled (`env.allowLocalModels=false`) but you have requested to only use local models (`local_files_only=true`).");
        if (!a2.env.allowRemoteModels) throw Error("Invalid configuration detected: both local and remote models are disabled. Fix by setting `env.allowLocalModels` or `env.allowRemoteModels` to `true`.");
      }
      let i3;
      if ((0, o2.dispatchCallback)(r3.progress_callback, { status: "initiate", name: e3, file: t3 }), !i3 && a2.env.useCustomCache) {
        if (!a2.env.customCache) throw Error("`env.useCustomCache=true`, but `env.customCache` is not defined.");
        if (!a2.env.customCache.match || !a2.env.customCache.put) throw new Error("`env.customCache` must be an object which implements the `match` and `put` functions of the Web Cache API. For more information, see https://developer.mozilla.org/en-US/docs/Web/API/Cache");
        i3 = a2.env.customCache;
      }
      if (!i3 && a2.env.useBrowserCache) {
        if ("undefined" == typeof caches) throw Error("Browser cache is not available in this environment.");
        try {
          i3 = await caches.open("transformers-cache");
        } catch (e4) {
          console.warn("An error occurred while opening the browser cache:", e4);
        }
      }
      if (!i3 && a2.env.useFSCache) {
        if (!a2.apis.IS_FS_AVAILABLE) throw Error("File System Cache is not available in this environment.");
        i3 = new h2(r3.cache_dir ?? a2.env.cacheDir);
      }
      const l3 = r3.revision ?? "main", f3 = w2(e3, t3), _3 = (g3 = e3, !(!c2.test(g3) || g3.includes("..") || g3.includes("--") || g3.endsWith(".git") || g3.endsWith(".ipynb")));
      var g3;
      const b2 = _3 ? w2(a2.env.localModelPath, f3) : f3, y2 = w2(a2.env.remoteHost, a2.env.remotePathTemplate.replaceAll("{model}", e3).replaceAll("{revision}", encodeURIComponent(l3)), t3);
      let M2;
      const x2 = i3 instanceof h2 ? "main" === l3 ? f3 : w2(e3, l3, t3) : y2;
      let v2, T2 = false;
      i3 && (v2 = await (async function(e4, ...t4) {
        for (let n4 of t4) try {
          let t5 = await e4.match(n4);
          if (t5) return t5;
        } catch (e5) {
          continue;
        }
      })(i3, b2, x2));
      const k2 = void 0 !== v2;
      if (void 0 === v2) {
        if (a2.env.allowLocalModels) {
          if (u2(f3, ["http:", "https:"])) {
            if (r3.local_files_only) throw new Error(`\`local_files_only=true\`, but attempted to load a remote file from: ${f3}.`);
            if (!a2.env.allowRemoteModels) throw new Error(`\`env.allowRemoteModels=false\`, but attempted to load a remote file from: ${f3}.`);
          } else try {
            v2 = await p2(b2), M2 = b2;
          } catch (e4) {
            console.warn(`Unable to load from local path "${b2}": "${e4}"`);
          }
        }
        if (void 0 === v2 || 404 === v2.status) {
          if (r3.local_files_only || !a2.env.allowRemoteModels) {
            if (n3) throw Error(`\`local_files_only=true\` or \`env.allowRemoteModels=false\` and file was not found locally at "${b2}".`);
            return null;
          }
          if (!_3) throw Error(`Local file missing at "${b2}" and download aborted due to invalid model ID "${e3}".`);
          if (v2 = await p2(y2), 200 !== v2.status) return (function(e4, t4, n4) {
            if (!n4) return null;
            const r4 = m2[e4] ?? `Error (${e4}) occurred while trying to load file`;
            throw Error(`${r4}: "${t4}".`);
          })(v2.status, y2, n3);
          M2 = x2;
        }
        T2 = i3 && "undefined" != typeof Response && v2 instanceof Response && 200 === v2.status;
      }
      let P2;
      if ((0, o2.dispatchCallback)(r3.progress_callback, { status: "download", name: e3, file: t3 }), !a2.apis.IS_NODE_ENV || !s3) {
        let n4;
        r3.progress_callback ? k2 && "undefined" != typeof navigator && /firefox/i.test(navigator.userAgent) ? (n4 = new Uint8Array(await v2.arrayBuffer()), (0, o2.dispatchCallback)(r3.progress_callback, { status: "progress", name: e3, file: t3, progress: 100, loaded: n4.length, total: n4.length })) : n4 = await (async function(e4, t4) {
          const n5 = e4.headers.get("Content-Length");
          null === n5 && console.warn("Unable to determine content-length from response headers. Will expand buffer when needed.");
          let r4 = parseInt(n5 ?? "0"), s4 = new Uint8Array(r4), a3 = 0;
          const o3 = e4.body.getReader();
          async function i4() {
            const { done: e5, value: n6 } = await o3.read();
            if (e5) return;
            const l4 = a3 + n6.length;
            if (l4 > r4) {
              r4 = l4;
              const e6 = new Uint8Array(r4);
              e6.set(s4), s4 = e6;
            }
            s4.set(n6, a3), a3 = l4;
            return t4({ progress: a3 / r4 * 100, loaded: a3, total: r4 }), i4();
          }
          return await i4(), s4;
        })(v2, ((n5) => {
          (0, o2.dispatchCallback)(r3.progress_callback, { status: "progress", name: e3, file: t3, ...n5 });
        })) : n4 = new Uint8Array(await v2.arrayBuffer()), P2 = n4;
      }
      if (T2 && M2 && void 0 === await i3.match(M2)) if (P2) await i3.put(M2, new Response(P2, { headers: v2.headers })).catch(((e4) => {
        console.warn(`Unable to add response to browser cache: ${e4}.`);
      }));
      else {
        const n4 = r3.progress_callback ? (n5) => (0, o2.dispatchCallback)(r3.progress_callback, { status: "progress", name: e3, file: t3, ...n5 }) : void 0;
        await i3.put(M2, v2, n4);
      }
      if ((0, o2.dispatchCallback)(r3.progress_callback, { status: "done", name: e3, file: t3 }), P2) {
        if (!a2.apis.IS_NODE_ENV && s3) throw new Error("Cannot return path in a browser environment.");
        return P2;
      }
      if (v2 instanceof d2) return v2.filePath;
      const $2 = await i3?.match(M2);
      if ($2 instanceof d2) return $2.filePath;
      if ($2 instanceof Response) return new Uint8Array(await $2.arrayBuffer());
      if ("string" == typeof $2) return $2;
      throw new Error("Unable to get model file path or buffer.");
    }
    async function _2(e3, t3, n3 = true, r3 = {}) {
      const s3 = await f2(e3, t3, n3, r3, false);
      if (null === s3) return null;
      return new TextDecoder("utf-8").decode(s3);
    }
    async function g2(e3, t3, n3 = true, r3 = {}) {
      const s3 = await _2(e3, t3, n3, r3);
      return null === s3 ? {} : JSON.parse(s3);
    }
    function w2(...e3) {
      return (e3 = e3.map(((t3, n3) => (n3 && (t3 = t3.replace(new RegExp("^/"), "")), n3 !== e3.length - 1 && (t3 = t3.replace(new RegExp("/$"), "")), t3)))).join("/");
    }
  }, "./src/utils/image.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { RawImage: () => h2, load_image: () => f2 });
    var r2 = n2("./src/utils/core.js"), s2 = n2("./src/utils/hub.js"), a2 = n2("./src/env.js"), o2 = n2("./src/utils/tensor.js"), i2 = n2("?2b25");
    let l2, d2, u2;
    const c2 = a2.apis.IS_BROWSER_ENV || a2.apis.IS_WEBWORKER_ENV;
    if (c2) l2 = (e3, t3) => {
      if (!self.OffscreenCanvas) throw new Error("OffscreenCanvas not supported by this browser.");
      return new self.OffscreenCanvas(e3, t3);
    }, u2 = self.createImageBitmap, d2 = self.ImageData;
    else {
      if (!i2) throw new Error("Unable to load image processing library.");
      u2 = async (e3) => {
        const t3 = (await e3.metadata()).channels, { data: n3, info: r3 } = await e3.rotate().raw().toBuffer({ resolveWithObject: true }), s3 = new h2(new Uint8ClampedArray(n3), r3.width, r3.height, r3.channels);
        return void 0 !== t3 && t3 !== r3.channels && s3.convert(t3), s3;
      };
    }
    const p2 = { 0: "nearest", 1: "lanczos", 2: "bilinear", 3: "bicubic", 4: "box", 5: "hamming" }, m2 = /* @__PURE__ */ new Map([["png", "image/png"], ["jpg", "image/jpeg"], ["jpeg", "image/jpeg"], ["gif", "image/gif"]]);
    class h2 {
      constructor(e3, t3, n3, r3) {
        this.data = e3, this.width = t3, this.height = n3, this.channels = r3;
      }
      get size() {
        return [this.width, this.height];
      }
      static async read(e3) {
        if (e3 instanceof h2) return e3;
        if ("string" == typeof e3 || e3 instanceof URL) return await this.fromURL(e3);
        if (e3 instanceof Blob) return await this.fromBlob(e3);
        if ("undefined" != typeof HTMLCanvasElement && e3 instanceof HTMLCanvasElement || "undefined" != typeof OffscreenCanvas && e3 instanceof OffscreenCanvas) return this.fromCanvas(e3);
        throw new Error("Unsupported input type: " + typeof e3);
      }
      static fromCanvas(e3) {
        if (!c2) throw new Error("fromCanvas() is only supported in browser environments.");
        const t3 = e3.getContext("2d").getImageData(0, 0, e3.width, e3.height).data;
        return new h2(t3, e3.width, e3.height, 4);
      }
      static async fromURL(e3) {
        const t3 = await (0, s2.getFile)(e3);
        if (200 !== t3.status) throw new Error(`Unable to read image from "${e3}" (${t3.status} ${t3.statusText})`);
        const n3 = await t3.blob();
        return this.fromBlob(n3);
      }
      static async fromBlob(e3) {
        if (c2) {
          const t3 = await u2(e3), n3 = l2(t3.width, t3.height).getContext("2d");
          return n3.drawImage(t3, 0, 0), new this(n3.getImageData(0, 0, t3.width, t3.height).data, t3.width, t3.height, 4);
        }
        {
          const t3 = i2(await e3.arrayBuffer());
          return await u2(t3);
        }
      }
      static fromTensor(e3, t3 = "CHW") {
        if (3 !== e3.dims.length) throw new Error(`Tensor should have 3 dimensions, but has ${e3.dims.length} dimensions.`);
        if ("CHW" === t3) e3 = e3.transpose(1, 2, 0);
        else if ("HWC" !== t3) throw new Error(`Unsupported channel format: ${t3}`);
        if (!(e3.data instanceof Uint8ClampedArray || e3.data instanceof Uint8Array)) throw new Error(`Unsupported tensor type: ${e3.type}`);
        switch (e3.dims[2]) {
          case 1:
          case 2:
          case 3:
          case 4:
            return new h2(e3.data, e3.dims[1], e3.dims[0], e3.dims[2]);
          default:
            throw new Error(`Unsupported number of channels: ${e3.dims[2]}`);
        }
      }
      grayscale() {
        if (1 === this.channels) return this;
        const e3 = new Uint8ClampedArray(this.width * this.height * 1);
        switch (this.channels) {
          case 3:
          case 4:
            for (let t3 = 0, n3 = 0; t3 < this.data.length; t3 += this.channels) {
              const r3 = this.data[t3], s3 = this.data[t3 + 1], a3 = this.data[t3 + 2];
              e3[n3++] = Math.round(0.2989 * r3 + 0.587 * s3 + 0.114 * a3);
            }
            break;
          default:
            throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);
        }
        return this._update(e3, this.width, this.height, 1);
      }
      rgb() {
        if (3 === this.channels) return this;
        const e3 = new Uint8ClampedArray(this.width * this.height * 3);
        switch (this.channels) {
          case 1:
            for (let t3 = 0, n3 = 0; t3 < this.data.length; ++t3) e3[n3++] = this.data[t3], e3[n3++] = this.data[t3], e3[n3++] = this.data[t3];
            break;
          case 4:
            for (let t3 = 0, n3 = 0; t3 < this.data.length; t3 += 4) e3[n3++] = this.data[t3], e3[n3++] = this.data[t3 + 1], e3[n3++] = this.data[t3 + 2];
            break;
          default:
            throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);
        }
        return this._update(e3, this.width, this.height, 3);
      }
      rgba() {
        if (4 === this.channels) return this;
        const e3 = new Uint8ClampedArray(this.width * this.height * 4);
        switch (this.channels) {
          case 1:
            for (let t3 = 0, n3 = 0; t3 < this.data.length; ++t3) e3[n3++] = this.data[t3], e3[n3++] = this.data[t3], e3[n3++] = this.data[t3], e3[n3++] = 255;
            break;
          case 3:
            for (let t3 = 0, n3 = 0; t3 < this.data.length; t3 += 3) e3[n3++] = this.data[t3], e3[n3++] = this.data[t3 + 1], e3[n3++] = this.data[t3 + 2], e3[n3++] = 255;
            break;
          default:
            throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);
        }
        return this._update(e3, this.width, this.height, 4);
      }
      putAlpha(e3) {
        if (e3.width !== this.width || e3.height !== this.height) throw new Error(`Expected mask size to be ${this.width}x${this.height}, but got ${e3.width}x${e3.height}`);
        if (1 !== e3.channels) throw new Error(`Expected mask to have 1 channel, but got ${e3.channels}`);
        const t3 = this.data, n3 = e3.data, r3 = this.width * this.height;
        if (3 === this.channels) {
          const e4 = new Uint8ClampedArray(4 * r3);
          for (let s3 = 0, a3 = 0, o3 = 0; s3 < r3; ++s3) e4[o3++] = t3[a3++], e4[o3++] = t3[a3++], e4[o3++] = t3[a3++], e4[o3++] = n3[s3];
          return this._update(e4, this.width, this.height, 4);
        }
        if (4 === this.channels) {
          for (let e4 = 0; e4 < r3; ++e4) t3[4 * e4 + 3] = n3[e4];
          return this;
        }
        throw new Error(`Expected image to have 3 or 4 channels, but got ${this.channels}`);
      }
      async resize(e3, t3, { resample: n3 = 2 } = {}) {
        if (this.width === e3 && this.height === t3) return this;
        let s3 = p2[n3] ?? n3;
        const a3 = (0, r2.isNullishDimension)(e3), o3 = (0, r2.isNullishDimension)(t3);
        if (a3 && o3) return this;
        if (a3 ? e3 = t3 / this.height * this.width : o3 && (t3 = e3 / this.width * this.height), c2) {
          const n4 = this.channels, r3 = this.toCanvas(), s4 = l2(e3, t3).getContext("2d");
          s4.drawImage(r3, 0, 0, e3, t3);
          return new h2(s4.getImageData(0, 0, e3, t3).data, e3, t3, 4).convert(n4);
        }
        {
          let n4 = this.toSharp();
          switch (s3) {
            case "box":
            case "hamming":
              "box" !== s3 && "hamming" !== s3 || (console.warn(`Resampling method ${s3} is not yet supported. Using bilinear instead.`), s3 = "bilinear");
            case "nearest":
            case "bilinear":
            case "bicubic":
              n4 = n4.affine([e3 / this.width, 0, 0, t3 / this.height], { interpolator: s3 });
              break;
            case "lanczos":
              n4 = n4.resize({ width: e3, height: t3, fit: "fill", kernel: "lanczos3" });
              break;
            default:
              throw new Error(`Resampling method ${s3} is not supported.`);
          }
          return await u2(n4);
        }
      }
      async pad([e3, t3, n3, r3]) {
        if (e3 = Math.max(e3, 0), t3 = Math.max(t3, 0), n3 = Math.max(n3, 0), r3 = Math.max(r3, 0), 0 === e3 && 0 === t3 && 0 === n3 && 0 === r3) return this;
        if (c2) {
          const s3 = this.channels, a3 = this.toCanvas(), o3 = this.width + e3 + t3, i3 = this.height + n3 + r3, d3 = l2(o3, i3).getContext("2d");
          d3.drawImage(a3, 0, 0, this.width, this.height, e3, n3, this.width, this.height);
          return new h2(d3.getImageData(0, 0, o3, i3).data, o3, i3, 4).convert(s3);
        }
        {
          const s3 = this.toSharp().extend({ left: e3, right: t3, top: n3, bottom: r3 });
          return await u2(s3);
        }
      }
      async crop([e3, t3, n3, r3]) {
        if (e3 = Math.max(e3, 0), t3 = Math.max(t3, 0), n3 = Math.min(n3, this.width - 1), r3 = Math.min(r3, this.height - 1), 0 === e3 && 0 === t3 && n3 === this.width - 1 && r3 === this.height - 1) return this;
        const s3 = n3 - e3 + 1, a3 = r3 - t3 + 1;
        if (c2) {
          const n4 = this.channels, r4 = this.toCanvas(), o3 = l2(s3, a3).getContext("2d");
          o3.drawImage(r4, e3, t3, s3, a3, 0, 0, s3, a3);
          return new h2(o3.getImageData(0, 0, s3, a3).data, s3, a3, 4).convert(n4);
        }
        {
          const n4 = this.toSharp().extract({ left: e3, top: t3, width: s3, height: a3 });
          return await u2(n4);
        }
      }
      async center_crop(e3, t3) {
        if (this.width === e3 && this.height === t3) return this;
        const n3 = (this.width - e3) / 2, r3 = (this.height - t3) / 2;
        if (c2) {
          const s3 = this.channels, a3 = this.toCanvas(), o3 = l2(e3, t3).getContext("2d");
          let i3 = 0, d3 = 0, u3 = 0, c3 = 0;
          n3 >= 0 ? i3 = n3 : u3 = -n3, r3 >= 0 ? d3 = r3 : c3 = -r3, o3.drawImage(a3, i3, d3, e3, t3, u3, c3, e3, t3);
          return new h2(o3.getImageData(0, 0, e3, t3).data, e3, t3, 4).convert(s3);
        }
        {
          let s3 = this.toSharp();
          if (n3 >= 0 && r3 >= 0) s3 = s3.extract({ left: Math.floor(n3), top: Math.floor(r3), width: e3, height: t3 });
          else if (n3 <= 0 && r3 <= 0) {
            const a3 = Math.floor(-r3), o3 = Math.floor(-n3);
            s3 = s3.extend({ top: a3, left: o3, right: e3 - this.width - o3, bottom: t3 - this.height - a3 });
          } else {
            let a3 = [0, 0], o3 = 0;
            r3 < 0 ? (a3[0] = Math.floor(-r3), a3[1] = t3 - this.height - a3[0]) : o3 = Math.floor(r3);
            let i3 = [0, 0], l3 = 0;
            n3 < 0 ? (i3[0] = Math.floor(-n3), i3[1] = e3 - this.width - i3[0]) : l3 = Math.floor(n3), s3 = s3.extend({ top: a3[0], bottom: a3[1], left: i3[0], right: i3[1] }).extract({ left: l3, top: o3, width: e3, height: t3 });
          }
          return await u2(s3);
        }
      }
      async toBlob(e3 = "image/png", t3 = 1) {
        if (!c2) throw new Error("toBlob() is only supported in browser environments.");
        const n3 = this.toCanvas();
        return await n3.convertToBlob({ type: e3, quality: t3 });
      }
      toTensor(e3 = "CHW") {
        let t3 = new o2.Tensor("uint8", new Uint8Array(this.data), [this.height, this.width, this.channels]);
        if ("HWC" === e3) ;
        else {
          if ("CHW" !== e3) throw new Error(`Unsupported channel format: ${e3}`);
          t3 = t3.permute(2, 0, 1);
        }
        return t3;
      }
      toCanvas() {
        if (!c2) throw new Error("toCanvas() is only supported in browser environments.");
        const e3 = this.clone().rgba(), t3 = l2(e3.width, e3.height), n3 = new d2(e3.data, e3.width, e3.height);
        return t3.getContext("2d").putImageData(n3, 0, 0), t3;
      }
      split() {
        const { data: e3, width: t3, height: n3, channels: r3 } = this, s3 = e3.constructor, a3 = e3.length / r3, o3 = Array.from({ length: r3 }, (() => new s3(a3)));
        for (let t4 = 0; t4 < a3; ++t4) {
          const n4 = r3 * t4;
          for (let s4 = 0; s4 < r3; ++s4) o3[s4][t4] = e3[n4 + s4];
        }
        return o3.map(((e4) => new h2(e4, t3, n3, 1)));
      }
      _update(e3, t3, n3, r3 = null) {
        return this.data = e3, this.width = t3, this.height = n3, null !== r3 && (this.channels = r3), this;
      }
      clone() {
        return new h2(this.data.slice(), this.width, this.height, this.channels);
      }
      convert(e3) {
        if (this.channels === e3) return this;
        switch (e3) {
          case 1:
            this.grayscale();
            break;
          case 3:
            this.rgb();
            break;
          case 4:
            this.rgba();
            break;
          default:
            throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);
        }
        return this;
      }
      async save(e3) {
        if (!c2) {
          if (a2.apis.IS_FS_AVAILABLE) {
            const t3 = this.toSharp();
            return await t3.toFile(e3);
          }
          throw new Error("Unable to save the image because filesystem is disabled in this environment.");
        }
        {
          if (a2.apis.IS_WEBWORKER_ENV) throw new Error("Unable to save an image from a Web Worker.");
          const t3 = e3.split(".").pop().toLowerCase(), n3 = m2.get(t3) ?? "image/png", s3 = await this.toBlob(n3);
          (0, r2.saveBlob)(e3, s3);
        }
      }
      toSharp() {
        if (c2) throw new Error("toSharp() is only supported in server-side environments.");
        return i2(this.data, { raw: { width: this.width, height: this.height, channels: this.channels } });
      }
    }
    const f2 = h2.read.bind(h2);
  }, "./src/utils/maths.js": (e2, t2, n2) => {
    function r2(e3, [t3, n3, r3], [s3, a3], o3 = "bilinear", i3 = false) {
      const l3 = a3 / r3, d3 = s3 / n3, u3 = new e3.constructor(s3 * a3 * t3), c3 = n3 * r3, p3 = s3 * a3;
      for (let o4 = 0; o4 < s3; ++o4) for (let s4 = 0; s4 < a3; ++s4) {
        const i4 = o4 * a3 + s4, m3 = (s4 + 0.5) / l3 - 0.5, h3 = (o4 + 0.5) / d3 - 0.5;
        let f3 = Math.floor(m3), _3 = Math.floor(h3);
        const g3 = Math.min(f3 + 1, r3 - 1), w3 = Math.min(_3 + 1, n3 - 1);
        f3 = Math.max(f3, 0), _3 = Math.max(_3, 0);
        const b3 = m3 - f3, y2 = h3 - _3, M2 = (1 - b3) * (1 - y2), x2 = b3 * (1 - y2), v2 = (1 - b3) * y2, T2 = b3 * y2, k2 = _3 * r3, P2 = w3 * r3, $2 = k2 + f3, C2 = k2 + g3, S2 = P2 + f3, F2 = P2 + g3;
        for (let n4 = 0; n4 < t3; ++n4) {
          const t4 = n4 * c3;
          u3[n4 * p3 + i4] = M2 * e3[t4 + $2] + x2 * e3[t4 + C2] + v2 * e3[t4 + S2] + T2 * e3[t4 + F2];
        }
      }
      return u3;
    }
    function s2(e3, t3, n3) {
      const r3 = new Array(n3.length), s3 = new Array(n3.length);
      for (let e4 = n3.length - 1, a4 = 1; e4 >= 0; --e4) s3[e4] = a4, r3[e4] = t3[n3[e4]], a4 *= r3[e4];
      const a3 = n3.map(((e4, t4) => s3[n3.indexOf(t4)])), o3 = new e3.constructor(e3.length);
      for (let n4 = 0; n4 < e3.length; ++n4) {
        let r4 = 0;
        for (let e4 = t3.length - 1, s4 = n4; e4 >= 0; --e4) r4 += s4 % t3[e4] * a3[e4], s4 = Math.floor(s4 / t3[e4]);
        o3[r4] = e3[n4];
      }
      return [o3, r3];
    }
    function a2(e3) {
      const t3 = c2(e3)[0], n3 = e3.map(((e4) => Math.exp(e4 - t3))), r3 = n3.reduce(((e4, t4) => e4 + t4), 0);
      return n3.map(((e4) => e4 / r3));
    }
    function o2(e3) {
      const t3 = c2(e3)[0];
      let n3 = 0;
      for (let r4 = 0; r4 < e3.length; ++r4) n3 += Math.exp(e3[r4] - t3);
      const r3 = Math.log(n3);
      return e3.map(((e4) => e4 - t3 - r3));
    }
    function i2(e3, t3) {
      let n3 = 0;
      for (let r3 = 0; r3 < e3.length; ++r3) n3 += e3[r3] * t3[r3];
      return n3;
    }
    function l2(e3, t3) {
      return i2(e3, t3) / (d2(e3) * d2(t3));
    }
    function d2(e3) {
      return Math.sqrt(e3.reduce(((e4, t3) => e4 + t3 * t3), 0));
    }
    function u2(e3) {
      if (0 === e3.length) throw Error("Array must not be empty");
      let t3 = e3[0], n3 = 0;
      for (let r3 = 1; r3 < e3.length; ++r3) e3[r3] < t3 && (t3 = e3[r3], n3 = r3);
      return [t3, n3];
    }
    function c2(e3) {
      if (0 === e3.length) throw Error("Array must not be empty");
      let t3 = e3[0], n3 = 0;
      for (let r3 = 1; r3 < e3.length; ++r3) e3[r3] > t3 && (t3 = e3[r3], n3 = r3);
      return [t3, n3];
    }
    function p2(e3) {
      return e3 > 0 && !(e3 & e3 - 1);
    }
    n2.r(t2), n2.d(t2, { FFT: () => f2, bankers_round: () => w2, cos_sim: () => l2, dot: () => i2, dynamic_time_warping: () => b2, interpolate_data: () => r2, log_softmax: () => o2, magnitude: () => d2, max: () => c2, medianFilter: () => _2, min: () => u2, permute_data: () => s2, round: () => g2, softmax: () => a2 });
    class m2 {
      constructor(e3) {
        if (this.size = 0 | e3, this.size <= 1 || !p2(this.size)) throw new Error("FFT size must be a power of two larger than 1");
        this._csize = e3 << 1, this.table = new Float64Array(2 * this.size);
        for (let e4 = 0; e4 < this.table.length; e4 += 2) {
          const t4 = Math.PI * e4 / this.size;
          this.table[e4] = Math.cos(t4), this.table[e4 + 1] = -Math.sin(t4);
        }
        let t3 = 0;
        for (let e4 = 1; this.size > e4; e4 <<= 1) ++t3;
        this._width = t3 % 2 == 0 ? t3 - 1 : t3, this._bitrev = new Int32Array(1 << this._width);
        for (let e4 = 0; e4 < this._bitrev.length; ++e4) {
          this._bitrev[e4] = 0;
          for (let t4 = 0; t4 < this._width; t4 += 2) {
            const n3 = this._width - t4 - 2;
            this._bitrev[e4] |= (e4 >>> t4 & 3) << n3;
          }
        }
      }
      createComplexArray() {
        return new Float64Array(this._csize);
      }
      fromComplexArray(e3, t3) {
        const n3 = t3 || new Array(e3.length >>> 1);
        for (let t4 = 0; t4 < e3.length; t4 += 2) n3[t4 >>> 1] = e3[t4];
        return n3;
      }
      toComplexArray(e3, t3) {
        const n3 = t3 || this.createComplexArray();
        for (let t4 = 0; t4 < n3.length; t4 += 2) n3[t4] = e3[t4 >>> 1], n3[t4 + 1] = 0;
        return n3;
      }
      transform(e3, t3) {
        if (e3 === t3) throw new Error("Input and output buffers must be different");
        this._transform4(e3, t3, 1);
      }
      realTransform(e3, t3) {
        if (e3 === t3) throw new Error("Input and output buffers must be different");
        this._realTransform4(e3, t3, 1);
      }
      inverseTransform(e3, t3) {
        if (e3 === t3) throw new Error("Input and output buffers must be different");
        this._transform4(e3, t3, -1);
        for (let t4 = 0; t4 < e3.length; ++t4) e3[t4] /= this.size;
      }
      _transform4(e3, t3, n3) {
        const r3 = this._csize;
        let s3, a3, o3 = 1 << this._width, i3 = r3 / o3 << 1;
        const l3 = this._bitrev;
        if (4 === i3) for (s3 = 0, a3 = 0; s3 < r3; s3 += i3, ++a3) {
          const n4 = l3[a3];
          this._singleTransform2(t3, e3, s3, n4, o3);
        }
        else for (s3 = 0, a3 = 0; s3 < r3; s3 += i3, ++a3) {
          const r4 = l3[a3];
          this._singleTransform4(t3, e3, s3, r4, o3, n3);
        }
        const d3 = this.table;
        for (o3 >>= 2; o3 >= 2; o3 >>= 2) {
          i3 = r3 / o3 << 1;
          const t4 = i3 >>> 2;
          for (s3 = 0; s3 < r3; s3 += i3) {
            const r4 = s3 + t4 - 1;
            for (let a4 = s3, i4 = 0; a4 < r4; a4 += 2, i4 += o3) {
              const r5 = a4, s4 = r5 + t4, o4 = s4 + t4, l4 = o4 + t4, u3 = e3[r5], c3 = e3[r5 + 1], p3 = e3[s4], m3 = e3[s4 + 1], h3 = e3[o4], f3 = e3[o4 + 1], _3 = e3[l4], g3 = e3[l4 + 1], w3 = d3[i4], b3 = n3 * d3[i4 + 1], y2 = p3 * w3 - m3 * b3, M2 = p3 * b3 + m3 * w3, x2 = d3[2 * i4], v2 = n3 * d3[2 * i4 + 1], T2 = h3 * x2 - f3 * v2, k2 = h3 * v2 + f3 * x2, P2 = d3[3 * i4], $2 = n3 * d3[3 * i4 + 1], C2 = _3 * P2 - g3 * $2, S2 = _3 * $2 + g3 * P2, F2 = u3 + T2, E2 = c3 + k2, I2 = u3 - T2, A2 = c3 - k2, z2 = y2 + C2, L2 = M2 + S2, O2 = n3 * (y2 - C2), D2 = n3 * (M2 - S2);
              e3[r5] = F2 + z2, e3[r5 + 1] = E2 + L2, e3[s4] = I2 + D2, e3[s4 + 1] = A2 - O2, e3[o4] = F2 - z2, e3[o4 + 1] = E2 - L2, e3[l4] = I2 - D2, e3[l4 + 1] = A2 + O2;
            }
          }
        }
      }
      _singleTransform2(e3, t3, n3, r3, s3) {
        const a3 = e3[r3], o3 = e3[r3 + 1], i3 = e3[r3 + s3], l3 = e3[r3 + s3 + 1];
        t3[n3] = a3 + i3, t3[n3 + 1] = o3 + l3, t3[n3 + 2] = a3 - i3, t3[n3 + 3] = o3 - l3;
      }
      _singleTransform4(e3, t3, n3, r3, s3, a3) {
        const o3 = 2 * s3, i3 = 3 * s3, l3 = e3[r3], d3 = e3[r3 + 1], u3 = e3[r3 + s3], c3 = e3[r3 + s3 + 1], p3 = e3[r3 + o3], m3 = e3[r3 + o3 + 1], h3 = e3[r3 + i3], f3 = e3[r3 + i3 + 1], _3 = l3 + p3, g3 = d3 + m3, w3 = l3 - p3, b3 = d3 - m3, y2 = u3 + h3, M2 = c3 + f3, x2 = a3 * (u3 - h3), v2 = a3 * (c3 - f3);
        t3[n3] = _3 + y2, t3[n3 + 1] = g3 + M2, t3[n3 + 2] = w3 + v2, t3[n3 + 3] = b3 - x2, t3[n3 + 4] = _3 - y2, t3[n3 + 5] = g3 - M2, t3[n3 + 6] = w3 - v2, t3[n3 + 7] = b3 + x2;
      }
      _realTransform4(e3, t3, n3) {
        const r3 = this._csize;
        let s3, a3, o3 = 1 << this._width, i3 = r3 / o3 << 1;
        const l3 = this._bitrev;
        if (4 === i3) for (s3 = 0, a3 = 0; s3 < r3; s3 += i3, ++a3) {
          const n4 = l3[a3];
          this._singleRealTransform2(t3, e3, s3, n4 >>> 1, o3 >>> 1);
        }
        else for (s3 = 0, a3 = 0; s3 < r3; s3 += i3, ++a3) {
          const r4 = l3[a3];
          this._singleRealTransform4(t3, e3, s3, r4 >>> 1, o3 >>> 1, n3);
        }
        const d3 = this.table;
        for (o3 >>= 2; o3 >= 2; o3 >>= 2) {
          i3 = r3 / o3 << 1;
          const t4 = i3 >>> 1, a4 = t4 >>> 1, l4 = a4 >>> 1;
          for (s3 = 0; s3 < r3; s3 += i3) for (let r4 = 0, i4 = 0; r4 <= l4; r4 += 2, i4 += o3) {
            const o4 = s3 + r4, u4 = o4 + a4, c3 = u4 + a4, p3 = c3 + a4, m3 = e3[o4], h3 = e3[o4 + 1], f3 = e3[u4], _3 = e3[u4 + 1], g3 = e3[c3], w3 = e3[c3 + 1], b3 = e3[p3], y2 = e3[p3 + 1], M2 = m3, x2 = h3, v2 = d3[i4], T2 = n3 * d3[i4 + 1], k2 = f3 * v2 - _3 * T2, P2 = f3 * T2 + _3 * v2, $2 = d3[2 * i4], C2 = n3 * d3[2 * i4 + 1], S2 = g3 * $2 - w3 * C2, F2 = g3 * C2 + w3 * $2, E2 = d3[3 * i4], I2 = n3 * d3[3 * i4 + 1], A2 = b3 * E2 - y2 * I2, z2 = b3 * I2 + y2 * E2, L2 = M2 + S2, O2 = x2 + F2, D2 = M2 - S2, B2 = x2 - F2, N2 = k2 + A2, j2 = P2 + z2, R2 = n3 * (k2 - A2), V2 = n3 * (P2 - z2);
            if (e3[o4] = L2 + N2, e3[o4 + 1] = O2 + j2, e3[u4] = D2 + V2, e3[u4 + 1] = B2 - R2, 0 === r4) {
              e3[c3] = L2 - N2, e3[c3 + 1] = O2 - j2;
              continue;
            }
            if (r4 === l4) continue;
            const G2 = s3 + a4 - r4, q2 = s3 + t4 - r4;
            e3[G2] = D2 - n3 * V2, e3[G2 + 1] = -B2 - n3 * R2, e3[q2] = L2 - n3 * N2, e3[q2 + 1] = n3 * j2 - O2;
          }
        }
        const u3 = r3 >>> 1;
        for (let t4 = 2; t4 < u3; t4 += 2) e3[r3 - t4] = e3[t4], e3[r3 - t4 + 1] = -e3[t4 + 1];
      }
      _singleRealTransform2(e3, t3, n3, r3, s3) {
        const a3 = e3[r3], o3 = e3[r3 + s3];
        t3[n3] = a3 + o3, t3[n3 + 1] = 0, t3[n3 + 2] = a3 - o3, t3[n3 + 3] = 0;
      }
      _singleRealTransform4(e3, t3, n3, r3, s3, a3) {
        const o3 = 2 * s3, i3 = 3 * s3, l3 = e3[r3], d3 = e3[r3 + s3], u3 = e3[r3 + o3], c3 = e3[r3 + i3], p3 = l3 + u3, m3 = l3 - u3, h3 = d3 + c3, f3 = a3 * (d3 - c3);
        t3[n3] = p3 + h3, t3[n3 + 1] = 0, t3[n3 + 2] = m3, t3[n3 + 3] = -f3, t3[n3 + 4] = p3 - h3, t3[n3 + 5] = 0, t3[n3 + 6] = m3, t3[n3 + 7] = f3;
      }
    }
    class h2 {
      constructor(e3) {
        const t3 = 2 * (e3 - 1), n3 = 2 * (2 * e3 - 1), r3 = 2 ** Math.ceil(Math.log2(n3));
        this.bufferSize = r3, this._a = t3;
        const s3 = new Float64Array(n3), a3 = new Float64Array(r3);
        this._chirpBuffer = new Float64Array(r3), this._buffer1 = new Float64Array(r3), this._buffer2 = new Float64Array(r3), this._outBuffer1 = new Float64Array(r3), this._outBuffer2 = new Float64Array(r3);
        const o3 = -2 * Math.PI / e3, i3 = Math.cos(o3), l3 = Math.sin(o3);
        for (let t4 = 0; t4 < n3 >> 1; ++t4) {
          const n4 = (t4 + 1 - e3) ** 2 / 2, r4 = Math.sqrt(i3 ** 2 + l3 ** 2) ** n4, o4 = n4 * Math.atan2(l3, i3), d3 = 2 * t4;
          s3[d3] = r4 * Math.cos(o4), s3[d3 + 1] = r4 * Math.sin(o4), a3[d3] = s3[d3], a3[d3 + 1] = -s3[d3 + 1];
        }
        this._slicedChirpBuffer = s3.subarray(t3, n3), this._f = new m2(r3 >> 1), this._f.transform(this._chirpBuffer, a3);
      }
      _transform(e3, t3, n3) {
        const r3 = this._buffer1, s3 = this._buffer2, a3 = this._outBuffer1, o3 = this._outBuffer2, i3 = this._chirpBuffer, l3 = this._slicedChirpBuffer, d3 = this._a;
        if (n3) for (let e4 = 0; e4 < l3.length; e4 += 2) {
          const n4 = e4 + 1, s4 = t3[e4 >> 1];
          r3[e4] = s4 * l3[e4], r3[n4] = s4 * l3[n4];
        }
        else for (let e4 = 0; e4 < l3.length; e4 += 2) {
          const n4 = e4 + 1;
          r3[e4] = t3[e4] * l3[e4] - t3[n4] * l3[n4], r3[n4] = t3[e4] * l3[n4] + t3[n4] * l3[e4];
        }
        this._f.transform(a3, r3);
        for (let e4 = 0; e4 < i3.length; e4 += 2) {
          const t4 = e4 + 1;
          s3[e4] = a3[e4] * i3[e4] - a3[t4] * i3[t4], s3[t4] = a3[e4] * i3[t4] + a3[t4] * i3[e4];
        }
        this._f.inverseTransform(o3, s3);
        for (let t4 = 0; t4 < o3.length; t4 += 2) {
          const n4 = o3[t4 + d3], r4 = o3[t4 + d3 + 1], s4 = l3[t4], a4 = l3[t4 + 1];
          e3[t4] = n4 * s4 - r4 * a4, e3[t4 + 1] = n4 * a4 + r4 * s4;
        }
      }
      transform(e3, t3) {
        this._transform(e3, t3, false);
      }
      realTransform(e3, t3) {
        this._transform(e3, t3, true);
      }
    }
    class f2 {
      constructor(e3) {
        this.fft_length = e3, this.isPowerOfTwo = p2(e3), this.isPowerOfTwo ? (this.fft = new m2(e3), this.outputBufferSize = 2 * e3) : (this.fft = new h2(e3), this.outputBufferSize = this.fft.bufferSize);
      }
      realTransform(e3, t3) {
        this.fft.realTransform(e3, t3);
      }
      transform(e3, t3) {
        this.fft.transform(e3, t3);
      }
    }
    function _2(e3, t3) {
      if (t3 % 2 == 0 || t3 <= 0) throw new Error("Window size must be a positive odd number");
      const n3 = new e3.constructor(e3.length), r3 = new e3.constructor(t3), s3 = Math.floor(t3 / 2);
      for (let t4 = 0; t4 < e3.length; ++t4) {
        let a3 = 0;
        for (let n4 = -s3; n4 <= s3; ++n4) {
          let s4 = t4 + n4;
          s4 < 0 ? s4 = Math.abs(s4) : s4 >= e3.length && (s4 = 2 * (e3.length - 1) - s4), r3[a3++] = e3[s4];
        }
        r3.sort(), n3[t4] = r3[s3];
      }
      return n3;
    }
    function g2(e3, t3) {
      const n3 = Math.pow(10, t3);
      return Math.round(e3 * n3) / n3;
    }
    function w2(e3) {
      const t3 = Math.round(e3);
      return Math.abs(e3) % 1 == 0.5 ? t3 % 2 == 0 ? t3 : t3 - 1 : t3;
    }
    function b2(e3) {
      const t3 = e3.length, n3 = e3[0].length, r3 = [t3 + 1, n3 + 1], s3 = Array.from({ length: r3[0] }, (() => Array(r3[1]).fill(1 / 0)));
      s3[0][0] = 0;
      const a3 = Array.from({ length: r3[0] }, (() => Array(r3[1]).fill(-1)));
      for (let t4 = 1; t4 < r3[1]; ++t4) for (let n4 = 1; n4 < r3[0]; ++n4) {
        const r4 = s3[n4 - 1][t4 - 1], o4 = s3[n4 - 1][t4], i4 = s3[n4][t4 - 1];
        let l4, d4;
        r4 < o4 && r4 < i4 ? (l4 = r4, d4 = 0) : o4 < r4 && o4 < i4 ? (l4 = o4, d4 = 1) : (l4 = i4, d4 = 2), s3[n4][t4] = e3[n4 - 1][t4 - 1] + l4, a3[n4][t4] = d4;
      }
      for (let e4 = 0; e4 < r3[1]; ++e4) a3[0][e4] = 2;
      for (let e4 = 0; e4 < r3[0]; ++e4) a3[e4][0] = 1;
      let o3 = t3, i3 = n3, l3 = [], d3 = [];
      for (; o3 > 0 || i3 > 0; ) switch (l3.push(o3 - 1), d3.push(i3 - 1), a3[o3][i3]) {
        case 0:
          --o3, --i3;
          break;
        case 1:
          --o3;
          break;
        case 2:
          --i3;
          break;
        default:
          throw new Error(`Internal error in dynamic time warping. Unexpected trace[${o3}, ${i3}]. Please file a bug report.`);
      }
      return l3.reverse(), d3.reverse(), [l3, d3];
    }
  }, "./src/utils/tensor.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { DataTypeMap: () => o2, Tensor: () => i2, cat: () => M2, full: () => $2, full_like: () => C2, interpolate: () => d2, interpolate_4d: () => u2, layer_norm: () => g2, matmul: () => c2, mean: () => k2, mean_pooling: () => _2, ones: () => S2, ones_like: () => F2, permute: () => l2, quantize_embeddings: () => L2, rand: () => A2, randn: () => z2, rfft: () => p2, slice: () => f2, stack: () => x2, std_mean: () => T2, topk: () => m2, zeros: () => E2, zeros_like: () => I2 });
    var r2 = n2("./src/utils/maths.js"), s2 = n2("./src/backends/onnx.js"), a2 = n2("./src/ops/registry.js");
    const o2 = Object.freeze({ float32: Float32Array, float16: "undefined" != typeof Float16Array ? Float16Array : Uint16Array, float64: Float64Array, string: Array, int8: Int8Array, uint8: Uint8Array, int16: Int16Array, uint16: Uint16Array, int32: Int32Array, uint32: Uint32Array, int64: BigInt64Array, uint64: BigUint64Array, bool: Uint8Array, uint4: Uint8Array, int4: Int8Array });
    class i2 {
      get dims() {
        return this.ort_tensor.dims;
      }
      set dims(e3) {
        this.ort_tensor.dims = e3;
      }
      get type() {
        return this.ort_tensor.type;
      }
      get data() {
        return this.ort_tensor.data;
      }
      get size() {
        return this.ort_tensor.size;
      }
      get location() {
        return this.ort_tensor.location;
      }
      ort_tensor;
      constructor(...e3) {
        return (0, s2.isONNXTensor)(e3[0]) ? this.ort_tensor = e3[0] : this.ort_tensor = new s2.Tensor(e3[0], e3[1], e3[2]), new Proxy(this, { get: (e4, t3) => {
          if ("string" == typeof t3) {
            let n3 = Number(t3);
            if (Number.isInteger(n3)) return e4._getitem(n3);
          }
          return e4[t3];
        }, set: (e4, t3, n3) => e4[t3] = n3 });
      }
      dispose() {
        this.ort_tensor.dispose();
      }
      *[Symbol.iterator]() {
        const [e3, ...t3] = this.dims;
        if (t3.length > 0) {
          const n3 = t3.reduce(((e4, t4) => e4 * t4));
          for (let r3 = 0; r3 < e3; ++r3) yield this._subarray(r3, n3, t3);
        } else yield* this.data;
      }
      _getitem(e3) {
        const [t3, ...n3] = this.dims;
        if (e3 = y2(e3, t3), n3.length > 0) {
          const t4 = n3.reduce(((e4, t5) => e4 * t5));
          return this._subarray(e3, t4, n3);
        }
        return new i2(this.type, [this.data[e3]], n3);
      }
      indexOf(e3) {
        const t3 = this.data;
        for (let n3 = 0; n3 < t3.length; ++n3) if (t3[n3] == e3) return n3;
        return -1;
      }
      _subarray(e3, t3, n3) {
        const r3 = e3 * t3, s3 = (e3 + 1) * t3, a3 = "subarray" in this.data ? this.data.subarray(r3, s3) : this.data.slice(r3, s3);
        return new i2(this.type, a3, n3);
      }
      item() {
        const e3 = this.data;
        if (1 !== e3.length) throw new Error(`a Tensor with ${e3.length} elements cannot be converted to Scalar`);
        return e3[0];
      }
      tolist() {
        return (function(e3, t3) {
          const n3 = e3.length, r3 = t3.reduce(((e4, t4) => e4 * t4));
          if (n3 !== r3) throw Error(`cannot reshape array of size ${n3} into shape (${t3})`);
          let s3 = e3;
          for (let e4 = t3.length - 1; e4 >= 0; e4--) s3 = s3.reduce(((n4, r4) => {
            let s4 = n4[n4.length - 1];
            return s4.length < t3[e4] ? s4.push(r4) : n4.push([r4]), n4;
          }), [[]]);
          return s3[0];
        })(this.data, this.dims);
      }
      sigmoid() {
        return this.clone().sigmoid_();
      }
      sigmoid_() {
        const e3 = this.data;
        for (let t3 = 0; t3 < e3.length; ++t3) e3[t3] = 1 / (1 + Math.exp(-e3[t3]));
        return this;
      }
      map(e3) {
        return this.clone().map_(e3);
      }
      map_(e3) {
        const t3 = this.data;
        for (let n3 = 0; n3 < t3.length; ++n3) t3[n3] = e3(t3[n3], n3, t3);
        return this;
      }
      mul(e3) {
        return this.clone().mul_(e3);
      }
      mul_(e3) {
        const t3 = this.data;
        for (let n3 = 0; n3 < t3.length; ++n3) t3[n3] *= e3;
        return this;
      }
      div(e3) {
        return this.clone().div_(e3);
      }
      div_(e3) {
        const t3 = this.data;
        for (let n3 = 0; n3 < t3.length; ++n3) t3[n3] /= e3;
        return this;
      }
      add(e3) {
        return this.clone().add_(e3);
      }
      add_(e3) {
        const t3 = this.data;
        for (let n3 = 0; n3 < t3.length; ++n3) t3[n3] += e3;
        return this;
      }
      sub(e3) {
        return this.clone().sub_(e3);
      }
      sub_(e3) {
        const t3 = this.data;
        for (let n3 = 0; n3 < t3.length; ++n3) t3[n3] -= e3;
        return this;
      }
      clone() {
        return new i2(this.type, this.data.slice(), this.dims.slice());
      }
      slice(...e3) {
        const t3 = [], n3 = [];
        for (let r4 = 0; r4 < this.dims.length; ++r4) {
          let s4 = e3[r4];
          if (null == s4) n3.push([0, this.dims[r4]]), t3.push(this.dims[r4]);
          else if ("number" == typeof s4) s4 = y2(s4, this.dims[r4], r4), n3.push([s4, s4 + 1]);
          else {
            if (!Array.isArray(s4) || 2 !== s4.length) throw new Error(`Invalid slice: ${s4}`);
            {
              let [e4, a4] = s4;
              if (e4 = null === e4 ? 0 : y2(e4, this.dims[r4], r4, false), a4 = null === a4 ? this.dims[r4] : y2(a4, this.dims[r4], r4, false), e4 > a4) throw new Error(`Invalid slice: ${s4}`);
              const o4 = [Math.max(e4, 0), Math.min(a4, this.dims[r4])];
              n3.push(o4), t3.push(o4[1] - o4[0]);
            }
          }
        }
        const r3 = n3.map((([e4, t4]) => t4 - e4)), s3 = r3.reduce(((e4, t4) => e4 * t4)), a3 = this.data, o3 = new a3.constructor(s3), l3 = this.stride();
        let d3 = true;
        for (let e4 = 1; e4 < r3.length; ++e4) if (0 !== n3[e4][0] || n3[e4][1] !== this.dims[e4]) {
          d3 = false;
          break;
        }
        if (d3) {
          const e4 = n3[0][0] * l3[0], t4 = n3[0][1] * l3[0];
          if (ArrayBuffer.isView(a3)) o3.set(a3.subarray(e4, t4));
          else {
            if (!Array.isArray(a3)) throw new Error("Unsupported data type for slicing");
            {
              const n4 = a3.slice(e4, t4);
              for (let e5 = 0; e5 < n4.length; ++e5) o3[e5] = n4[e5];
            }
          }
        } else for (let e4 = 0; e4 < s3; ++e4) {
          let t4 = 0;
          for (let s4 = r3.length - 1, a4 = e4; s4 >= 0; --s4) {
            const e5 = r3[s4];
            t4 += (a4 % e5 + n3[s4][0]) * l3[s4], a4 = Math.floor(a4 / e5);
          }
          o3[e4] = a3[t4];
        }
        return new i2(this.type, o3, t3);
      }
      permute(...e3) {
        return l2(this, e3);
      }
      transpose(...e3) {
        return this.permute(...e3);
      }
      sum(e3 = null, t3 = false) {
        return this.norm(1, e3, t3);
      }
      norm(e3 = "fro", t3 = null, n3 = false) {
        if ("fro" === e3) e3 = 2;
        else if ("string" == typeof e3) throw Error(`Unsupported norm: ${e3}`);
        const r3 = this.data, s3 = (t4, n4) => t4 + n4 ** e3;
        if (null === t3) {
          const t4 = r3.reduce(s3, 0) ** (1 / e3);
          return new i2(this.type, [t4], []);
        }
        const [a3, o3, l3] = v2(s3, this, t3, n3);
        if (1 !== e3) for (let t4 = 0; t4 < o3.length; ++t4) o3[t4] = o3[t4] ** (1 / e3);
        return new i2(a3, o3, l3);
      }
      normalize_(e3 = 2, t3 = 1) {
        t3 = y2(t3, this.dims.length);
        const n3 = this.norm(e3, t3, true), r3 = this.data, s3 = n3.data;
        for (let e4 = 0; e4 < r3.length; ++e4) {
          let n4 = 0;
          for (let r4 = this.dims.length - 1, s4 = e4, a3 = 1; r4 >= 0; --r4) {
            const e5 = this.dims[r4];
            if (r4 !== t3) {
              n4 += s4 % e5 * a3, a3 *= this.dims[r4];
            }
            s4 = Math.floor(s4 / e5);
          }
          r3[e4] /= s3[n4];
        }
        return this;
      }
      normalize(e3 = 2, t3 = 1) {
        return this.clone().normalize_(e3, t3);
      }
      stride() {
        return (function(e3) {
          const t3 = new Array(e3.length);
          for (let n3 = e3.length - 1, r3 = 1; n3 >= 0; --n3) t3[n3] = r3, r3 *= e3[n3];
          return t3;
        })(this.dims);
      }
      squeeze(e3 = null) {
        return new i2(this.type, this.data, w2(this.dims, e3));
      }
      squeeze_(e3 = null) {
        return this.dims = w2(this.dims, e3), this;
      }
      unsqueeze(e3 = null) {
        return new i2(this.type, this.data, b2(this.dims, e3));
      }
      unsqueeze_(e3 = null) {
        return this.dims = b2(this.dims, e3), this;
      }
      flatten_(e3 = 0, t3 = -1) {
        t3 = (t3 + this.dims.length) % this.dims.length;
        let n3 = this.dims.slice(0, e3), r3 = this.dims.slice(e3, t3 + 1), s3 = this.dims.slice(t3 + 1);
        return this.dims = [...n3, r3.reduce(((e4, t4) => e4 * t4), 1), ...s3], this;
      }
      flatten(e3 = 0, t3 = -1) {
        return this.clone().flatten_(e3, t3);
      }
      view(...e3) {
        let t3 = -1;
        for (let n4 = 0; n4 < e3.length; ++n4) if (-1 === e3[n4]) {
          if (-1 !== t3) throw new Error("Only one dimension can be inferred");
          t3 = n4;
        }
        const n3 = this.data;
        if (-1 !== t3) {
          const r3 = e3.reduce(((e4, n4, r4) => r4 !== t3 ? e4 * n4 : e4), 1);
          e3[t3] = n3.length / r3;
        }
        return new i2(this.type, n3, e3);
      }
      neg_() {
        const e3 = this.data;
        for (let t3 = 0; t3 < e3.length; ++t3) e3[t3] = -e3[t3];
        return this;
      }
      neg() {
        return this.clone().neg_();
      }
      gt(e3) {
        const t3 = new Uint8Array(this.data.length), n3 = this.data;
        for (let r3 = 0; r3 < n3.length; ++r3) t3[r3] = n3[r3] > e3 ? 1 : 0;
        return new i2("bool", t3, this.dims);
      }
      lt(e3) {
        const t3 = new Uint8Array(this.data.length), n3 = this.data;
        for (let r3 = 0; r3 < n3.length; ++r3) t3[r3] = n3[r3] < e3 ? 1 : 0;
        return new i2("bool", t3, this.dims);
      }
      clamp_(e3, t3) {
        const n3 = this.data;
        for (let r3 = 0; r3 < n3.length; ++r3) n3[r3] = Math.min(Math.max(n3[r3], e3), t3);
        return this;
      }
      clamp(e3, t3) {
        return this.clone().clamp_(e3, t3);
      }
      round_() {
        const e3 = this.data;
        for (let t3 = 0; t3 < e3.length; ++t3) e3[t3] = Math.round(e3[t3]);
        return this;
      }
      round() {
        return this.clone().round_();
      }
      mean(e3 = null, t3 = false) {
        return k2(this, e3, t3);
      }
      min(e3 = null, t3 = false) {
        if (null === e3) {
          const e4 = (0, r2.min)(this.data)[0];
          return new i2(this.type, [e4], []);
        }
        const [n3, s3, a3] = v2(((e4, t4) => Math.min(e4, t4)), this, e3, t3, 1 / 0);
        return new i2(n3, s3, a3);
      }
      max(e3 = null, t3 = false) {
        if (null === e3) {
          const e4 = (0, r2.max)(this.data)[0];
          return new i2(this.type, [e4], []);
        }
        const [n3, s3, a3] = v2(((e4, t4) => Math.max(e4, t4)), this, e3, t3, -1 / 0);
        return new i2(n3, s3, a3);
      }
      argmin(e3 = null, t3 = false) {
        if (null !== e3) throw new Error("`dim !== null` not yet implemented.");
        const n3 = (0, r2.min)(this.data)[1];
        return new i2("int64", [BigInt(n3)], []);
      }
      argmax(e3 = null, t3 = false) {
        if (null !== e3) throw new Error("`dim !== null` not yet implemented.");
        const n3 = (0, r2.max)(this.data)[1];
        return new i2("int64", [BigInt(n3)], []);
      }
      to(e3) {
        if (this.type === e3) return this;
        if (!o2.hasOwnProperty(e3)) throw new Error(`Unsupported type: ${e3}`);
        let t3;
        const n3 = ["int64", "uint64"].includes(this.type), r3 = ["int64", "uint64"].includes(e3);
        return n3 && !r3 ? t3 = Number : !n3 && r3 && (t3 = ["float16", "float32", "float64"].includes(this.type) ? (e4) => BigInt(Math.floor(e4)) : BigInt), new i2(e3, o2[e3].from(this.data, t3), this.dims);
      }
    }
    function l2(e3, t3) {
      const [n3, s3] = (0, r2.permute_data)(e3.data, e3.dims, t3);
      return new i2(e3.type, n3, s3);
    }
    function d2(e3, [t3, n3], s3 = "bilinear", a3 = false) {
      const o3 = e3.dims.at(-3) ?? 1, l3 = e3.dims.at(-2), d3 = e3.dims.at(-1);
      let u3 = (0, r2.interpolate_data)(e3.data, [o3, l3, d3], [t3, n3], s3, a3);
      return new i2(e3.type, u3, [o3, t3, n3]);
    }
    async function u2(e3, { size: t3 = null, mode: n3 = "bilinear" } = {}) {
      if (4 !== e3.dims.length) throw new Error("`interpolate_4d` currently only supports 4D input.");
      if (!t3) throw new Error("`interpolate_4d` requires a `size` argument.");
      let r3, s3;
      if (2 === t3.length) r3 = [...e3.dims.slice(0, 2), ...t3];
      else if (3 === t3.length) r3 = [e3.dims[0], ...t3];
      else {
        if (4 !== t3.length) throw new Error("`size` must be of length 2, 3, or 4.");
        r3 = t3;
      }
      if ("nearest" === n3) s3 = await a2.TensorOpRegistry.nearest_interpolate_4d;
      else if ("bilinear" === n3) s3 = await a2.TensorOpRegistry.bilinear_interpolate_4d;
      else {
        if ("bicubic" !== n3) throw new Error(`Unsupported mode: ${n3}`);
        s3 = await a2.TensorOpRegistry.bicubic_interpolate_4d;
      }
      const o3 = new i2("int64", new BigInt64Array(r3.map(BigInt)), [r3.length]);
      return await s3({ x: e3, s: o3 });
    }
    async function c2(e3, t3) {
      const n3 = await a2.TensorOpRegistry.matmul;
      return await n3({ a: e3, b: t3 });
    }
    async function p2(e3, t3) {
      const n3 = await a2.TensorOpRegistry.rfft;
      return await n3({ x: e3, a: t3 });
    }
    async function m2(e3, t3) {
      const n3 = await a2.TensorOpRegistry.top_k;
      return t3 = null == t3 ? e3.dims.at(-1) : Math.min(t3, e3.dims.at(-1)), await n3({ x: e3, k: new i2("int64", [BigInt(t3)], [1]) });
    }
    const h2 = (e3) => new i2("int64", e3, [e3.length]);
    async function f2(e3, t3, n3, r3, s3) {
      const o3 = await a2.TensorOpRegistry.slice;
      return await o3({ x: e3, s: h2(t3), e: h2(n3), a: h2(r3), t: h2(s3 ?? new Array(r3.length).fill(1)) });
    }
    function _2(e3, t3) {
      const n3 = e3.data, r3 = t3.data, s3 = [e3.dims[0], e3.dims[2]], a3 = new n3.constructor(s3[0] * s3[1]), [o3, l3, d3] = e3.dims;
      let u3 = 0;
      for (let e4 = 0; e4 < o3; ++e4) {
        const t4 = e4 * d3 * l3;
        for (let s4 = 0; s4 < d3; ++s4) {
          let o4 = 0, i3 = 0;
          const c3 = e4 * l3, p3 = t4 + s4;
          for (let e5 = 0; e5 < l3; ++e5) {
            const t5 = Number(r3[c3 + e5]);
            i3 += t5, o4 += n3[p3 + e5 * d3] * t5;
          }
          const m3 = o4 / i3;
          a3[u3++] = m3;
        }
      }
      return new i2(e3.type, a3, s3);
    }
    function g2(e3, t3, { eps: n3 = 1e-5 } = {}) {
      if (2 !== e3.dims.length) throw new Error("`layer_norm` currently only supports 2D input.");
      const [r3, s3] = e3.dims;
      if (1 !== t3.length && t3[0] !== s3) throw new Error("`normalized_shape` must be a 1D array with shape `[input.dims[1]]`.");
      const [a3, o3] = T2(e3, 1, 0, true), l3 = a3.data, d3 = o3.data, u3 = e3.data, c3 = new u3.constructor(u3.length);
      for (let e4 = 0; e4 < r3; ++e4) {
        const t4 = e4 * s3;
        for (let r4 = 0; r4 < s3; ++r4) {
          const s4 = t4 + r4;
          c3[s4] = (u3[s4] - d3[e4]) / (l3[e4] + n3);
        }
      }
      return new i2(e3.type, c3, e3.dims);
    }
    function w2(e3, t3) {
      return e3 = e3.slice(), null === t3 ? e3 = e3.filter(((e4) => 1 !== e4)) : "number" == typeof t3 ? 1 === e3[t3] && e3.splice(t3, 1) : Array.isArray(t3) && (e3 = e3.filter(((e4, n3) => 1 !== e4 || !t3.includes(n3)))), e3;
    }
    function b2(e3, t3) {
      return t3 = y2(t3, e3.length + 1), (e3 = e3.slice()).splice(t3, 0, 1), e3;
    }
    function y2(e3, t3, n3 = null, r3 = true) {
      if (e3 < -t3 || e3 >= t3) {
        if (r3) throw new Error(`IndexError: index ${e3} is out of bounds for dimension${null === n3 ? "" : " " + n3} with size ${t3}`);
        return e3 < -t3 ? 0 : t3;
      }
      return e3 < 0 && (e3 = (e3 % t3 + t3) % t3), e3;
    }
    function M2(e3, t3 = 0) {
      t3 = y2(t3, e3[0].dims.length);
      const n3 = e3[0].dims.slice();
      n3[t3] = e3.reduce(((e4, n4) => e4 + n4.dims[t3]), 0);
      const r3 = n3.reduce(((e4, t4) => e4 * t4), 1), s3 = new e3[0].data.constructor(r3), a3 = e3[0].type;
      if (0 === t3) {
        let t4 = 0;
        for (const n4 of e3) {
          const e4 = n4.data;
          s3.set(e4, t4), t4 += e4.length;
        }
      } else {
        let r4 = 0;
        for (let a4 = 0; a4 < e3.length; ++a4) {
          const { data: o3, dims: i3 } = e3[a4];
          for (let e4 = 0; e4 < o3.length; ++e4) {
            let a5 = 0;
            for (let s4 = i3.length - 1, o4 = e4, l3 = 1; s4 >= 0; --s4) {
              const e5 = i3[s4];
              let d3 = o4 % e5;
              s4 === t3 && (d3 += r4), a5 += d3 * l3, l3 *= n3[s4], o4 = Math.floor(o4 / e5);
            }
            s3[a5] = o3[e4];
          }
          r4 += i3[t3];
        }
      }
      return new i2(a3, s3, n3);
    }
    function x2(e3, t3 = 0) {
      return M2(e3.map(((e4) => e4.unsqueeze(t3))), t3);
    }
    function v2(e3, t3, n3 = null, r3 = false, s3 = null) {
      const a3 = t3.data, o3 = t3.dims;
      n3 = y2(n3, o3.length);
      const i3 = o3.slice();
      i3[n3] = 1;
      const l3 = new a3.constructor(a3.length / o3[n3]);
      null !== s3 && l3.fill(s3);
      for (let t4 = 0; t4 < a3.length; ++t4) {
        let r4 = 0;
        for (let e4 = o3.length - 1, s4 = t4, a4 = 1; e4 >= 0; --e4) {
          const t5 = o3[e4];
          if (e4 !== n3) {
            r4 += s4 % t5 * a4, a4 *= i3[e4];
          }
          s4 = Math.floor(s4 / t5);
        }
        l3[r4] = e3(l3[r4], a3[t4], t4, r4);
      }
      return r3 || i3.splice(n3, 1), [t3.type, l3, i3];
    }
    function T2(e3, t3 = null, n3 = 1, r3 = false) {
      const s3 = e3.data, a3 = e3.dims;
      if (null === t3) {
        const t4 = s3.reduce(((e4, t5) => e4 + t5), 0) / s3.length, r4 = Math.sqrt(s3.reduce(((e4, n4) => e4 + (n4 - t4) ** 2), 0) / (s3.length - n3)), a4 = new i2(e3.type, [t4], []);
        return [new i2(e3.type, [r4], []), a4];
      }
      const o3 = k2(e3, t3 = y2(t3, a3.length), r3), l3 = o3.data, [d3, u3, c3] = v2(((e4, t4, n4, r4) => e4 + (t4 - l3[r4]) ** 2), e3, t3, r3);
      for (let e4 = 0; e4 < u3.length; ++e4) u3[e4] = Math.sqrt(u3[e4] / (a3[t3] - n3));
      return [new i2(d3, u3, c3), o3];
    }
    function k2(e3, t3 = null, n3 = false) {
      const r3 = e3.dims, s3 = e3.data;
      if (null === t3) {
        const t4 = s3.reduce(((e4, t5) => e4 + t5), 0);
        return new i2(e3.type, [t4 / s3.length], []);
      }
      t3 = y2(t3, r3.length);
      const [a3, o3, l3] = v2(((e4, t4) => e4 + t4), e3, t3, n3);
      if (1 !== r3[t3]) for (let e4 = 0; e4 < o3.length; ++e4) o3[e4] /= r3[t3];
      return new i2(a3, o3, l3);
    }
    function P2(e3, t3, n3, r3) {
      const s3 = e3.reduce(((e4, t4) => e4 * t4), 1);
      return new i2(n3, new r3(s3).fill(t3), e3);
    }
    function $2(e3, t3) {
      let n3, r3;
      if ("number" == typeof t3) n3 = "float32", r3 = Float32Array;
      else if ("bigint" == typeof t3) n3 = "int64", r3 = BigInt64Array;
      else {
        if ("boolean" != typeof t3) throw new Error("Unsupported data type: " + typeof t3);
        n3 = "bool", r3 = Uint8Array;
      }
      return P2(e3, t3, n3, r3);
    }
    function C2(e3, t3) {
      return $2(e3.dims, t3);
    }
    function S2(e3) {
      return P2(e3, 1n, "int64", BigInt64Array);
    }
    function F2(e3) {
      return S2(e3.dims);
    }
    function E2(e3) {
      return P2(e3, 0n, "int64", BigInt64Array);
    }
    function I2(e3) {
      return E2(e3.dims);
    }
    function A2(e3) {
      const t3 = e3.reduce(((e4, t4) => e4 * t4), 1);
      return new i2("float32", Float32Array.from({ length: t3 }, (() => Math.random())), e3);
    }
    function z2(e3) {
      const t3 = e3.reduce(((e4, t4) => e4 * t4), 1);
      return new i2("float32", Float32Array.from({ length: t3 }, (() => (function() {
        const e4 = 1 - Math.random(), t4 = 1 - Math.random();
        return Math.sqrt(-2 * Math.log(e4)) * Math.cos(2 * Math.PI * t4);
      })())), e3);
    }
    function L2(e3, t3) {
      if (2 !== e3.dims.length) throw new Error("The tensor must have 2 dimensions");
      if (e3.dims.at(-1) % 8 != 0) throw new Error("The last dimension of the tensor must be a multiple of 8");
      if (!["binary", "ubinary"].includes(t3)) throw new Error("The precision must be either 'binary' or 'ubinary'");
      const n3 = "binary" === t3, r3 = n3 ? "int8" : "uint8", s3 = n3 ? Int8Array : Uint8Array, a3 = e3.data, o3 = new s3(a3.length / 8);
      for (let e4 = 0; e4 < a3.length; ++e4) {
        const t4 = a3[e4] > 0 ? 1 : 0, r4 = Math.floor(e4 / 8), s4 = e4 % 8;
        o3[r4] |= t4 << 7 - s4, n3 && 0 === s4 && (o3[r4] -= 128);
      }
      return new i2(r3, o3, [e3.dims[0], e3.dims[1] / 8]);
    }
  }, "./src/utils/video.js": (e2, t2, n2) => {
    n2.r(t2), n2.d(t2, { RawVideo: () => o2, RawVideoFrame: () => a2, load_video: () => i2 });
    var r2 = n2("./src/utils/image.js"), s2 = n2("./src/env.js");
    class a2 {
      constructor(e3, t3) {
        this.image = e3, this.timestamp = t3;
      }
    }
    class o2 {
      constructor(e3, t3) {
        e3.length > 0 && e3[0] instanceof r2.RawImage && (e3 = e3.map(((n3, r3) => new a2(n3, (r3 + 1) / (e3.length + 1) * t3)))), this.frames = e3, this.duration = t3;
      }
      get width() {
        return this.frames[0].image.width;
      }
      get height() {
        return this.frames[0].image.height;
      }
      get fps() {
        return this.frames.length / this.duration;
      }
    }
    async function i2(e3, { num_frames: t3 = null, fps: n3 = null } = {}) {
      if (!s2.apis.IS_BROWSER_ENV) throw new Error("`load_video` is currently only supported in browser environments.");
      if (null == t3 && null == n3) throw new Error("Either num_frames or fps must be provided.");
      const i3 = [], l2 = document.createElement("video");
      if (l2.crossOrigin = "anonymous", l2.muted = true, "string" == typeof e3) l2.src = e3;
      else if (e3 instanceof Blob) l2.src = URL.createObjectURL(e3);
      else {
        if (!(e3 instanceof HTMLVideoElement)) throw new Error("Invalid URL or video element provided.");
        l2.src = e3.src;
      }
      if (await new Promise(((e4) => l2.onloadedmetadata = e4)), l2.seekable.start(0) === l2.seekable.end(0)) {
        const e4 = await fetch(l2.src), t4 = await e4.blob();
        l2.src = URL.createObjectURL(t4), await new Promise(((e5) => l2.onloadedmetadata = e5));
      }
      const d2 = l2.duration;
      let u2, c2;
      null != t3 ? (u2 = t3, c2 = 1 === t3 ? 0 : d2 / (t3 - 1)) : (c2 = 1 / n3, u2 = Math.floor(d2 / c2));
      let p2 = [];
      for (let e4 = 0; e4 < u2; ++e4) p2.push(1 === t3 ? d2 / 2 : e4 * c2);
      const m2 = document.createElement("canvas");
      m2.width = l2.videoWidth, m2.height = l2.videoHeight;
      const h2 = m2.getContext("2d", { willReadFrequently: true });
      for (const e4 of p2) {
        l2.currentTime = e4, await new Promise(((e5) => {
          l2.onseeked = e5;
        })), h2.drawImage(l2, 0, 0, m2.width, m2.height);
        const t4 = h2.getImageData(0, 0, m2.width, m2.height), n4 = new r2.RawImage(t4.data, m2.width, m2.height, 4), s3 = new a2(n4, e4);
        i3.push(s3);
      }
      return l2.remove(), new o2(i3, d2);
    }
  } };
  var r = {};
  function s(e2) {
    var t2 = r[e2];
    if (void 0 !== t2) return t2.exports;
    var a2 = r[e2] = { exports: {} };
    return n[e2](a2, a2.exports, s), a2.exports;
  }
  t = Object.getPrototypeOf ? (e2) => Object.getPrototypeOf(e2) : (e2) => e2.__proto__, s.t = function(n2, r2) {
    if (1 & r2 && (n2 = this(n2)), 8 & r2) return n2;
    if ("object" == typeof n2 && n2) {
      if (4 & r2 && n2.__esModule) return n2;
      if (16 & r2 && "function" == typeof n2.then) return n2;
    }
    var a2 = /* @__PURE__ */ Object.create(null);
    s.r(a2);
    var o2 = {};
    e = e || [null, t({}), t([]), t(t)];
    for (var i2 = 2 & r2 && n2; "object" == typeof i2 && !~e.indexOf(i2); i2 = t(i2)) Object.getOwnPropertyNames(i2).forEach(((e2) => o2[e2] = () => n2[e2]));
    return o2.default = () => n2, s.d(a2, o2), a2;
  }, s.d = (e2, t2) => {
    for (var n2 in t2) s.o(t2, n2) && !s.o(e2, n2) && Object.defineProperty(e2, n2, { enumerable: true, get: t2[n2] });
  }, s.o = (e2, t2) => Object.prototype.hasOwnProperty.call(e2, t2), s.r = (e2) => {
    "undefined" != typeof Symbol && Symbol.toStringTag && Object.defineProperty(e2, Symbol.toStringTag, { value: "Module" }), Object.defineProperty(e2, "__esModule", { value: true });
  }, (() => {
    var e2;
    if ("string" == typeof import_meta.url && (e2 = import_meta.url), !e2) throw new Error("Automatic publicPath is not supported in this browser");
    e2 = e2.replace(/#.*$/, "").replace(/\?.*$/, "").replace(/\/[^\/]+$/, "/"), s.p = e2;
  })(), s.b = void 0;
  var a = {};
  (() => {
    s.r(a), s.d(a, { ASTFeatureExtractor: () => m2.ASTFeatureExtractor, ASTForAudioClassification: () => n2.ASTForAudioClassification, ASTModel: () => n2.ASTModel, ASTPreTrainedModel: () => n2.ASTPreTrainedModel, AlbertForMaskedLM: () => n2.AlbertForMaskedLM, AlbertForQuestionAnswering: () => n2.AlbertForQuestionAnswering, AlbertForSequenceClassification: () => n2.AlbertForSequenceClassification, AlbertModel: () => n2.AlbertModel, AlbertPreTrainedModel: () => n2.AlbertPreTrainedModel, AlbertTokenizer: () => r2.AlbertTokenizer, ArceeForCausalLM: () => n2.ArceeForCausalLM, ArceeModel: () => n2.ArceeModel, ArceePreTrainedModel: () => n2.ArceePreTrainedModel, AudioClassificationPipeline: () => t2.AudioClassificationPipeline, AutoConfig: () => o2.AutoConfig, AutoFeatureExtractor: () => h2.AutoFeatureExtractor, AutoImageProcessor: () => g2.AutoImageProcessor, AutoModel: () => n2.AutoModel, AutoModelForAudioClassification: () => n2.AutoModelForAudioClassification, AutoModelForAudioFrameClassification: () => n2.AutoModelForAudioFrameClassification, AutoModelForAudioTextToText: () => n2.AutoModelForAudioTextToText, AutoModelForCTC: () => n2.AutoModelForCTC, AutoModelForCausalLM: () => n2.AutoModelForCausalLM, AutoModelForDepthEstimation: () => n2.AutoModelForDepthEstimation, AutoModelForDocumentQuestionAnswering: () => n2.AutoModelForDocumentQuestionAnswering, AutoModelForImageClassification: () => n2.AutoModelForImageClassification, AutoModelForImageFeatureExtraction: () => n2.AutoModelForImageFeatureExtraction, AutoModelForImageMatting: () => n2.AutoModelForImageMatting, AutoModelForImageSegmentation: () => n2.AutoModelForImageSegmentation, AutoModelForImageTextToText: () => n2.AutoModelForImageTextToText, AutoModelForImageToImage: () => n2.AutoModelForImageToImage, AutoModelForMaskGeneration: () => n2.AutoModelForMaskGeneration, AutoModelForMaskedLM: () => n2.AutoModelForMaskedLM, AutoModelForNormalEstimation: () => n2.AutoModelForNormalEstimation, AutoModelForObjectDetection: () => n2.AutoModelForObjectDetection, AutoModelForPoseEstimation: () => n2.AutoModelForPoseEstimation, AutoModelForQuestionAnswering: () => n2.AutoModelForQuestionAnswering, AutoModelForSemanticSegmentation: () => n2.AutoModelForSemanticSegmentation, AutoModelForSeq2SeqLM: () => n2.AutoModelForSeq2SeqLM, AutoModelForSequenceClassification: () => n2.AutoModelForSequenceClassification, AutoModelForSpeechSeq2Seq: () => n2.AutoModelForSpeechSeq2Seq, AutoModelForTextToSpectrogram: () => n2.AutoModelForTextToSpectrogram, AutoModelForTextToWaveform: () => n2.AutoModelForTextToWaveform, AutoModelForTokenClassification: () => n2.AutoModelForTokenClassification, AutoModelForUniversalSegmentation: () => n2.AutoModelForUniversalSegmentation, AutoModelForVision2Seq: () => n2.AutoModelForVision2Seq, AutoModelForXVector: () => n2.AutoModelForXVector, AutoModelForZeroShotObjectDetection: () => n2.AutoModelForZeroShotObjectDetection, AutoProcessor: () => y2.AutoProcessor, AutoTokenizer: () => r2.AutoTokenizer, AutomaticSpeechRecognitionPipeline: () => t2.AutomaticSpeechRecognitionPipeline, BackgroundRemovalPipeline: () => t2.BackgroundRemovalPipeline, BartForConditionalGeneration: () => n2.BartForConditionalGeneration, BartForSequenceClassification: () => n2.BartForSequenceClassification, BartModel: () => n2.BartModel, BartPretrainedModel: () => n2.BartPretrainedModel, BartTokenizer: () => r2.BartTokenizer, BaseModelOutput: () => n2.BaseModelOutput, BaseStreamer: () => M2.BaseStreamer, BeitFeatureExtractor: () => _2.BeitFeatureExtractor, BeitForImageClassification: () => n2.BeitForImageClassification, BeitModel: () => n2.BeitModel, BeitPreTrainedModel: () => n2.BeitPreTrainedModel, BertForMaskedLM: () => n2.BertForMaskedLM, BertForQuestionAnswering: () => n2.BertForQuestionAnswering, BertForSequenceClassification: () => n2.BertForSequenceClassification, BertForTokenClassification: () => n2.BertForTokenClassification, BertModel: () => n2.BertModel, BertPreTrainedModel: () => n2.BertPreTrainedModel, BertTokenizer: () => r2.BertTokenizer, BitImageProcessor: () => _2.BitImageProcessor, BlenderbotForConditionalGeneration: () => n2.BlenderbotForConditionalGeneration, BlenderbotModel: () => n2.BlenderbotModel, BlenderbotPreTrainedModel: () => n2.BlenderbotPreTrainedModel, BlenderbotSmallForConditionalGeneration: () => n2.BlenderbotSmallForConditionalGeneration, BlenderbotSmallModel: () => n2.BlenderbotSmallModel, BlenderbotSmallPreTrainedModel: () => n2.BlenderbotSmallPreTrainedModel, BlenderbotSmallTokenizer: () => r2.BlenderbotSmallTokenizer, BlenderbotTokenizer: () => r2.BlenderbotTokenizer, BloomForCausalLM: () => n2.BloomForCausalLM, BloomModel: () => n2.BloomModel, BloomPreTrainedModel: () => n2.BloomPreTrainedModel, BloomTokenizer: () => r2.BloomTokenizer, CLIPFeatureExtractor: () => _2.CLIPFeatureExtractor, CLIPImageProcessor: () => _2.CLIPImageProcessor, CLIPModel: () => n2.CLIPModel, CLIPPreTrainedModel: () => n2.CLIPPreTrainedModel, CLIPSegForImageSegmentation: () => n2.CLIPSegForImageSegmentation, CLIPSegModel: () => n2.CLIPSegModel, CLIPSegPreTrainedModel: () => n2.CLIPSegPreTrainedModel, CLIPTextModel: () => n2.CLIPTextModel, CLIPTextModelWithProjection: () => n2.CLIPTextModelWithProjection, CLIPTokenizer: () => r2.CLIPTokenizer, CLIPVisionModel: () => n2.CLIPVisionModel, CLIPVisionModelWithProjection: () => n2.CLIPVisionModelWithProjection, CamembertForMaskedLM: () => n2.CamembertForMaskedLM, CamembertForQuestionAnswering: () => n2.CamembertForQuestionAnswering, CamembertForSequenceClassification: () => n2.CamembertForSequenceClassification, CamembertForTokenClassification: () => n2.CamembertForTokenClassification, CamembertModel: () => n2.CamembertModel, CamembertPreTrainedModel: () => n2.CamembertPreTrainedModel, CamembertTokenizer: () => r2.CamembertTokenizer, CausalLMOutput: () => n2.CausalLMOutput, CausalLMOutputWithPast: () => n2.CausalLMOutputWithPast, ChineseCLIPFeatureExtractor: () => _2.ChineseCLIPFeatureExtractor, ChineseCLIPModel: () => n2.ChineseCLIPModel, ChineseCLIPPreTrainedModel: () => n2.ChineseCLIPPreTrainedModel, ClapAudioModelWithProjection: () => n2.ClapAudioModelWithProjection, ClapFeatureExtractor: () => m2.ClapFeatureExtractor, ClapModel: () => n2.ClapModel, ClapPreTrainedModel: () => n2.ClapPreTrainedModel, ClapTextModelWithProjection: () => n2.ClapTextModelWithProjection, ClassifierFreeGuidanceLogitsProcessor: () => v2.ClassifierFreeGuidanceLogitsProcessor, CodeGenForCausalLM: () => n2.CodeGenForCausalLM, CodeGenModel: () => n2.CodeGenModel, CodeGenPreTrainedModel: () => n2.CodeGenPreTrainedModel, CodeGenTokenizer: () => r2.CodeGenTokenizer, CodeLlamaTokenizer: () => r2.CodeLlamaTokenizer, CohereForCausalLM: () => n2.CohereForCausalLM, CohereModel: () => n2.CohereModel, CoherePreTrainedModel: () => n2.CoherePreTrainedModel, CohereTokenizer: () => r2.CohereTokenizer, ConvBertForMaskedLM: () => n2.ConvBertForMaskedLM, ConvBertForQuestionAnswering: () => n2.ConvBertForQuestionAnswering, ConvBertForSequenceClassification: () => n2.ConvBertForSequenceClassification, ConvBertForTokenClassification: () => n2.ConvBertForTokenClassification, ConvBertModel: () => n2.ConvBertModel, ConvBertPreTrainedModel: () => n2.ConvBertPreTrainedModel, ConvBertTokenizer: () => r2.ConvBertTokenizer, ConvNextFeatureExtractor: () => _2.ConvNextFeatureExtractor, ConvNextForImageClassification: () => n2.ConvNextForImageClassification, ConvNextImageProcessor: () => _2.ConvNextImageProcessor, ConvNextModel: () => n2.ConvNextModel, ConvNextPreTrainedModel: () => n2.ConvNextPreTrainedModel, ConvNextV2ForImageClassification: () => n2.ConvNextV2ForImageClassification, ConvNextV2Model: () => n2.ConvNextV2Model, ConvNextV2PreTrainedModel: () => n2.ConvNextV2PreTrainedModel, DFineForObjectDetection: () => n2.DFineForObjectDetection, DFineModel: () => n2.DFineModel, DFinePreTrainedModel: () => n2.DFinePreTrainedModel, DINOv3ConvNextModel: () => n2.DINOv3ConvNextModel, DINOv3ConvNextPreTrainedModel: () => n2.DINOv3ConvNextPreTrainedModel, DINOv3ViTImageProcessor: () => _2.DINOv3ViTImageProcessor, DINOv3ViTModel: () => n2.DINOv3ViTModel, DINOv3ViTPreTrainedModel: () => n2.DINOv3ViTPreTrainedModel, DPTFeatureExtractor: () => _2.DPTFeatureExtractor, DPTForDepthEstimation: () => n2.DPTForDepthEstimation, DPTImageProcessor: () => _2.DPTImageProcessor, DPTModel: () => n2.DPTModel, DPTPreTrainedModel: () => n2.DPTPreTrainedModel, DacDecoderModel: () => n2.DacDecoderModel, DacDecoderOutput: () => n2.DacDecoderOutput, DacEncoderModel: () => n2.DacEncoderModel, DacEncoderOutput: () => n2.DacEncoderOutput, DacFeatureExtractor: () => m2.DacFeatureExtractor, DacModel: () => n2.DacModel, DacPreTrainedModel: () => n2.DacPreTrainedModel, DataTypeMap: () => u2.DataTypeMap, DebertaForMaskedLM: () => n2.DebertaForMaskedLM, DebertaForQuestionAnswering: () => n2.DebertaForQuestionAnswering, DebertaForSequenceClassification: () => n2.DebertaForSequenceClassification, DebertaForTokenClassification: () => n2.DebertaForTokenClassification, DebertaModel: () => n2.DebertaModel, DebertaPreTrainedModel: () => n2.DebertaPreTrainedModel, DebertaTokenizer: () => r2.DebertaTokenizer, DebertaV2ForMaskedLM: () => n2.DebertaV2ForMaskedLM, DebertaV2ForQuestionAnswering: () => n2.DebertaV2ForQuestionAnswering, DebertaV2ForSequenceClassification: () => n2.DebertaV2ForSequenceClassification, DebertaV2ForTokenClassification: () => n2.DebertaV2ForTokenClassification, DebertaV2Model: () => n2.DebertaV2Model, DebertaV2PreTrainedModel: () => n2.DebertaV2PreTrainedModel, DebertaV2Tokenizer: () => r2.DebertaV2Tokenizer, DecisionTransformerModel: () => n2.DecisionTransformerModel, DecisionTransformerPreTrainedModel: () => n2.DecisionTransformerPreTrainedModel, DeiTFeatureExtractor: () => _2.DeiTFeatureExtractor, DeiTForImageClassification: () => n2.DeiTForImageClassification, DeiTImageProcessor: () => _2.DeiTImageProcessor, DeiTModel: () => n2.DeiTModel, DeiTPreTrainedModel: () => n2.DeiTPreTrainedModel, DepthAnythingForDepthEstimation: () => n2.DepthAnythingForDepthEstimation, DepthAnythingPreTrainedModel: () => n2.DepthAnythingPreTrainedModel, DepthEstimationPipeline: () => t2.DepthEstimationPipeline, DepthProForDepthEstimation: () => n2.DepthProForDepthEstimation, DepthProPreTrainedModel: () => n2.DepthProPreTrainedModel, DetrFeatureExtractor: () => _2.DetrFeatureExtractor, DetrForObjectDetection: () => n2.DetrForObjectDetection, DetrForSegmentation: () => n2.DetrForSegmentation, DetrImageProcessor: () => _2.DetrImageProcessor, DetrModel: () => n2.DetrModel, DetrObjectDetectionOutput: () => n2.DetrObjectDetectionOutput, DetrPreTrainedModel: () => n2.DetrPreTrainedModel, DetrSegmentationOutput: () => n2.DetrSegmentationOutput, Dinov2ForImageClassification: () => n2.Dinov2ForImageClassification, Dinov2Model: () => n2.Dinov2Model, Dinov2PreTrainedModel: () => n2.Dinov2PreTrainedModel, Dinov2WithRegistersForImageClassification: () => n2.Dinov2WithRegistersForImageClassification, Dinov2WithRegistersModel: () => n2.Dinov2WithRegistersModel, Dinov2WithRegistersPreTrainedModel: () => n2.Dinov2WithRegistersPreTrainedModel, DistilBertForMaskedLM: () => n2.DistilBertForMaskedLM, DistilBertForQuestionAnswering: () => n2.DistilBertForQuestionAnswering, DistilBertForSequenceClassification: () => n2.DistilBertForSequenceClassification, DistilBertForTokenClassification: () => n2.DistilBertForTokenClassification, DistilBertModel: () => n2.DistilBertModel, DistilBertPreTrainedModel: () => n2.DistilBertPreTrainedModel, DistilBertTokenizer: () => r2.DistilBertTokenizer, DocumentQuestionAnsweringPipeline: () => t2.DocumentQuestionAnsweringPipeline, DonutFeatureExtractor: () => _2.DonutFeatureExtractor, DonutImageProcessor: () => _2.DonutImageProcessor, DonutSwinModel: () => n2.DonutSwinModel, DonutSwinPreTrainedModel: () => n2.DonutSwinPreTrainedModel, EdgeTamModel: () => n2.EdgeTamModel, EfficientNetForImageClassification: () => n2.EfficientNetForImageClassification, EfficientNetImageProcessor: () => _2.EfficientNetImageProcessor, EfficientNetModel: () => n2.EfficientNetModel, EfficientNetPreTrainedModel: () => n2.EfficientNetPreTrainedModel, ElectraForMaskedLM: () => n2.ElectraForMaskedLM, ElectraForQuestionAnswering: () => n2.ElectraForQuestionAnswering, ElectraForSequenceClassification: () => n2.ElectraForSequenceClassification, ElectraForTokenClassification: () => n2.ElectraForTokenClassification, ElectraModel: () => n2.ElectraModel, ElectraPreTrainedModel: () => n2.ElectraPreTrainedModel, ElectraTokenizer: () => r2.ElectraTokenizer, EncodecFeatureExtractor: () => m2.EncodecFeatureExtractor, EosTokenCriteria: () => x2.EosTokenCriteria, Ernie4_5_ForCausalLM: () => n2.Ernie4_5_ForCausalLM, Ernie4_5_Model: () => n2.Ernie4_5_Model, Ernie4_5_PretrainedModel: () => n2.Ernie4_5_PretrainedModel, Ernie4_5_Tokenizer: () => r2.Ernie4_5_Tokenizer, EsmForMaskedLM: () => n2.EsmForMaskedLM, EsmForSequenceClassification: () => n2.EsmForSequenceClassification, EsmForTokenClassification: () => n2.EsmForTokenClassification, EsmModel: () => n2.EsmModel, EsmPreTrainedModel: () => n2.EsmPreTrainedModel, EsmTokenizer: () => r2.EsmTokenizer, ExaoneForCausalLM: () => n2.ExaoneForCausalLM, ExaoneModel: () => n2.ExaoneModel, ExaonePreTrainedModel: () => n2.ExaonePreTrainedModel, FFT: () => c2.FFT, FalconForCausalLM: () => n2.FalconForCausalLM, FalconModel: () => n2.FalconModel, FalconPreTrainedModel: () => n2.FalconPreTrainedModel, FalconTokenizer: () => r2.FalconTokenizer, FastViTForImageClassification: () => n2.FastViTForImageClassification, FastViTModel: () => n2.FastViTModel, FastViTPreTrainedModel: () => n2.FastViTPreTrainedModel, FeatureExtractionPipeline: () => t2.FeatureExtractionPipeline, FeatureExtractor: () => p2.FeatureExtractor, FillMaskPipeline: () => t2.FillMaskPipeline, Florence2ForConditionalGeneration: () => n2.Florence2ForConditionalGeneration, Florence2PreTrainedModel: () => n2.Florence2PreTrainedModel, Florence2Processor: () => b2.Florence2Processor, ForcedBOSTokenLogitsProcessor: () => v2.ForcedBOSTokenLogitsProcessor, ForcedEOSTokenLogitsProcessor: () => v2.ForcedEOSTokenLogitsProcessor, GLPNFeatureExtractor: () => _2.GLPNFeatureExtractor, GLPNForDepthEstimation: () => n2.GLPNForDepthEstimation, GLPNModel: () => n2.GLPNModel, GLPNPreTrainedModel: () => n2.GLPNPreTrainedModel, GPT2LMHeadModel: () => n2.GPT2LMHeadModel, GPT2Model: () => n2.GPT2Model, GPT2PreTrainedModel: () => n2.GPT2PreTrainedModel, GPT2Tokenizer: () => r2.GPT2Tokenizer, GPTBigCodeForCausalLM: () => n2.GPTBigCodeForCausalLM, GPTBigCodeModel: () => n2.GPTBigCodeModel, GPTBigCodePreTrainedModel: () => n2.GPTBigCodePreTrainedModel, GPTJForCausalLM: () => n2.GPTJForCausalLM, GPTJModel: () => n2.GPTJModel, GPTJPreTrainedModel: () => n2.GPTJPreTrainedModel, GPTNeoForCausalLM: () => n2.GPTNeoForCausalLM, GPTNeoModel: () => n2.GPTNeoModel, GPTNeoPreTrainedModel: () => n2.GPTNeoPreTrainedModel, GPTNeoXForCausalLM: () => n2.GPTNeoXForCausalLM, GPTNeoXModel: () => n2.GPTNeoXModel, GPTNeoXPreTrainedModel: () => n2.GPTNeoXPreTrainedModel, GPTNeoXTokenizer: () => r2.GPTNeoXTokenizer, Gemma2ForCausalLM: () => n2.Gemma2ForCausalLM, Gemma2Model: () => n2.Gemma2Model, Gemma2PreTrainedModel: () => n2.Gemma2PreTrainedModel, Gemma3ForCausalLM: () => n2.Gemma3ForCausalLM, Gemma3Model: () => n2.Gemma3Model, Gemma3PreTrainedModel: () => n2.Gemma3PreTrainedModel, Gemma3nAudioFeatureExtractor: () => m2.Gemma3nAudioFeatureExtractor, Gemma3nForConditionalGeneration: () => n2.Gemma3nForConditionalGeneration, Gemma3nPreTrainedModel: () => n2.Gemma3nPreTrainedModel, Gemma3nProcessor: () => b2.Gemma3nProcessor, GemmaForCausalLM: () => n2.GemmaForCausalLM, GemmaModel: () => n2.GemmaModel, GemmaPreTrainedModel: () => n2.GemmaPreTrainedModel, GemmaTokenizer: () => r2.GemmaTokenizer, GlmForCausalLM: () => n2.GlmForCausalLM, GlmModel: () => n2.GlmModel, GlmPreTrainedModel: () => n2.GlmPreTrainedModel, GraniteForCausalLM: () => n2.GraniteForCausalLM, GraniteModel: () => n2.GraniteModel, GraniteMoeHybridForCausalLM: () => n2.GraniteMoeHybridForCausalLM, GraniteMoeHybridModel: () => n2.GraniteMoeHybridModel, GraniteMoeHybridPreTrainedModel: () => n2.GraniteMoeHybridPreTrainedModel, GranitePreTrainedModel: () => n2.GranitePreTrainedModel, Grok1Tokenizer: () => r2.Grok1Tokenizer, GroundingDinoForObjectDetection: () => n2.GroundingDinoForObjectDetection, GroundingDinoImageProcessor: () => _2.GroundingDinoImageProcessor, GroundingDinoPreTrainedModel: () => n2.GroundingDinoPreTrainedModel, GroundingDinoProcessor: () => b2.GroundingDinoProcessor, GroupViTModel: () => n2.GroupViTModel, GroupViTPreTrainedModel: () => n2.GroupViTPreTrainedModel, HeliumForCausalLM: () => n2.HeliumForCausalLM, HeliumModel: () => n2.HeliumModel, HeliumPreTrainedModel: () => n2.HeliumPreTrainedModel, HerbertTokenizer: () => r2.HerbertTokenizer, HieraForImageClassification: () => n2.HieraForImageClassification, HieraModel: () => n2.HieraModel, HieraPreTrainedModel: () => n2.HieraPreTrainedModel, HubertForCTC: () => n2.HubertForCTC, HubertForSequenceClassification: () => n2.HubertForSequenceClassification, HubertModel: () => n2.HubertModel, HubertPreTrainedModel: () => n2.HubertPreTrainedModel, IJepaForImageClassification: () => n2.IJepaForImageClassification, IJepaModel: () => n2.IJepaModel, IJepaPreTrainedModel: () => n2.IJepaPreTrainedModel, Idefics3ForConditionalGeneration: () => n2.Idefics3ForConditionalGeneration, Idefics3ImageProcessor: () => _2.Idefics3ImageProcessor, Idefics3PreTrainedModel: () => n2.Idefics3PreTrainedModel, Idefics3Processor: () => b2.Idefics3Processor, ImageClassificationPipeline: () => t2.ImageClassificationPipeline, ImageFeatureExtractionPipeline: () => t2.ImageFeatureExtractionPipeline, ImageFeatureExtractor: () => m2.ImageFeatureExtractor, ImageMattingOutput: () => n2.ImageMattingOutput, ImageProcessor: () => f2.ImageProcessor, ImageSegmentationPipeline: () => t2.ImageSegmentationPipeline, ImageToImagePipeline: () => t2.ImageToImagePipeline, ImageToTextPipeline: () => t2.ImageToTextPipeline, InterruptableStoppingCriteria: () => x2.InterruptableStoppingCriteria, JAISLMHeadModel: () => n2.JAISLMHeadModel, JAISModel: () => n2.JAISModel, JAISPreTrainedModel: () => n2.JAISPreTrainedModel, JinaCLIPImageProcessor: () => _2.JinaCLIPImageProcessor, JinaCLIPModel: () => n2.JinaCLIPModel, JinaCLIPPreTrainedModel: () => n2.JinaCLIPPreTrainedModel, JinaCLIPProcessor: () => b2.JinaCLIPProcessor, JinaCLIPTextModel: () => n2.JinaCLIPTextModel, JinaCLIPVisionModel: () => n2.JinaCLIPVisionModel, Lfm2ForCausalLM: () => n2.Lfm2ForCausalLM, Lfm2Model: () => n2.Lfm2Model, Lfm2PreTrainedModel: () => n2.Lfm2PreTrainedModel, LiteWhisperForConditionalGeneration: () => n2.LiteWhisperForConditionalGeneration, Llama4ForCausalLM: () => n2.Llama4ForCausalLM, Llama4PreTrainedModel: () => n2.Llama4PreTrainedModel, LlamaForCausalLM: () => n2.LlamaForCausalLM, LlamaModel: () => n2.LlamaModel, LlamaPreTrainedModel: () => n2.LlamaPreTrainedModel, LlamaTokenizer: () => r2.LlamaTokenizer, LlavaForConditionalGeneration: () => n2.LlavaForConditionalGeneration, LlavaOnevisionForConditionalGeneration: () => n2.LlavaOnevisionForConditionalGeneration, LlavaOnevisionImageProcessor: () => _2.LlavaOnevisionImageProcessor, LlavaPreTrainedModel: () => n2.LlavaPreTrainedModel, LlavaProcessor: () => b2.LlavaProcessor, LlavaQwen2ForCausalLM: () => n2.LlavaQwen2ForCausalLM, LogitsProcessor: () => v2.LogitsProcessor, LogitsProcessorList: () => v2.LogitsProcessorList, LogitsWarper: () => v2.LogitsWarper, LongT5ForConditionalGeneration: () => n2.LongT5ForConditionalGeneration, LongT5Model: () => n2.LongT5Model, LongT5PreTrainedModel: () => n2.LongT5PreTrainedModel, M2M100ForConditionalGeneration: () => n2.M2M100ForConditionalGeneration, M2M100Model: () => n2.M2M100Model, M2M100PreTrainedModel: () => n2.M2M100PreTrainedModel, M2M100Tokenizer: () => r2.M2M100Tokenizer, MBart50Tokenizer: () => r2.MBart50Tokenizer, MBartForCausalLM: () => n2.MBartForCausalLM, MBartForConditionalGeneration: () => n2.MBartForConditionalGeneration, MBartForSequenceClassification: () => n2.MBartForSequenceClassification, MBartModel: () => n2.MBartModel, MBartPreTrainedModel: () => n2.MBartPreTrainedModel, MBartTokenizer: () => r2.MBartTokenizer, MPNetForMaskedLM: () => n2.MPNetForMaskedLM, MPNetForQuestionAnswering: () => n2.MPNetForQuestionAnswering, MPNetForSequenceClassification: () => n2.MPNetForSequenceClassification, MPNetForTokenClassification: () => n2.MPNetForTokenClassification, MPNetModel: () => n2.MPNetModel, MPNetPreTrainedModel: () => n2.MPNetPreTrainedModel, MPNetTokenizer: () => r2.MPNetTokenizer, MT5ForConditionalGeneration: () => n2.MT5ForConditionalGeneration, MT5Model: () => n2.MT5Model, MT5PreTrainedModel: () => n2.MT5PreTrainedModel, MarianMTModel: () => n2.MarianMTModel, MarianModel: () => n2.MarianModel, MarianPreTrainedModel: () => n2.MarianPreTrainedModel, MarianTokenizer: () => r2.MarianTokenizer, Mask2FormerImageProcessor: () => _2.Mask2FormerImageProcessor, MaskFormerFeatureExtractor: () => _2.MaskFormerFeatureExtractor, MaskFormerForInstanceSegmentation: () => n2.MaskFormerForInstanceSegmentation, MaskFormerImageProcessor: () => _2.MaskFormerImageProcessor, MaskFormerModel: () => n2.MaskFormerModel, MaskFormerPreTrainedModel: () => n2.MaskFormerPreTrainedModel, MaskedLMOutput: () => n2.MaskedLMOutput, MaxLengthCriteria: () => x2.MaxLengthCriteria, Metric3DForDepthEstimation: () => n2.Metric3DForDepthEstimation, Metric3DPreTrainedModel: () => n2.Metric3DPreTrainedModel, Metric3Dv2ForDepthEstimation: () => n2.Metric3Dv2ForDepthEstimation, Metric3Dv2PreTrainedModel: () => n2.Metric3Dv2PreTrainedModel, MgpstrForSceneTextRecognition: () => n2.MgpstrForSceneTextRecognition, MgpstrModelOutput: () => n2.MgpstrModelOutput, MgpstrPreTrainedModel: () => n2.MgpstrPreTrainedModel, MgpstrProcessor: () => b2.MgpstrProcessor, MgpstrTokenizer: () => r2.MgpstrTokenizer, MimiDecoderModel: () => n2.MimiDecoderModel, MimiDecoderOutput: () => n2.MimiDecoderOutput, MimiEncoderModel: () => n2.MimiEncoderModel, MimiEncoderOutput: () => n2.MimiEncoderOutput, MimiModel: () => n2.MimiModel, MimiPreTrainedModel: () => n2.MimiPreTrainedModel, MinLengthLogitsProcessor: () => v2.MinLengthLogitsProcessor, MinNewTokensLengthLogitsProcessor: () => v2.MinNewTokensLengthLogitsProcessor, MistralForCausalLM: () => n2.MistralForCausalLM, MistralModel: () => n2.MistralModel, MistralPreTrainedModel: () => n2.MistralPreTrainedModel, MobileBertForMaskedLM: () => n2.MobileBertForMaskedLM, MobileBertForQuestionAnswering: () => n2.MobileBertForQuestionAnswering, MobileBertForSequenceClassification: () => n2.MobileBertForSequenceClassification, MobileBertModel: () => n2.MobileBertModel, MobileBertPreTrainedModel: () => n2.MobileBertPreTrainedModel, MobileBertTokenizer: () => r2.MobileBertTokenizer, MobileLLMForCausalLM: () => n2.MobileLLMForCausalLM, MobileLLMModel: () => n2.MobileLLMModel, MobileLLMPreTrainedModel: () => n2.MobileLLMPreTrainedModel, MobileNetV1FeatureExtractor: () => _2.MobileNetV1FeatureExtractor, MobileNetV1ForImageClassification: () => n2.MobileNetV1ForImageClassification, MobileNetV1ForSemanticSegmentation: () => n2.MobileNetV1ForSemanticSegmentation, MobileNetV1ImageProcessor: () => _2.MobileNetV1ImageProcessor, MobileNetV1Model: () => n2.MobileNetV1Model, MobileNetV1PreTrainedModel: () => n2.MobileNetV1PreTrainedModel, MobileNetV2FeatureExtractor: () => _2.MobileNetV2FeatureExtractor, MobileNetV2ForImageClassification: () => n2.MobileNetV2ForImageClassification, MobileNetV2ForSemanticSegmentation: () => n2.MobileNetV2ForSemanticSegmentation, MobileNetV2ImageProcessor: () => _2.MobileNetV2ImageProcessor, MobileNetV2Model: () => n2.MobileNetV2Model, MobileNetV2PreTrainedModel: () => n2.MobileNetV2PreTrainedModel, MobileNetV3FeatureExtractor: () => _2.MobileNetV3FeatureExtractor, MobileNetV3ForImageClassification: () => n2.MobileNetV3ForImageClassification, MobileNetV3ForSemanticSegmentation: () => n2.MobileNetV3ForSemanticSegmentation, MobileNetV3ImageProcessor: () => _2.MobileNetV3ImageProcessor, MobileNetV3Model: () => n2.MobileNetV3Model, MobileNetV3PreTrainedModel: () => n2.MobileNetV3PreTrainedModel, MobileNetV4FeatureExtractor: () => _2.MobileNetV4FeatureExtractor, MobileNetV4ForImageClassification: () => n2.MobileNetV4ForImageClassification, MobileNetV4ForSemanticSegmentation: () => n2.MobileNetV4ForSemanticSegmentation, MobileNetV4ImageProcessor: () => _2.MobileNetV4ImageProcessor, MobileNetV4Model: () => n2.MobileNetV4Model, MobileNetV4PreTrainedModel: () => n2.MobileNetV4PreTrainedModel, MobileViTFeatureExtractor: () => _2.MobileViTFeatureExtractor, MobileViTForImageClassification: () => n2.MobileViTForImageClassification, MobileViTImageProcessor: () => _2.MobileViTImageProcessor, MobileViTModel: () => n2.MobileViTModel, MobileViTPreTrainedModel: () => n2.MobileViTPreTrainedModel, MobileViTV2ForImageClassification: () => n2.MobileViTV2ForImageClassification, MobileViTV2Model: () => n2.MobileViTV2Model, MobileViTV2PreTrainedModel: () => n2.MobileViTV2PreTrainedModel, ModelOutput: () => n2.ModelOutput, ModernBertDecoderForCausalLM: () => n2.ModernBertDecoderForCausalLM, ModernBertDecoderModel: () => n2.ModernBertDecoderModel, ModernBertDecoderPreTrainedModel: () => n2.ModernBertDecoderPreTrainedModel, ModernBertForMaskedLM: () => n2.ModernBertForMaskedLM, ModernBertForSequenceClassification: () => n2.ModernBertForSequenceClassification, ModernBertForTokenClassification: () => n2.ModernBertForTokenClassification, ModernBertModel: () => n2.ModernBertModel, ModernBertPreTrainedModel: () => n2.ModernBertPreTrainedModel, Moondream1ForConditionalGeneration: () => n2.Moondream1ForConditionalGeneration, MoonshineFeatureExtractor: () => m2.MoonshineFeatureExtractor, MoonshineForConditionalGeneration: () => n2.MoonshineForConditionalGeneration, MoonshineModel: () => n2.MoonshineModel, MoonshinePreTrainedModel: () => n2.MoonshinePreTrainedModel, MoonshineProcessor: () => b2.MoonshineProcessor, MptForCausalLM: () => n2.MptForCausalLM, MptModel: () => n2.MptModel, MptPreTrainedModel: () => n2.MptPreTrainedModel, MultiModalityCausalLM: () => n2.MultiModalityCausalLM, MultiModalityPreTrainedModel: () => n2.MultiModalityPreTrainedModel, MusicgenForCausalLM: () => n2.MusicgenForCausalLM, MusicgenForConditionalGeneration: () => n2.MusicgenForConditionalGeneration, MusicgenModel: () => n2.MusicgenModel, MusicgenPreTrainedModel: () => n2.MusicgenPreTrainedModel, NanoChatForCausalLM: () => n2.NanoChatForCausalLM, NanoChatModel: () => n2.NanoChatModel, NanoChatPreTrainedModel: () => n2.NanoChatPreTrainedModel, NeoBertForMaskedLM: () => n2.NeoBertForMaskedLM, NeoBertForQuestionAnswering: () => n2.NeoBertForQuestionAnswering, NeoBertForSequenceClassification: () => n2.NeoBertForSequenceClassification, NeoBertForTokenClassification: () => n2.NeoBertForTokenClassification, NeoBertModel: () => n2.NeoBertModel, NeoBertPreTrainedModel: () => n2.NeoBertPreTrainedModel, NllbTokenizer: () => r2.NllbTokenizer, NoBadWordsLogitsProcessor: () => v2.NoBadWordsLogitsProcessor, NoRepeatNGramLogitsProcessor: () => v2.NoRepeatNGramLogitsProcessor, NomicBertModel: () => n2.NomicBertModel, NomicBertPreTrainedModel: () => n2.NomicBertPreTrainedModel, NougatImageProcessor: () => _2.NougatImageProcessor, NougatTokenizer: () => r2.NougatTokenizer, OPTForCausalLM: () => n2.OPTForCausalLM, OPTModel: () => n2.OPTModel, OPTPreTrainedModel: () => n2.OPTPreTrainedModel, ObjectDetectionPipeline: () => t2.ObjectDetectionPipeline, Olmo2ForCausalLM: () => n2.Olmo2ForCausalLM, Olmo2Model: () => n2.Olmo2Model, Olmo2PreTrainedModel: () => n2.Olmo2PreTrainedModel, OlmoForCausalLM: () => n2.OlmoForCausalLM, OlmoModel: () => n2.OlmoModel, OlmoPreTrainedModel: () => n2.OlmoPreTrainedModel, OpenELMForCausalLM: () => n2.OpenELMForCausalLM, OpenELMModel: () => n2.OpenELMModel, OpenELMPreTrainedModel: () => n2.OpenELMPreTrainedModel, OwlViTFeatureExtractor: () => _2.OwlViTFeatureExtractor, OwlViTForObjectDetection: () => n2.OwlViTForObjectDetection, OwlViTImageProcessor: () => _2.OwlViTImageProcessor, OwlViTModel: () => n2.OwlViTModel, OwlViTPreTrainedModel: () => n2.OwlViTPreTrainedModel, OwlViTProcessor: () => b2.OwlViTProcessor, Owlv2ForObjectDetection: () => n2.Owlv2ForObjectDetection, Owlv2ImageProcessor: () => _2.Owlv2ImageProcessor, Owlv2Model: () => n2.Owlv2Model, Owlv2PreTrainedModel: () => n2.Owlv2PreTrainedModel, PaliGemmaForConditionalGeneration: () => n2.PaliGemmaForConditionalGeneration, PaliGemmaPreTrainedModel: () => n2.PaliGemmaPreTrainedModel, PaliGemmaProcessor: () => b2.PaliGemmaProcessor, ParakeetFeatureExtractor: () => m2.ParakeetFeatureExtractor, ParakeetForCTC: () => n2.ParakeetForCTC, ParakeetPreTrainedModel: () => n2.ParakeetPreTrainedModel, PatchTSMixerForPrediction: () => n2.PatchTSMixerForPrediction, PatchTSMixerModel: () => n2.PatchTSMixerModel, PatchTSMixerPreTrainedModel: () => n2.PatchTSMixerPreTrainedModel, PatchTSTForPrediction: () => n2.PatchTSTForPrediction, PatchTSTModel: () => n2.PatchTSTModel, PatchTSTPreTrainedModel: () => n2.PatchTSTPreTrainedModel, Phi3ForCausalLM: () => n2.Phi3ForCausalLM, Phi3Model: () => n2.Phi3Model, Phi3PreTrainedModel: () => n2.Phi3PreTrainedModel, Phi3VForCausalLM: () => n2.Phi3VForCausalLM, Phi3VImageProcessor: () => _2.Phi3VImageProcessor, Phi3VPreTrainedModel: () => n2.Phi3VPreTrainedModel, Phi3VProcessor: () => b2.Phi3VProcessor, PhiForCausalLM: () => n2.PhiForCausalLM, PhiModel: () => n2.PhiModel, PhiPreTrainedModel: () => n2.PhiPreTrainedModel, Pipeline: () => t2.Pipeline, PreTrainedModel: () => n2.PreTrainedModel, PreTrainedTokenizer: () => r2.PreTrainedTokenizer, PretrainedConfig: () => o2.PretrainedConfig, PretrainedMixin: () => n2.PretrainedMixin, Processor: () => w2.Processor, PvtForImageClassification: () => n2.PvtForImageClassification, PvtImageProcessor: () => _2.PvtImageProcessor, PvtModel: () => n2.PvtModel, PvtPreTrainedModel: () => n2.PvtPreTrainedModel, PyAnnoteFeatureExtractor: () => m2.PyAnnoteFeatureExtractor, PyAnnoteForAudioFrameClassification: () => n2.PyAnnoteForAudioFrameClassification, PyAnnoteModel: () => n2.PyAnnoteModel, PyAnnotePreTrainedModel: () => n2.PyAnnotePreTrainedModel, PyAnnoteProcessor: () => b2.PyAnnoteProcessor, QuestionAnsweringModelOutput: () => n2.QuestionAnsweringModelOutput, QuestionAnsweringPipeline: () => t2.QuestionAnsweringPipeline, Qwen2ForCausalLM: () => n2.Qwen2ForCausalLM, Qwen2Model: () => n2.Qwen2Model, Qwen2PreTrainedModel: () => n2.Qwen2PreTrainedModel, Qwen2Tokenizer: () => r2.Qwen2Tokenizer, Qwen2VLForConditionalGeneration: () => n2.Qwen2VLForConditionalGeneration, Qwen2VLImageProcessor: () => _2.Qwen2VLImageProcessor, Qwen2VLPreTrainedModel: () => n2.Qwen2VLPreTrainedModel, Qwen2VLProcessor: () => b2.Qwen2VLProcessor, Qwen3ForCausalLM: () => n2.Qwen3ForCausalLM, Qwen3Model: () => n2.Qwen3Model, Qwen3PreTrainedModel: () => n2.Qwen3PreTrainedModel, RFDetrForObjectDetection: () => n2.RFDetrForObjectDetection, RFDetrModel: () => n2.RFDetrModel, RFDetrObjectDetectionOutput: () => n2.RFDetrObjectDetectionOutput, RFDetrPreTrainedModel: () => n2.RFDetrPreTrainedModel, RTDetrForObjectDetection: () => n2.RTDetrForObjectDetection, RTDetrImageProcessor: () => _2.RTDetrImageProcessor, RTDetrModel: () => n2.RTDetrModel, RTDetrObjectDetectionOutput: () => n2.RTDetrObjectDetectionOutput, RTDetrPreTrainedModel: () => n2.RTDetrPreTrainedModel, RTDetrV2ForObjectDetection: () => n2.RTDetrV2ForObjectDetection, RTDetrV2Model: () => n2.RTDetrV2Model, RTDetrV2ObjectDetectionOutput: () => n2.RTDetrV2ObjectDetectionOutput, RTDetrV2PreTrainedModel: () => n2.RTDetrV2PreTrainedModel, RawAudio: () => i2.RawAudio, RawImage: () => l2.RawImage, RawVideo: () => d2.RawVideo, RawVideoFrame: () => d2.RawVideoFrame, RepetitionPenaltyLogitsProcessor: () => v2.RepetitionPenaltyLogitsProcessor, ResNetForImageClassification: () => n2.ResNetForImageClassification, ResNetModel: () => n2.ResNetModel, ResNetPreTrainedModel: () => n2.ResNetPreTrainedModel, RoFormerForMaskedLM: () => n2.RoFormerForMaskedLM, RoFormerForQuestionAnswering: () => n2.RoFormerForQuestionAnswering, RoFormerForSequenceClassification: () => n2.RoFormerForSequenceClassification, RoFormerForTokenClassification: () => n2.RoFormerForTokenClassification, RoFormerModel: () => n2.RoFormerModel, RoFormerPreTrainedModel: () => n2.RoFormerPreTrainedModel, RoFormerTokenizer: () => r2.RoFormerTokenizer, RobertaForMaskedLM: () => n2.RobertaForMaskedLM, RobertaForQuestionAnswering: () => n2.RobertaForQuestionAnswering, RobertaForSequenceClassification: () => n2.RobertaForSequenceClassification, RobertaForTokenClassification: () => n2.RobertaForTokenClassification, RobertaModel: () => n2.RobertaModel, RobertaPreTrainedModel: () => n2.RobertaPreTrainedModel, RobertaTokenizer: () => r2.RobertaTokenizer, Sam2ImageProcessor: () => _2.Sam2ImageProcessor, Sam2ImageSegmentationOutput: () => n2.Sam2ImageSegmentationOutput, Sam2Model: () => n2.Sam2Model, Sam2PreTrainedModel: () => n2.Sam2PreTrainedModel, Sam2Processor: () => b2.Sam2Processor, Sam2VideoProcessor: () => b2.Sam2VideoProcessor, Sam3ImageProcessor: () => _2.Sam3ImageProcessor, Sam3TrackerModel: () => n2.Sam3TrackerModel, SamImageProcessor: () => _2.SamImageProcessor, SamImageSegmentationOutput: () => n2.SamImageSegmentationOutput, SamModel: () => n2.SamModel, SamPreTrainedModel: () => n2.SamPreTrainedModel, SamProcessor: () => b2.SamProcessor, SapiensForDepthEstimation: () => n2.SapiensForDepthEstimation, SapiensForNormalEstimation: () => n2.SapiensForNormalEstimation, SapiensForSemanticSegmentation: () => n2.SapiensForSemanticSegmentation, SapiensPreTrainedModel: () => n2.SapiensPreTrainedModel, SeamlessM4TFeatureExtractor: () => m2.SeamlessM4TFeatureExtractor, SegformerFeatureExtractor: () => _2.SegformerFeatureExtractor, SegformerForImageClassification: () => n2.SegformerForImageClassification, SegformerForSemanticSegmentation: () => n2.SegformerForSemanticSegmentation, SegformerImageProcessor: () => _2.SegformerImageProcessor, SegformerModel: () => n2.SegformerModel, SegformerPreTrainedModel: () => n2.SegformerPreTrainedModel, Seq2SeqLMOutput: () => n2.Seq2SeqLMOutput, SequenceClassifierOutput: () => n2.SequenceClassifierOutput, SiglipImageProcessor: () => _2.SiglipImageProcessor, SiglipModel: () => n2.SiglipModel, SiglipPreTrainedModel: () => n2.SiglipPreTrainedModel, SiglipTextModel: () => n2.SiglipTextModel, SiglipTokenizer: () => r2.SiglipTokenizer, SiglipVisionModel: () => n2.SiglipVisionModel, SmolLM3ForCausalLM: () => n2.SmolLM3ForCausalLM, SmolLM3Model: () => n2.SmolLM3Model, SmolLM3PreTrainedModel: () => n2.SmolLM3PreTrainedModel, SmolVLMForConditionalGeneration: () => n2.SmolVLMForConditionalGeneration, SmolVLMImageProcessor: () => _2.SmolVLMImageProcessor, SmolVLMProcessor: () => b2.SmolVLMProcessor, SnacDecoderModel: () => n2.SnacDecoderModel, SnacEncoderModel: () => n2.SnacEncoderModel, SnacFeatureExtractor: () => m2.SnacFeatureExtractor, SnacModel: () => n2.SnacModel, SnacPreTrainedModel: () => n2.SnacPreTrainedModel, SpeechT5FeatureExtractor: () => m2.SpeechT5FeatureExtractor, SpeechT5ForSpeechToText: () => n2.SpeechT5ForSpeechToText, SpeechT5ForTextToSpeech: () => n2.SpeechT5ForTextToSpeech, SpeechT5HifiGan: () => n2.SpeechT5HifiGan, SpeechT5Model: () => n2.SpeechT5Model, SpeechT5PreTrainedModel: () => n2.SpeechT5PreTrainedModel, SpeechT5Processor: () => b2.SpeechT5Processor, SpeechT5Tokenizer: () => r2.SpeechT5Tokenizer, SqueezeBertForMaskedLM: () => n2.SqueezeBertForMaskedLM, SqueezeBertForQuestionAnswering: () => n2.SqueezeBertForQuestionAnswering, SqueezeBertForSequenceClassification: () => n2.SqueezeBertForSequenceClassification, SqueezeBertModel: () => n2.SqueezeBertModel, SqueezeBertPreTrainedModel: () => n2.SqueezeBertPreTrainedModel, SqueezeBertTokenizer: () => r2.SqueezeBertTokenizer, StableLmForCausalLM: () => n2.StableLmForCausalLM, StableLmModel: () => n2.StableLmModel, StableLmPreTrainedModel: () => n2.StableLmPreTrainedModel, Starcoder2ForCausalLM: () => n2.Starcoder2ForCausalLM, Starcoder2Model: () => n2.Starcoder2Model, Starcoder2PreTrainedModel: () => n2.Starcoder2PreTrainedModel, StoppingCriteria: () => x2.StoppingCriteria, StoppingCriteriaList: () => x2.StoppingCriteriaList, StyleTextToSpeech2Model: () => n2.StyleTextToSpeech2Model, StyleTextToSpeech2PreTrainedModel: () => n2.StyleTextToSpeech2PreTrainedModel, SummarizationPipeline: () => t2.SummarizationPipeline, SupertonicForConditionalGeneration: () => n2.SupertonicForConditionalGeneration, SupertonicPreTrainedModel: () => n2.SupertonicPreTrainedModel, SuppressTokensAtBeginLogitsProcessor: () => v2.SuppressTokensAtBeginLogitsProcessor, Swin2SRForImageSuperResolution: () => n2.Swin2SRForImageSuperResolution, Swin2SRImageProcessor: () => _2.Swin2SRImageProcessor, Swin2SRModel: () => n2.Swin2SRModel, Swin2SRPreTrainedModel: () => n2.Swin2SRPreTrainedModel, SwinForImageClassification: () => n2.SwinForImageClassification, SwinForSemanticSegmentation: () => n2.SwinForSemanticSegmentation, SwinModel: () => n2.SwinModel, SwinPreTrainedModel: () => n2.SwinPreTrainedModel, T5ForConditionalGeneration: () => n2.T5ForConditionalGeneration, T5Model: () => n2.T5Model, T5PreTrainedModel: () => n2.T5PreTrainedModel, T5Tokenizer: () => r2.T5Tokenizer, TableTransformerForObjectDetection: () => n2.TableTransformerForObjectDetection, TableTransformerModel: () => n2.TableTransformerModel, TableTransformerObjectDetectionOutput: () => n2.TableTransformerObjectDetectionOutput, TableTransformerPreTrainedModel: () => n2.TableTransformerPreTrainedModel, TemperatureLogitsWarper: () => v2.TemperatureLogitsWarper, Tensor: () => u2.Tensor, Text2TextGenerationPipeline: () => t2.Text2TextGenerationPipeline, TextClassificationPipeline: () => t2.TextClassificationPipeline, TextGenerationPipeline: () => t2.TextGenerationPipeline, TextStreamer: () => M2.TextStreamer, TextToAudioPipeline: () => t2.TextToAudioPipeline, TokenClassificationPipeline: () => t2.TokenClassificationPipeline, TokenClassifierOutput: () => n2.TokenClassifierOutput, TokenizerModel: () => r2.TokenizerModel, TopKLogitsWarper: () => v2.TopKLogitsWarper, TopPLogitsWarper: () => v2.TopPLogitsWarper, TrOCRForCausalLM: () => n2.TrOCRForCausalLM, TrOCRPreTrainedModel: () => n2.TrOCRPreTrainedModel, TranslationPipeline: () => t2.TranslationPipeline, UltravoxModel: () => n2.UltravoxModel, UltravoxPreTrainedModel: () => n2.UltravoxPreTrainedModel, UltravoxProcessor: () => b2.UltravoxProcessor, UniSpeechForCTC: () => n2.UniSpeechForCTC, UniSpeechForSequenceClassification: () => n2.UniSpeechForSequenceClassification, UniSpeechModel: () => n2.UniSpeechModel, UniSpeechPreTrainedModel: () => n2.UniSpeechPreTrainedModel, UniSpeechSatForAudioFrameClassification: () => n2.UniSpeechSatForAudioFrameClassification, UniSpeechSatForCTC: () => n2.UniSpeechSatForCTC, UniSpeechSatForSequenceClassification: () => n2.UniSpeechSatForSequenceClassification, UniSpeechSatModel: () => n2.UniSpeechSatModel, UniSpeechSatPreTrainedModel: () => n2.UniSpeechSatPreTrainedModel, VLChatProcessor: () => b2.VLChatProcessor, VLMImageProcessor: () => _2.VLMImageProcessor, VaultGemmaForCausalLM: () => n2.VaultGemmaForCausalLM, VaultGemmaModel: () => n2.VaultGemmaModel, VaultGemmaPreTrainedModel: () => n2.VaultGemmaPreTrainedModel, ViTFeatureExtractor: () => _2.ViTFeatureExtractor, ViTForImageClassification: () => n2.ViTForImageClassification, ViTImageProcessor: () => _2.ViTImageProcessor, ViTMAEModel: () => n2.ViTMAEModel, ViTMAEPreTrainedModel: () => n2.ViTMAEPreTrainedModel, ViTMSNForImageClassification: () => n2.ViTMSNForImageClassification, ViTMSNModel: () => n2.ViTMSNModel, ViTMSNPreTrainedModel: () => n2.ViTMSNPreTrainedModel, ViTModel: () => n2.ViTModel, ViTPreTrainedModel: () => n2.ViTPreTrainedModel, VisionEncoderDecoderModel: () => n2.VisionEncoderDecoderModel, VitMatteForImageMatting: () => n2.VitMatteForImageMatting, VitMatteImageProcessor: () => _2.VitMatteImageProcessor, VitMattePreTrainedModel: () => n2.VitMattePreTrainedModel, VitPoseForPoseEstimation: () => n2.VitPoseForPoseEstimation, VitPoseImageProcessor: () => _2.VitPoseImageProcessor, VitPosePreTrainedModel: () => n2.VitPosePreTrainedModel, VitsModel: () => n2.VitsModel, VitsModelOutput: () => n2.VitsModelOutput, VitsPreTrainedModel: () => n2.VitsPreTrainedModel, VitsTokenizer: () => r2.VitsTokenizer, VoxtralForConditionalGeneration: () => n2.VoxtralForConditionalGeneration, VoxtralProcessor: () => b2.VoxtralProcessor, Wav2Vec2BertForCTC: () => n2.Wav2Vec2BertForCTC, Wav2Vec2BertForSequenceClassification: () => n2.Wav2Vec2BertForSequenceClassification, Wav2Vec2BertModel: () => n2.Wav2Vec2BertModel, Wav2Vec2BertPreTrainedModel: () => n2.Wav2Vec2BertPreTrainedModel, Wav2Vec2CTCTokenizer: () => r2.Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor: () => m2.Wav2Vec2FeatureExtractor, Wav2Vec2ForAudioFrameClassification: () => n2.Wav2Vec2ForAudioFrameClassification, Wav2Vec2ForCTC: () => n2.Wav2Vec2ForCTC, Wav2Vec2ForSequenceClassification: () => n2.Wav2Vec2ForSequenceClassification, Wav2Vec2Model: () => n2.Wav2Vec2Model, Wav2Vec2PreTrainedModel: () => n2.Wav2Vec2PreTrainedModel, Wav2Vec2Processor: () => b2.Wav2Vec2Processor, Wav2Vec2ProcessorWithLM: () => b2.Wav2Vec2ProcessorWithLM, WavLMForAudioFrameClassification: () => n2.WavLMForAudioFrameClassification, WavLMForCTC: () => n2.WavLMForCTC, WavLMForSequenceClassification: () => n2.WavLMForSequenceClassification, WavLMForXVector: () => n2.WavLMForXVector, WavLMModel: () => n2.WavLMModel, WavLMPreTrainedModel: () => n2.WavLMPreTrainedModel, WeSpeakerFeatureExtractor: () => m2.WeSpeakerFeatureExtractor, WeSpeakerResNetModel: () => n2.WeSpeakerResNetModel, WeSpeakerResNetPreTrainedModel: () => n2.WeSpeakerResNetPreTrainedModel, WhisperFeatureExtractor: () => m2.WhisperFeatureExtractor, WhisperForConditionalGeneration: () => n2.WhisperForConditionalGeneration, WhisperModel: () => n2.WhisperModel, WhisperPreTrainedModel: () => n2.WhisperPreTrainedModel, WhisperProcessor: () => b2.WhisperProcessor, WhisperTextStreamer: () => M2.WhisperTextStreamer, WhisperTimeStampLogitsProcessor: () => v2.WhisperTimeStampLogitsProcessor, WhisperTokenizer: () => r2.WhisperTokenizer, XLMForQuestionAnswering: () => n2.XLMForQuestionAnswering, XLMForSequenceClassification: () => n2.XLMForSequenceClassification, XLMForTokenClassification: () => n2.XLMForTokenClassification, XLMModel: () => n2.XLMModel, XLMPreTrainedModel: () => n2.XLMPreTrainedModel, XLMRobertaForMaskedLM: () => n2.XLMRobertaForMaskedLM, XLMRobertaForQuestionAnswering: () => n2.XLMRobertaForQuestionAnswering, XLMRobertaForSequenceClassification: () => n2.XLMRobertaForSequenceClassification, XLMRobertaForTokenClassification: () => n2.XLMRobertaForTokenClassification, XLMRobertaModel: () => n2.XLMRobertaModel, XLMRobertaPreTrainedModel: () => n2.XLMRobertaPreTrainedModel, XLMRobertaTokenizer: () => r2.XLMRobertaTokenizer, XLMTokenizer: () => r2.XLMTokenizer, XLMWithLMHeadModel: () => n2.XLMWithLMHeadModel, XVectorOutput: () => n2.XVectorOutput, YolosFeatureExtractor: () => _2.YolosFeatureExtractor, YolosForObjectDetection: () => n2.YolosForObjectDetection, YolosImageProcessor: () => _2.YolosImageProcessor, YolosModel: () => n2.YolosModel, YolosObjectDetectionOutput: () => n2.YolosObjectDetectionOutput, YolosPreTrainedModel: () => n2.YolosPreTrainedModel, ZeroShotAudioClassificationPipeline: () => t2.ZeroShotAudioClassificationPipeline, ZeroShotClassificationPipeline: () => t2.ZeroShotClassificationPipeline, ZeroShotImageClassificationPipeline: () => t2.ZeroShotImageClassificationPipeline, ZeroShotObjectDetectionPipeline: () => t2.ZeroShotObjectDetectionPipeline, bankers_round: () => c2.bankers_round, cat: () => u2.cat, cos_sim: () => c2.cos_sim, dot: () => c2.dot, dynamic_time_warping: () => c2.dynamic_time_warping, env: () => e2.env, full: () => u2.full, full_like: () => u2.full_like, getCacheShapes: () => o2.getCacheShapes, hamming: () => i2.hamming, hanning: () => i2.hanning, interpolate: () => u2.interpolate, interpolate_4d: () => u2.interpolate_4d, interpolate_data: () => c2.interpolate_data, is_chinese_char: () => r2.is_chinese_char, layer_norm: () => u2.layer_norm, load_image: () => l2.load_image, load_video: () => d2.load_video, log_softmax: () => c2.log_softmax, magnitude: () => c2.magnitude, matmul: () => u2.matmul, max: () => c2.max, mean: () => u2.mean, mean_pooling: () => u2.mean_pooling, medianFilter: () => c2.medianFilter, mel_filter_bank: () => i2.mel_filter_bank, min: () => c2.min, ones: () => u2.ones, ones_like: () => u2.ones_like, permute: () => u2.permute, permute_data: () => c2.permute_data, pipeline: () => t2.pipeline, quantize_embeddings: () => u2.quantize_embeddings, rand: () => u2.rand, randn: () => u2.randn, read_audio: () => i2.read_audio, rfft: () => u2.rfft, round: () => c2.round, slice: () => u2.slice, softmax: () => c2.softmax, spectrogram: () => i2.spectrogram, stack: () => u2.stack, std_mean: () => u2.std_mean, topk: () => u2.topk, window_function: () => i2.window_function, zeros: () => u2.zeros, zeros_like: () => u2.zeros_like });
    var e2 = s("./src/env.js"), t2 = s("./src/pipelines.js"), n2 = s("./src/models.js"), r2 = s("./src/tokenizers.js"), o2 = s("./src/configs.js"), i2 = s("./src/utils/audio.js"), l2 = s("./src/utils/image.js"), d2 = s("./src/utils/video.js"), u2 = s("./src/utils/tensor.js"), c2 = s("./src/utils/maths.js"), p2 = s("./src/base/feature_extraction_utils.js"), m2 = s("./src/models/feature_extractors.js"), h2 = s("./src/models/auto/feature_extraction_auto.js"), f2 = s("./src/base/image_processors_utils.js"), _2 = s("./src/models/image_processors.js"), g2 = s("./src/models/auto/image_processing_auto.js"), w2 = s("./src/base/processing_utils.js"), b2 = s("./src/models/processors.js"), y2 = s("./src/models/auto/processing_auto.js"), M2 = s("./src/generation/streamers.js"), x2 = s("./src/generation/stopping_criteria.js"), v2 = s("./src/generation/logits_process.js");
  })();
  var o = a.ASTFeatureExtractor;
  var i = a.ASTForAudioClassification;
  var l = a.ASTModel;
  var d = a.ASTPreTrainedModel;
  var u = a.AlbertForMaskedLM;
  var c = a.AlbertForQuestionAnswering;
  var p = a.AlbertForSequenceClassification;
  var m = a.AlbertModel;
  var h = a.AlbertPreTrainedModel;
  var f = a.AlbertTokenizer;
  var _ = a.ArceeForCausalLM;
  var g = a.ArceeModel;
  var w = a.ArceePreTrainedModel;
  var b = a.AudioClassificationPipeline;
  var y = a.AutoConfig;
  var M = a.AutoFeatureExtractor;
  var x = a.AutoImageProcessor;
  var v = a.AutoModel;
  var T = a.AutoModelForAudioClassification;
  var k = a.AutoModelForAudioFrameClassification;
  var P = a.AutoModelForAudioTextToText;
  var $ = a.AutoModelForCTC;
  var C = a.AutoModelForCausalLM;
  var S = a.AutoModelForDepthEstimation;
  var F = a.AutoModelForDocumentQuestionAnswering;
  var E = a.AutoModelForImageClassification;
  var I = a.AutoModelForImageFeatureExtraction;
  var A = a.AutoModelForImageMatting;
  var z = a.AutoModelForImageSegmentation;
  var L = a.AutoModelForImageTextToText;
  var O = a.AutoModelForImageToImage;
  var D = a.AutoModelForMaskGeneration;
  var B = a.AutoModelForMaskedLM;
  var N = a.AutoModelForNormalEstimation;
  var j = a.AutoModelForObjectDetection;
  var R = a.AutoModelForPoseEstimation;
  var V = a.AutoModelForQuestionAnswering;
  var G = a.AutoModelForSemanticSegmentation;
  var q = a.AutoModelForSeq2SeqLM;
  var U = a.AutoModelForSequenceClassification;
  var W = a.AutoModelForSpeechSeq2Seq;
  var H = a.AutoModelForTextToSpectrogram;
  var Q = a.AutoModelForTextToWaveform;
  var K = a.AutoModelForTokenClassification;
  var X = a.AutoModelForUniversalSegmentation;
  var J = a.AutoModelForVision2Seq;
  var Y = a.AutoModelForXVector;
  var Z = a.AutoModelForZeroShotObjectDetection;
  var ee = a.AutoProcessor;
  var te = a.AutoTokenizer;
  var ne = a.AutomaticSpeechRecognitionPipeline;
  var re = a.BackgroundRemovalPipeline;
  var se = a.BartForConditionalGeneration;
  var ae = a.BartForSequenceClassification;
  var oe = a.BartModel;
  var ie = a.BartPretrainedModel;
  var le = a.BartTokenizer;
  var de = a.BaseModelOutput;
  var ue = a.BaseStreamer;
  var ce = a.BeitFeatureExtractor;
  var pe = a.BeitForImageClassification;
  var me = a.BeitModel;
  var he = a.BeitPreTrainedModel;
  var fe = a.BertForMaskedLM;
  var _e = a.BertForQuestionAnswering;
  var ge = a.BertForSequenceClassification;
  var we = a.BertForTokenClassification;
  var be = a.BertModel;
  var ye = a.BertPreTrainedModel;
  var Me = a.BertTokenizer;
  var xe = a.BitImageProcessor;
  var ve = a.BlenderbotForConditionalGeneration;
  var Te = a.BlenderbotModel;
  var ke = a.BlenderbotPreTrainedModel;
  var Pe = a.BlenderbotSmallForConditionalGeneration;
  var $e = a.BlenderbotSmallModel;
  var Ce = a.BlenderbotSmallPreTrainedModel;
  var Se = a.BlenderbotSmallTokenizer;
  var Fe = a.BlenderbotTokenizer;
  var Ee = a.BloomForCausalLM;
  var Ie = a.BloomModel;
  var Ae = a.BloomPreTrainedModel;
  var ze = a.BloomTokenizer;
  var Le = a.CLIPFeatureExtractor;
  var Oe = a.CLIPImageProcessor;
  var De = a.CLIPModel;
  var Be = a.CLIPPreTrainedModel;
  var Ne = a.CLIPSegForImageSegmentation;
  var je = a.CLIPSegModel;
  var Re = a.CLIPSegPreTrainedModel;
  var Ve = a.CLIPTextModel;
  var Ge = a.CLIPTextModelWithProjection;
  var qe = a.CLIPTokenizer;
  var Ue = a.CLIPVisionModel;
  var We = a.CLIPVisionModelWithProjection;
  var He = a.CamembertForMaskedLM;
  var Qe = a.CamembertForQuestionAnswering;
  var Ke = a.CamembertForSequenceClassification;
  var Xe = a.CamembertForTokenClassification;
  var Je = a.CamembertModel;
  var Ye = a.CamembertPreTrainedModel;
  var Ze = a.CamembertTokenizer;
  var et = a.CausalLMOutput;
  var tt = a.CausalLMOutputWithPast;
  var nt = a.ChineseCLIPFeatureExtractor;
  var rt = a.ChineseCLIPModel;
  var st = a.ChineseCLIPPreTrainedModel;
  var at = a.ClapAudioModelWithProjection;
  var ot = a.ClapFeatureExtractor;
  var it = a.ClapModel;
  var lt = a.ClapPreTrainedModel;
  var dt = a.ClapTextModelWithProjection;
  var ut = a.ClassifierFreeGuidanceLogitsProcessor;
  var ct = a.CodeGenForCausalLM;
  var pt = a.CodeGenModel;
  var mt = a.CodeGenPreTrainedModel;
  var ht = a.CodeGenTokenizer;
  var ft = a.CodeLlamaTokenizer;
  var _t = a.CohereForCausalLM;
  var gt = a.CohereModel;
  var wt = a.CoherePreTrainedModel;
  var bt = a.CohereTokenizer;
  var yt = a.ConvBertForMaskedLM;
  var Mt = a.ConvBertForQuestionAnswering;
  var xt = a.ConvBertForSequenceClassification;
  var vt = a.ConvBertForTokenClassification;
  var Tt = a.ConvBertModel;
  var kt = a.ConvBertPreTrainedModel;
  var Pt = a.ConvBertTokenizer;
  var $t = a.ConvNextFeatureExtractor;
  var Ct = a.ConvNextForImageClassification;
  var St = a.ConvNextImageProcessor;
  var Ft = a.ConvNextModel;
  var Et = a.ConvNextPreTrainedModel;
  var It = a.ConvNextV2ForImageClassification;
  var At = a.ConvNextV2Model;
  var zt = a.ConvNextV2PreTrainedModel;
  var Lt = a.DFineForObjectDetection;
  var Ot = a.DFineModel;
  var Dt = a.DFinePreTrainedModel;
  var Bt = a.DINOv3ConvNextModel;
  var Nt = a.DINOv3ConvNextPreTrainedModel;
  var jt = a.DINOv3ViTImageProcessor;
  var Rt = a.DINOv3ViTModel;
  var Vt = a.DINOv3ViTPreTrainedModel;
  var Gt = a.DPTFeatureExtractor;
  var qt = a.DPTForDepthEstimation;
  var Ut = a.DPTImageProcessor;
  var Wt = a.DPTModel;
  var Ht = a.DPTPreTrainedModel;
  var Qt = a.DacDecoderModel;
  var Kt = a.DacDecoderOutput;
  var Xt = a.DacEncoderModel;
  var Jt = a.DacEncoderOutput;
  var Yt = a.DacFeatureExtractor;
  var Zt = a.DacModel;
  var en = a.DacPreTrainedModel;
  var tn = a.DataTypeMap;
  var nn = a.DebertaForMaskedLM;
  var rn = a.DebertaForQuestionAnswering;
  var sn = a.DebertaForSequenceClassification;
  var an = a.DebertaForTokenClassification;
  var on = a.DebertaModel;
  var ln = a.DebertaPreTrainedModel;
  var dn = a.DebertaTokenizer;
  var un = a.DebertaV2ForMaskedLM;
  var cn = a.DebertaV2ForQuestionAnswering;
  var pn = a.DebertaV2ForSequenceClassification;
  var mn = a.DebertaV2ForTokenClassification;
  var hn = a.DebertaV2Model;
  var fn = a.DebertaV2PreTrainedModel;
  var _n = a.DebertaV2Tokenizer;
  var gn = a.DecisionTransformerModel;
  var wn = a.DecisionTransformerPreTrainedModel;
  var bn = a.DeiTFeatureExtractor;
  var yn = a.DeiTForImageClassification;
  var Mn = a.DeiTImageProcessor;
  var xn = a.DeiTModel;
  var vn = a.DeiTPreTrainedModel;
  var Tn = a.DepthAnythingForDepthEstimation;
  var kn = a.DepthAnythingPreTrainedModel;
  var Pn = a.DepthEstimationPipeline;
  var $n = a.DepthProForDepthEstimation;
  var Cn = a.DepthProPreTrainedModel;
  var Sn = a.DetrFeatureExtractor;
  var Fn = a.DetrForObjectDetection;
  var En = a.DetrForSegmentation;
  var In = a.DetrImageProcessor;
  var An = a.DetrModel;
  var zn = a.DetrObjectDetectionOutput;
  var Ln = a.DetrPreTrainedModel;
  var On = a.DetrSegmentationOutput;
  var Dn = a.Dinov2ForImageClassification;
  var Bn = a.Dinov2Model;
  var Nn = a.Dinov2PreTrainedModel;
  var jn = a.Dinov2WithRegistersForImageClassification;
  var Rn = a.Dinov2WithRegistersModel;
  var Vn = a.Dinov2WithRegistersPreTrainedModel;
  var Gn = a.DistilBertForMaskedLM;
  var qn = a.DistilBertForQuestionAnswering;
  var Un = a.DistilBertForSequenceClassification;
  var Wn = a.DistilBertForTokenClassification;
  var Hn = a.DistilBertModel;
  var Qn = a.DistilBertPreTrainedModel;
  var Kn = a.DistilBertTokenizer;
  var Xn = a.DocumentQuestionAnsweringPipeline;
  var Jn = a.DonutFeatureExtractor;
  var Yn = a.DonutImageProcessor;
  var Zn = a.DonutSwinModel;
  var er = a.DonutSwinPreTrainedModel;
  var tr = a.EdgeTamModel;
  var nr = a.EfficientNetForImageClassification;
  var rr = a.EfficientNetImageProcessor;
  var sr = a.EfficientNetModel;
  var ar = a.EfficientNetPreTrainedModel;
  var or = a.ElectraForMaskedLM;
  var ir = a.ElectraForQuestionAnswering;
  var lr = a.ElectraForSequenceClassification;
  var dr = a.ElectraForTokenClassification;
  var ur = a.ElectraModel;
  var cr = a.ElectraPreTrainedModel;
  var pr = a.ElectraTokenizer;
  var mr = a.EncodecFeatureExtractor;
  var hr = a.EosTokenCriteria;
  var fr = a.Ernie4_5_ForCausalLM;
  var _r = a.Ernie4_5_Model;
  var gr = a.Ernie4_5_PretrainedModel;
  var wr = a.Ernie4_5_Tokenizer;
  var br = a.EsmForMaskedLM;
  var yr = a.EsmForSequenceClassification;
  var Mr = a.EsmForTokenClassification;
  var xr = a.EsmModel;
  var vr = a.EsmPreTrainedModel;
  var Tr = a.EsmTokenizer;
  var kr = a.ExaoneForCausalLM;
  var Pr = a.ExaoneModel;
  var $r = a.ExaonePreTrainedModel;
  var Cr = a.FFT;
  var Sr = a.FalconForCausalLM;
  var Fr = a.FalconModel;
  var Er = a.FalconPreTrainedModel;
  var Ir = a.FalconTokenizer;
  var Ar = a.FastViTForImageClassification;
  var zr = a.FastViTModel;
  var Lr = a.FastViTPreTrainedModel;
  var Or = a.FeatureExtractionPipeline;
  var Dr = a.FeatureExtractor;
  var Br = a.FillMaskPipeline;
  var Nr = a.Florence2ForConditionalGeneration;
  var jr = a.Florence2PreTrainedModel;
  var Rr = a.Florence2Processor;
  var Vr = a.ForcedBOSTokenLogitsProcessor;
  var Gr = a.ForcedEOSTokenLogitsProcessor;
  var qr = a.GLPNFeatureExtractor;
  var Ur = a.GLPNForDepthEstimation;
  var Wr = a.GLPNModel;
  var Hr = a.GLPNPreTrainedModel;
  var Qr = a.GPT2LMHeadModel;
  var Kr = a.GPT2Model;
  var Xr = a.GPT2PreTrainedModel;
  var Jr = a.GPT2Tokenizer;
  var Yr = a.GPTBigCodeForCausalLM;
  var Zr = a.GPTBigCodeModel;
  var es = a.GPTBigCodePreTrainedModel;
  var ts = a.GPTJForCausalLM;
  var ns = a.GPTJModel;
  var rs = a.GPTJPreTrainedModel;
  var ss = a.GPTNeoForCausalLM;
  var as = a.GPTNeoModel;
  var os = a.GPTNeoPreTrainedModel;
  var is = a.GPTNeoXForCausalLM;
  var ls = a.GPTNeoXModel;
  var ds = a.GPTNeoXPreTrainedModel;
  var us = a.GPTNeoXTokenizer;
  var cs = a.Gemma2ForCausalLM;
  var ps = a.Gemma2Model;
  var ms = a.Gemma2PreTrainedModel;
  var hs = a.Gemma3ForCausalLM;
  var fs = a.Gemma3Model;
  var _s = a.Gemma3PreTrainedModel;
  var gs = a.Gemma3nAudioFeatureExtractor;
  var ws = a.Gemma3nForConditionalGeneration;
  var bs = a.Gemma3nPreTrainedModel;
  var ys = a.Gemma3nProcessor;
  var Ms = a.GemmaForCausalLM;
  var xs = a.GemmaModel;
  var vs = a.GemmaPreTrainedModel;
  var Ts = a.GemmaTokenizer;
  var ks = a.GlmForCausalLM;
  var Ps = a.GlmModel;
  var $s = a.GlmPreTrainedModel;
  var Cs = a.GraniteForCausalLM;
  var Ss = a.GraniteModel;
  var Fs = a.GraniteMoeHybridForCausalLM;
  var Es = a.GraniteMoeHybridModel;
  var Is = a.GraniteMoeHybridPreTrainedModel;
  var As = a.GranitePreTrainedModel;
  var zs = a.Grok1Tokenizer;
  var Ls = a.GroundingDinoForObjectDetection;
  var Os = a.GroundingDinoImageProcessor;
  var Ds = a.GroundingDinoPreTrainedModel;
  var Bs = a.GroundingDinoProcessor;
  var Ns = a.GroupViTModel;
  var js = a.GroupViTPreTrainedModel;
  var Rs = a.HeliumForCausalLM;
  var Vs = a.HeliumModel;
  var Gs = a.HeliumPreTrainedModel;
  var qs = a.HerbertTokenizer;
  var Us = a.HieraForImageClassification;
  var Ws = a.HieraModel;
  var Hs = a.HieraPreTrainedModel;
  var Qs = a.HubertForCTC;
  var Ks = a.HubertForSequenceClassification;
  var Xs = a.HubertModel;
  var Js = a.HubertPreTrainedModel;
  var Ys = a.IJepaForImageClassification;
  var Zs = a.IJepaModel;
  var ea = a.IJepaPreTrainedModel;
  var ta = a.Idefics3ForConditionalGeneration;
  var na = a.Idefics3ImageProcessor;
  var ra = a.Idefics3PreTrainedModel;
  var sa = a.Idefics3Processor;
  var aa = a.ImageClassificationPipeline;
  var oa = a.ImageFeatureExtractionPipeline;
  var ia = a.ImageFeatureExtractor;
  var la = a.ImageMattingOutput;
  var da = a.ImageProcessor;
  var ua = a.ImageSegmentationPipeline;
  var ca = a.ImageToImagePipeline;
  var pa = a.ImageToTextPipeline;
  var ma = a.InterruptableStoppingCriteria;
  var ha = a.JAISLMHeadModel;
  var fa = a.JAISModel;
  var _a = a.JAISPreTrainedModel;
  var ga = a.JinaCLIPImageProcessor;
  var wa = a.JinaCLIPModel;
  var ba = a.JinaCLIPPreTrainedModel;
  var ya = a.JinaCLIPProcessor;
  var Ma = a.JinaCLIPTextModel;
  var xa = a.JinaCLIPVisionModel;
  var va = a.Lfm2ForCausalLM;
  var Ta = a.Lfm2Model;
  var ka = a.Lfm2PreTrainedModel;
  var Pa = a.LiteWhisperForConditionalGeneration;
  var $a = a.Llama4ForCausalLM;
  var Ca = a.Llama4PreTrainedModel;
  var Sa = a.LlamaForCausalLM;
  var Fa = a.LlamaModel;
  var Ea = a.LlamaPreTrainedModel;
  var Ia = a.LlamaTokenizer;
  var Aa = a.LlavaForConditionalGeneration;
  var za = a.LlavaOnevisionForConditionalGeneration;
  var La = a.LlavaOnevisionImageProcessor;
  var Oa = a.LlavaPreTrainedModel;
  var Da = a.LlavaProcessor;
  var Ba = a.LlavaQwen2ForCausalLM;
  var Na = a.LogitsProcessor;
  var ja = a.LogitsProcessorList;
  var Ra = a.LogitsWarper;
  var Va = a.LongT5ForConditionalGeneration;
  var Ga = a.LongT5Model;
  var qa = a.LongT5PreTrainedModel;
  var Ua = a.M2M100ForConditionalGeneration;
  var Wa = a.M2M100Model;
  var Ha = a.M2M100PreTrainedModel;
  var Qa = a.M2M100Tokenizer;
  var Ka = a.MBart50Tokenizer;
  var Xa = a.MBartForCausalLM;
  var Ja = a.MBartForConditionalGeneration;
  var Ya = a.MBartForSequenceClassification;
  var Za = a.MBartModel;
  var eo = a.MBartPreTrainedModel;
  var to = a.MBartTokenizer;
  var no = a.MPNetForMaskedLM;
  var ro = a.MPNetForQuestionAnswering;
  var so = a.MPNetForSequenceClassification;
  var ao = a.MPNetForTokenClassification;
  var oo = a.MPNetModel;
  var io = a.MPNetPreTrainedModel;
  var lo = a.MPNetTokenizer;
  var uo = a.MT5ForConditionalGeneration;
  var co = a.MT5Model;
  var po = a.MT5PreTrainedModel;
  var mo = a.MarianMTModel;
  var ho = a.MarianModel;
  var fo = a.MarianPreTrainedModel;
  var _o = a.MarianTokenizer;
  var go = a.Mask2FormerImageProcessor;
  var wo = a.MaskFormerFeatureExtractor;
  var bo = a.MaskFormerForInstanceSegmentation;
  var yo = a.MaskFormerImageProcessor;
  var Mo = a.MaskFormerModel;
  var xo = a.MaskFormerPreTrainedModel;
  var vo = a.MaskedLMOutput;
  var To = a.MaxLengthCriteria;
  var ko = a.Metric3DForDepthEstimation;
  var Po = a.Metric3DPreTrainedModel;
  var $o = a.Metric3Dv2ForDepthEstimation;
  var Co = a.Metric3Dv2PreTrainedModel;
  var So = a.MgpstrForSceneTextRecognition;
  var Fo = a.MgpstrModelOutput;
  var Eo = a.MgpstrPreTrainedModel;
  var Io = a.MgpstrProcessor;
  var Ao = a.MgpstrTokenizer;
  var zo = a.MimiDecoderModel;
  var Lo = a.MimiDecoderOutput;
  var Oo = a.MimiEncoderModel;
  var Do = a.MimiEncoderOutput;
  var Bo = a.MimiModel;
  var No = a.MimiPreTrainedModel;
  var jo = a.MinLengthLogitsProcessor;
  var Ro = a.MinNewTokensLengthLogitsProcessor;
  var Vo = a.MistralForCausalLM;
  var Go = a.MistralModel;
  var qo = a.MistralPreTrainedModel;
  var Uo = a.MobileBertForMaskedLM;
  var Wo = a.MobileBertForQuestionAnswering;
  var Ho = a.MobileBertForSequenceClassification;
  var Qo = a.MobileBertModel;
  var Ko = a.MobileBertPreTrainedModel;
  var Xo = a.MobileBertTokenizer;
  var Jo = a.MobileLLMForCausalLM;
  var Yo = a.MobileLLMModel;
  var Zo = a.MobileLLMPreTrainedModel;
  var ei = a.MobileNetV1FeatureExtractor;
  var ti = a.MobileNetV1ForImageClassification;
  var ni = a.MobileNetV1ForSemanticSegmentation;
  var ri = a.MobileNetV1ImageProcessor;
  var si = a.MobileNetV1Model;
  var ai = a.MobileNetV1PreTrainedModel;
  var oi = a.MobileNetV2FeatureExtractor;
  var ii = a.MobileNetV2ForImageClassification;
  var li = a.MobileNetV2ForSemanticSegmentation;
  var di = a.MobileNetV2ImageProcessor;
  var ui = a.MobileNetV2Model;
  var ci = a.MobileNetV2PreTrainedModel;
  var pi = a.MobileNetV3FeatureExtractor;
  var mi = a.MobileNetV3ForImageClassification;
  var hi = a.MobileNetV3ForSemanticSegmentation;
  var fi = a.MobileNetV3ImageProcessor;
  var _i = a.MobileNetV3Model;
  var gi = a.MobileNetV3PreTrainedModel;
  var wi = a.MobileNetV4FeatureExtractor;
  var bi = a.MobileNetV4ForImageClassification;
  var yi = a.MobileNetV4ForSemanticSegmentation;
  var Mi = a.MobileNetV4ImageProcessor;
  var xi = a.MobileNetV4Model;
  var vi = a.MobileNetV4PreTrainedModel;
  var Ti = a.MobileViTFeatureExtractor;
  var ki = a.MobileViTForImageClassification;
  var Pi = a.MobileViTImageProcessor;
  var $i = a.MobileViTModel;
  var Ci = a.MobileViTPreTrainedModel;
  var Si = a.MobileViTV2ForImageClassification;
  var Fi = a.MobileViTV2Model;
  var Ei = a.MobileViTV2PreTrainedModel;
  var Ii = a.ModelOutput;
  var Ai = a.ModernBertDecoderForCausalLM;
  var zi = a.ModernBertDecoderModel;
  var Li = a.ModernBertDecoderPreTrainedModel;
  var Oi = a.ModernBertForMaskedLM;
  var Di = a.ModernBertForSequenceClassification;
  var Bi = a.ModernBertForTokenClassification;
  var Ni = a.ModernBertModel;
  var ji = a.ModernBertPreTrainedModel;
  var Ri = a.Moondream1ForConditionalGeneration;
  var Vi = a.MoonshineFeatureExtractor;
  var Gi = a.MoonshineForConditionalGeneration;
  var qi = a.MoonshineModel;
  var Ui = a.MoonshinePreTrainedModel;
  var Wi = a.MoonshineProcessor;
  var Hi = a.MptForCausalLM;
  var Qi = a.MptModel;
  var Ki = a.MptPreTrainedModel;
  var Xi = a.MultiModalityCausalLM;
  var Ji = a.MultiModalityPreTrainedModel;
  var Yi = a.MusicgenForCausalLM;
  var Zi = a.MusicgenForConditionalGeneration;
  var el = a.MusicgenModel;
  var tl = a.MusicgenPreTrainedModel;
  var nl = a.NanoChatForCausalLM;
  var rl = a.NanoChatModel;
  var sl = a.NanoChatPreTrainedModel;
  var al = a.NeoBertForMaskedLM;
  var ol = a.NeoBertForQuestionAnswering;
  var il = a.NeoBertForSequenceClassification;
  var ll = a.NeoBertForTokenClassification;
  var dl = a.NeoBertModel;
  var ul = a.NeoBertPreTrainedModel;
  var cl = a.NllbTokenizer;
  var pl = a.NoBadWordsLogitsProcessor;
  var ml = a.NoRepeatNGramLogitsProcessor;
  var hl = a.NomicBertModel;
  var fl = a.NomicBertPreTrainedModel;
  var _l = a.NougatImageProcessor;
  var gl = a.NougatTokenizer;
  var wl = a.OPTForCausalLM;
  var bl = a.OPTModel;
  var yl = a.OPTPreTrainedModel;
  var Ml = a.ObjectDetectionPipeline;
  var xl = a.Olmo2ForCausalLM;
  var vl = a.Olmo2Model;
  var Tl = a.Olmo2PreTrainedModel;
  var kl = a.OlmoForCausalLM;
  var Pl = a.OlmoModel;
  var $l = a.OlmoPreTrainedModel;
  var Cl = a.OpenELMForCausalLM;
  var Sl = a.OpenELMModel;
  var Fl = a.OpenELMPreTrainedModel;
  var El = a.OwlViTFeatureExtractor;
  var Il = a.OwlViTForObjectDetection;
  var Al = a.OwlViTImageProcessor;
  var zl = a.OwlViTModel;
  var Ll = a.OwlViTPreTrainedModel;
  var Ol = a.OwlViTProcessor;
  var Dl = a.Owlv2ForObjectDetection;
  var Bl = a.Owlv2ImageProcessor;
  var Nl = a.Owlv2Model;
  var jl = a.Owlv2PreTrainedModel;
  var Rl = a.PaliGemmaForConditionalGeneration;
  var Vl = a.PaliGemmaPreTrainedModel;
  var Gl = a.PaliGemmaProcessor;
  var ql = a.ParakeetFeatureExtractor;
  var Ul = a.ParakeetForCTC;
  var Wl = a.ParakeetPreTrainedModel;
  var Hl = a.PatchTSMixerForPrediction;
  var Ql = a.PatchTSMixerModel;
  var Kl = a.PatchTSMixerPreTrainedModel;
  var Xl = a.PatchTSTForPrediction;
  var Jl = a.PatchTSTModel;
  var Yl = a.PatchTSTPreTrainedModel;
  var Zl = a.Phi3ForCausalLM;
  var ed = a.Phi3Model;
  var td = a.Phi3PreTrainedModel;
  var nd = a.Phi3VForCausalLM;
  var rd = a.Phi3VImageProcessor;
  var sd = a.Phi3VPreTrainedModel;
  var ad = a.Phi3VProcessor;
  var od = a.PhiForCausalLM;
  var id = a.PhiModel;
  var ld = a.PhiPreTrainedModel;
  var dd = a.Pipeline;
  var ud = a.PreTrainedModel;
  var cd = a.PreTrainedTokenizer;
  var pd = a.PretrainedConfig;
  var md = a.PretrainedMixin;
  var hd = a.Processor;
  var fd = a.PvtForImageClassification;
  var _d = a.PvtImageProcessor;
  var gd = a.PvtModel;
  var wd = a.PvtPreTrainedModel;
  var bd = a.PyAnnoteFeatureExtractor;
  var yd = a.PyAnnoteForAudioFrameClassification;
  var Md = a.PyAnnoteModel;
  var xd = a.PyAnnotePreTrainedModel;
  var vd = a.PyAnnoteProcessor;
  var Td = a.QuestionAnsweringModelOutput;
  var kd = a.QuestionAnsweringPipeline;
  var Pd = a.Qwen2ForCausalLM;
  var $d = a.Qwen2Model;
  var Cd = a.Qwen2PreTrainedModel;
  var Sd = a.Qwen2Tokenizer;
  var Fd = a.Qwen2VLForConditionalGeneration;
  var Ed = a.Qwen2VLImageProcessor;
  var Id = a.Qwen2VLPreTrainedModel;
  var Ad = a.Qwen2VLProcessor;
  var zd = a.Qwen3ForCausalLM;
  var Ld = a.Qwen3Model;
  var Od = a.Qwen3PreTrainedModel;
  var Dd = a.RFDetrForObjectDetection;
  var Bd = a.RFDetrModel;
  var Nd = a.RFDetrObjectDetectionOutput;
  var jd = a.RFDetrPreTrainedModel;
  var Rd = a.RTDetrForObjectDetection;
  var Vd = a.RTDetrImageProcessor;
  var Gd = a.RTDetrModel;
  var qd = a.RTDetrObjectDetectionOutput;
  var Ud = a.RTDetrPreTrainedModel;
  var Wd = a.RTDetrV2ForObjectDetection;
  var Hd = a.RTDetrV2Model;
  var Qd = a.RTDetrV2ObjectDetectionOutput;
  var Kd = a.RTDetrV2PreTrainedModel;
  var Xd = a.RawAudio;
  var Jd = a.RawImage;
  var Yd = a.RawVideo;
  var Zd = a.RawVideoFrame;
  var eu = a.RepetitionPenaltyLogitsProcessor;
  var tu = a.ResNetForImageClassification;
  var nu = a.ResNetModel;
  var ru = a.ResNetPreTrainedModel;
  var su = a.RoFormerForMaskedLM;
  var au = a.RoFormerForQuestionAnswering;
  var ou = a.RoFormerForSequenceClassification;
  var iu = a.RoFormerForTokenClassification;
  var lu = a.RoFormerModel;
  var du = a.RoFormerPreTrainedModel;
  var uu = a.RoFormerTokenizer;
  var cu = a.RobertaForMaskedLM;
  var pu = a.RobertaForQuestionAnswering;
  var mu = a.RobertaForSequenceClassification;
  var hu = a.RobertaForTokenClassification;
  var fu = a.RobertaModel;
  var _u = a.RobertaPreTrainedModel;
  var gu = a.RobertaTokenizer;
  var wu = a.Sam2ImageProcessor;
  var bu = a.Sam2ImageSegmentationOutput;
  var yu = a.Sam2Model;
  var Mu = a.Sam2PreTrainedModel;
  var xu = a.Sam2Processor;
  var vu = a.Sam2VideoProcessor;
  var Tu = a.Sam3ImageProcessor;
  var ku = a.Sam3TrackerModel;
  var Pu = a.SamImageProcessor;
  var $u = a.SamImageSegmentationOutput;
  var Cu = a.SamModel;
  var Su = a.SamPreTrainedModel;
  var Fu = a.SamProcessor;
  var Eu = a.SapiensForDepthEstimation;
  var Iu = a.SapiensForNormalEstimation;
  var Au = a.SapiensForSemanticSegmentation;
  var zu = a.SapiensPreTrainedModel;
  var Lu = a.SeamlessM4TFeatureExtractor;
  var Ou = a.SegformerFeatureExtractor;
  var Du = a.SegformerForImageClassification;
  var Bu = a.SegformerForSemanticSegmentation;
  var Nu = a.SegformerImageProcessor;
  var ju = a.SegformerModel;
  var Ru = a.SegformerPreTrainedModel;
  var Vu = a.Seq2SeqLMOutput;
  var Gu = a.SequenceClassifierOutput;
  var qu = a.SiglipImageProcessor;
  var Uu = a.SiglipModel;
  var Wu = a.SiglipPreTrainedModel;
  var Hu = a.SiglipTextModel;
  var Qu = a.SiglipTokenizer;
  var Ku = a.SiglipVisionModel;
  var Xu = a.SmolLM3ForCausalLM;
  var Ju = a.SmolLM3Model;
  var Yu = a.SmolLM3PreTrainedModel;
  var Zu = a.SmolVLMForConditionalGeneration;
  var ec = a.SmolVLMImageProcessor;
  var tc = a.SmolVLMProcessor;
  var nc = a.SnacDecoderModel;
  var rc = a.SnacEncoderModel;
  var sc = a.SnacFeatureExtractor;
  var ac = a.SnacModel;
  var oc = a.SnacPreTrainedModel;
  var ic = a.SpeechT5FeatureExtractor;
  var lc = a.SpeechT5ForSpeechToText;
  var dc = a.SpeechT5ForTextToSpeech;
  var uc = a.SpeechT5HifiGan;
  var cc = a.SpeechT5Model;
  var pc = a.SpeechT5PreTrainedModel;
  var mc = a.SpeechT5Processor;
  var hc = a.SpeechT5Tokenizer;
  var fc = a.SqueezeBertForMaskedLM;
  var _c = a.SqueezeBertForQuestionAnswering;
  var gc = a.SqueezeBertForSequenceClassification;
  var wc = a.SqueezeBertModel;
  var bc = a.SqueezeBertPreTrainedModel;
  var yc = a.SqueezeBertTokenizer;
  var Mc = a.StableLmForCausalLM;
  var xc = a.StableLmModel;
  var vc = a.StableLmPreTrainedModel;
  var Tc = a.Starcoder2ForCausalLM;
  var kc = a.Starcoder2Model;
  var Pc = a.Starcoder2PreTrainedModel;
  var $c = a.StoppingCriteria;
  var Cc = a.StoppingCriteriaList;
  var Sc = a.StyleTextToSpeech2Model;
  var Fc = a.StyleTextToSpeech2PreTrainedModel;
  var Ec = a.SummarizationPipeline;
  var Ic = a.SupertonicForConditionalGeneration;
  var Ac = a.SupertonicPreTrainedModel;
  var zc = a.SuppressTokensAtBeginLogitsProcessor;
  var Lc = a.Swin2SRForImageSuperResolution;
  var Oc = a.Swin2SRImageProcessor;
  var Dc = a.Swin2SRModel;
  var Bc = a.Swin2SRPreTrainedModel;
  var Nc = a.SwinForImageClassification;
  var jc = a.SwinForSemanticSegmentation;
  var Rc = a.SwinModel;
  var Vc = a.SwinPreTrainedModel;
  var Gc = a.T5ForConditionalGeneration;
  var qc = a.T5Model;
  var Uc = a.T5PreTrainedModel;
  var Wc = a.T5Tokenizer;
  var Hc = a.TableTransformerForObjectDetection;
  var Qc = a.TableTransformerModel;
  var Kc = a.TableTransformerObjectDetectionOutput;
  var Xc = a.TableTransformerPreTrainedModel;
  var Jc = a.TemperatureLogitsWarper;
  var Yc = a.Tensor;
  var Zc = a.Text2TextGenerationPipeline;
  var ep = a.TextClassificationPipeline;
  var tp = a.TextGenerationPipeline;
  var np = a.TextStreamer;
  var rp = a.TextToAudioPipeline;
  var sp = a.TokenClassificationPipeline;
  var ap = a.TokenClassifierOutput;
  var op = a.TokenizerModel;
  var ip = a.TopKLogitsWarper;
  var lp = a.TopPLogitsWarper;
  var dp = a.TrOCRForCausalLM;
  var up = a.TrOCRPreTrainedModel;
  var cp = a.TranslationPipeline;
  var pp = a.UltravoxModel;
  var mp = a.UltravoxPreTrainedModel;
  var hp = a.UltravoxProcessor;
  var fp = a.UniSpeechForCTC;
  var _p = a.UniSpeechForSequenceClassification;
  var gp = a.UniSpeechModel;
  var wp = a.UniSpeechPreTrainedModel;
  var bp = a.UniSpeechSatForAudioFrameClassification;
  var yp = a.UniSpeechSatForCTC;
  var Mp = a.UniSpeechSatForSequenceClassification;
  var xp = a.UniSpeechSatModel;
  var vp = a.UniSpeechSatPreTrainedModel;
  var Tp = a.VLChatProcessor;
  var kp = a.VLMImageProcessor;
  var Pp = a.VaultGemmaForCausalLM;
  var $p = a.VaultGemmaModel;
  var Cp = a.VaultGemmaPreTrainedModel;
  var Sp = a.ViTFeatureExtractor;
  var Fp = a.ViTForImageClassification;
  var Ep = a.ViTImageProcessor;
  var Ip = a.ViTMAEModel;
  var Ap = a.ViTMAEPreTrainedModel;
  var zp = a.ViTMSNForImageClassification;
  var Lp = a.ViTMSNModel;
  var Op = a.ViTMSNPreTrainedModel;
  var Dp = a.ViTModel;
  var Bp = a.ViTPreTrainedModel;
  var Np = a.VisionEncoderDecoderModel;
  var jp = a.VitMatteForImageMatting;
  var Rp = a.VitMatteImageProcessor;
  var Vp = a.VitMattePreTrainedModel;
  var Gp = a.VitPoseForPoseEstimation;
  var qp = a.VitPoseImageProcessor;
  var Up = a.VitPosePreTrainedModel;
  var Wp = a.VitsModel;
  var Hp = a.VitsModelOutput;
  var Qp = a.VitsPreTrainedModel;
  var Kp = a.VitsTokenizer;
  var Xp = a.VoxtralForConditionalGeneration;
  var Jp = a.VoxtralProcessor;
  var Yp = a.Wav2Vec2BertForCTC;
  var Zp = a.Wav2Vec2BertForSequenceClassification;
  var em = a.Wav2Vec2BertModel;
  var tm = a.Wav2Vec2BertPreTrainedModel;
  var nm = a.Wav2Vec2CTCTokenizer;
  var rm = a.Wav2Vec2FeatureExtractor;
  var sm = a.Wav2Vec2ForAudioFrameClassification;
  var am = a.Wav2Vec2ForCTC;
  var om = a.Wav2Vec2ForSequenceClassification;
  var im = a.Wav2Vec2Model;
  var lm = a.Wav2Vec2PreTrainedModel;
  var dm = a.Wav2Vec2Processor;
  var um = a.Wav2Vec2ProcessorWithLM;
  var cm = a.WavLMForAudioFrameClassification;
  var pm = a.WavLMForCTC;
  var mm = a.WavLMForSequenceClassification;
  var hm = a.WavLMForXVector;
  var fm = a.WavLMModel;
  var _m = a.WavLMPreTrainedModel;
  var gm = a.WeSpeakerFeatureExtractor;
  var wm = a.WeSpeakerResNetModel;
  var bm = a.WeSpeakerResNetPreTrainedModel;
  var ym = a.WhisperFeatureExtractor;
  var Mm = a.WhisperForConditionalGeneration;
  var xm = a.WhisperModel;
  var vm = a.WhisperPreTrainedModel;
  var Tm = a.WhisperProcessor;
  var km = a.WhisperTextStreamer;
  var Pm = a.WhisperTimeStampLogitsProcessor;
  var $m = a.WhisperTokenizer;
  var Cm = a.XLMForQuestionAnswering;
  var Sm = a.XLMForSequenceClassification;
  var Fm = a.XLMForTokenClassification;
  var Em = a.XLMModel;
  var Im = a.XLMPreTrainedModel;
  var Am = a.XLMRobertaForMaskedLM;
  var zm = a.XLMRobertaForQuestionAnswering;
  var Lm = a.XLMRobertaForSequenceClassification;
  var Om = a.XLMRobertaForTokenClassification;
  var Dm = a.XLMRobertaModel;
  var Bm = a.XLMRobertaPreTrainedModel;
  var Nm = a.XLMRobertaTokenizer;
  var jm = a.XLMTokenizer;
  var Rm = a.XLMWithLMHeadModel;
  var Vm = a.XVectorOutput;
  var Gm = a.YolosFeatureExtractor;
  var qm = a.YolosForObjectDetection;
  var Um = a.YolosImageProcessor;
  var Wm = a.YolosModel;
  var Hm = a.YolosObjectDetectionOutput;
  var Qm = a.YolosPreTrainedModel;
  var Km = a.ZeroShotAudioClassificationPipeline;
  var Xm = a.ZeroShotClassificationPipeline;
  var Jm = a.ZeroShotImageClassificationPipeline;
  var Ym = a.ZeroShotObjectDetectionPipeline;
  var Zm = a.bankers_round;
  var eh = a.cat;
  var th = a.cos_sim;
  var nh = a.dot;
  var rh = a.dynamic_time_warping;
  var sh = a.env;
  var ah = a.full;
  var oh = a.full_like;
  var ih = a.getCacheShapes;
  var lh = a.hamming;
  var dh = a.hanning;
  var uh = a.interpolate;
  var ch = a.interpolate_4d;
  var ph = a.interpolate_data;
  var mh = a.is_chinese_char;
  var hh = a.layer_norm;
  var fh = a.load_image;
  var _h = a.load_video;
  var gh = a.log_softmax;
  var wh = a.magnitude;
  var bh = a.matmul;
  var yh = a.max;
  var Mh = a.mean;
  var xh = a.mean_pooling;
  var vh = a.medianFilter;
  var Th = a.mel_filter_bank;
  var kh = a.min;
  var Ph = a.ones;
  var $h = a.ones_like;
  var Ch = a.permute;
  var Sh = a.permute_data;
  var Fh = a.pipeline;
  var Eh = a.quantize_embeddings;
  var Ih = a.rand;
  var Ah = a.randn;
  var zh = a.read_audio;
  var Lh = a.rfft;
  var Oh = a.round;
  var Dh = a.slice;
  var Bh = a.softmax;
  var Nh = a.spectrogram;
  var jh = a.stack;
  var Rh = a.std_mean;
  var Vh = a.topk;
  var Gh = a.window_function;
  var qh = a.zeros;
  var Uh = a.zeros_like;
  return __toCommonJS(transformers_min_exports);
})();
